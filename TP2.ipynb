{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "colab": {
   "name": "TP2.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "Uqupqkz4P4TN",
    "4ahhiflxP4aQ",
    "JJ2rufAJP4aj",
    "eUnKGaHyP4ay"
   ]
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "cnW5zDBVP4OH",
    "colab_type": "text"
   },
   "source": [
    "# 75.06/95.58 Organización de Datos\n",
    "# Primer Cuatrimestre de 2020\n",
    "# Trabajo Práctico 2: Enunciado\n",
    "\n",
    "\n",
    "El segundo TP es una competencia de Machine Learning en donde cada grupo debe intentar determinar, para cada tweet brindado, si el mismo esta basado en un hecho real o no.\n",
    "\n",
    "La competencia se desarrolla en la plataforma de Kaggle  https://www.kaggle.com/c/nlp-getting-started.  \n",
    "\n",
    "El dataset consta de una serie de tweets, para los cuales se informa:\n",
    "\n",
    "- id - identificador unico para cada  tweet\n",
    "- text - el texto del tweet\n",
    "- location - ubicación desde donde fue enviado (podría no estar)\n",
    "- keyword - un keyword para el tweet  (podría faltar)\n",
    "- target - en train.csv, indica si se trata de un desastre real  (1) o no (0)\n",
    " \n",
    "\n",
    "\n",
    "Los submits con el resultado deben tener el formato:\n",
    "\n",
    "Id: Un id numérico para identificar el tweet\n",
    "target: 1 / 0 según se crea que el tweet se trata sobre un desastre real, o no.\n",
    "\n",
    "Los grupos deberán probar distintos algoritmos de Machine Learning para intentar predecir si el tweet está basado en hechos reales o no. A medida que los grupos realicen pruebas deben realizar el correspondiente submit en Kaggle para evaluar el resultado de los mismos.\n",
    "\n",
    "Al finalizar la competencia el grupo que mejor resultado tenga obtendrá 10 puntos para cada uno de sus integrantes que podrán ser usados en el examen por promoción o segundo recuperatorio.\n",
    "\n",
    "## Requisitos para la entrega del TP2:\n",
    "\n",
    "- El TP debe programarse en Python o R.\n",
    "- Debe entregarse un pdf con el informe de algoritmos probados, algoritmo final utilizado, transformaciones realizadas a los datos, feature engineering, etc. \n",
    "- El informe debe incluir también un link a github con el informe presentado en pdf, y todo el código.\n",
    "- El grupo debe presentar el TP en una computadora en la fecha indicada por la cátedra, el TP debe correr en un lapso de tiempo razonable (inferior a 1 hora) y generar un submission válido que iguale el mejor resultado obtenido por el grupo en Kaggle. (mas detalles a definir)\n",
    "\n",
    "## El TP2 se va a evaluar en función del siguiente criterio:\n",
    "\n",
    "- Cantidad de trabajo (esfuerzo) del grupo: ¿Probaron muchos algoritmos? ¿Hicieron un buen trabajo de pre-procesamiento de los datos y feature engineering?\n",
    "- Resultado obtenido en Kaggle (obviamente cuanto mejor resultado mejor nota)\n",
    "- Presentación final del informe, calidad de la redacción, uso de información obtenida en el TP1, conclusiones presentadas.\n",
    "- Performance de la solución final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUk05Uz4P4OM",
    "colab_type": "text"
   },
   "source": [
    "## Forma de evaluar kaggle\n",
    "\n",
    "Las presentaciones se evalúan utilizando F1 entre las respuestas previstas y esperadas.\n",
    "\n",
    "F1 se calcula de la siguiente manera:\n",
    "\n",
    "$ F1=(2∗precision∗recall)/(precision+recall) $\n",
    "\n",
    "donde:\n",
    "\n",
    "$precision=TP/(TP+FP)$\n",
    "\n",
    "$recall=TP/(TP+FN)$\n",
    "\n",
    "\n",
    "con:\n",
    "\n",
    "- Verdadero positivo [TP] = your prediction is 1, and the ground truth is also 1 - you predicted a positive and that's true!\n",
    "- Falso positivo [FP] = your prediction is 1, and the ground truth is 0 - you predicted a positive, and that's false.\n",
    "- Falso Negativo [FN] = your prediction is 0, and the ground truth is 1 - you predicted a negative, and that's false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cSZFzd4P4OO",
    "colab_type": "text"
   },
   "source": [
    "importaciones"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false,
    "id": "cTwwakLTP4OQ",
    "colab_type": "code",
    "colab": {},
    "outputId": "19b808ba-8842-4da3-bba4-16cfe5b6326c"
   },
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import plotly.graph_objects as go\n",
    "\n",
    "#plt.style.use('default')\n",
    "from gensim.sklearn_api import tfidf\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import re\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "import math\n",
    "#librerias para KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#red neuronal\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "#arboles de decicion\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#catboost\n",
    "from catboost import CatBoostRegressor\n",
    "#xgb\n",
    "import xgboost as xgb\n",
    "\n",
    "#palabras\n",
    "import nltk\n",
    "#nltk.download('stopwords')#si no tiene stopword habilitar esta linea\n",
    "from nltk.corpus import stopwords\n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "#tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import lightgbm as lgb\n",
    "from copy import deepcopy"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false,
    "id": "zP138F79P4Oe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwordEnglis = stopwords.words('english')\n",
    "#tfidf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "import spacy\n",
    "# para activar este ultimo escribir en consola \"python -m spacy download en_core_web_sm\"\n",
    "from spacy.lang.fi import Finnish\n",
    "import en_core_web_sm"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQnVPpM3P4Om",
    "colab_type": "text"
   },
   "source": [
    "inicio de csv"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true,
    "id": "uMT4s9UHP4Oq",
    "colab_type": "code",
    "colab": {},
    "outputId": "1113f972-2aa3-4d46-f245-7d705d45888b"
   },
   "source": [
    "tweets_original_entrenamiento = pd.read_csv('train.csv',index_col=['id'])\n",
    "tweets_original_entrenamiento.head()"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword location                                               text  target\nid                                                                            \n1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true,
    "id": "Mwih-3cCP4O5",
    "colab_type": "code",
    "colab": {},
    "outputId": "6ae22e80-c4ef-48fa-8510-965f36fc6abb"
   },
   "source": [
    "tweets_original_prueba = pd.read_csv('test.csv',index_col=['id'])\n",
    "tweets_original_prueba.head()"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword location                                               text\nid                                                                    \n0      NaN      NaN                 Just happened a terrible car crash\n2      NaN      NaN  Heard about #earthquake is different cities, s...\n3      NaN      NaN  there is a forest fire at spot pond, geese are...\n9      NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2nw3BrZP4PH",
    "colab_type": "text"
   },
   "source": [
    "calculo resultado"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "lUrfCoA7P4PO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#resultados\n",
    "resultados_de_test = pd.read_csv('respuestas.csv',index_col=['id'])\n",
    "#revisar los resultados\n",
    "def calclarPresicionYRecall(df):\n",
    "    respuestas = pd.read_csv('respuestas.csv',index_col=['id'])\n",
    "    respuestas['prediccion'] = df['target']\n",
    "    #respuestas['TP'] = [1 if (respuestas['target'] == 1 and respuestas['prediccion'] == 1) else 0]\n",
    "    #respuestas['FP'] = [1 if (respuestas['target'] == 0 and respuestas['prediccion'] == 1) else 0]\n",
    "    #respuestas['FN'] = [1 if (respuestas['target'] == 1 and respuestas['prediccion'] == 0) else 0]\n",
    "    \n",
    "    respuestas.loc[respuestas['prediccion'] + respuestas['target'] == 2 , 'TP'] = 1\n",
    "    respuestas.loc[respuestas['prediccion'] + (respuestas['target'] * 2) == 1 , 'FP'] = 1\n",
    "    respuestas.loc[respuestas['prediccion'] + (respuestas['target'] * 2) == 2 , 'FN'] = 1\n",
    "    respuestas['TP'].fillna(0, inplace=True)\n",
    "    respuestas['FP'].fillna(0, inplace=True)\n",
    "    respuestas['FN'].fillna(0, inplace=True)\n",
    "\n",
    "    tp = respuestas['TP'].sum()\n",
    "    fp = respuestas['FP'].sum()\n",
    "    fn = respuestas['FN'].sum()\n",
    "    \n",
    "    #print(tp,fp,fn)\n",
    "    #print(respuestas.head())\n",
    "    \n",
    "    sumaPresicion = tp + fp\n",
    "    sumaRecall = tp + fn\n",
    "    presicion = tp / sumaPresicion\n",
    "    recall = tp / sumaRecall\n",
    "    return (presicion,recall)\n",
    "\n",
    "def F1(df):\n",
    "    presicion,recall = calclarPresicionYRecall(df)\n",
    "    resultado = 2 * presicion * recall\n",
    "    resultado /= (presicion + recall)\n",
    "    return resultado"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "A9u_TOh7P4Pa",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "def eliminarErrorDeValores(df):\n",
    "    df.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df.columns.values]\n",
    "    return df"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKGu5teHP4P1",
    "colab_type": "text"
   },
   "source": [
    "inicio de problema\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "QV7qjS2MP4P3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#esto deberia ahorrar columnas al hacer un BOW\n",
    "def digitos_en_binario(numero):\n",
    "    logaritmo2 = math.log2(numero)\n",
    "    entero = int(logaritmo2)\n",
    "    entero += 1\n",
    "    return entero\n",
    "\n",
    "def transformar_a_vector_binario(numero,digitos):\n",
    "    nBinario = aBinario(numero)\n",
    "    digit = len(nBinario)\n",
    "    while (digit < digitos):\n",
    "        digit = len(nBinario)\n",
    "        nBinario.insert(0,0)\n",
    "    return nBinario\n",
    "\n",
    "def aBinario(numero):\n",
    "    numeroDecimal = numero\n",
    "    numeroBinario = []\n",
    "    if (numeroDecimal < 2):\n",
    "        numeroBinario.append(numeroDecimal)\n",
    "        return numeroBinario\n",
    "    while numeroDecimal >=2:\n",
    "        numeroBinario.append(numeroDecimal % 2)\n",
    "        numeroDecimal //= 2\n",
    "    numeroBinario.append(numeroDecimal)\n",
    "    numeroBinario.reverse()\n",
    "    return numeroBinario\n",
    "\n",
    "#PRUEVA\n",
    "#if (digitos_en_binario(63) != 6):\n",
    "#    print(\"error en digitos_en_binario\")\n",
    "#bina = aBinario(64)\n",
    "#if (bina != 6 and bina[0] != 1 and bina[1] != 0 and bina[2] != 0 and bina[3] != 0 and bina[4] != 0 and bina[5] != 0):\n",
    "#    print(\"error en aBinario\")\n",
    "#print(transformar_a_vector_binario(64,8))\n",
    "#TODO OK"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "wsHvYu2wP4QF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\"\"\"\n",
    "vacio = 0000\n",
    "a = 0001\n",
    "b = 0010\n",
    "c = 0011\n",
    "d = 0100\n",
    "e = 0101\n",
    "f = 0110\n",
    "h = 0111\n",
    "r = 1000\n",
    "s = 1001\n",
    "t = 1010\n",
    "w = 1011\n",
    "\"\"\"\n",
    "LETRAS_0 = ['a','c','e','h','s','w']\n",
    "def letra0(x):\n",
    "    if (x in LETRAS_0):\n",
    "        return 1\n",
    "    return 0\n",
    "LETRAS_1 = ['b','c','f','h','t','w']\n",
    "def letra1(x):\n",
    "    if (x in LETRAS_1):\n",
    "        return 1\n",
    "    return 0\n",
    "LETRAS_2 = ['d','e','f','h']\n",
    "def letra2(x):\n",
    "    if (x in LETRAS_2):\n",
    "        return 1\n",
    "    return 0\n",
    "LETRAS_3 = ['r','s','t','w']\n",
    "def letra3(x):\n",
    "    if (x in LETRAS_3):\n",
    "        return 1\n",
    "    return 0\n",
    "def letra_inicial_Keyword_BOW(df):\n",
    "    #for i in range(0,4):\n",
    "    #    texto = 'letra_' + str(i)\n",
    "    #    df[texto] = 0\n",
    "    df['letra_0'] = 0\n",
    "    df['letra_1'] = 0\n",
    "    df['letra_2'] = 0\n",
    "    df['letra_3'] = 0\n",
    "    df['letra_0'] = df['keyword'].str.strip().str[0].map(lambda x:letra0(x))\n",
    "    df['letra_1'] = df['keyword'].str.strip().str[0].map(lambda x:letra0(x))\n",
    "    df['letra_2'] = df['keyword'].str.strip().str[0].map(lambda x:letra0(x))\n",
    "    df['letra_3'] = df['keyword'].str.strip().str[0].map(lambda x:letra0(x))\n",
    "    return df\n",
    "     "
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%   \n"
    },
    "id": "-dizShLTP4QK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "def set_palabras_del_train(df):\n",
    "    palabrasTexto = []\n",
    "    palabrasKeyword = []\n",
    "    \n",
    "    df['palabras_de_texto'] = df['text'].str.lower().str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    df['palabras_de_keyword'] = df['text'].str.lower().str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    \n",
    "    return (palabrasTexto,palabrasKeyword)\n",
    "\n",
    "def hashtag_en_tweet(listado):\n",
    "    \"\"\"defino hashtag como un numeral seguido por una cadena de texto\"\"\"\n",
    "    contador = 0\n",
    "    for palabra in listado:\n",
    "        if (palabra[0] == '#'):\n",
    "            contador += 1\n",
    "    return contador\n",
    "\n",
    "def cantidad_de_palabras_en_texto(lista,palabra):\n",
    "    contador = 0\n",
    "    for elemento in lista:\n",
    "        if (elemento == palabra):\n",
    "            contador += 1\n",
    "    return contador\n",
    "\n",
    "def localizacion(x,lista):\n",
    "    if (x == \"\"):\n",
    "        return 0\n",
    "    for i in range(len(lista)):\n",
    "        palabra = lista[i]\n",
    "        if (palabra == x):\n",
    "            return (i + 1)\n",
    "    return 0\n",
    "\n",
    "def ubicacionEnLista(x,pos):\n",
    "    return x[pos]\n",
    "\n",
    "def BOW_locacion(df,lista,columna):\n",
    "    cantidadDePalabras = len(lista)\n",
    "    if (cantidadDePalabras == 0):\n",
    "        return df\n",
    "    \n",
    "    binarioMaximo = cantidadDePalabras + 1\n",
    "    digitosBinario = digitos_en_binario(binarioMaximo)\n",
    "    \n",
    "    df[columna] = df[columna].map(lambda x: transformar_a_vector_binario(localizacion(x,lista),digitosBinario))\n",
    "    for j in range(digitosBinario):\n",
    "        df[\"{}_palabra_{}\".format(columna,j)] = df[columna].map(lambda x: ubicacionEnLista(x,j))\n",
    "    return df\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "P502XYWUP4QS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def eliminar_signos(texto):\n",
    "    palabra = \"\"\n",
    "    for caracter in texto:\n",
    "        if (caracter < 'a' or caracter > 'z'):\n",
    "            continue\n",
    "        palabra += caracter\n",
    "    return palabra"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%   \n",
     "is_executing": false
    },
    "id": "rY3vKoASP4QW",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def preparar_df(df,listadoDePalabrasDelTextoDelSetDeEntrenamiento=[],listadoDePalabrasDeLocalizacionesDelSetDeEntrenamiento=[],listadoDePalabrasDelKeywordDelSetDeEntrenamiento=[]):\n",
    "    df['text'].fillna(\"\", inplace=True)\n",
    "    df['keyword'].fillna(\"\", inplace=True)\n",
    "    df['location'].fillna(\"\", inplace=True)\n",
    "    \n",
    "    df['longitud_de_texto'] = df['text'].str.len()\n",
    "    df['longitud_de_keyword'] = df['keyword'].str.len()\n",
    "    \n",
    "    df['palabras_de_texto'] = df['text'].str.lower().str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    df['palabras_de_keyword'] = df['keyword'].str.lower().str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    \n",
    "    df['cantidad_de_palabras_texto'] = df['palabras_de_texto'].map(len)\n",
    "    df['cantidad_de_palabras_keyword'] = df['palabras_de_keyword'].map(len)\n",
    "    \n",
    "    df['cantidad_de_hashtag_en_texto'] = df['palabras_de_texto'].map(hashtag_en_tweet)\n",
    "    \n",
    "    df['palabras_de_texto'] = df['palabras_de_texto'].apply(lambda x: [item for item in x if item in listadoDePalabrasDelTextoDelSetDeEntrenamiento])\n",
    "    #df['palabras_de_keyword'] = df['palabras_de_keyword'].apply(lambda x: [item for item in x if item in listadoDePalabrasDelKeywordDelSetDeEntrenamiento])\n",
    "    \n",
    "    df = letra_inicial_Keyword_BOW(df)\n",
    "    \n",
    "    df['palabras_de_texto'] = df['palabras_de_texto'].apply(lambda x: [eliminar_signos(item) for item in x])\n",
    "    \n",
    "    for palabra in listadoDePalabrasDelTextoDelSetDeEntrenamiento:\n",
    "        df[palabra] = df['palabras_de_texto'].map(lambda x: cantidad_de_palabras_en_texto(x,palabra))\n",
    "    \n",
    "    df = BOW_locacion(df,listadoDePalabrasDeLocalizacionesDelSetDeEntrenamiento,'location')\n",
    "    df = BOW_locacion(df,listadoDePalabrasDelKeywordDelSetDeEntrenamiento,'keyword')\n",
    "    \n",
    "    df['longitud_de_texto_sin_signos'] = df['text'].map(eliminar_signos).str.len()\n",
    "    \n",
    "    #df['text'] = df['text'].str.replace(r' ', '')\n",
    "    #df['keyword'] = df['keyword'].str.replace(r' ', '')\n",
    "    #df['location'] = df['location'].str.replace(r' ', '')\n",
    "    \n",
    "    #TF-IDF\n",
    "    #x = TfidfVectorizer.fit_transform(df['palabras_de_texto'])\n",
    "    #df_tfidf = pd.DataFrame(x.toarray(), columns=tfidf.get_feature_names())\n",
    "    #for col in df_tfidf.columns():\n",
    "    #    df = df.join(df_tfidf[col])\n",
    "    #df.join(df_tfidf)#mal planteado\n",
    "    \n",
    "    df = df.drop(columns=['id','keyword','text','location'])\n",
    "    df = df.drop(columns=['palabras_de_texto','palabras_de_keyword'])\n",
    "    \n",
    "    return df"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "kXZxH2xEP4Qg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def extraer_palabras(serie):\n",
    "    URL_INICIO = \"http\"\n",
    "    lista = []\n",
    "    #dic = {}\n",
    "    for listado in serie:\n",
    "        for elemento in listado:\n",
    "            palabra = eliminar_signos(elemento)\n",
    "            #la mayoria de las palabras en ingles tienen una esperansa de 4.8773 caracteres con varianza de 2.6171\n",
    "            longitud = len(palabra)\n",
    "            #simbolos = ('0','1','2','3','4','5','6','7','8','9','#','/','','\"','@',';','?','[','(','{','.','!','$','&','*','-')\n",
    "            #if (palabra in lista or longitud > 7 or longitud < 2 or palabra[0] in simbolos or palabra[-1] in simbolos or palabra[:4] == URL_INICIO):\n",
    "            if (palabra in lista or longitud < 2 or palabra[:4] == URL_INICIO or palabra in stopwordEnglis):\n",
    "                continue\n",
    "            lista.append(elemento)\n",
    "    #resultado = []\n",
    "    #max = 0\n",
    "    #for palabra in lista:\n",
    "    #    max = dic[palabra]\n",
    "    #    if (dic[palabra] < 800):\n",
    "    #        continue\n",
    "    #    resultado.append(palabra)\n",
    "    return lista\n",
    "\n",
    "def generar_lista(x,lista):\n",
    "    if (x in lista or x == \"\"):\n",
    "        return\n",
    "    lista.append(x)\n",
    "    return"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "QdY87ZcMP4Qt",
    "colab_type": "text"
   },
   "source": [
    "ABRO LOS SETS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "XBf4BADeP4Qw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#train\n",
    "train_label = tweets_original_entrenamiento['target']\n",
    "train_set = deepcopy(tweets_original_entrenamiento)\n",
    "train_set = train_set.drop(columns=['target'])\n",
    "#test\n",
    "test_set = deepcopy(tweets_original_prueba)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "VZ-uZAaSP4Q4",
    "colab_type": "text"
   },
   "source": [
    "PROCESADO DE SET"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "uyA94YKvP4Q6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def listadoDeElementos(df1,df2,columna):\n",
    "    df1[columna].fillna(\"\", inplace=True)\n",
    "    df2[columna].fillna(\"\", inplace=True)\n",
    "    seriePalabrasDf1 = df1[columna].str.lower().str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    listadoDePalabrasDelDf1 = extraer_palabras(seriePalabrasDf1)\n",
    "    seriePalabrasDf2 = df2[columna].str.lower().str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    listadoDePalabrasDelDf2 = extraer_palabras(seriePalabrasDf2)\n",
    "    lista_final = {}\n",
    "    for elem in listadoDePalabrasDelDf1:\n",
    "        elemento = eliminar_signos(elem)\n",
    "        if (not elemento in listadoDePalabrasDelDf2):\n",
    "            continue\n",
    "        if (elemento in lista_final.keys()):\n",
    "            lista_final[elemento] += 1\n",
    "        else:\n",
    "            lista_final[elemento] = 1\n",
    "    \n",
    "    listadoDePalabras = []\n",
    "    for clave in lista_final.keys():\n",
    "        if (lista_final[clave] <= 1):\n",
    "            continue\n",
    "        listadoDePalabras.append(clave)\n",
    "    \n",
    "    print(len(listadoDePalabras))\n",
    "    return listadoDePalabras"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "N8fILtGAP4RB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def fusionarTextoConKeyword(df1,df2):\n",
    "    df1['text'] = df1['text'] + df1['keyword']\n",
    "    df2['text'] = df2['text'] + df2['keyword']\n",
    "    return df1,df2\n",
    "train_set,test_set = fusionarTextoConKeyword(train_set,test_set)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "m6FksubPP4RF",
    "colab_type": "code",
    "colab": {},
    "outputId": "a49aa3c1-b07e-4ef4-a524-76a5f60cbfbf"
   },
   "source": [
    "#Recordar esta celda debe ser activada despues de abrir los sets si no lanza error\n",
    "listadoDePalabrasDelTexto = listadoDeElementos(train_set,test_set,'text')"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "499\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "pYdbEFeBP4RM",
    "colab_type": "code",
    "colab": {},
    "outputId": "99cb0105-54ef-4c68-bbcd-86ba3676b1ca"
   },
   "source": [
    "listadoDePalabrasDeLocalizacionesDelSetDeEntrenamiento = listadoDeElementos(train_set,test_set,'location')"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "111\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "4HHcapSGP4RT",
    "colab_type": "code",
    "colab": {},
    "outputId": "fd0f460c-eddf-423e-f198-2757c3ba8651"
   },
   "source": [
    "listadoDePalabrasDelKeywordDelSetDeEntrenamiento = listadoDeElementos(train_set,test_set,'keyword')"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "WRhOfGqfP4Ra",
    "colab_type": "code",
    "colab": {},
    "outputId": "ed3ad597-4ce3-4b1d-fa67-5948f6d6eb34"
   },
   "source": [
    "#train_set = preparar_df(train_set,listadoDePalabrasDelTextoDelSetDeEntrenamiento,listadoDePalabrasDeLocalizacionesDelSetDeEntrenamiento,listadoDePalabrasDelKeywordDelSetDeEntrenamiento)\n",
    "train_set = preparar_df(train_set,listadoDePalabrasDelTexto,listadoDePalabrasDeLocalizacionesDelSetDeEntrenamiento,listadoDePalabrasDelKeywordDelSetDeEntrenamiento)\n",
    "train_set.head()"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "    longitud_de_texto  longitud_de_keyword  cantidad_de_palabras_texto  \\\nid                                                                       \n1                   0                    0                           0   \n4                   0                    0                           0   \n5                   0                    0                           0   \n6                   0                    0                           0   \n7                   0                    0                           0   \n\n    cantidad_de_palabras_keyword  cantidad_de_hashtag_en_texto  letra_0  \\\nid                                                                        \n1                              0                             0        0   \n4                              0                             0        0   \n5                              0                             0        0   \n6                              0                             0        0   \n7                              0                             0        0   \n\n    letra_1  letra_2  letra_3  heavy  ...  pa  conclusively  \\\nid                                    ...                     \n1         0        0        0      0  ...   0             0   \n4         0        0        0      0  ...   0             0   \n5         0        0        0      0  ...   0             0   \n6         0        0        0      0  ...   0             0   \n7         0        0        0      0  ...   0             0   \n\n    location_palabra_0  location_palabra_1  location_palabra_2  \\\nid                                                               \n1                    0                   0                   0   \n4                    0                   0                   0   \n5                    0                   0                   0   \n6                    0                   0                   0   \n7                    0                   0                   0   \n\n    location_palabra_3  location_palabra_4  location_palabra_5  \\\nid                                                               \n1                    0                   0                   0   \n4                    0                   0                   0   \n5                    0                   0                   0   \n6                    0                   0                   0   \n7                    0                   0                   0   \n\n    location_palabra_6  longitud_de_texto_sin_signos  \nid                                                    \n1                    0                             0  \n4                    0                             0  \n5                    0                             0  \n6                    0                             0  \n7                    0                             0  \n\n[5 rows x 515 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitud_de_texto</th>\n      <th>longitud_de_keyword</th>\n      <th>cantidad_de_palabras_texto</th>\n      <th>cantidad_de_palabras_keyword</th>\n      <th>cantidad_de_hashtag_en_texto</th>\n      <th>letra_0</th>\n      <th>letra_1</th>\n      <th>letra_2</th>\n      <th>letra_3</th>\n      <th>heavy</th>\n      <th>...</th>\n      <th>pa</th>\n      <th>conclusively</th>\n      <th>location_palabra_0</th>\n      <th>location_palabra_1</th>\n      <th>location_palabra_2</th>\n      <th>location_palabra_3</th>\n      <th>location_palabra_4</th>\n      <th>location_palabra_5</th>\n      <th>location_palabra_6</th>\n      <th>longitud_de_texto_sin_signos</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 515 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "tBp93kdSP4Rf",
    "colab_type": "code",
    "colab": {},
    "outputId": "310e98e8-ae2f-4309-fa8e-a6ae43d81687"
   },
   "source": [
    "#test_set = preparar_df(test_set,listadoDePalabrasDelTextoDelSetDeEntrenamiento,listadoDePalabrasDeLocalizacionesDelSetDeEntrenamiento,listadoDePalabrasDelKeywordDelSetDeEntrenamiento)\n",
    "test_set = preparar_df(test_set,listadoDePalabrasDelTexto,listadoDePalabrasDeLocalizacionesDelSetDeEntrenamiento,listadoDePalabrasDelKeywordDelSetDeEntrenamiento)\n",
    "test_set.head()"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "    longitud_de_texto  longitud_de_keyword  cantidad_de_palabras_texto  \\\nid                                                                       \n0                   0                    0                           0   \n2                   0                    0                           0   \n3                   0                    0                           0   \n9                   0                    0                           0   \n11                  0                    0                           0   \n\n    cantidad_de_palabras_keyword  cantidad_de_hashtag_en_texto  letra_0  \\\nid                                                                        \n0                              0                             0        0   \n2                              0                             0        0   \n3                              0                             0        0   \n9                              0                             0        0   \n11                             0                             0        0   \n\n    letra_1  letra_2  letra_3  heavy  ...  pa  conclusively  \\\nid                                    ...                     \n0         0        0        0      0  ...   0             0   \n2         0        0        0      0  ...   0             0   \n3         0        0        0      0  ...   0             0   \n9         0        0        0      0  ...   0             0   \n11        0        0        0      0  ...   0             0   \n\n    location_palabra_0  location_palabra_1  location_palabra_2  \\\nid                                                               \n0                    0                   0                   0   \n2                    0                   0                   0   \n3                    0                   0                   0   \n9                    0                   0                   0   \n11                   0                   0                   0   \n\n    location_palabra_3  location_palabra_4  location_palabra_5  \\\nid                                                               \n0                    0                   0                   0   \n2                    0                   0                   0   \n3                    0                   0                   0   \n9                    0                   0                   0   \n11                   0                   0                   0   \n\n    location_palabra_6  longitud_de_texto_sin_signos  \nid                                                    \n0                    0                             0  \n2                    0                             0  \n3                    0                             0  \n9                    0                             0  \n11                   0                             0  \n\n[5 rows x 515 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitud_de_texto</th>\n      <th>longitud_de_keyword</th>\n      <th>cantidad_de_palabras_texto</th>\n      <th>cantidad_de_palabras_keyword</th>\n      <th>cantidad_de_hashtag_en_texto</th>\n      <th>letra_0</th>\n      <th>letra_1</th>\n      <th>letra_2</th>\n      <th>letra_3</th>\n      <th>heavy</th>\n      <th>...</th>\n      <th>pa</th>\n      <th>conclusively</th>\n      <th>location_palabra_0</th>\n      <th>location_palabra_1</th>\n      <th>location_palabra_2</th>\n      <th>location_palabra_3</th>\n      <th>location_palabra_4</th>\n      <th>location_palabra_5</th>\n      <th>location_palabra_6</th>\n      <th>longitud_de_texto_sin_signos</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 515 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "ntmVXuJMP4Rm",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#SOLO USAR SI SE SOSPECHA DE ERROR EN PROCESAMIENTO DE DATOS (si existen str en las columnas)\n",
    "def verificador_de_contenido_string_en_columnas():\n",
    "    for n in test_set.columns:\n",
    "        try:\n",
    "            #test_set[n] = pd.to_numeric(test_set[n])\n",
    "            test_set[n].astype(int)\n",
    "        except:\n",
    "            print(n)\n",
    "    for n in train_set.columns:\n",
    "        try:\n",
    "            #train_set[n] = pd.to_numeric(train_set[n])\n",
    "            train_set[n].astype(int)\n",
    "        except:\n",
    "            print(n)\n",
    "\n",
    "def verificador_de_columnas():#NO USAR por algun motivo falla en su funcion\n",
    "    colTest = test_set.columns\n",
    "    colTrain = train_set.columns\n",
    "    print(colTest)\n",
    "    print(colTrain)\n",
    "    if (len(colTest) != len(colTrain)):\n",
    "        print(\"Error en cantidad de columnas\")\n",
    "    for n in colTest:\n",
    "        try:\n",
    "            colTrain[n]\n",
    "        except:\n",
    "            print(\"error de nombre de columna\",n)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "4Ar55-lEP4Rs",
    "colab_type": "code",
    "colab": {},
    "outputId": "48b0ea38-1b7e-4391-c45e-30bfe6a2d6a5"
   },
   "source": [
    "def verificador_de_valoracion_de_columnas(df):\n",
    "    nulas = []\n",
    "    colum = df.columns \n",
    "    contador = 0\n",
    "    for col in colum:\n",
    "        if (test_set[col].sum() > 0):\n",
    "            continue\n",
    "        contador += 1\n",
    "        nulas.append(col)\n",
    "        #print(col)\n",
    "    print(\"columnas en cero: \",contador)\n",
    "    return nulas\n",
    "print(\"test set\")\n",
    "n1 = verificador_de_valoracion_de_columnas(test_set)\n",
    "print(\"train set\")\n",
    "n2 = verificador_de_valoracion_de_columnas(train_set)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "test set\ncolumnas en cero:  0\ntrain set\ncolumnas en cero:  0\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    },
    "id": "C9eq4dCBP4R0",
    "colab_type": "code",
    "colab": {},
    "outputId": "6edbd319-7c5f-4d6a-9922-a3fd2a2e8c03"
   },
   "source": [
    "def desacerse_de_columnasNulas_en_comun(df1,df2,l1,l2):\n",
    "    colABorrar = []\n",
    "    for elemento in l1:\n",
    "        if (not elemento in l2):\n",
    "            continue\n",
    "        colABorrar.append(elemento)\n",
    "    print(colABorrar)\n",
    "    df1 = df1.drop(columns=colABorrar)\n",
    "    df2 = df2.drop(columns=colABorrar)\n",
    "    return df1,df2\n",
    "if (n1 != 0 and n2 != 0):\n",
    "    train_set,test_set = desacerse_de_columnasNulas_en_comun(train_set,test_set,n1,n2)"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['location_palabra_1', 'location_palabra_4']\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "IXRRaDyxP4R8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def ensamble(df,n,prediccion,desplazamiento=0):\n",
    "    #-0.5 < desplazamiento < 0.5\n",
    "    prediccion += desplazamiento\n",
    "    df['target'] = df['target'] + prediccion.round()\n",
    "    n += 1\n",
    "    return (n,df)\n",
    "\n",
    "def calcular_resultado_de_prediccion(df,n):\n",
    "    \"\"\"para ensambles redondeados\"\"\"\n",
    "    df['target'] = df['target'].div(n).round()\n",
    "    return df\n",
    "\n",
    "def calcular_resultado_de_prediccion_segun_norma(df,n):\n",
    "    \"\"\"para ensambles sin redondeo\"\"\"\n",
    "    num = n**0.5\n",
    "    df['target'] = df['target'].div(num).round()\n",
    "    return df"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "4S-vxiYTP4S9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def busqueda_binaria_de_maximos(listasDeParametros,nParametros,n=0,funcion=None):\n",
    "    if (n == len(listasDeParametros)):\n",
    "        parametros = []\n",
    "        for i in range(n):\n",
    "            parametros.append(listasDeParametros[i][nParametros[i]])\n",
    "        print(parametros)\n",
    "        #return ultimo_Hiper_Parametro_catboost(parametros),parametros\n",
    "        return funcion(parametros),parametros\n",
    "    \n",
    "    posIzq = 0\n",
    "    posDer = len(listasDeParametros[n])-1\n",
    "    \n",
    "    nParametros[n] = posIzq\n",
    "    izq,parametrosOptimos = busqueda_binaria_de_maximos(listasDeParametros,nParametros,n+1,funcion)\n",
    "    \n",
    "    nParametros[n] = posDer\n",
    "    der,parametrosOptimos = busqueda_binaria_de_maximos(listasDeParametros,nParametros,n+1,funcion)\n",
    "    \n",
    "    while posIzq <= posDer:\n",
    "        posMedio = (posIzq+posDer)//2\n",
    "\n",
    "        if (posDer - posIzq <= 1):\n",
    "            if (izq > der):\n",
    "                return izq,parametrosOptimos\n",
    "            return der,parametrosOptimos\n",
    "\n",
    "        elif izq > der:\n",
    "            posDer = posMedio\n",
    "            nParametros[n] = posDer\n",
    "            der,parametrosOptimos = busqueda_binaria_de_maximos(listasDeParametros,nParametros,n+1,funcion)\n",
    "    \n",
    "        else:\n",
    "            posIzq = posMedio\n",
    "            nParametros[n] = posIzq\n",
    "            izq,parametrosOptimos = busqueda_binaria_de_maximos(listasDeParametros,nParametros,n+1,funcion)\n",
    "        \n",
    "    return -1,[-1]\n",
    "\n",
    "def ultimo_Hiper_Parametro_catboost(parametros):\n",
    "    # Initialize CatBoostRegressor\n",
    "    model = CatBoostRegressor(iterations=parametros[0],\n",
    "                              learning_rate=parametros[1],\n",
    "                              depth=parametros[2])\n",
    "    # Fit model\n",
    "    model.fit(train_set, train_label)\n",
    "    # Get predictions\n",
    "    predicion = model.predict(test_set)\n",
    "    \n",
    "    ######verificacion de hiperparamentros\n",
    "    resultados_de_prediccion = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "    cantidadDePredicciones,resultados_de_prediccion = ensamble(resultados_de_prediccion,0,predicion,parametros[3])\n",
    "    maximo_local = F1(resultados_de_prediccion)\n",
    "    return maximo_local\n",
    "\n",
    "def ultimo_Hiper_Parametro_XGBoost(parametros):\n",
    "    xgb_reg = xgb.XGBRegressor(max_depth = parametros[0], \n",
    "                               colsample_bytree = parametros[1], \n",
    "                               learning_rate = parametros[2], \n",
    "                               alpha = parametros[3],\n",
    "                               objetive = 'reg:squarederror')\n",
    "    \n",
    "    xgb_reg.fit(train_set, train_label)\n",
    "\n",
    "    ######verificacion de hiperparamentros\n",
    "    resultados_de_prediccion = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "    predicts = xgb_reg.predict(test_set).round()\n",
    "    resultados_de_prediccion['target'] = predicts\n",
    "    maximo_local = F1(resultados_de_prediccion)\n",
    "    return maximo_local\n",
    "\n",
    "def ultimo_Hiper_Parametro_Ramdom_forest(parametros):\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=parametros[0],\n",
    "                               n_estimators = parametros[1],\n",
    "                               max_features = parametros[2],\n",
    "                               max_depth =parametros[3],\n",
    "                               min_samples_split=parametros[4])\n",
    "    rf.fit(train_set, train_label)\n",
    "\n",
    "    ######verificacion de hiperparamentros\n",
    "    resultados_de_prediccion = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "    predicts = rf.predict(test_set).round()\n",
    "    resultados_de_prediccion['target'] = predicts\n",
    "    maximo_local = F1(resultados_de_prediccion)\n",
    "    return maximo_local\n",
    "\n",
    "def ultimo_Hiper_Parametro_LigthBM(parametros):\n",
    "    \n",
    "    lgb_train = lgb.Dataset(train_set, train_label)\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "    }\n",
    "    \n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    valid_sets = lgb_train,\n",
    "                    num_boost_round=parametros[0],\n",
    "                    early_stopping_rounds=parametros[1])\n",
    "\n",
    "    ######verificacion de hiperparamentros\n",
    "    resultados_de_prediccion = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "    predicts = gbm.predict(test_set, num_iteration=gbm.best_iteration)\n",
    "    predicts += parametros[2]\n",
    "    predicts = predicts.round()\n",
    "    resultados_de_prediccion['target'] = predicts\n",
    "    maximo_local = F1(resultados_de_prediccion)\n",
    "    return maximo_local"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Uqupqkz4P4TN",
    "colab_type": "text"
   },
   "source": [
    "## CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "NCuyyDrRP4TO",
    "colab_type": "code",
    "colab": {},
    "outputId": "cc993fc1-84d8-48e9-91e9-050939932a53"
   },
   "source": [
    "#los rangos se van afinando segun corren las pruevas\n",
    "def busqueda_de_hiperparametros_optimos_catboost_busqueda_binaria():\n",
    "    parametrosCatboostIter = list(range(3,11,1))\n",
    "    parametrosCatboostLR = list(range(30,81,1))\n",
    "    for i in range(len(parametrosCatboostLR)):\n",
    "        parametrosCatboostLR[i] /= 100\n",
    "    parametrosCatboostProfundidad = list(range(6,16,1))\n",
    "    parametrosDesviacion = list(range(-30,31,5))\n",
    "    for i in range(len(parametrosDesviacion)):\n",
    "        parametrosDesviacion[i] /= 100\n",
    "    listaDeParametros = [parametrosCatboostIter,parametrosCatboostLR,parametrosCatboostProfundidad,parametrosDesviacion]\n",
    "    maximo,parametros =busqueda_binaria_de_maximos(listaDeParametros,\n",
    "                                                   [0,0,0,0],\n",
    "                                                   0,\n",
    "                                                   ultimo_Hiper_Parametro_catboost)\n",
    "    print(\"maximo {} parametros (iter,learning,profundidad,desplazamiento) {}\".format(maximo,parametros))\n",
    "busqueda_de_hiperparametros_optimos_catboost_busqueda_binaria()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[3, 0.3, 6, -0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 4.62ms\tremaining: 9.24ms\n",
      "1:\tlearn: 0.4796834\ttotal: 8.49ms\tremaining: 4.25ms\n",
      "2:\tlearn: 0.4757652\ttotal: 12.3ms\tremaining: 0us\n",
      "[3, 0.3, 6, 0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 8.27ms\tremaining: 16.5ms\n",
      "1:\tlearn: 0.4796834\ttotal: 12.6ms\tremaining: 6.29ms\n",
      "2:\tlearn: 0.4757652\ttotal: 16.7ms\tremaining: 0us\n",
      "[3, 0.3, 6, 0.0]\n",
      "0:\tlearn: 0.4852609\ttotal: 3.97ms\tremaining: 7.94ms\n",
      "1:\tlearn: 0.4796834\ttotal: 7.87ms\tremaining: 3.93ms\n",
      "2:\tlearn: 0.4757652\ttotal: 11.7ms\tremaining: 0us\n",
      "[3, 0.3, 6, 0.15]\n",
      "0:\tlearn: 0.4852609\ttotal: 9.47ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.4796834\ttotal: 18.9ms\tremaining: 9.47ms\n",
      "2:\tlearn: 0.4757652\ttotal: 36.7ms\tremaining: 0us\n",
      "[3, 0.3, 6, 0.2]\n",
      "0:\tlearn: 0.4852609\ttotal: 4.01ms\tremaining: 8.02ms\n",
      "1:\tlearn: 0.4796834\ttotal: 7.78ms\tremaining: 3.89ms\n",
      "2:\tlearn: 0.4757652\ttotal: 11.7ms\tremaining: 0us\n",
      "[3, 0.3, 15, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 22.2ms\tremaining: 44.4ms\n",
      "1:\tlearn: 0.4769595\ttotal: 527ms\tremaining: 264ms\n",
      "2:\tlearn: 0.4714456\ttotal: 994ms\tremaining: 0us\n",
      "[3, 0.3, 15, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 13.2ms\tremaining: 26.3ms\n",
      "1:\tlearn: 0.4769595\ttotal: 504ms\tremaining: 252ms\n",
      "2:\tlearn: 0.4714456\ttotal: 1.03s\tremaining: 0us\n",
      "[3, 0.3, 15, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 13.5ms\tremaining: 27ms\n",
      "1:\tlearn: 0.4769595\ttotal: 521ms\tremaining: 260ms\n",
      "2:\tlearn: 0.4714456\ttotal: 999ms\tremaining: 0us\n",
      "[3, 0.3, 15, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.87ms\tremaining: 19.7ms\n",
      "1:\tlearn: 0.4769595\ttotal: 498ms\tremaining: 249ms\n",
      "2:\tlearn: 0.4714456\ttotal: 953ms\tremaining: 0us\n",
      "[3, 0.3, 15, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.67ms\tremaining: 19.3ms\n",
      "1:\tlearn: 0.4769595\ttotal: 490ms\tremaining: 245ms\n",
      "2:\tlearn: 0.4714456\ttotal: 965ms\tremaining: 0us\n",
      "[3, 0.3, 10, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 15.9ms\tremaining: 31.8ms\n",
      "1:\tlearn: 0.4786840\ttotal: 32.5ms\tremaining: 16.2ms\n",
      "2:\tlearn: 0.4743082\ttotal: 47.6ms\tremaining: 0us\n",
      "[3, 0.3, 10, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.6ms\tremaining: 21.3ms\n",
      "1:\tlearn: 0.4786840\ttotal: 44.3ms\tremaining: 22.2ms\n",
      "2:\tlearn: 0.4743082\ttotal: 94.5ms\tremaining: 0us\n",
      "[3, 0.3, 10, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.23ms\tremaining: 18.5ms\n",
      "1:\tlearn: 0.4786840\ttotal: 23.5ms\tremaining: 11.8ms\n",
      "2:\tlearn: 0.4743082\ttotal: 38.4ms\tremaining: 0us\n",
      "[3, 0.3, 10, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.69ms\tremaining: 19.4ms\n",
      "1:\tlearn: 0.4786840\ttotal: 25ms\tremaining: 12.5ms\n",
      "2:\tlearn: 0.4743082\ttotal: 65.9ms\tremaining: 0us\n",
      "[3, 0.3, 10, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.81ms\tremaining: 17.6ms\n",
      "1:\tlearn: 0.4786840\ttotal: 23.9ms\tremaining: 12ms\n",
      "2:\tlearn: 0.4743082\ttotal: 41.3ms\tremaining: 0us\n",
      "[3, 0.3, 12, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.67ms\tremaining: 19.3ms\n",
      "1:\tlearn: 0.4778843\ttotal: 99.4ms\tremaining: 49.7ms\n",
      "2:\tlearn: 0.4738999\ttotal: 197ms\tremaining: 0us\n",
      "[3, 0.3, 12, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.49ms\tremaining: 19ms\n",
      "1:\tlearn: 0.4778843\ttotal: 69.5ms\tremaining: 34.8ms\n",
      "2:\tlearn: 0.4738999\ttotal: 128ms\tremaining: 0us\n",
      "[3, 0.3, 12, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.55ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4778843\ttotal: 64.1ms\tremaining: 32ms\n",
      "2:\tlearn: 0.4738999\ttotal: 117ms\tremaining: 0us\n",
      "[3, 0.3, 12, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.5ms\tremaining: 21ms\n",
      "1:\tlearn: 0.4778843\ttotal: 65ms\tremaining: 32.5ms\n",
      "2:\tlearn: 0.4738999\ttotal: 117ms\tremaining: 0us\n",
      "[3, 0.3, 12, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 14.8ms\tremaining: 29.6ms\n",
      "1:\tlearn: 0.4778843\ttotal: 158ms\tremaining: 79.1ms\n",
      "2:\tlearn: 0.4738999\ttotal: 218ms\tremaining: 0us\n",
      "[3, 0.3, 13, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.6ms\tremaining: 21.1ms\n",
      "1:\tlearn: 0.4776303\ttotal: 120ms\tremaining: 60.1ms\n",
      "2:\tlearn: 0.4735011\ttotal: 222ms\tremaining: 0us\n",
      "[3, 0.3, 13, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 16ms\tremaining: 32ms\n",
      "1:\tlearn: 0.4776303\ttotal: 127ms\tremaining: 63.6ms\n",
      "2:\tlearn: 0.4735011\ttotal: 228ms\tremaining: 0us\n",
      "[3, 0.3, 13, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.55ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4776303\ttotal: 114ms\tremaining: 57.1ms\n",
      "2:\tlearn: 0.4735011\ttotal: 221ms\tremaining: 0us\n",
      "[3, 0.3, 13, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.3ms\tremaining: 20.5ms\n",
      "1:\tlearn: 0.4776303\ttotal: 113ms\tremaining: 56.5ms\n",
      "2:\tlearn: 0.4735011\ttotal: 215ms\tremaining: 0us\n",
      "[3, 0.3, 13, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.88ms\tremaining: 17.8ms\n",
      "1:\tlearn: 0.4776303\ttotal: 114ms\tremaining: 56.8ms\n",
      "2:\tlearn: 0.4735011\ttotal: 215ms\tremaining: 0us\n",
      "[3, 0.3, 14, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.5ms\tremaining: 20.9ms\n",
      "1:\tlearn: 0.4773298\ttotal: 217ms\tremaining: 108ms\n",
      "2:\tlearn: 0.4728931\ttotal: 525ms\tremaining: 0us\n",
      "[3, 0.3, 14, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.45ms\tremaining: 16.9ms\n",
      "1:\tlearn: 0.4773298\ttotal: 231ms\tremaining: 116ms\n",
      "2:\tlearn: 0.4728931\ttotal: 487ms\tremaining: 0us\n",
      "[3, 0.3, 14, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.91ms\tremaining: 17.8ms\n",
      "1:\tlearn: 0.4773298\ttotal: 288ms\tremaining: 144ms\n",
      "2:\tlearn: 0.4728931\ttotal: 496ms\tremaining: 0us\n",
      "[3, 0.3, 14, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.19ms\tremaining: 18.4ms\n",
      "1:\tlearn: 0.4773298\ttotal: 224ms\tremaining: 112ms\n",
      "2:\tlearn: 0.4728931\ttotal: 530ms\tremaining: 0us\n",
      "[3, 0.3, 14, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.29ms\tremaining: 16.6ms\n",
      "1:\tlearn: 0.4773298\ttotal: 310ms\tremaining: 155ms\n",
      "2:\tlearn: 0.4728931\ttotal: 645ms\tremaining: 0us\n",
      "[3, 0.8, 6, -0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.28ms\tremaining: 8.55ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.78ms\tremaining: 4.39ms\n",
      "2:\tlearn: 0.4667365\ttotal: 13.1ms\tremaining: 0us\n",
      "[3, 0.8, 6, 0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.65ms\tremaining: 9.3ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.49ms\tremaining: 4.24ms\n",
      "2:\tlearn: 0.4667365\ttotal: 12.3ms\tremaining: 0us\n",
      "[3, 0.8, 6, 0.0]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.63ms\tremaining: 9.26ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.9ms\tremaining: 4.45ms\n",
      "2:\tlearn: 0.4667365\ttotal: 12.9ms\tremaining: 0us\n",
      "[3, 0.8, 6, 0.15]\n",
      "0:\tlearn: 0.4762695\ttotal: 3.81ms\tremaining: 7.61ms\n",
      "1:\tlearn: 0.4707614\ttotal: 7.75ms\tremaining: 3.88ms\n",
      "2:\tlearn: 0.4667365\ttotal: 11.5ms\tremaining: 0us\n",
      "[3, 0.8, 6, 0.2]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.23ms\tremaining: 8.45ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.58ms\tremaining: 4.29ms\n",
      "2:\tlearn: 0.4667365\ttotal: 14.3ms\tremaining: 0us\n",
      "[3, 0.8, 15, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.44ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.4658921\ttotal: 513ms\tremaining: 257ms\n",
      "2:\tlearn: 0.4614984\ttotal: 975ms\tremaining: 0us\n",
      "[3, 0.8, 15, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.21ms\tremaining: 16.4ms\n",
      "1:\tlearn: 0.4658921\ttotal: 498ms\tremaining: 249ms\n",
      "2:\tlearn: 0.4614984\ttotal: 1.07s\tremaining: 0us\n",
      "[3, 0.8, 15, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.2ms\tremaining: 24.4ms\n",
      "1:\tlearn: 0.4658921\ttotal: 578ms\tremaining: 289ms\n",
      "2:\tlearn: 0.4614984\ttotal: 1.22s\tremaining: 0us\n",
      "[3, 0.8, 15, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.5ms\tremaining: 23.1ms\n",
      "1:\tlearn: 0.4658921\ttotal: 514ms\tremaining: 257ms\n",
      "2:\tlearn: 0.4614984\ttotal: 982ms\tremaining: 0us\n",
      "[3, 0.8, 15, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.1ms\tremaining: 22.2ms\n",
      "1:\tlearn: 0.4658921\ttotal: 515ms\tremaining: 257ms\n",
      "2:\tlearn: 0.4614984\ttotal: 1.05s\tremaining: 0us\n",
      "[3, 0.8, 10, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.8ms\tremaining: 25.5ms\n",
      "1:\tlearn: 0.4684354\ttotal: 31.5ms\tremaining: 15.8ms\n",
      "2:\tlearn: 0.4642800\ttotal: 52.3ms\tremaining: 0us\n",
      "[3, 0.8, 10, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 13.2ms\tremaining: 26.5ms\n",
      "1:\tlearn: 0.4684354\ttotal: 37.4ms\tremaining: 18.7ms\n",
      "2:\tlearn: 0.4642800\ttotal: 57.3ms\tremaining: 0us\n",
      "[3, 0.8, 10, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 19ms\tremaining: 38.1ms\n",
      "1:\tlearn: 0.4684354\ttotal: 36.7ms\tremaining: 18.3ms\n",
      "2:\tlearn: 0.4642800\ttotal: 53.4ms\tremaining: 0us\n",
      "[3, 0.8, 10, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 18.3ms\tremaining: 36.6ms\n",
      "1:\tlearn: 0.4684354\ttotal: 47.5ms\tremaining: 23.7ms\n",
      "2:\tlearn: 0.4642800\ttotal: 64ms\tremaining: 0us\n",
      "[3, 0.8, 10, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.76ms\tremaining: 17.5ms\n",
      "1:\tlearn: 0.4684354\ttotal: 23.1ms\tremaining: 11.5ms\n",
      "2:\tlearn: 0.4642800\ttotal: 39.9ms\tremaining: 0us\n",
      "[3, 0.8, 8, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.67ms\tremaining: 13.3ms\n",
      "1:\tlearn: 0.4682512\ttotal: 13ms\tremaining: 6.51ms\n",
      "2:\tlearn: 0.4650605\ttotal: 19.6ms\tremaining: 0us\n",
      "[3, 0.8, 8, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 7.57ms\tremaining: 15.1ms\n",
      "1:\tlearn: 0.4682512\ttotal: 17.6ms\tremaining: 8.82ms\n",
      "2:\tlearn: 0.4650605\ttotal: 32.1ms\tremaining: 0us\n",
      "[3, 0.8, 8, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 7.71ms\tremaining: 15.4ms\n",
      "1:\tlearn: 0.4682512\ttotal: 16.4ms\tremaining: 8.21ms\n",
      "2:\tlearn: 0.4650605\ttotal: 24.9ms\tremaining: 0us\n",
      "[3, 0.8, 8, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.4ms\tremaining: 12.8ms\n",
      "1:\tlearn: 0.4682512\ttotal: 12.8ms\tremaining: 6.41ms\n",
      "2:\tlearn: 0.4650605\ttotal: 19.4ms\tremaining: 0us\n",
      "[3, 0.8, 8, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.19ms\tremaining: 12.4ms\n",
      "1:\tlearn: 0.4682512\ttotal: 13ms\tremaining: 6.49ms\n",
      "2:\tlearn: 0.4650605\ttotal: 19.3ms\tremaining: 0us\n",
      "[3, 0.8, 7, -0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 7.35ms\tremaining: 14.7ms\n",
      "1:\tlearn: 0.4687965\ttotal: 13.4ms\tremaining: 6.72ms\n",
      "2:\tlearn: 0.4653862\ttotal: 32.8ms\tremaining: 0us\n",
      "[3, 0.8, 7, 0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.34ms\tremaining: 10.7ms\n",
      "1:\tlearn: 0.4687965\ttotal: 11.4ms\tremaining: 5.7ms\n",
      "2:\tlearn: 0.4653862\ttotal: 16.9ms\tremaining: 0us\n",
      "[3, 0.8, 7, 0.0]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.27ms\tremaining: 10.5ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.7ms\tremaining: 5.34ms\n",
      "2:\tlearn: 0.4653862\ttotal: 17ms\tremaining: 0us\n",
      "[3, 0.8, 7, 0.15]\n",
      "0:\tlearn: 0.4762583\ttotal: 4.96ms\tremaining: 9.93ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.2ms\tremaining: 5.12ms\n",
      "2:\tlearn: 0.4653862\ttotal: 15.8ms\tremaining: 0us\n",
      "[3, 0.8, 7, 0.2]\n",
      "0:\tlearn: 0.4762583\ttotal: 17ms\tremaining: 34ms\n",
      "1:\tlearn: 0.4687965\ttotal: 24.1ms\tremaining: 12ms\n",
      "2:\tlearn: 0.4653862\ttotal: 31.1ms\tremaining: 0us\n",
      "[3, 0.55, 6, -0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 5.48ms\tremaining: 11ms\n",
      "1:\tlearn: 0.4730186\ttotal: 9.38ms\tremaining: 4.69ms\n",
      "2:\tlearn: 0.4702860\ttotal: 13.2ms\tremaining: 0us\n",
      "[3, 0.55, 6, 0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 5.93ms\tremaining: 11.9ms\n",
      "1:\tlearn: 0.4730186\ttotal: 11.1ms\tremaining: 5.53ms\n",
      "2:\tlearn: 0.4702860\ttotal: 15.9ms\tremaining: 0us\n",
      "[3, 0.55, 6, 0.0]\n",
      "0:\tlearn: 0.4795967\ttotal: 5.43ms\tremaining: 10.9ms\n",
      "1:\tlearn: 0.4730186\ttotal: 9.69ms\tremaining: 4.84ms\n",
      "2:\tlearn: 0.4702860\ttotal: 14.3ms\tremaining: 0us\n",
      "[3, 0.55, 6, 0.15]\n",
      "0:\tlearn: 0.4795967\ttotal: 5.04ms\tremaining: 10.1ms\n",
      "1:\tlearn: 0.4730186\ttotal: 9.99ms\tremaining: 5ms\n",
      "2:\tlearn: 0.4702860\ttotal: 14.6ms\tremaining: 0us\n",
      "[3, 0.55, 6, 0.2]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.34ms\tremaining: 8.68ms\n",
      "1:\tlearn: 0.4730186\ttotal: 8.39ms\tremaining: 4.2ms\n",
      "2:\tlearn: 0.4702860\ttotal: 12.6ms\tremaining: 0us\n",
      "[3, 0.55, 15, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 21.4ms\tremaining: 42.8ms\n",
      "1:\tlearn: 0.4689110\ttotal: 505ms\tremaining: 252ms\n",
      "2:\tlearn: 0.4640795\ttotal: 966ms\tremaining: 0us\n",
      "[3, 0.55, 15, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.23ms\tremaining: 18.5ms\n",
      "1:\tlearn: 0.4689110\ttotal: 469ms\tremaining: 235ms\n",
      "2:\tlearn: 0.4640795\ttotal: 929ms\tremaining: 0us\n",
      "[3, 0.55, 15, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.7ms\tremaining: 19.4ms\n",
      "1:\tlearn: 0.4689110\ttotal: 480ms\tremaining: 240ms\n",
      "2:\tlearn: 0.4640795\ttotal: 929ms\tremaining: 0us\n",
      "[3, 0.55, 15, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.2ms\tremaining: 24.3ms\n",
      "1:\tlearn: 0.4689110\ttotal: 507ms\tremaining: 254ms\n",
      "2:\tlearn: 0.4640795\ttotal: 955ms\tremaining: 0us\n",
      "[3, 0.55, 15, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.25ms\tremaining: 16.5ms\n",
      "1:\tlearn: 0.4689110\ttotal: 552ms\tremaining: 276ms\n",
      "2:\tlearn: 0.4640795\ttotal: 1.03s\tremaining: 0us\n",
      "[3, 0.55, 10, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.93ms\tremaining: 17.9ms\n",
      "1:\tlearn: 0.4715198\ttotal: 23ms\tremaining: 11.5ms\n",
      "2:\tlearn: 0.4676485\ttotal: 36.7ms\tremaining: 0us\n",
      "[3, 0.55, 10, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.55ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4715198\ttotal: 27.9ms\tremaining: 13.9ms\n",
      "2:\tlearn: 0.4676485\ttotal: 44.5ms\tremaining: 0us\n",
      "[3, 0.55, 10, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.9ms\tremaining: 25.8ms\n",
      "1:\tlearn: 0.4715198\ttotal: 28.1ms\tremaining: 14.1ms\n",
      "2:\tlearn: 0.4676485\ttotal: 44.4ms\tremaining: 0us\n",
      "[3, 0.55, 10, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.35ms\tremaining: 16.7ms\n",
      "1:\tlearn: 0.4715198\ttotal: 22.2ms\tremaining: 11.1ms\n",
      "2:\tlearn: 0.4676485\ttotal: 36ms\tremaining: 0us\n",
      "[3, 0.55, 10, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.49ms\tremaining: 19ms\n",
      "1:\tlearn: 0.4715198\ttotal: 29.3ms\tremaining: 14.7ms\n",
      "2:\tlearn: 0.4676485\ttotal: 45.6ms\tremaining: 0us\n",
      "[3, 0.55, 12, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.66ms\tremaining: 17.3ms\n",
      "1:\tlearn: 0.4704514\ttotal: 60.5ms\tremaining: 30.2ms\n",
      "2:\tlearn: 0.4668875\ttotal: 114ms\tremaining: 0us\n",
      "[3, 0.55, 12, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.24ms\tremaining: 18.5ms\n",
      "1:\tlearn: 0.4704514\ttotal: 62ms\tremaining: 31ms\n",
      "2:\tlearn: 0.4668875\ttotal: 114ms\tremaining: 0us\n",
      "[3, 0.55, 12, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.5ms\tremaining: 21.1ms\n",
      "1:\tlearn: 0.4704514\ttotal: 79.7ms\tremaining: 39.8ms\n",
      "2:\tlearn: 0.4668875\ttotal: 137ms\tremaining: 0us\n",
      "[3, 0.55, 12, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 13.3ms\tremaining: 26.6ms\n",
      "1:\tlearn: 0.4704514\ttotal: 75.3ms\tremaining: 37.7ms\n",
      "2:\tlearn: 0.4668875\ttotal: 150ms\tremaining: 0us\n",
      "[3, 0.55, 12, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.66ms\tremaining: 17.3ms\n",
      "1:\tlearn: 0.4704514\ttotal: 70.2ms\tremaining: 35.1ms\n",
      "2:\tlearn: 0.4668875\ttotal: 124ms\tremaining: 0us\n",
      "[3, 0.55, 13, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.51ms\tremaining: 19ms\n",
      "1:\tlearn: 0.4700386\ttotal: 125ms\tremaining: 62.6ms\n",
      "2:\tlearn: 0.4651124\ttotal: 281ms\tremaining: 0us\n",
      "[3, 0.55, 13, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.4ms\tremaining: 20.8ms\n",
      "1:\tlearn: 0.4700386\ttotal: 127ms\tremaining: 63.7ms\n",
      "2:\tlearn: 0.4651124\ttotal: 267ms\tremaining: 0us\n",
      "[3, 0.55, 13, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.1ms\tremaining: 20.2ms\n",
      "1:\tlearn: 0.4700386\ttotal: 142ms\tremaining: 70.9ms\n",
      "2:\tlearn: 0.4651124\ttotal: 287ms\tremaining: 0us\n",
      "[3, 0.55, 13, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.1ms\tremaining: 20.3ms\n",
      "1:\tlearn: 0.4700386\ttotal: 125ms\tremaining: 62.3ms\n",
      "2:\tlearn: 0.4651124\ttotal: 273ms\tremaining: 0us\n",
      "[3, 0.55, 13, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.56ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4700386\ttotal: 126ms\tremaining: 63ms\n",
      "2:\tlearn: 0.4651124\ttotal: 298ms\tremaining: 0us\n",
      "[3, 0.55, 14, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.79ms\tremaining: 19.6ms\n",
      "1:\tlearn: 0.4695164\ttotal: 252ms\tremaining: 126ms\n",
      "2:\tlearn: 0.4654149\ttotal: 493ms\tremaining: 0us\n",
      "[3, 0.55, 14, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.51ms\tremaining: 17ms\n",
      "1:\tlearn: 0.4695164\ttotal: 270ms\tremaining: 135ms\n",
      "2:\tlearn: 0.4654149\ttotal: 516ms\tremaining: 0us\n",
      "[3, 0.55, 14, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.78ms\tremaining: 19.6ms\n",
      "1:\tlearn: 0.4695164\ttotal: 263ms\tremaining: 131ms\n",
      "2:\tlearn: 0.4654149\ttotal: 479ms\tremaining: 0us\n",
      "[3, 0.55, 14, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.7ms\tremaining: 25.3ms\n",
      "1:\tlearn: 0.4695164\ttotal: 249ms\tremaining: 124ms\n",
      "2:\tlearn: 0.4654149\ttotal: 517ms\tremaining: 0us\n",
      "[3, 0.55, 14, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 15.2ms\tremaining: 30.3ms\n",
      "1:\tlearn: 0.4695164\ttotal: 283ms\tremaining: 142ms\n",
      "2:\tlearn: 0.4654149\ttotal: 496ms\tremaining: 0us\n",
      "[3, 0.42, 6, -0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 6.8ms\tremaining: 13.6ms\n",
      "1:\tlearn: 0.4764006\ttotal: 11.5ms\tremaining: 5.74ms\n",
      "2:\tlearn: 0.4730150\ttotal: 15.7ms\tremaining: 0us\n",
      "[3, 0.42, 6, 0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.62ms\tremaining: 9.24ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.48ms\tremaining: 4.74ms\n",
      "2:\tlearn: 0.4730150\ttotal: 14ms\tremaining: 0us\n",
      "[3, 0.42, 6, 0.0]\n",
      "0:\tlearn: 0.4822549\ttotal: 5.41ms\tremaining: 10.8ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.66ms\tremaining: 4.83ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13.9ms\tremaining: 0us\n",
      "[3, 0.42, 6, 0.15]\n",
      "0:\tlearn: 0.4822549\ttotal: 5.28ms\tremaining: 10.6ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.53ms\tremaining: 4.76ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13.8ms\tremaining: 0us\n",
      "[3, 0.42, 6, 0.2]\n",
      "0:\tlearn: 0.4822549\ttotal: 11.1ms\tremaining: 22.3ms\n",
      "1:\tlearn: 0.4764006\ttotal: 16.4ms\tremaining: 8.18ms\n",
      "2:\tlearn: 0.4730150\ttotal: 21.1ms\tremaining: 0us\n",
      "[3, 0.42, 15, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.2ms\tremaining: 22.4ms\n",
      "1:\tlearn: 0.4725597\ttotal: 486ms\tremaining: 243ms\n",
      "2:\tlearn: 0.4670568\ttotal: 956ms\tremaining: 0us\n",
      "[3, 0.42, 15, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.1ms\tremaining: 18.2ms\n",
      "1:\tlearn: 0.4725597\ttotal: 465ms\tremaining: 233ms\n",
      "2:\tlearn: 0.4670568\ttotal: 951ms\tremaining: 0us\n",
      "[3, 0.42, 15, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 13.8ms\tremaining: 27.7ms\n",
      "1:\tlearn: 0.4725597\ttotal: 453ms\tremaining: 226ms\n",
      "2:\tlearn: 0.4670568\ttotal: 927ms\tremaining: 0us\n",
      "[3, 0.42, 15, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 13.6ms\tremaining: 27.2ms\n",
      "1:\tlearn: 0.4725597\ttotal: 460ms\tremaining: 230ms\n",
      "2:\tlearn: 0.4670568\ttotal: 925ms\tremaining: 0us\n",
      "[3, 0.42, 15, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.2ms\tremaining: 22.5ms\n",
      "1:\tlearn: 0.4725597\ttotal: 476ms\tremaining: 238ms\n",
      "2:\tlearn: 0.4670568\ttotal: 922ms\tremaining: 0us\n",
      "[3, 0.42, 10, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.98ms\tremaining: 18ms\n",
      "1:\tlearn: 0.4747524\ttotal: 22.6ms\tremaining: 11.3ms\n",
      "2:\tlearn: 0.4704503\ttotal: 36.4ms\tremaining: 0us\n",
      "[3, 0.42, 10, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 19.5ms\tremaining: 39.1ms\n",
      "1:\tlearn: 0.4747524\ttotal: 39.7ms\tremaining: 19.9ms\n",
      "2:\tlearn: 0.4704503\ttotal: 56.8ms\tremaining: 0us\n",
      "[3, 0.42, 10, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.4ms\tremaining: 16.8ms\n",
      "1:\tlearn: 0.4747524\ttotal: 22.1ms\tremaining: 11.1ms\n",
      "2:\tlearn: 0.4704503\ttotal: 35.8ms\tremaining: 0us\n",
      "[3, 0.42, 10, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.3ms\tremaining: 24.6ms\n",
      "1:\tlearn: 0.4747524\ttotal: 28.6ms\tremaining: 14.3ms\n",
      "2:\tlearn: 0.4704503\ttotal: 49.2ms\tremaining: 0us\n",
      "[3, 0.42, 10, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.44ms\tremaining: 16.9ms\n",
      "1:\tlearn: 0.4747524\ttotal: 21.9ms\tremaining: 10.9ms\n",
      "2:\tlearn: 0.4704503\ttotal: 35.7ms\tremaining: 0us\n",
      "[3, 0.42, 12, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.5ms\tremaining: 23.1ms\n",
      "1:\tlearn: 0.4738094\ttotal: 80.5ms\tremaining: 40.2ms\n",
      "2:\tlearn: 0.4686075\ttotal: 145ms\tremaining: 0us\n",
      "[3, 0.42, 12, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.9ms\tremaining: 21.8ms\n",
      "1:\tlearn: 0.4738094\ttotal: 72.1ms\tremaining: 36ms\n",
      "2:\tlearn: 0.4686075\ttotal: 159ms\tremaining: 0us\n",
      "[3, 0.42, 12, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.2ms\tremaining: 16.4ms\n",
      "1:\tlearn: 0.4738094\ttotal: 60.6ms\tremaining: 30.3ms\n",
      "2:\tlearn: 0.4686075\ttotal: 114ms\tremaining: 0us\n",
      "[3, 0.42, 12, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.77ms\tremaining: 19.5ms\n",
      "1:\tlearn: 0.4738094\ttotal: 69.3ms\tremaining: 34.7ms\n",
      "2:\tlearn: 0.4686075\ttotal: 125ms\tremaining: 0us\n",
      "[3, 0.42, 12, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.9ms\tremaining: 21.9ms\n",
      "1:\tlearn: 0.4738094\ttotal: 94.6ms\tremaining: 47.3ms\n",
      "2:\tlearn: 0.4686075\ttotal: 162ms\tremaining: 0us\n",
      "[3, 0.42, 13, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.24ms\tremaining: 16.5ms\n",
      "1:\tlearn: 0.4734661\ttotal: 124ms\tremaining: 62.2ms\n",
      "2:\tlearn: 0.4690787\ttotal: 272ms\tremaining: 0us\n",
      "[3, 0.42, 13, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.28ms\tremaining: 16.6ms\n",
      "1:\tlearn: 0.4734661\ttotal: 110ms\tremaining: 55.2ms\n",
      "2:\tlearn: 0.4690787\ttotal: 228ms\tremaining: 0us\n",
      "[3, 0.42, 13, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.55ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4734661\ttotal: 110ms\tremaining: 54.9ms\n",
      "2:\tlearn: 0.4690787\ttotal: 239ms\tremaining: 0us\n",
      "[3, 0.42, 13, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.4ms\tremaining: 16.8ms\n",
      "1:\tlearn: 0.4734661\ttotal: 109ms\tremaining: 54.7ms\n",
      "2:\tlearn: 0.4690787\ttotal: 250ms\tremaining: 0us\n",
      "[3, 0.42, 13, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.23ms\tremaining: 16.5ms\n",
      "1:\tlearn: 0.4734661\ttotal: 111ms\tremaining: 55.7ms\n",
      "2:\tlearn: 0.4690787\ttotal: 229ms\tremaining: 0us\n",
      "[3, 0.36, 6, -0.3]\n",
      "0:\tlearn: 0.4836922\ttotal: 4.01ms\tremaining: 8.02ms\n",
      "1:\tlearn: 0.4778795\ttotal: 8.05ms\tremaining: 4.03ms\n",
      "2:\tlearn: 0.4743400\ttotal: 12.5ms\tremaining: 0us\n",
      "[3, 0.36, 6, 0.3]\n",
      "0:\tlearn: 0.4836922\ttotal: 6.29ms\tremaining: 12.6ms\n",
      "1:\tlearn: 0.4778795\ttotal: 10.9ms\tremaining: 5.47ms\n",
      "2:\tlearn: 0.4743400\ttotal: 15.6ms\tremaining: 0us\n",
      "[3, 0.36, 6, 0.0]\n",
      "0:\tlearn: 0.4836922\ttotal: 5.1ms\tremaining: 10.2ms\n",
      "1:\tlearn: 0.4778795\ttotal: 9.15ms\tremaining: 4.58ms\n",
      "2:\tlearn: 0.4743400\ttotal: 13.3ms\tremaining: 0us\n",
      "[3, 0.36, 6, 0.15]\n",
      "0:\tlearn: 0.4836922\ttotal: 5.87ms\tremaining: 11.7ms\n",
      "1:\tlearn: 0.4778795\ttotal: 11.4ms\tremaining: 5.68ms\n",
      "2:\tlearn: 0.4743400\ttotal: 16.7ms\tremaining: 0us\n",
      "[3, 0.36, 6, 0.2]\n",
      "0:\tlearn: 0.4836922\ttotal: 6.97ms\tremaining: 13.9ms\n",
      "1:\tlearn: 0.4778795\ttotal: 11.1ms\tremaining: 5.57ms\n",
      "2:\tlearn: 0.4743400\ttotal: 16ms\tremaining: 0us\n",
      "[3, 0.36, 15, -0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.96ms\tremaining: 19.9ms\n",
      "1:\tlearn: 0.4745914\ttotal: 475ms\tremaining: 238ms\n",
      "2:\tlearn: 0.4690171\ttotal: 954ms\tremaining: 0us\n",
      "[3, 0.36, 15, 0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.57ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4745914\ttotal: 479ms\tremaining: 240ms\n",
      "2:\tlearn: 0.4690171\ttotal: 954ms\tremaining: 0us\n",
      "[3, 0.36, 15, 0.0]\n",
      "0:\tlearn: 0.4834441\ttotal: 10.8ms\tremaining: 21.6ms\n",
      "1:\tlearn: 0.4745914\ttotal: 473ms\tremaining: 236ms\n",
      "2:\tlearn: 0.4690171\ttotal: 918ms\tremaining: 0us\n",
      "[3, 0.36, 15, 0.15]\n",
      "0:\tlearn: 0.4834441\ttotal: 10.7ms\tremaining: 21.4ms\n",
      "1:\tlearn: 0.4745914\ttotal: 474ms\tremaining: 237ms\n",
      "2:\tlearn: 0.4690171\ttotal: 931ms\tremaining: 0us\n",
      "[3, 0.36, 15, 0.2]\n",
      "0:\tlearn: 0.4834441\ttotal: 14.3ms\tremaining: 28.5ms\n",
      "1:\tlearn: 0.4745914\ttotal: 498ms\tremaining: 249ms\n",
      "2:\tlearn: 0.4690171\ttotal: 953ms\tremaining: 0us\n",
      "[3, 0.36, 10, -0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.54ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4765633\ttotal: 26.6ms\tremaining: 13.3ms\n",
      "2:\tlearn: 0.4720102\ttotal: 41.8ms\tremaining: 0us\n",
      "[3, 0.36, 10, 0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.38ms\tremaining: 18.8ms\n",
      "1:\tlearn: 0.4765633\ttotal: 24.2ms\tremaining: 12.1ms\n",
      "2:\tlearn: 0.4720102\ttotal: 41.5ms\tremaining: 0us\n",
      "[3, 0.36, 10, 0.0]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.7ms\tremaining: 19.4ms\n",
      "1:\tlearn: 0.4765633\ttotal: 25ms\tremaining: 12.5ms\n",
      "2:\tlearn: 0.4720102\ttotal: 39.4ms\tremaining: 0us\n",
      "[3, 0.36, 10, 0.15]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.11ms\tremaining: 18.2ms\n",
      "1:\tlearn: 0.4765633\ttotal: 23.9ms\tremaining: 12ms\n",
      "2:\tlearn: 0.4720102\ttotal: 39.4ms\tremaining: 0us\n",
      "[3, 0.36, 10, 0.2]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.66ms\tremaining: 17.3ms\n",
      "1:\tlearn: 0.4765633\ttotal: 22.3ms\tremaining: 11.2ms\n",
      "2:\tlearn: 0.4720102\ttotal: 35.6ms\tremaining: 0us\n",
      "[3, 0.36, 12, -0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 10ms\tremaining: 20.1ms\n",
      "1:\tlearn: 0.4756821\ttotal: 66.4ms\tremaining: 33.2ms\n",
      "2:\tlearn: 0.4703774\ttotal: 120ms\tremaining: 0us\n",
      "[3, 0.36, 12, 0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.44ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.4756821\ttotal: 68.5ms\tremaining: 34.3ms\n",
      "2:\tlearn: 0.4703774\ttotal: 120ms\tremaining: 0us\n",
      "[3, 0.36, 12, 0.0]\n",
      "0:\tlearn: 0.4834441\ttotal: 15.9ms\tremaining: 31.7ms\n",
      "1:\tlearn: 0.4756821\ttotal: 80.3ms\tremaining: 40.1ms\n",
      "2:\tlearn: 0.4703774\ttotal: 150ms\tremaining: 0us\n",
      "[3, 0.36, 12, 0.15]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.54ms\tremaining: 17.1ms\n",
      "1:\tlearn: 0.4756821\ttotal: 62.5ms\tremaining: 31.3ms\n",
      "2:\tlearn: 0.4703774\ttotal: 134ms\tremaining: 0us\n",
      "[3, 0.36, 12, 0.2]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.45ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.4756821\ttotal: 62.4ms\tremaining: 31.2ms\n",
      "2:\tlearn: 0.4703774\ttotal: 113ms\tremaining: 0us\n",
      "[3, 0.36, 13, -0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.63ms\tremaining: 17.3ms\n",
      "1:\tlearn: 0.4753823\ttotal: 111ms\tremaining: 55.3ms\n",
      "2:\tlearn: 0.4704790\ttotal: 217ms\tremaining: 0us\n",
      "[3, 0.36, 13, 0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.45ms\tremaining: 16.9ms\n",
      "1:\tlearn: 0.4753823\ttotal: 122ms\tremaining: 60.9ms\n",
      "2:\tlearn: 0.4704790\ttotal: 255ms\tremaining: 0us\n",
      "[3, 0.36, 13, 0.0]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.41ms\tremaining: 16.8ms\n",
      "1:\tlearn: 0.4753823\ttotal: 112ms\tremaining: 55.9ms\n",
      "2:\tlearn: 0.4704790\ttotal: 252ms\tremaining: 0us\n",
      "[3, 0.36, 13, 0.15]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.27ms\tremaining: 16.5ms\n",
      "1:\tlearn: 0.4753823\ttotal: 111ms\tremaining: 55.5ms\n",
      "2:\tlearn: 0.4704790\ttotal: 232ms\tremaining: 0us\n",
      "[3, 0.36, 13, 0.2]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.75ms\tremaining: 17.5ms\n",
      "1:\tlearn: 0.4753823\ttotal: 113ms\tremaining: 56.4ms\n",
      "2:\tlearn: 0.4704790\ttotal: 234ms\tremaining: 0us\n",
      "[3, 0.36, 14, -0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.41ms\tremaining: 16.8ms\n",
      "1:\tlearn: 0.4750253\ttotal: 222ms\tremaining: 111ms\n",
      "2:\tlearn: 0.4706063\ttotal: 481ms\tremaining: 0us\n",
      "[3, 0.36, 14, 0.3]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.48ms\tremaining: 17ms\n",
      "1:\tlearn: 0.4750253\ttotal: 245ms\tremaining: 122ms\n",
      "2:\tlearn: 0.4706063\ttotal: 482ms\tremaining: 0us\n",
      "[3, 0.36, 14, 0.0]\n",
      "0:\tlearn: 0.4834441\ttotal: 9.13ms\tremaining: 18.3ms\n",
      "1:\tlearn: 0.4750253\ttotal: 272ms\tremaining: 136ms\n",
      "2:\tlearn: 0.4706063\ttotal: 476ms\tremaining: 0us\n",
      "[3, 0.36, 14, 0.15]\n",
      "0:\tlearn: 0.4834441\ttotal: 11.4ms\tremaining: 22.7ms\n",
      "1:\tlearn: 0.4750253\ttotal: 234ms\tremaining: 117ms\n",
      "2:\tlearn: 0.4706063\ttotal: 485ms\tremaining: 0us\n",
      "[3, 0.36, 14, 0.2]\n",
      "0:\tlearn: 0.4834441\ttotal: 8.82ms\tremaining: 17.6ms\n",
      "1:\tlearn: 0.4750253\ttotal: 250ms\tremaining: 125ms\n",
      "2:\tlearn: 0.4706063\ttotal: 521ms\tremaining: 0us\n",
      "[3, 0.33, 6, -0.3]\n",
      "0:\tlearn: 0.4844602\ttotal: 4.22ms\tremaining: 8.44ms\n",
      "1:\tlearn: 0.4787384\ttotal: 7.96ms\tremaining: 3.98ms\n",
      "2:\tlearn: 0.4752026\ttotal: 11.8ms\tremaining: 0us\n",
      "[3, 0.33, 6, 0.3]\n",
      "0:\tlearn: 0.4844602\ttotal: 6.57ms\tremaining: 13.1ms\n",
      "1:\tlearn: 0.4787384\ttotal: 11.1ms\tremaining: 5.56ms\n",
      "2:\tlearn: 0.4752026\ttotal: 15.3ms\tremaining: 0us\n",
      "[3, 0.33, 6, 0.0]\n",
      "0:\tlearn: 0.4844602\ttotal: 4.12ms\tremaining: 8.23ms\n",
      "1:\tlearn: 0.4787384\ttotal: 8.44ms\tremaining: 4.22ms\n",
      "2:\tlearn: 0.4752026\ttotal: 12.4ms\tremaining: 0us\n",
      "[3, 0.33, 6, 0.15]\n",
      "0:\tlearn: 0.4844602\ttotal: 7.84ms\tremaining: 15.7ms\n",
      "1:\tlearn: 0.4787384\ttotal: 12.7ms\tremaining: 6.33ms\n",
      "2:\tlearn: 0.4752026\ttotal: 19.2ms\tremaining: 0us\n",
      "[3, 0.33, 6, 0.2]\n",
      "0:\tlearn: 0.4844602\ttotal: 4.09ms\tremaining: 8.19ms\n",
      "1:\tlearn: 0.4787384\ttotal: 8.23ms\tremaining: 4.12ms\n",
      "2:\tlearn: 0.4752026\ttotal: 12.2ms\tremaining: 0us\n",
      "[3, 0.33, 15, -0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 13.1ms\tremaining: 26.1ms\n",
      "1:\tlearn: 0.4757314\ttotal: 495ms\tremaining: 247ms\n",
      "2:\tlearn: 0.4701667\ttotal: 949ms\tremaining: 0us\n",
      "[3, 0.33, 15, 0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 12ms\tremaining: 24ms\n",
      "1:\tlearn: 0.4757314\ttotal: 493ms\tremaining: 246ms\n",
      "2:\tlearn: 0.4701667\ttotal: 943ms\tremaining: 0us\n",
      "[3, 0.33, 15, 0.0]\n",
      "0:\tlearn: 0.4842309\ttotal: 13.3ms\tremaining: 26.6ms\n",
      "1:\tlearn: 0.4757314\ttotal: 475ms\tremaining: 238ms\n",
      "2:\tlearn: 0.4701667\ttotal: 934ms\tremaining: 0us\n",
      "[3, 0.33, 15, 0.15]\n",
      "0:\tlearn: 0.4842309\ttotal: 12.7ms\tremaining: 25.4ms\n",
      "1:\tlearn: 0.4757314\ttotal: 524ms\tremaining: 262ms\n",
      "2:\tlearn: 0.4701667\ttotal: 985ms\tremaining: 0us\n",
      "[3, 0.33, 15, 0.2]\n",
      "0:\tlearn: 0.4842309\ttotal: 12.1ms\tremaining: 24.2ms\n",
      "1:\tlearn: 0.4757314\ttotal: 530ms\tremaining: 265ms\n",
      "2:\tlearn: 0.4701667\ttotal: 987ms\tremaining: 0us\n",
      "[3, 0.33, 10, -0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 11.1ms\tremaining: 22.2ms\n",
      "1:\tlearn: 0.4775831\ttotal: 31.9ms\tremaining: 16ms\n",
      "2:\tlearn: 0.4730374\ttotal: 51.1ms\tremaining: 0us\n",
      "[3, 0.33, 10, 0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 9.53ms\tremaining: 19.1ms\n",
      "1:\tlearn: 0.4775831\ttotal: 24.5ms\tremaining: 12.3ms\n",
      "2:\tlearn: 0.4730374\ttotal: 43.4ms\tremaining: 0us\n",
      "[3, 0.33, 10, 0.0]\n",
      "0:\tlearn: 0.4842309\ttotal: 13.9ms\tremaining: 27.8ms\n",
      "1:\tlearn: 0.4775831\ttotal: 33.5ms\tremaining: 16.7ms\n",
      "2:\tlearn: 0.4730374\ttotal: 49ms\tremaining: 0us\n",
      "[3, 0.33, 10, 0.15]\n",
      "0:\tlearn: 0.4842309\ttotal: 8.77ms\tremaining: 17.5ms\n",
      "1:\tlearn: 0.4775831\ttotal: 24.2ms\tremaining: 12.1ms\n",
      "2:\tlearn: 0.4730374\ttotal: 40.1ms\tremaining: 0us\n",
      "[3, 0.33, 10, 0.2]\n",
      "0:\tlearn: 0.4842309\ttotal: 8.95ms\tremaining: 17.9ms\n",
      "1:\tlearn: 0.4775831\ttotal: 23.4ms\tremaining: 11.7ms\n",
      "2:\tlearn: 0.4730374\ttotal: 37.4ms\tremaining: 0us\n",
      "[3, 0.33, 12, -0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 13ms\tremaining: 25.9ms\n",
      "1:\tlearn: 0.4767400\ttotal: 76.1ms\tremaining: 38.1ms\n",
      "2:\tlearn: 0.4732935\ttotal: 111ms\tremaining: 0us\n",
      "[3, 0.33, 12, 0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 10.3ms\tremaining: 20.7ms\n",
      "1:\tlearn: 0.4767400\ttotal: 62.6ms\tremaining: 31.3ms\n",
      "2:\tlearn: 0.4732935\ttotal: 70.9ms\tremaining: 0us\n",
      "[3, 0.33, 12, 0.0]\n",
      "0:\tlearn: 0.4842309\ttotal: 16.2ms\tremaining: 32.4ms\n",
      "1:\tlearn: 0.4767400\ttotal: 79.9ms\tremaining: 39.9ms\n",
      "2:\tlearn: 0.4732935\ttotal: 90.1ms\tremaining: 0us\n",
      "[3, 0.33, 12, 0.15]\n",
      "0:\tlearn: 0.4842309\ttotal: 10.8ms\tremaining: 21.5ms\n",
      "1:\tlearn: 0.4767400\ttotal: 74ms\tremaining: 37ms\n",
      "2:\tlearn: 0.4732935\ttotal: 83.5ms\tremaining: 0us\n",
      "[3, 0.33, 12, 0.2]\n",
      "0:\tlearn: 0.4842309\ttotal: 8.35ms\tremaining: 16.7ms\n",
      "1:\tlearn: 0.4767400\ttotal: 59ms\tremaining: 29.5ms\n",
      "2:\tlearn: 0.4732935\ttotal: 67.6ms\tremaining: 0us\n",
      "[3, 0.33, 13, -0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 9.81ms\tremaining: 19.6ms\n",
      "1:\tlearn: 0.4764628\ttotal: 154ms\tremaining: 76.8ms\n",
      "2:\tlearn: 0.4723083\ttotal: 276ms\tremaining: 0us\n",
      "[3, 0.33, 13, 0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 15.6ms\tremaining: 31.2ms\n",
      "1:\tlearn: 0.4764628\ttotal: 143ms\tremaining: 71.3ms\n",
      "2:\tlearn: 0.4723083\ttotal: 259ms\tremaining: 0us\n",
      "[3, 0.33, 13, 0.0]\n",
      "0:\tlearn: 0.4842309\ttotal: 16.5ms\tremaining: 33ms\n",
      "1:\tlearn: 0.4764628\ttotal: 141ms\tremaining: 70.6ms\n",
      "2:\tlearn: 0.4723083\ttotal: 251ms\tremaining: 0us\n",
      "[3, 0.33, 13, 0.15]\n",
      "0:\tlearn: 0.4842309\ttotal: 12.4ms\tremaining: 24.8ms\n",
      "1:\tlearn: 0.4764628\ttotal: 164ms\tremaining: 82ms\n",
      "2:\tlearn: 0.4723083\ttotal: 282ms\tremaining: 0us\n",
      "[3, 0.33, 13, 0.2]\n",
      "0:\tlearn: 0.4842309\ttotal: 9.77ms\tremaining: 19.5ms\n",
      "1:\tlearn: 0.4764628\ttotal: 135ms\tremaining: 67.3ms\n",
      "2:\tlearn: 0.4723083\ttotal: 248ms\tremaining: 0us\n",
      "[3, 0.33, 14, -0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 16.1ms\tremaining: 32.3ms\n",
      "1:\tlearn: 0.4761339\ttotal: 249ms\tremaining: 124ms\n",
      "2:\tlearn: 0.4717227\ttotal: 475ms\tremaining: 0us\n",
      "[3, 0.33, 14, 0.3]\n",
      "0:\tlearn: 0.4842309\ttotal: 9.33ms\tremaining: 18.7ms\n",
      "1:\tlearn: 0.4761339\ttotal: 302ms\tremaining: 151ms\n",
      "2:\tlearn: 0.4717227\ttotal: 543ms\tremaining: 0us\n",
      "[3, 0.33, 14, 0.0]\n",
      "0:\tlearn: 0.4842309\ttotal: 11.8ms\tremaining: 23.6ms\n",
      "1:\tlearn: 0.4761339\ttotal: 287ms\tremaining: 143ms\n",
      "2:\tlearn: 0.4717227\ttotal: 493ms\tremaining: 0us\n",
      "[3, 0.33, 14, 0.15]\n",
      "0:\tlearn: 0.4842309\ttotal: 10.8ms\tremaining: 21.5ms\n",
      "1:\tlearn: 0.4761339\ttotal: 230ms\tremaining: 115ms\n",
      "2:\tlearn: 0.4717227\ttotal: 500ms\tremaining: 0us\n",
      "[3, 0.33, 14, 0.2]\n",
      "0:\tlearn: 0.4842309\ttotal: 9.03ms\tremaining: 18.1ms\n",
      "1:\tlearn: 0.4761339\ttotal: 256ms\tremaining: 128ms\n",
      "2:\tlearn: 0.4717227\ttotal: 496ms\tremaining: 0us\n",
      "[3, 0.31, 6, -0.3]\n",
      "0:\tlearn: 0.4849904\ttotal: 5.35ms\tremaining: 10.7ms\n",
      "1:\tlearn: 0.4793585\ttotal: 9.79ms\tremaining: 4.9ms\n",
      "2:\tlearn: 0.4754215\ttotal: 14.3ms\tremaining: 0us\n",
      "[3, 0.31, 6, 0.3]\n",
      "0:\tlearn: 0.4849904\ttotal: 5.79ms\tremaining: 11.6ms\n",
      "1:\tlearn: 0.4793585\ttotal: 9.84ms\tremaining: 4.92ms\n",
      "2:\tlearn: 0.4754215\ttotal: 13.6ms\tremaining: 0us\n",
      "[3, 0.31, 6, 0.0]\n",
      "0:\tlearn: 0.4849904\ttotal: 4.74ms\tremaining: 9.49ms\n",
      "1:\tlearn: 0.4793585\ttotal: 9.3ms\tremaining: 4.65ms\n",
      "2:\tlearn: 0.4754215\ttotal: 14ms\tremaining: 0us\n",
      "[3, 0.31, 6, 0.15]\n",
      "0:\tlearn: 0.4849904\ttotal: 8.42ms\tremaining: 16.8ms\n",
      "1:\tlearn: 0.4793585\ttotal: 13.6ms\tremaining: 6.81ms\n",
      "2:\tlearn: 0.4754215\ttotal: 18.1ms\tremaining: 0us\n",
      "[3, 0.31, 6, 0.2]\n",
      "0:\tlearn: 0.4849904\ttotal: 4.54ms\tremaining: 9.07ms\n",
      "1:\tlearn: 0.4793585\ttotal: 9.08ms\tremaining: 4.54ms\n",
      "2:\tlearn: 0.4754215\ttotal: 13.6ms\tremaining: 0us\n",
      "[3, 0.31, 15, -0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 8.99ms\tremaining: 18ms\n",
      "1:\tlearn: 0.4765401\ttotal: 511ms\tremaining: 256ms\n",
      "2:\tlearn: 0.4710041\ttotal: 948ms\tremaining: 0us\n",
      "[3, 0.31, 15, 0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.73ms\tremaining: 19.5ms\n",
      "1:\tlearn: 0.4765401\ttotal: 495ms\tremaining: 248ms\n",
      "2:\tlearn: 0.4710041\ttotal: 957ms\tremaining: 0us\n",
      "[3, 0.31, 15, 0.0]\n",
      "0:\tlearn: 0.4847738\ttotal: 12.7ms\tremaining: 25.4ms\n",
      "1:\tlearn: 0.4765401\ttotal: 511ms\tremaining: 255ms\n",
      "2:\tlearn: 0.4710041\ttotal: 968ms\tremaining: 0us\n",
      "[3, 0.31, 15, 0.15]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.58ms\tremaining: 19.2ms\n",
      "1:\tlearn: 0.4765401\ttotal: 486ms\tremaining: 243ms\n",
      "2:\tlearn: 0.4710041\ttotal: 950ms\tremaining: 0us\n",
      "[3, 0.31, 15, 0.2]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.43ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.4765401\ttotal: 456ms\tremaining: 228ms\n",
      "2:\tlearn: 0.4710041\ttotal: 943ms\tremaining: 0us\n",
      "[3, 0.31, 10, -0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.35ms\tremaining: 18.7ms\n",
      "1:\tlearn: 0.4783078\ttotal: 26.3ms\tremaining: 13.1ms\n",
      "2:\tlearn: 0.4739292\ttotal: 41.3ms\tremaining: 0us\n",
      "[3, 0.31, 10, 0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.4ms\tremaining: 18.8ms\n",
      "1:\tlearn: 0.4783078\ttotal: 24.7ms\tremaining: 12.4ms\n",
      "2:\tlearn: 0.4739292\ttotal: 42.5ms\tremaining: 0us\n",
      "[3, 0.31, 10, 0.0]\n",
      "0:\tlearn: 0.4847738\ttotal: 10.3ms\tremaining: 20.5ms\n",
      "1:\tlearn: 0.4783078\ttotal: 25.1ms\tremaining: 12.5ms\n",
      "2:\tlearn: 0.4739292\ttotal: 40.6ms\tremaining: 0us\n",
      "[3, 0.31, 10, 0.15]\n",
      "0:\tlearn: 0.4847738\ttotal: 10.8ms\tremaining: 21.5ms\n",
      "1:\tlearn: 0.4783078\ttotal: 28.1ms\tremaining: 14ms\n",
      "2:\tlearn: 0.4739292\ttotal: 62ms\tremaining: 0us\n",
      "[3, 0.31, 10, 0.2]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.32ms\tremaining: 18.6ms\n",
      "1:\tlearn: 0.4783078\ttotal: 23.4ms\tremaining: 11.7ms\n",
      "2:\tlearn: 0.4739292\ttotal: 37.1ms\tremaining: 0us\n",
      "[3, 0.31, 12, -0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 13.6ms\tremaining: 27.2ms\n",
      "1:\tlearn: 0.4774930\ttotal: 74.8ms\tremaining: 37.4ms\n",
      "2:\tlearn: 0.4735224\ttotal: 127ms\tremaining: 0us\n",
      "[3, 0.31, 12, 0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.74ms\tremaining: 19.5ms\n",
      "1:\tlearn: 0.4774930\ttotal: 73.8ms\tremaining: 36.9ms\n",
      "2:\tlearn: 0.4735224\ttotal: 146ms\tremaining: 0us\n",
      "[3, 0.31, 12, 0.0]\n",
      "0:\tlearn: 0.4847738\ttotal: 10.6ms\tremaining: 21.2ms\n",
      "1:\tlearn: 0.4774930\ttotal: 68.1ms\tremaining: 34.1ms\n",
      "2:\tlearn: 0.4735224\ttotal: 147ms\tremaining: 0us\n",
      "[3, 0.31, 12, 0.15]\n",
      "0:\tlearn: 0.4847738\ttotal: 8.29ms\tremaining: 16.6ms\n",
      "1:\tlearn: 0.4774930\ttotal: 61ms\tremaining: 30.5ms\n",
      "2:\tlearn: 0.4735224\ttotal: 112ms\tremaining: 0us\n",
      "[3, 0.31, 12, 0.2]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.46ms\tremaining: 18.9ms\n",
      "1:\tlearn: 0.4774930\ttotal: 79.3ms\tremaining: 39.7ms\n",
      "2:\tlearn: 0.4735224\ttotal: 135ms\tremaining: 0us\n",
      "[3, 0.31, 13, -0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 15.1ms\tremaining: 30.3ms\n",
      "1:\tlearn: 0.4772312\ttotal: 160ms\tremaining: 79.9ms\n",
      "2:\tlearn: 0.4730892\ttotal: 274ms\tremaining: 0us\n",
      "[3, 0.31, 13, 0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 21.8ms\tremaining: 43.5ms\n",
      "1:\tlearn: 0.4772312\ttotal: 160ms\tremaining: 79.8ms\n",
      "2:\tlearn: 0.4730892\ttotal: 267ms\tremaining: 0us\n",
      "[3, 0.31, 13, 0.0]\n",
      "0:\tlearn: 0.4847738\ttotal: 21.5ms\tremaining: 42.9ms\n",
      "1:\tlearn: 0.4772312\ttotal: 159ms\tremaining: 79.4ms\n",
      "2:\tlearn: 0.4730892\ttotal: 272ms\tremaining: 0us\n",
      "[3, 0.31, 13, 0.15]\n",
      "0:\tlearn: 0.4847738\ttotal: 10.5ms\tremaining: 21.1ms\n",
      "1:\tlearn: 0.4772312\ttotal: 141ms\tremaining: 70.7ms\n",
      "2:\tlearn: 0.4730892\ttotal: 257ms\tremaining: 0us\n",
      "[3, 0.31, 13, 0.2]\n",
      "0:\tlearn: 0.4847738\ttotal: 9.58ms\tremaining: 19.2ms\n",
      "1:\tlearn: 0.4772312\ttotal: 132ms\tremaining: 66.2ms\n",
      "2:\tlearn: 0.4730892\ttotal: 253ms\tremaining: 0us\n",
      "[3, 0.31, 14, -0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 14.8ms\tremaining: 29.5ms\n",
      "1:\tlearn: 0.4769212\ttotal: 276ms\tremaining: 138ms\n",
      "2:\tlearn: 0.4724886\ttotal: 505ms\tremaining: 0us\n",
      "[3, 0.31, 14, 0.3]\n",
      "0:\tlearn: 0.4847738\ttotal: 8.44ms\tremaining: 16.9ms\n",
      "1:\tlearn: 0.4769212\ttotal: 284ms\tremaining: 142ms\n",
      "2:\tlearn: 0.4724886\ttotal: 533ms\tremaining: 0us\n",
      "[3, 0.31, 14, 0.0]\n",
      "0:\tlearn: 0.4847738\ttotal: 8.52ms\tremaining: 17ms\n",
      "1:\tlearn: 0.4769212\ttotal: 298ms\tremaining: 149ms\n",
      "2:\tlearn: 0.4724886\ttotal: 539ms\tremaining: 0us\n",
      "[3, 0.31, 14, 0.15]\n",
      "0:\tlearn: 0.4847738\ttotal: 10.5ms\tremaining: 21ms\n",
      "1:\tlearn: 0.4769212\ttotal: 270ms\tremaining: 135ms\n",
      "2:\tlearn: 0.4724886\ttotal: 537ms\tremaining: 0us\n",
      "[3, 0.31, 14, 0.2]\n",
      "0:\tlearn: 0.4847738\ttotal: 8.9ms\tremaining: 17.8ms\n",
      "1:\tlearn: 0.4769212\ttotal: 279ms\tremaining: 139ms\n",
      "2:\tlearn: 0.4724886\ttotal: 511ms\tremaining: 0us\n",
      "[10, 0.3, 6, -0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 4.41ms\tremaining: 39.7ms\n",
      "1:\tlearn: 0.4796834\ttotal: 11.7ms\tremaining: 46.8ms\n",
      "2:\tlearn: 0.4757652\ttotal: 16.1ms\tremaining: 37.6ms\n",
      "3:\tlearn: 0.4737764\ttotal: 21.3ms\tremaining: 32ms\n",
      "4:\tlearn: 0.4716943\ttotal: 27.5ms\tremaining: 27.5ms\n",
      "5:\tlearn: 0.4696759\ttotal: 32.2ms\tremaining: 21.5ms\n",
      "6:\tlearn: 0.4683623\ttotal: 36.7ms\tremaining: 15.7ms\n",
      "7:\tlearn: 0.4672969\ttotal: 41.5ms\tremaining: 10.4ms\n",
      "8:\tlearn: 0.4661468\ttotal: 49.3ms\tremaining: 5.47ms\n",
      "9:\tlearn: 0.4649618\ttotal: 54.1ms\tremaining: 0us\n",
      "[10, 0.3, 6, 0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.44ms\tremaining: 49ms\n",
      "1:\tlearn: 0.4796834\ttotal: 9.95ms\tremaining: 39.8ms\n",
      "2:\tlearn: 0.4757652\ttotal: 14.7ms\tremaining: 34.2ms\n",
      "3:\tlearn: 0.4737764\ttotal: 19.8ms\tremaining: 29.7ms\n",
      "4:\tlearn: 0.4716943\ttotal: 24ms\tremaining: 24ms\n",
      "5:\tlearn: 0.4696759\ttotal: 30.1ms\tremaining: 20.1ms\n",
      "6:\tlearn: 0.4683623\ttotal: 34ms\tremaining: 14.6ms\n",
      "7:\tlearn: 0.4672969\ttotal: 37.9ms\tremaining: 9.48ms\n",
      "8:\tlearn: 0.4661468\ttotal: 42ms\tremaining: 4.67ms\n",
      "9:\tlearn: 0.4649618\ttotal: 45.9ms\tremaining: 0us\n",
      "[10, 0.3, 6, 0.0]\n",
      "0:\tlearn: 0.4852609\ttotal: 10.1ms\tremaining: 90.6ms\n",
      "1:\tlearn: 0.4796834\ttotal: 14.4ms\tremaining: 57.7ms\n",
      "2:\tlearn: 0.4757652\ttotal: 19.5ms\tremaining: 45.6ms\n",
      "3:\tlearn: 0.4737764\ttotal: 37.3ms\tremaining: 55.9ms\n",
      "4:\tlearn: 0.4716943\ttotal: 55.3ms\tremaining: 55.3ms\n",
      "5:\tlearn: 0.4696759\ttotal: 59.8ms\tremaining: 39.9ms\n",
      "6:\tlearn: 0.4683623\ttotal: 68.4ms\tremaining: 29.3ms\n",
      "7:\tlearn: 0.4672969\ttotal: 76ms\tremaining: 19ms\n",
      "8:\tlearn: 0.4661468\ttotal: 81.7ms\tremaining: 9.08ms\n",
      "9:\tlearn: 0.4649618\ttotal: 86.1ms\tremaining: 0us\n",
      "[10, 0.3, 6, 0.15]\n",
      "0:\tlearn: 0.4852609\ttotal: 3.81ms\tremaining: 34.3ms\n",
      "1:\tlearn: 0.4796834\ttotal: 7.75ms\tremaining: 31ms\n",
      "2:\tlearn: 0.4757652\ttotal: 11.7ms\tremaining: 27.2ms\n",
      "3:\tlearn: 0.4737764\ttotal: 15.5ms\tremaining: 23.3ms\n",
      "4:\tlearn: 0.4716943\ttotal: 19.4ms\tremaining: 19.4ms\n",
      "5:\tlearn: 0.4696759\ttotal: 23.2ms\tremaining: 15.5ms\n",
      "6:\tlearn: 0.4683623\ttotal: 27.2ms\tremaining: 11.7ms\n",
      "7:\tlearn: 0.4672969\ttotal: 31.3ms\tremaining: 7.81ms\n",
      "8:\tlearn: 0.4661468\ttotal: 35ms\tremaining: 3.89ms\n",
      "9:\tlearn: 0.4649618\ttotal: 39ms\tremaining: 0us\n",
      "[10, 0.3, 6, 0.2]\n",
      "0:\tlearn: 0.4852609\ttotal: 10.5ms\tremaining: 94.8ms\n",
      "1:\tlearn: 0.4796834\ttotal: 37.4ms\tremaining: 150ms\n",
      "2:\tlearn: 0.4757652\ttotal: 55.4ms\tremaining: 129ms\n",
      "3:\tlearn: 0.4737764\ttotal: 59.9ms\tremaining: 89.9ms\n",
      "4:\tlearn: 0.4716943\ttotal: 64.4ms\tremaining: 64.4ms\n",
      "5:\tlearn: 0.4696759\ttotal: 72.4ms\tremaining: 48.3ms\n",
      "6:\tlearn: 0.4683623\ttotal: 78.5ms\tremaining: 33.6ms\n",
      "7:\tlearn: 0.4672969\ttotal: 83.3ms\tremaining: 20.8ms\n",
      "8:\tlearn: 0.4661468\ttotal: 87.7ms\tremaining: 9.74ms\n",
      "9:\tlearn: 0.4649618\ttotal: 92.1ms\tremaining: 0us\n",
      "[10, 0.3, 15, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.8ms\tremaining: 79.2ms\n",
      "1:\tlearn: 0.4769595\ttotal: 502ms\tremaining: 2.01s\n",
      "2:\tlearn: 0.4714456\ttotal: 955ms\tremaining: 2.23s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.42s\tremaining: 2.13s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.88s\tremaining: 1.88s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.34s\tremaining: 1.56s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.82s\tremaining: 1.21s\n",
      "7:\tlearn: 0.4589930\ttotal: 2.83s\tremaining: 709ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.31s\tremaining: 368ms\n",
      "9:\tlearn: 0.4558563\ttotal: 3.79s\tremaining: 0us\n",
      "[10, 0.3, 15, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.5ms\tremaining: 94.4ms\n",
      "1:\tlearn: 0.4769595\ttotal: 499ms\tremaining: 2s\n",
      "2:\tlearn: 0.4714456\ttotal: 973ms\tremaining: 2.27s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.46s\tremaining: 2.19s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.93s\tremaining: 1.93s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.38s\tremaining: 1.59s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.87s\tremaining: 1.23s\n",
      "7:\tlearn: 0.4589930\ttotal: 2.88s\tremaining: 720ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.35s\tremaining: 373ms\n",
      "9:\tlearn: 0.4558563\ttotal: 3.83s\tremaining: 0us\n",
      "[10, 0.3, 15, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.8ms\tremaining: 97.3ms\n",
      "1:\tlearn: 0.4769595\ttotal: 474ms\tremaining: 1.9s\n",
      "2:\tlearn: 0.4714456\ttotal: 930ms\tremaining: 2.17s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.38s\tremaining: 2.07s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.84s\tremaining: 1.84s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.31s\tremaining: 1.54s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.79s\tremaining: 1.2s\n",
      "7:\tlearn: 0.4589930\ttotal: 2.81s\tremaining: 702ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.27s\tremaining: 364ms\n",
      "9:\tlearn: 0.4558563\ttotal: 3.73s\tremaining: 0us\n",
      "[10, 0.3, 15, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.16ms\tremaining: 82.4ms\n",
      "1:\tlearn: 0.4769595\ttotal: 485ms\tremaining: 1.94s\n",
      "2:\tlearn: 0.4714456\ttotal: 965ms\tremaining: 2.25s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.43s\tremaining: 2.15s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.91s\tremaining: 1.91s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.37s\tremaining: 1.58s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.83s\tremaining: 1.21s\n",
      "7:\tlearn: 0.4589930\ttotal: 2.85s\tremaining: 712ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.31s\tremaining: 368ms\n",
      "9:\tlearn: 0.4558563\ttotal: 3.77s\tremaining: 0us\n",
      "[10, 0.3, 15, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.4ms\tremaining: 93.8ms\n",
      "1:\tlearn: 0.4769595\ttotal: 508ms\tremaining: 2.03s\n",
      "2:\tlearn: 0.4714456\ttotal: 987ms\tremaining: 2.3s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.46s\tremaining: 2.19s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.93s\tremaining: 1.93s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.41s\tremaining: 1.61s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.88s\tremaining: 1.24s\n",
      "7:\tlearn: 0.4589930\ttotal: 2.9s\tremaining: 725ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.38s\tremaining: 376ms\n",
      "9:\tlearn: 0.4558563\ttotal: 3.85s\tremaining: 0us\n",
      "[10, 0.3, 10, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.98ms\tremaining: 80.8ms\n",
      "1:\tlearn: 0.4786840\ttotal: 22.8ms\tremaining: 91.3ms\n",
      "2:\tlearn: 0.4743082\ttotal: 37.2ms\tremaining: 86.9ms\n",
      "3:\tlearn: 0.4713878\ttotal: 50.8ms\tremaining: 76.2ms\n",
      "4:\tlearn: 0.4683005\ttotal: 65.6ms\tremaining: 65.6ms\n",
      "5:\tlearn: 0.4662774\ttotal: 79.6ms\tremaining: 53.1ms\n",
      "6:\tlearn: 0.4645284\ttotal: 93.6ms\tremaining: 40.1ms\n",
      "7:\tlearn: 0.4637179\ttotal: 98.5ms\tremaining: 24.6ms\n",
      "8:\tlearn: 0.4614943\ttotal: 107ms\tremaining: 11.9ms\n",
      "9:\tlearn: 0.4606356\ttotal: 123ms\tremaining: 0us\n",
      "[10, 0.3, 10, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 14.6ms\tremaining: 131ms\n",
      "1:\tlearn: 0.4786840\ttotal: 31.3ms\tremaining: 125ms\n",
      "2:\tlearn: 0.4743082\ttotal: 46.6ms\tremaining: 109ms\n",
      "3:\tlearn: 0.4713878\ttotal: 62ms\tremaining: 92.9ms\n",
      "4:\tlearn: 0.4683005\ttotal: 76.6ms\tremaining: 76.6ms\n",
      "5:\tlearn: 0.4662774\ttotal: 91.7ms\tremaining: 61.1ms\n",
      "6:\tlearn: 0.4645284\ttotal: 106ms\tremaining: 45.4ms\n",
      "7:\tlearn: 0.4637179\ttotal: 111ms\tremaining: 27.7ms\n",
      "8:\tlearn: 0.4614943\ttotal: 120ms\tremaining: 13.3ms\n",
      "9:\tlearn: 0.4606356\ttotal: 135ms\tremaining: 0us\n",
      "[10, 0.3, 10, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.7ms\tremaining: 114ms\n",
      "1:\tlearn: 0.4786840\ttotal: 29.3ms\tremaining: 117ms\n",
      "2:\tlearn: 0.4743082\ttotal: 45.7ms\tremaining: 107ms\n",
      "3:\tlearn: 0.4713878\ttotal: 64.2ms\tremaining: 96.4ms\n",
      "4:\tlearn: 0.4683005\ttotal: 82.8ms\tremaining: 82.8ms\n",
      "5:\tlearn: 0.4662774\ttotal: 100ms\tremaining: 66.9ms\n",
      "6:\tlearn: 0.4645284\ttotal: 117ms\tremaining: 50.2ms\n",
      "7:\tlearn: 0.4637179\ttotal: 123ms\tremaining: 30.7ms\n",
      "8:\tlearn: 0.4614943\ttotal: 132ms\tremaining: 14.7ms\n",
      "9:\tlearn: 0.4606356\ttotal: 149ms\tremaining: 0us\n",
      "[10, 0.3, 10, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.82ms\tremaining: 88.4ms\n",
      "1:\tlearn: 0.4786840\ttotal: 25.7ms\tremaining: 103ms\n",
      "2:\tlearn: 0.4743082\ttotal: 40.9ms\tremaining: 95.5ms\n",
      "3:\tlearn: 0.4713878\ttotal: 57.7ms\tremaining: 86.6ms\n",
      "4:\tlearn: 0.4683005\ttotal: 74.5ms\tremaining: 74.5ms\n",
      "5:\tlearn: 0.4662774\ttotal: 90.4ms\tremaining: 60.3ms\n",
      "6:\tlearn: 0.4645284\ttotal: 132ms\tremaining: 56.5ms\n",
      "7:\tlearn: 0.4637179\ttotal: 147ms\tremaining: 36.7ms\n",
      "8:\tlearn: 0.4614943\ttotal: 175ms\tremaining: 19.4ms\n",
      "9:\tlearn: 0.4606356\ttotal: 199ms\tremaining: 0us\n",
      "[10, 0.3, 10, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.6ms\tremaining: 86.4ms\n",
      "1:\tlearn: 0.4786840\ttotal: 26.1ms\tremaining: 105ms\n",
      "2:\tlearn: 0.4743082\ttotal: 44.2ms\tremaining: 103ms\n",
      "3:\tlearn: 0.4713878\ttotal: 61ms\tremaining: 91.5ms\n",
      "4:\tlearn: 0.4683005\ttotal: 77.4ms\tremaining: 77.4ms\n",
      "5:\tlearn: 0.4662774\ttotal: 93.1ms\tremaining: 62ms\n",
      "6:\tlearn: 0.4645284\ttotal: 109ms\tremaining: 46.8ms\n",
      "7:\tlearn: 0.4637179\ttotal: 114ms\tremaining: 28.5ms\n",
      "8:\tlearn: 0.4614943\ttotal: 123ms\tremaining: 13.7ms\n",
      "9:\tlearn: 0.4606356\ttotal: 152ms\tremaining: 0us\n",
      "[10, 0.3, 12, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.91ms\tremaining: 80.2ms\n",
      "1:\tlearn: 0.4778843\ttotal: 62.4ms\tremaining: 250ms\n",
      "2:\tlearn: 0.4738999\ttotal: 117ms\tremaining: 273ms\n",
      "3:\tlearn: 0.4696749\ttotal: 183ms\tremaining: 274ms\n",
      "4:\tlearn: 0.4678542\ttotal: 275ms\tremaining: 275ms\n",
      "5:\tlearn: 0.4655216\ttotal: 349ms\tremaining: 233ms\n",
      "6:\tlearn: 0.4639614\ttotal: 412ms\tremaining: 176ms\n",
      "7:\tlearn: 0.4618543\ttotal: 469ms\tremaining: 117ms\n",
      "8:\tlearn: 0.4604753\ttotal: 521ms\tremaining: 57.9ms\n",
      "9:\tlearn: 0.4591879\ttotal: 580ms\tremaining: 0us\n",
      "[10, 0.3, 12, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.3ms\tremaining: 92.3ms\n",
      "1:\tlearn: 0.4778843\ttotal: 75.8ms\tremaining: 303ms\n",
      "2:\tlearn: 0.4738999\ttotal: 130ms\tremaining: 302ms\n",
      "3:\tlearn: 0.4696749\ttotal: 182ms\tremaining: 273ms\n",
      "4:\tlearn: 0.4678542\ttotal: 239ms\tremaining: 239ms\n",
      "5:\tlearn: 0.4655216\ttotal: 325ms\tremaining: 217ms\n",
      "6:\tlearn: 0.4639614\ttotal: 397ms\tremaining: 170ms\n",
      "7:\tlearn: 0.4618543\ttotal: 468ms\tremaining: 117ms\n",
      "8:\tlearn: 0.4604753\ttotal: 528ms\tremaining: 58.7ms\n",
      "9:\tlearn: 0.4591879\ttotal: 581ms\tremaining: 0us\n",
      "[10, 0.3, 12, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.78ms\tremaining: 88ms\n",
      "1:\tlearn: 0.4778843\ttotal: 95.3ms\tremaining: 381ms\n",
      "2:\tlearn: 0.4738999\ttotal: 160ms\tremaining: 372ms\n",
      "3:\tlearn: 0.4696749\ttotal: 215ms\tremaining: 322ms\n",
      "4:\tlearn: 0.4678542\ttotal: 267ms\tremaining: 267ms\n",
      "5:\tlearn: 0.4655216\ttotal: 321ms\tremaining: 214ms\n",
      "6:\tlearn: 0.4639614\ttotal: 385ms\tremaining: 165ms\n",
      "7:\tlearn: 0.4618543\ttotal: 480ms\tremaining: 120ms\n",
      "8:\tlearn: 0.4604753\ttotal: 544ms\tremaining: 60.4ms\n",
      "9:\tlearn: 0.4591879\ttotal: 603ms\tremaining: 0us\n",
      "[10, 0.3, 12, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.92ms\tremaining: 89.3ms\n",
      "1:\tlearn: 0.4778843\ttotal: 80.1ms\tremaining: 320ms\n",
      "2:\tlearn: 0.4738999\ttotal: 153ms\tremaining: 356ms\n",
      "3:\tlearn: 0.4696749\ttotal: 218ms\tremaining: 327ms\n",
      "4:\tlearn: 0.4678542\ttotal: 283ms\tremaining: 283ms\n",
      "5:\tlearn: 0.4655216\ttotal: 340ms\tremaining: 227ms\n",
      "6:\tlearn: 0.4639614\ttotal: 392ms\tremaining: 168ms\n",
      "7:\tlearn: 0.4618543\ttotal: 446ms\tremaining: 111ms\n",
      "8:\tlearn: 0.4604753\ttotal: 503ms\tremaining: 55.9ms\n",
      "9:\tlearn: 0.4591879\ttotal: 581ms\tremaining: 0us\n",
      "[10, 0.3, 12, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.4ms\tremaining: 84.6ms\n",
      "1:\tlearn: 0.4778843\ttotal: 62.3ms\tremaining: 249ms\n",
      "2:\tlearn: 0.4738999\ttotal: 114ms\tremaining: 266ms\n",
      "3:\tlearn: 0.4696749\ttotal: 173ms\tremaining: 259ms\n",
      "4:\tlearn: 0.4678542\ttotal: 246ms\tremaining: 246ms\n",
      "5:\tlearn: 0.4655216\ttotal: 332ms\tremaining: 222ms\n",
      "6:\tlearn: 0.4639614\ttotal: 401ms\tremaining: 172ms\n",
      "7:\tlearn: 0.4618543\ttotal: 461ms\tremaining: 115ms\n",
      "8:\tlearn: 0.4604753\ttotal: 516ms\tremaining: 57.4ms\n",
      "9:\tlearn: 0.4591879\ttotal: 574ms\tremaining: 0us\n",
      "[10, 0.3, 13, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.4ms\tremaining: 112ms\n",
      "1:\tlearn: 0.4776303\ttotal: 144ms\tremaining: 574ms\n",
      "2:\tlearn: 0.4735011\ttotal: 275ms\tremaining: 643ms\n",
      "3:\tlearn: 0.4707331\ttotal: 366ms\tremaining: 549ms\n",
      "4:\tlearn: 0.4669265\ttotal: 502ms\tremaining: 502ms\n",
      "5:\tlearn: 0.4646028\ttotal: 557ms\tremaining: 372ms\n",
      "6:\tlearn: 0.4634280\ttotal: 565ms\tremaining: 242ms\n",
      "7:\tlearn: 0.4620786\ttotal: 708ms\tremaining: 177ms\n",
      "8:\tlearn: 0.4604731\ttotal: 846ms\tremaining: 94ms\n",
      "9:\tlearn: 0.4588202\ttotal: 954ms\tremaining: 0us\n",
      "[10, 0.3, 13, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.8ms\tremaining: 115ms\n",
      "1:\tlearn: 0.4776303\ttotal: 134ms\tremaining: 537ms\n",
      "2:\tlearn: 0.4735011\ttotal: 251ms\tremaining: 587ms\n",
      "3:\tlearn: 0.4707331\ttotal: 304ms\tremaining: 456ms\n",
      "4:\tlearn: 0.4669265\ttotal: 417ms\tremaining: 417ms\n",
      "5:\tlearn: 0.4646028\ttotal: 484ms\tremaining: 323ms\n",
      "6:\tlearn: 0.4634280\ttotal: 491ms\tremaining: 210ms\n",
      "7:\tlearn: 0.4620786\ttotal: 625ms\tremaining: 156ms\n",
      "8:\tlearn: 0.4604731\ttotal: 758ms\tremaining: 84.3ms\n",
      "9:\tlearn: 0.4588202\ttotal: 867ms\tremaining: 0us\n",
      "[10, 0.3, 13, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.4ms\tremaining: 112ms\n",
      "1:\tlearn: 0.4776303\ttotal: 127ms\tremaining: 508ms\n",
      "2:\tlearn: 0.4735011\ttotal: 232ms\tremaining: 542ms\n",
      "3:\tlearn: 0.4707331\ttotal: 296ms\tremaining: 444ms\n",
      "4:\tlearn: 0.4669265\ttotal: 449ms\tremaining: 449ms\n",
      "5:\tlearn: 0.4646028\ttotal: 508ms\tremaining: 339ms\n",
      "6:\tlearn: 0.4634280\ttotal: 517ms\tremaining: 222ms\n",
      "7:\tlearn: 0.4620786\ttotal: 622ms\tremaining: 155ms\n",
      "8:\tlearn: 0.4604731\ttotal: 735ms\tremaining: 81.6ms\n",
      "9:\tlearn: 0.4588202\ttotal: 879ms\tremaining: 0us\n",
      "[10, 0.3, 13, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.34ms\tremaining: 75.1ms\n",
      "1:\tlearn: 0.4776303\ttotal: 112ms\tremaining: 447ms\n",
      "2:\tlearn: 0.4735011\ttotal: 239ms\tremaining: 559ms\n",
      "3:\tlearn: 0.4707331\ttotal: 314ms\tremaining: 471ms\n",
      "4:\tlearn: 0.4669265\ttotal: 439ms\tremaining: 439ms\n",
      "5:\tlearn: 0.4646028\ttotal: 491ms\tremaining: 328ms\n",
      "6:\tlearn: 0.4634280\ttotal: 497ms\tremaining: 213ms\n",
      "7:\tlearn: 0.4620786\ttotal: 616ms\tremaining: 154ms\n",
      "8:\tlearn: 0.4604731\ttotal: 758ms\tremaining: 84.2ms\n",
      "9:\tlearn: 0.4588202\ttotal: 896ms\tremaining: 0us\n",
      "[10, 0.3, 13, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.29ms\tremaining: 74.6ms\n",
      "1:\tlearn: 0.4776303\ttotal: 139ms\tremaining: 557ms\n",
      "2:\tlearn: 0.4735011\ttotal: 280ms\tremaining: 654ms\n",
      "3:\tlearn: 0.4707331\ttotal: 341ms\tremaining: 511ms\n",
      "4:\tlearn: 0.4669265\ttotal: 449ms\tremaining: 449ms\n",
      "5:\tlearn: 0.4646028\ttotal: 505ms\tremaining: 336ms\n",
      "6:\tlearn: 0.4634280\ttotal: 512ms\tremaining: 219ms\n",
      "7:\tlearn: 0.4620786\ttotal: 654ms\tremaining: 163ms\n",
      "8:\tlearn: 0.4604731\ttotal: 774ms\tremaining: 86ms\n",
      "9:\tlearn: 0.4588202\ttotal: 881ms\tremaining: 0us\n",
      "[10, 0.8, 6, -0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 20.2ms\tremaining: 182ms\n",
      "1:\tlearn: 0.4707614\ttotal: 27.9ms\tremaining: 112ms\n",
      "2:\tlearn: 0.4667365\ttotal: 32.3ms\tremaining: 75.5ms\n",
      "3:\tlearn: 0.4636906\ttotal: 36.8ms\tremaining: 55.2ms\n",
      "4:\tlearn: 0.4617121\ttotal: 42.8ms\tremaining: 42.8ms\n",
      "5:\tlearn: 0.4596172\ttotal: 47.1ms\tremaining: 31.4ms\n",
      "6:\tlearn: 0.4582917\ttotal: 51.5ms\tremaining: 22.1ms\n",
      "7:\tlearn: 0.4560211\ttotal: 56.9ms\tremaining: 14.2ms\n",
      "8:\tlearn: 0.4544331\ttotal: 62ms\tremaining: 6.89ms\n",
      "9:\tlearn: 0.4536765\ttotal: 67.5ms\tremaining: 0us\n",
      "[10, 0.8, 6, 0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.43ms\tremaining: 39.9ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.42ms\tremaining: 33.7ms\n",
      "2:\tlearn: 0.4667365\ttotal: 12.5ms\tremaining: 29.2ms\n",
      "3:\tlearn: 0.4636906\ttotal: 19.2ms\tremaining: 28.8ms\n",
      "4:\tlearn: 0.4617121\ttotal: 23.5ms\tremaining: 23.5ms\n",
      "5:\tlearn: 0.4596172\ttotal: 27.9ms\tremaining: 18.6ms\n",
      "6:\tlearn: 0.4582917\ttotal: 32.7ms\tremaining: 14ms\n",
      "7:\tlearn: 0.4560211\ttotal: 37.2ms\tremaining: 9.31ms\n",
      "8:\tlearn: 0.4544331\ttotal: 41.5ms\tremaining: 4.61ms\n",
      "9:\tlearn: 0.4536765\ttotal: 46.2ms\tremaining: 0us\n",
      "[10, 0.8, 6, 0.0]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.7ms\tremaining: 42.3ms\n",
      "1:\tlearn: 0.4707614\ttotal: 9.53ms\tremaining: 38.1ms\n",
      "2:\tlearn: 0.4667365\ttotal: 13.8ms\tremaining: 32.2ms\n",
      "3:\tlearn: 0.4636906\ttotal: 18.3ms\tremaining: 27.4ms\n",
      "4:\tlearn: 0.4617121\ttotal: 23.3ms\tremaining: 23.3ms\n",
      "5:\tlearn: 0.4596172\ttotal: 27.3ms\tremaining: 18.2ms\n",
      "6:\tlearn: 0.4582917\ttotal: 31.2ms\tremaining: 13.4ms\n",
      "7:\tlearn: 0.4560211\ttotal: 35.1ms\tremaining: 8.77ms\n",
      "8:\tlearn: 0.4544331\ttotal: 39.1ms\tremaining: 4.35ms\n",
      "9:\tlearn: 0.4536765\ttotal: 43ms\tremaining: 0us\n",
      "[10, 0.8, 6, 0.15]\n",
      "0:\tlearn: 0.4762695\ttotal: 13.5ms\tremaining: 122ms\n",
      "1:\tlearn: 0.4707614\ttotal: 18.4ms\tremaining: 73.8ms\n",
      "2:\tlearn: 0.4667365\ttotal: 23.3ms\tremaining: 54.3ms\n",
      "3:\tlearn: 0.4636906\ttotal: 28.1ms\tremaining: 42.1ms\n",
      "4:\tlearn: 0.4617121\ttotal: 32.6ms\tremaining: 32.6ms\n",
      "5:\tlearn: 0.4596172\ttotal: 47.2ms\tremaining: 31.5ms\n",
      "6:\tlearn: 0.4582917\ttotal: 53.9ms\tremaining: 23.1ms\n",
      "7:\tlearn: 0.4560211\ttotal: 69.4ms\tremaining: 17.3ms\n",
      "8:\tlearn: 0.4544331\ttotal: 74.5ms\tremaining: 8.27ms\n",
      "9:\tlearn: 0.4536765\ttotal: 78.9ms\tremaining: 0us\n",
      "[10, 0.8, 6, 0.2]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.07ms\tremaining: 36.7ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.3ms\tremaining: 33.2ms\n",
      "2:\tlearn: 0.4667365\ttotal: 12.1ms\tremaining: 28.3ms\n",
      "3:\tlearn: 0.4636906\ttotal: 16.2ms\tremaining: 24.3ms\n",
      "4:\tlearn: 0.4617121\ttotal: 20.8ms\tremaining: 20.8ms\n",
      "5:\tlearn: 0.4596172\ttotal: 25.8ms\tremaining: 17.2ms\n",
      "6:\tlearn: 0.4582917\ttotal: 29.8ms\tremaining: 12.8ms\n",
      "7:\tlearn: 0.4560211\ttotal: 33.9ms\tremaining: 8.48ms\n",
      "8:\tlearn: 0.4544331\ttotal: 37.9ms\tremaining: 4.21ms\n",
      "9:\tlearn: 0.4536765\ttotal: 41.9ms\tremaining: 0us\n",
      "[10, 0.8, 15, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.3ms\tremaining: 92.3ms\n",
      "1:\tlearn: 0.4658921\ttotal: 526ms\tremaining: 2.1s\n",
      "2:\tlearn: 0.4614984\ttotal: 992ms\tremaining: 2.31s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.47s\tremaining: 2.2s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.93s\tremaining: 1.93s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.4s\tremaining: 1.6s\n",
      "6:\tlearn: 0.4499802\ttotal: 2.86s\tremaining: 1.22s\n",
      "7:\tlearn: 0.4479680\ttotal: 3.32s\tremaining: 830ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.79s\tremaining: 422ms\n",
      "9:\tlearn: 0.4420926\ttotal: 4.27s\tremaining: 0us\n",
      "[10, 0.8, 15, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.69ms\tremaining: 78.2ms\n",
      "1:\tlearn: 0.4658921\ttotal: 491ms\tremaining: 1.97s\n",
      "2:\tlearn: 0.4614984\ttotal: 960ms\tremaining: 2.24s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.43s\tremaining: 2.15s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.92s\tremaining: 1.92s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.39s\tremaining: 1.59s\n",
      "6:\tlearn: 0.4499802\ttotal: 2.86s\tremaining: 1.23s\n",
      "7:\tlearn: 0.4479680\ttotal: 3.33s\tremaining: 834ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.8s\tremaining: 422ms\n",
      "9:\tlearn: 0.4420926\ttotal: 4.27s\tremaining: 0us\n",
      "[10, 0.8, 15, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 11ms\tremaining: 98.8ms\n",
      "1:\tlearn: 0.4658921\ttotal: 498ms\tremaining: 1.99s\n",
      "2:\tlearn: 0.4614984\ttotal: 959ms\tremaining: 2.24s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.42s\tremaining: 2.13s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.91s\tremaining: 1.91s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.38s\tremaining: 1.59s\n",
      "6:\tlearn: 0.4499802\ttotal: 2.88s\tremaining: 1.24s\n",
      "7:\tlearn: 0.4479680\ttotal: 3.35s\tremaining: 838ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.83s\tremaining: 426ms\n",
      "9:\tlearn: 0.4420926\ttotal: 4.32s\tremaining: 0us\n",
      "[10, 0.8, 15, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 17.3ms\tremaining: 156ms\n",
      "1:\tlearn: 0.4658921\ttotal: 607ms\tremaining: 2.43s\n",
      "2:\tlearn: 0.4614984\ttotal: 1.07s\tremaining: 2.49s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.53s\tremaining: 2.29s\n",
      "4:\tlearn: 0.4540621\ttotal: 2s\tremaining: 2s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.48s\tremaining: 1.65s\n",
      "6:\tlearn: 0.4499802\ttotal: 2.97s\tremaining: 1.27s\n",
      "7:\tlearn: 0.4479680\ttotal: 3.45s\tremaining: 864ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.96s\tremaining: 440ms\n",
      "9:\tlearn: 0.4420926\ttotal: 4.42s\tremaining: 0us\n",
      "[10, 0.8, 15, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 16.3ms\tremaining: 147ms\n",
      "1:\tlearn: 0.4658921\ttotal: 485ms\tremaining: 1.94s\n",
      "2:\tlearn: 0.4614984\ttotal: 946ms\tremaining: 2.21s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.43s\tremaining: 2.14s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.92s\tremaining: 1.92s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.42s\tremaining: 1.61s\n",
      "6:\tlearn: 0.4499802\ttotal: 2.89s\tremaining: 1.24s\n",
      "7:\tlearn: 0.4479680\ttotal: 3.35s\tremaining: 839ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.8s\tremaining: 422ms\n",
      "9:\tlearn: 0.4420926\ttotal: 4.25s\tremaining: 0us\n",
      "[10, 0.8, 10, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.46ms\tremaining: 85.2ms\n",
      "1:\tlearn: 0.4684354\ttotal: 24.3ms\tremaining: 97.3ms\n",
      "2:\tlearn: 0.4642800\ttotal: 39.6ms\tremaining: 92.3ms\n",
      "3:\tlearn: 0.4627032\ttotal: 42.3ms\tremaining: 63.5ms\n",
      "4:\tlearn: 0.4607357\ttotal: 56.1ms\tremaining: 56.1ms\n",
      "5:\tlearn: 0.4583929\ttotal: 70.2ms\tremaining: 46.8ms\n",
      "6:\tlearn: 0.4565229\ttotal: 84.1ms\tremaining: 36ms\n",
      "7:\tlearn: 0.4531244\ttotal: 97.6ms\tremaining: 24.4ms\n",
      "8:\tlearn: 0.4517706\ttotal: 112ms\tremaining: 12.4ms\n",
      "9:\tlearn: 0.4491301\ttotal: 127ms\tremaining: 0us\n",
      "[10, 0.8, 10, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.8ms\tremaining: 106ms\n",
      "1:\tlearn: 0.4684354\ttotal: 26.9ms\tremaining: 108ms\n",
      "2:\tlearn: 0.4642800\ttotal: 42.3ms\tremaining: 98.6ms\n",
      "3:\tlearn: 0.4627032\ttotal: 45.4ms\tremaining: 68.2ms\n",
      "4:\tlearn: 0.4607357\ttotal: 61.2ms\tremaining: 61.2ms\n",
      "5:\tlearn: 0.4583929\ttotal: 77.7ms\tremaining: 51.8ms\n",
      "6:\tlearn: 0.4565229\ttotal: 91.8ms\tremaining: 39.3ms\n",
      "7:\tlearn: 0.4531244\ttotal: 107ms\tremaining: 26.7ms\n",
      "8:\tlearn: 0.4517706\ttotal: 121ms\tremaining: 13.5ms\n",
      "9:\tlearn: 0.4491301\ttotal: 135ms\tremaining: 0us\n",
      "[10, 0.8, 10, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.4684354\ttotal: 36.7ms\tremaining: 147ms\n",
      "2:\tlearn: 0.4642800\ttotal: 58.7ms\tremaining: 137ms\n",
      "3:\tlearn: 0.4627032\ttotal: 61.9ms\tremaining: 92.9ms\n",
      "4:\tlearn: 0.4607357\ttotal: 79ms\tremaining: 79ms\n",
      "5:\tlearn: 0.4583929\ttotal: 95.5ms\tremaining: 63.7ms\n",
      "6:\tlearn: 0.4565229\ttotal: 111ms\tremaining: 47.8ms\n",
      "7:\tlearn: 0.4531244\ttotal: 128ms\tremaining: 32.1ms\n",
      "8:\tlearn: 0.4517706\ttotal: 144ms\tremaining: 16ms\n",
      "9:\tlearn: 0.4491301\ttotal: 160ms\tremaining: 0us\n",
      "[10, 0.8, 10, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.7ms\tremaining: 105ms\n",
      "1:\tlearn: 0.4684354\ttotal: 27.4ms\tremaining: 110ms\n",
      "2:\tlearn: 0.4642800\ttotal: 43.3ms\tremaining: 101ms\n",
      "3:\tlearn: 0.4627032\ttotal: 46.4ms\tremaining: 69.6ms\n",
      "4:\tlearn: 0.4607357\ttotal: 73.5ms\tremaining: 73.5ms\n",
      "5:\tlearn: 0.4583929\ttotal: 92.9ms\tremaining: 62ms\n",
      "6:\tlearn: 0.4565229\ttotal: 131ms\tremaining: 56.2ms\n",
      "7:\tlearn: 0.4531244\ttotal: 159ms\tremaining: 39.7ms\n",
      "8:\tlearn: 0.4517706\ttotal: 186ms\tremaining: 20.7ms\n",
      "9:\tlearn: 0.4491301\ttotal: 202ms\tremaining: 0us\n",
      "[10, 0.8, 10, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.79ms\tremaining: 79.2ms\n",
      "1:\tlearn: 0.4684354\ttotal: 24.3ms\tremaining: 97.1ms\n",
      "2:\tlearn: 0.4642800\ttotal: 44ms\tremaining: 103ms\n",
      "3:\tlearn: 0.4627032\ttotal: 47ms\tremaining: 70.5ms\n",
      "4:\tlearn: 0.4607357\ttotal: 62ms\tremaining: 62ms\n",
      "5:\tlearn: 0.4583929\ttotal: 82.3ms\tremaining: 54.9ms\n",
      "6:\tlearn: 0.4565229\ttotal: 98ms\tremaining: 42ms\n",
      "7:\tlearn: 0.4531244\ttotal: 119ms\tremaining: 29.8ms\n",
      "8:\tlearn: 0.4517706\ttotal: 136ms\tremaining: 15.1ms\n",
      "9:\tlearn: 0.4491301\ttotal: 164ms\tremaining: 0us\n",
      "[10, 0.8, 8, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.75ms\tremaining: 60.8ms\n",
      "1:\tlearn: 0.4682512\ttotal: 13.2ms\tremaining: 52.9ms\n",
      "2:\tlearn: 0.4650605\ttotal: 20.3ms\tremaining: 47.3ms\n",
      "3:\tlearn: 0.4630741\ttotal: 26.7ms\tremaining: 40.1ms\n",
      "4:\tlearn: 0.4600410\ttotal: 33.2ms\tremaining: 33.2ms\n",
      "5:\tlearn: 0.4577069\ttotal: 39.6ms\tremaining: 26.4ms\n",
      "6:\tlearn: 0.4559546\ttotal: 45.9ms\tremaining: 19.7ms\n",
      "7:\tlearn: 0.4543265\ttotal: 52.4ms\tremaining: 13.1ms\n",
      "8:\tlearn: 0.4528626\ttotal: 58.8ms\tremaining: 6.53ms\n",
      "9:\tlearn: 0.4519920\ttotal: 65.1ms\tremaining: 0us\n",
      "[10, 0.8, 8, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.06ms\tremaining: 72.5ms\n",
      "1:\tlearn: 0.4682512\ttotal: 15.6ms\tremaining: 62.5ms\n",
      "2:\tlearn: 0.4650605\ttotal: 22.5ms\tremaining: 52.6ms\n",
      "3:\tlearn: 0.4630741\ttotal: 28.9ms\tremaining: 43.4ms\n",
      "4:\tlearn: 0.4600410\ttotal: 35.5ms\tremaining: 35.5ms\n",
      "5:\tlearn: 0.4577069\ttotal: 41.9ms\tremaining: 27.9ms\n",
      "6:\tlearn: 0.4559546\ttotal: 48.4ms\tremaining: 20.7ms\n",
      "7:\tlearn: 0.4543265\ttotal: 55ms\tremaining: 13.8ms\n",
      "8:\tlearn: 0.4528626\ttotal: 61.5ms\tremaining: 6.83ms\n",
      "9:\tlearn: 0.4519920\ttotal: 68.3ms\tremaining: 0us\n",
      "[10, 0.8, 8, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 26.3ms\tremaining: 237ms\n",
      "1:\tlearn: 0.4682512\ttotal: 34.1ms\tremaining: 136ms\n",
      "2:\tlearn: 0.4650605\ttotal: 41.4ms\tremaining: 96.5ms\n",
      "3:\tlearn: 0.4630741\ttotal: 52ms\tremaining: 78ms\n",
      "4:\tlearn: 0.4600410\ttotal: 59.4ms\tremaining: 59.4ms\n",
      "5:\tlearn: 0.4577069\ttotal: 67.3ms\tremaining: 44.9ms\n",
      "6:\tlearn: 0.4559546\ttotal: 74.3ms\tremaining: 31.8ms\n",
      "7:\tlearn: 0.4543265\ttotal: 81.7ms\tremaining: 20.4ms\n",
      "8:\tlearn: 0.4528626\ttotal: 88.8ms\tremaining: 9.87ms\n",
      "9:\tlearn: 0.4519920\ttotal: 95.7ms\tremaining: 0us\n",
      "[10, 0.8, 8, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.58ms\tremaining: 59.2ms\n",
      "1:\tlearn: 0.4682512\ttotal: 14.1ms\tremaining: 56.4ms\n",
      "2:\tlearn: 0.4650605\ttotal: 20.8ms\tremaining: 48.6ms\n",
      "3:\tlearn: 0.4630741\ttotal: 27.7ms\tremaining: 41.6ms\n",
      "4:\tlearn: 0.4600410\ttotal: 35ms\tremaining: 35ms\n",
      "5:\tlearn: 0.4577069\ttotal: 42.6ms\tremaining: 28.4ms\n",
      "6:\tlearn: 0.4559546\ttotal: 49.8ms\tremaining: 21.3ms\n",
      "7:\tlearn: 0.4543265\ttotal: 56.6ms\tremaining: 14.2ms\n",
      "8:\tlearn: 0.4528626\ttotal: 63.5ms\tremaining: 7.05ms\n",
      "9:\tlearn: 0.4519920\ttotal: 70.5ms\tremaining: 0us\n",
      "[10, 0.8, 8, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.11ms\tremaining: 82ms\n",
      "1:\tlearn: 0.4682512\ttotal: 16.5ms\tremaining: 66ms\n",
      "2:\tlearn: 0.4650605\ttotal: 23.7ms\tremaining: 55.4ms\n",
      "3:\tlearn: 0.4630741\ttotal: 30.7ms\tremaining: 46ms\n",
      "4:\tlearn: 0.4600410\ttotal: 38.7ms\tremaining: 38.7ms\n",
      "5:\tlearn: 0.4577069\ttotal: 45.6ms\tremaining: 30.4ms\n",
      "6:\tlearn: 0.4559546\ttotal: 51.9ms\tremaining: 22.2ms\n",
      "7:\tlearn: 0.4543265\ttotal: 58.5ms\tremaining: 14.6ms\n",
      "8:\tlearn: 0.4528626\ttotal: 64.9ms\tremaining: 7.21ms\n",
      "9:\tlearn: 0.4519920\ttotal: 71.3ms\tremaining: 0us\n",
      "[10, 0.8, 7, -0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 10.8ms\tremaining: 97ms\n",
      "1:\tlearn: 0.4687965\ttotal: 16.1ms\tremaining: 64.5ms\n",
      "2:\tlearn: 0.4653862\ttotal: 21.6ms\tremaining: 50.4ms\n",
      "3:\tlearn: 0.4622296\ttotal: 32.3ms\tremaining: 48.5ms\n",
      "4:\tlearn: 0.4598883\ttotal: 39.7ms\tremaining: 39.7ms\n",
      "5:\tlearn: 0.4581321\ttotal: 51.9ms\tremaining: 34.6ms\n",
      "6:\tlearn: 0.4567709\ttotal: 88.9ms\tremaining: 38.1ms\n",
      "7:\tlearn: 0.4533516\ttotal: 95.1ms\tremaining: 23.8ms\n",
      "8:\tlearn: 0.4517451\ttotal: 101ms\tremaining: 11.2ms\n",
      "9:\tlearn: 0.4504957\ttotal: 108ms\tremaining: 0us\n",
      "[10, 0.8, 7, 0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.37ms\tremaining: 48.4ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.6ms\tremaining: 42.5ms\n",
      "2:\tlearn: 0.4653862\ttotal: 15.7ms\tremaining: 36.7ms\n",
      "3:\tlearn: 0.4622296\ttotal: 21.3ms\tremaining: 32ms\n",
      "4:\tlearn: 0.4598883\ttotal: 26.6ms\tremaining: 26.6ms\n",
      "5:\tlearn: 0.4581321\ttotal: 31.8ms\tremaining: 21.2ms\n",
      "6:\tlearn: 0.4567709\ttotal: 37.4ms\tremaining: 16ms\n",
      "7:\tlearn: 0.4533516\ttotal: 42.5ms\tremaining: 10.6ms\n",
      "8:\tlearn: 0.4517451\ttotal: 47.8ms\tremaining: 5.31ms\n",
      "9:\tlearn: 0.4504957\ttotal: 52.9ms\tremaining: 0us\n",
      "[10, 0.8, 7, 0.0]\n",
      "0:\tlearn: 0.4762583\ttotal: 7.09ms\tremaining: 63.9ms\n",
      "1:\tlearn: 0.4687965\ttotal: 12.7ms\tremaining: 50.7ms\n",
      "2:\tlearn: 0.4653862\ttotal: 18.1ms\tremaining: 42.2ms\n",
      "3:\tlearn: 0.4622296\ttotal: 23.9ms\tremaining: 35.9ms\n",
      "4:\tlearn: 0.4598883\ttotal: 29ms\tremaining: 29ms\n",
      "5:\tlearn: 0.4581321\ttotal: 34ms\tremaining: 22.6ms\n",
      "6:\tlearn: 0.4567709\ttotal: 39.3ms\tremaining: 16.8ms\n",
      "7:\tlearn: 0.4533516\ttotal: 44.7ms\tremaining: 11.2ms\n",
      "8:\tlearn: 0.4517451\ttotal: 49.8ms\tremaining: 5.54ms\n",
      "9:\tlearn: 0.4504957\ttotal: 55ms\tremaining: 0us\n",
      "[10, 0.8, 7, 0.15]\n",
      "0:\tlearn: 0.4762583\ttotal: 30.1ms\tremaining: 271ms\n",
      "1:\tlearn: 0.4687965\ttotal: 35.4ms\tremaining: 141ms\n",
      "2:\tlearn: 0.4653862\ttotal: 45.6ms\tremaining: 106ms\n",
      "3:\tlearn: 0.4622296\ttotal: 54.6ms\tremaining: 81.9ms\n",
      "4:\tlearn: 0.4598883\ttotal: 62.1ms\tremaining: 62.1ms\n",
      "5:\tlearn: 0.4581321\ttotal: 72.7ms\tremaining: 48.4ms\n",
      "6:\tlearn: 0.4567709\ttotal: 78.6ms\tremaining: 33.7ms\n",
      "7:\tlearn: 0.4533516\ttotal: 84.6ms\tremaining: 21.1ms\n",
      "8:\tlearn: 0.4517451\ttotal: 90.1ms\tremaining: 10ms\n",
      "9:\tlearn: 0.4504957\ttotal: 97.6ms\tremaining: 0us\n",
      "[10, 0.8, 7, 0.2]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.11ms\tremaining: 46ms\n",
      "1:\tlearn: 0.4687965\ttotal: 11.8ms\tremaining: 47.2ms\n",
      "2:\tlearn: 0.4653862\ttotal: 17.1ms\tremaining: 39.9ms\n",
      "3:\tlearn: 0.4622296\ttotal: 22.4ms\tremaining: 33.6ms\n",
      "4:\tlearn: 0.4598883\ttotal: 27.9ms\tremaining: 27.9ms\n",
      "5:\tlearn: 0.4581321\ttotal: 33.5ms\tremaining: 22.4ms\n",
      "6:\tlearn: 0.4567709\ttotal: 39.4ms\tremaining: 16.9ms\n",
      "7:\tlearn: 0.4533516\ttotal: 45.4ms\tremaining: 11.3ms\n",
      "8:\tlearn: 0.4517451\ttotal: 51.7ms\tremaining: 5.75ms\n",
      "9:\tlearn: 0.4504957\ttotal: 57ms\tremaining: 0us\n",
      "[10, 0.55, 6, -0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 6.96ms\tremaining: 62.6ms\n",
      "1:\tlearn: 0.4730186\ttotal: 11.6ms\tremaining: 46.3ms\n",
      "2:\tlearn: 0.4702860\ttotal: 15.7ms\tremaining: 36.6ms\n",
      "3:\tlearn: 0.4675422\ttotal: 20.1ms\tremaining: 30.1ms\n",
      "4:\tlearn: 0.4655547\ttotal: 24.7ms\tremaining: 24.7ms\n",
      "5:\tlearn: 0.4641129\ttotal: 29.1ms\tremaining: 19.4ms\n",
      "6:\tlearn: 0.4622549\ttotal: 33.1ms\tremaining: 14.2ms\n",
      "7:\tlearn: 0.4607061\ttotal: 37ms\tremaining: 9.26ms\n",
      "8:\tlearn: 0.4594070\ttotal: 40.9ms\tremaining: 4.54ms\n",
      "9:\tlearn: 0.4583881\ttotal: 44.7ms\tremaining: 0us\n",
      "[10, 0.55, 6, 0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.32ms\tremaining: 38.9ms\n",
      "1:\tlearn: 0.4730186\ttotal: 8.41ms\tremaining: 33.6ms\n",
      "2:\tlearn: 0.4702860\ttotal: 12.4ms\tremaining: 29ms\n",
      "3:\tlearn: 0.4675422\ttotal: 16.7ms\tremaining: 25ms\n",
      "4:\tlearn: 0.4655547\ttotal: 20.9ms\tremaining: 20.9ms\n",
      "5:\tlearn: 0.4641129\ttotal: 25.1ms\tremaining: 16.7ms\n",
      "6:\tlearn: 0.4622549\ttotal: 30.8ms\tremaining: 13.2ms\n",
      "7:\tlearn: 0.4607061\ttotal: 35.2ms\tremaining: 8.8ms\n",
      "8:\tlearn: 0.4594070\ttotal: 39.5ms\tremaining: 4.39ms\n",
      "9:\tlearn: 0.4583881\ttotal: 43.7ms\tremaining: 0us\n",
      "[10, 0.55, 6, 0.0]\n",
      "0:\tlearn: 0.4795967\ttotal: 7.07ms\tremaining: 63.6ms\n",
      "1:\tlearn: 0.4730186\ttotal: 11.1ms\tremaining: 44.6ms\n",
      "2:\tlearn: 0.4702860\ttotal: 16.3ms\tremaining: 38ms\n",
      "3:\tlearn: 0.4675422\ttotal: 20.8ms\tremaining: 31.2ms\n",
      "4:\tlearn: 0.4655547\ttotal: 25ms\tremaining: 25ms\n",
      "5:\tlearn: 0.4641129\ttotal: 29.6ms\tremaining: 19.8ms\n",
      "6:\tlearn: 0.4622549\ttotal: 34.1ms\tremaining: 14.6ms\n",
      "7:\tlearn: 0.4607061\ttotal: 38.2ms\tremaining: 9.55ms\n",
      "8:\tlearn: 0.4594070\ttotal: 42.1ms\tremaining: 4.68ms\n",
      "9:\tlearn: 0.4583881\ttotal: 46ms\tremaining: 0us\n",
      "[10, 0.55, 6, 0.15]\n",
      "0:\tlearn: 0.4795967\ttotal: 17ms\tremaining: 153ms\n",
      "1:\tlearn: 0.4730186\ttotal: 21.4ms\tremaining: 85.8ms\n",
      "2:\tlearn: 0.4702860\ttotal: 25.9ms\tremaining: 60.5ms\n",
      "3:\tlearn: 0.4675422\ttotal: 30.3ms\tremaining: 45.5ms\n",
      "4:\tlearn: 0.4655547\ttotal: 34.8ms\tremaining: 34.8ms\n",
      "5:\tlearn: 0.4641129\ttotal: 39.3ms\tremaining: 26.2ms\n",
      "6:\tlearn: 0.4622549\ttotal: 44ms\tremaining: 18.8ms\n",
      "7:\tlearn: 0.4607061\ttotal: 48.4ms\tremaining: 12.1ms\n",
      "8:\tlearn: 0.4594070\ttotal: 53ms\tremaining: 5.89ms\n",
      "9:\tlearn: 0.4583881\ttotal: 59.8ms\tremaining: 0us\n",
      "[10, 0.55, 6, 0.2]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.31ms\tremaining: 38.8ms\n",
      "1:\tlearn: 0.4730186\ttotal: 8.12ms\tremaining: 32.5ms\n",
      "2:\tlearn: 0.4702860\ttotal: 12ms\tremaining: 28.1ms\n",
      "3:\tlearn: 0.4675422\ttotal: 16ms\tremaining: 24ms\n",
      "4:\tlearn: 0.4655547\ttotal: 19.9ms\tremaining: 19.9ms\n",
      "5:\tlearn: 0.4641129\ttotal: 23.8ms\tremaining: 15.8ms\n",
      "6:\tlearn: 0.4622549\ttotal: 27.6ms\tremaining: 11.8ms\n",
      "7:\tlearn: 0.4607061\ttotal: 31.5ms\tremaining: 7.88ms\n",
      "8:\tlearn: 0.4594070\ttotal: 35.4ms\tremaining: 3.93ms\n",
      "9:\tlearn: 0.4583881\ttotal: 39.3ms\tremaining: 0us\n",
      "[10, 0.55, 15, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 14.6ms\tremaining: 132ms\n",
      "1:\tlearn: 0.4689110\ttotal: 468ms\tremaining: 1.87s\n",
      "2:\tlearn: 0.4640795\ttotal: 926ms\tremaining: 2.16s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.38s\tremaining: 2.07s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.89s\tremaining: 1.89s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.42s\tremaining: 1.61s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.89s\tremaining: 1.24s\n",
      "7:\tlearn: 0.4509348\ttotal: 3.35s\tremaining: 838ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.83s\tremaining: 425ms\n",
      "9:\tlearn: 0.4465806\ttotal: 4.31s\tremaining: 0us\n",
      "[10, 0.55, 15, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.79ms\tremaining: 88.1ms\n",
      "1:\tlearn: 0.4689110\ttotal: 529ms\tremaining: 2.11s\n",
      "2:\tlearn: 0.4640795\ttotal: 1s\tremaining: 2.33s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.48s\tremaining: 2.22s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.97s\tremaining: 1.97s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.43s\tremaining: 1.62s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.92s\tremaining: 1.25s\n",
      "7:\tlearn: 0.4509348\ttotal: 3.4s\tremaining: 850ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.85s\tremaining: 428ms\n",
      "9:\tlearn: 0.4465806\ttotal: 4.33s\tremaining: 0us\n",
      "[10, 0.55, 15, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 11.3ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4689110\ttotal: 476ms\tremaining: 1.91s\n",
      "2:\tlearn: 0.4640795\ttotal: 986ms\tremaining: 2.3s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.46s\tremaining: 2.19s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.96s\tremaining: 1.96s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.45s\tremaining: 1.64s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.92s\tremaining: 1.25s\n",
      "7:\tlearn: 0.4509348\ttotal: 3.4s\tremaining: 849ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.87s\tremaining: 430ms\n",
      "9:\tlearn: 0.4465806\ttotal: 4.34s\tremaining: 0us\n",
      "[10, 0.55, 15, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 10ms\tremaining: 90.3ms\n",
      "1:\tlearn: 0.4689110\ttotal: 465ms\tremaining: 1.86s\n",
      "2:\tlearn: 0.4640795\ttotal: 942ms\tremaining: 2.2s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.43s\tremaining: 2.14s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.92s\tremaining: 1.92s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.42s\tremaining: 1.61s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.87s\tremaining: 1.23s\n",
      "7:\tlearn: 0.4509348\ttotal: 3.33s\tremaining: 833ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.78s\tremaining: 421ms\n",
      "9:\tlearn: 0.4465806\ttotal: 4.23s\tremaining: 0us\n",
      "[10, 0.55, 15, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.83ms\tremaining: 88.5ms\n",
      "1:\tlearn: 0.4689110\ttotal: 463ms\tremaining: 1.85s\n",
      "2:\tlearn: 0.4640795\ttotal: 935ms\tremaining: 2.18s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.39s\tremaining: 2.08s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.83s\tremaining: 1.83s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.31s\tremaining: 1.54s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.79s\tremaining: 1.19s\n",
      "7:\tlearn: 0.4509348\ttotal: 3.25s\tremaining: 812ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.74s\tremaining: 415ms\n",
      "9:\tlearn: 0.4465806\ttotal: 4.2s\tremaining: 0us\n",
      "[10, 0.55, 10, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.07ms\tremaining: 81.6ms\n",
      "1:\tlearn: 0.4715198\ttotal: 27.1ms\tremaining: 108ms\n",
      "2:\tlearn: 0.4676485\ttotal: 43.8ms\tremaining: 102ms\n",
      "3:\tlearn: 0.4663151\ttotal: 46.9ms\tremaining: 70.4ms\n",
      "4:\tlearn: 0.4641480\ttotal: 61.7ms\tremaining: 61.7ms\n",
      "5:\tlearn: 0.4609741\ttotal: 75.1ms\tremaining: 50ms\n",
      "6:\tlearn: 0.4590071\ttotal: 89ms\tremaining: 38.1ms\n",
      "7:\tlearn: 0.4568040\ttotal: 104ms\tremaining: 25.9ms\n",
      "8:\tlearn: 0.4556349\ttotal: 119ms\tremaining: 13.2ms\n",
      "9:\tlearn: 0.4545201\ttotal: 123ms\tremaining: 0us\n",
      "[10, 0.55, 10, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 13ms\tremaining: 117ms\n",
      "1:\tlearn: 0.4715198\ttotal: 28.5ms\tremaining: 114ms\n",
      "2:\tlearn: 0.4676485\ttotal: 44.2ms\tremaining: 103ms\n",
      "3:\tlearn: 0.4663151\ttotal: 48.3ms\tremaining: 72.4ms\n",
      "4:\tlearn: 0.4641480\ttotal: 67.4ms\tremaining: 67.4ms\n",
      "5:\tlearn: 0.4609741\ttotal: 84.5ms\tremaining: 56.4ms\n",
      "6:\tlearn: 0.4590071\ttotal: 99.7ms\tremaining: 42.7ms\n",
      "7:\tlearn: 0.4568040\ttotal: 116ms\tremaining: 29ms\n",
      "8:\tlearn: 0.4556349\ttotal: 130ms\tremaining: 14.5ms\n",
      "9:\tlearn: 0.4545201\ttotal: 134ms\tremaining: 0us\n",
      "[10, 0.55, 10, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 15.2ms\tremaining: 137ms\n",
      "1:\tlearn: 0.4715198\ttotal: 44.6ms\tremaining: 179ms\n",
      "2:\tlearn: 0.4676485\ttotal: 76.7ms\tremaining: 179ms\n",
      "3:\tlearn: 0.4663151\ttotal: 84.2ms\tremaining: 126ms\n",
      "4:\tlearn: 0.4641480\ttotal: 108ms\tremaining: 108ms\n",
      "5:\tlearn: 0.4609741\ttotal: 123ms\tremaining: 82.2ms\n",
      "6:\tlearn: 0.4590071\ttotal: 139ms\tremaining: 59.8ms\n",
      "7:\tlearn: 0.4568040\ttotal: 154ms\tremaining: 38.6ms\n",
      "8:\tlearn: 0.4556349\ttotal: 170ms\tremaining: 18.9ms\n",
      "9:\tlearn: 0.4545201\ttotal: 174ms\tremaining: 0us\n",
      "[10, 0.55, 10, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.85ms\tremaining: 79.6ms\n",
      "1:\tlearn: 0.4715198\ttotal: 24.2ms\tremaining: 96.7ms\n",
      "2:\tlearn: 0.4676485\ttotal: 77.1ms\tremaining: 180ms\n",
      "3:\tlearn: 0.4663151\ttotal: 80.3ms\tremaining: 120ms\n",
      "4:\tlearn: 0.4641480\ttotal: 99.1ms\tremaining: 99.1ms\n",
      "5:\tlearn: 0.4609741\ttotal: 116ms\tremaining: 77.3ms\n",
      "6:\tlearn: 0.4590071\ttotal: 132ms\tremaining: 56.6ms\n",
      "7:\tlearn: 0.4568040\ttotal: 149ms\tremaining: 37.2ms\n",
      "8:\tlearn: 0.4556349\ttotal: 165ms\tremaining: 18.3ms\n",
      "9:\tlearn: 0.4545201\ttotal: 169ms\tremaining: 0us\n",
      "[10, 0.55, 10, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.73ms\tremaining: 78.5ms\n",
      "1:\tlearn: 0.4715198\ttotal: 23.6ms\tremaining: 94.6ms\n",
      "2:\tlearn: 0.4676485\ttotal: 40.7ms\tremaining: 95.1ms\n",
      "3:\tlearn: 0.4663151\ttotal: 43.8ms\tremaining: 65.7ms\n",
      "4:\tlearn: 0.4641480\ttotal: 59.5ms\tremaining: 59.5ms\n",
      "5:\tlearn: 0.4609741\ttotal: 74.9ms\tremaining: 50ms\n",
      "6:\tlearn: 0.4590071\ttotal: 90.6ms\tremaining: 38.8ms\n",
      "7:\tlearn: 0.4568040\ttotal: 106ms\tremaining: 26.4ms\n",
      "8:\tlearn: 0.4556349\ttotal: 125ms\tremaining: 13.9ms\n",
      "9:\tlearn: 0.4545201\ttotal: 134ms\tremaining: 0us\n",
      "[10, 0.55, 12, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.39ms\tremaining: 75.5ms\n",
      "1:\tlearn: 0.4704514\ttotal: 60.4ms\tremaining: 242ms\n",
      "2:\tlearn: 0.4668875\ttotal: 113ms\tremaining: 265ms\n",
      "3:\tlearn: 0.4641234\ttotal: 173ms\tremaining: 259ms\n",
      "4:\tlearn: 0.4616543\ttotal: 245ms\tremaining: 245ms\n",
      "5:\tlearn: 0.4587449\ttotal: 327ms\tremaining: 218ms\n",
      "6:\tlearn: 0.4567311\ttotal: 387ms\tremaining: 166ms\n",
      "7:\tlearn: 0.4540933\ttotal: 448ms\tremaining: 112ms\n",
      "8:\tlearn: 0.4532213\ttotal: 503ms\tremaining: 55.9ms\n",
      "9:\tlearn: 0.4517772\ttotal: 568ms\tremaining: 0us\n",
      "[10, 0.55, 12, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.4ms\tremaining: 93.6ms\n",
      "1:\tlearn: 0.4704514\ttotal: 67.1ms\tremaining: 268ms\n",
      "2:\tlearn: 0.4668875\ttotal: 120ms\tremaining: 281ms\n",
      "3:\tlearn: 0.4641234\ttotal: 178ms\tremaining: 268ms\n",
      "4:\tlearn: 0.4616543\ttotal: 239ms\tremaining: 239ms\n",
      "5:\tlearn: 0.4587449\ttotal: 316ms\tremaining: 211ms\n",
      "6:\tlearn: 0.4567311\ttotal: 382ms\tremaining: 164ms\n",
      "7:\tlearn: 0.4540933\ttotal: 440ms\tremaining: 110ms\n",
      "8:\tlearn: 0.4532213\ttotal: 491ms\tremaining: 54.6ms\n",
      "9:\tlearn: 0.4517772\ttotal: 553ms\tremaining: 0us\n",
      "[10, 0.55, 12, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.77ms\tremaining: 87.9ms\n",
      "1:\tlearn: 0.4704514\ttotal: 61.9ms\tremaining: 248ms\n",
      "2:\tlearn: 0.4668875\ttotal: 114ms\tremaining: 266ms\n",
      "3:\tlearn: 0.4641234\ttotal: 168ms\tremaining: 252ms\n",
      "4:\tlearn: 0.4616543\ttotal: 240ms\tremaining: 240ms\n",
      "5:\tlearn: 0.4587449\ttotal: 324ms\tremaining: 216ms\n",
      "6:\tlearn: 0.4567311\ttotal: 386ms\tremaining: 165ms\n",
      "7:\tlearn: 0.4540933\ttotal: 450ms\tremaining: 112ms\n",
      "8:\tlearn: 0.4532213\ttotal: 501ms\tremaining: 55.7ms\n",
      "9:\tlearn: 0.4517772\ttotal: 553ms\tremaining: 0us\n",
      "[10, 0.55, 12, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.8ms\tremaining: 116ms\n",
      "1:\tlearn: 0.4704514\ttotal: 71.9ms\tremaining: 288ms\n",
      "2:\tlearn: 0.4668875\ttotal: 126ms\tremaining: 294ms\n",
      "3:\tlearn: 0.4641234\ttotal: 177ms\tremaining: 266ms\n",
      "4:\tlearn: 0.4616543\ttotal: 232ms\tremaining: 232ms\n",
      "5:\tlearn: 0.4587449\ttotal: 300ms\tremaining: 200ms\n",
      "6:\tlearn: 0.4567311\ttotal: 378ms\tremaining: 162ms\n",
      "7:\tlearn: 0.4540933\ttotal: 439ms\tremaining: 110ms\n",
      "8:\tlearn: 0.4532213\ttotal: 502ms\tremaining: 55.7ms\n",
      "9:\tlearn: 0.4517772\ttotal: 562ms\tremaining: 0us\n",
      "[10, 0.55, 12, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 23.4ms\tremaining: 211ms\n",
      "1:\tlearn: 0.4704514\ttotal: 91.4ms\tremaining: 366ms\n",
      "2:\tlearn: 0.4668875\ttotal: 153ms\tremaining: 357ms\n",
      "3:\tlearn: 0.4641234\ttotal: 207ms\tremaining: 311ms\n",
      "4:\tlearn: 0.4616543\ttotal: 263ms\tremaining: 263ms\n",
      "5:\tlearn: 0.4587449\ttotal: 316ms\tremaining: 211ms\n",
      "6:\tlearn: 0.4567311\ttotal: 374ms\tremaining: 160ms\n",
      "7:\tlearn: 0.4540933\ttotal: 439ms\tremaining: 110ms\n",
      "8:\tlearn: 0.4532213\ttotal: 513ms\tremaining: 57ms\n",
      "9:\tlearn: 0.4517772\ttotal: 577ms\tremaining: 0us\n",
      "[10, 0.55, 13, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 14.6ms\tremaining: 131ms\n",
      "1:\tlearn: 0.4700386\ttotal: 156ms\tremaining: 624ms\n",
      "2:\tlearn: 0.4651124\ttotal: 293ms\tremaining: 683ms\n",
      "3:\tlearn: 0.4623159\ttotal: 409ms\tremaining: 614ms\n",
      "4:\tlearn: 0.4590456\ttotal: 460ms\tremaining: 460ms\n",
      "5:\tlearn: 0.4565869\ttotal: 591ms\tremaining: 394ms\n",
      "6:\tlearn: 0.4540567\ttotal: 735ms\tremaining: 315ms\n",
      "7:\tlearn: 0.4522890\ttotal: 854ms\tremaining: 214ms\n",
      "8:\tlearn: 0.4507350\ttotal: 893ms\tremaining: 99.2ms\n",
      "9:\tlearn: 0.4489248\ttotal: 1s\tremaining: 0us\n",
      "[10, 0.55, 13, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.4ms\tremaining: 93.9ms\n",
      "1:\tlearn: 0.4700386\ttotal: 126ms\tremaining: 504ms\n",
      "2:\tlearn: 0.4651124\ttotal: 235ms\tremaining: 549ms\n",
      "3:\tlearn: 0.4623159\ttotal: 346ms\tremaining: 519ms\n",
      "4:\tlearn: 0.4590456\ttotal: 431ms\tremaining: 431ms\n",
      "5:\tlearn: 0.4565869\ttotal: 584ms\tremaining: 389ms\n",
      "6:\tlearn: 0.4540567\ttotal: 698ms\tremaining: 299ms\n",
      "7:\tlearn: 0.4522890\ttotal: 804ms\tremaining: 201ms\n",
      "8:\tlearn: 0.4507350\ttotal: 833ms\tremaining: 92.6ms\n",
      "9:\tlearn: 0.4489248\ttotal: 986ms\tremaining: 0us\n",
      "[10, 0.55, 13, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.52ms\tremaining: 85.7ms\n",
      "1:\tlearn: 0.4700386\ttotal: 129ms\tremaining: 516ms\n",
      "2:\tlearn: 0.4651124\ttotal: 269ms\tremaining: 627ms\n",
      "3:\tlearn: 0.4623159\ttotal: 378ms\tremaining: 567ms\n",
      "4:\tlearn: 0.4590456\ttotal: 430ms\tremaining: 430ms\n",
      "5:\tlearn: 0.4565869\ttotal: 549ms\tremaining: 366ms\n",
      "6:\tlearn: 0.4540567\ttotal: 720ms\tremaining: 309ms\n",
      "7:\tlearn: 0.4522890\ttotal: 847ms\tremaining: 212ms\n",
      "8:\tlearn: 0.4507350\ttotal: 876ms\tremaining: 97.3ms\n",
      "9:\tlearn: 0.4489248\ttotal: 982ms\tremaining: 0us\n",
      "[10, 0.55, 13, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.7ms\tremaining: 96.4ms\n",
      "1:\tlearn: 0.4700386\ttotal: 129ms\tremaining: 517ms\n",
      "2:\tlearn: 0.4651124\ttotal: 246ms\tremaining: 575ms\n",
      "3:\tlearn: 0.4623159\ttotal: 353ms\tremaining: 529ms\n",
      "4:\tlearn: 0.4590456\ttotal: 415ms\tremaining: 415ms\n",
      "5:\tlearn: 0.4565869\ttotal: 578ms\tremaining: 385ms\n",
      "6:\tlearn: 0.4540567\ttotal: 698ms\tremaining: 299ms\n",
      "7:\tlearn: 0.4522890\ttotal: 814ms\tremaining: 203ms\n",
      "8:\tlearn: 0.4507350\ttotal: 843ms\tremaining: 93.7ms\n",
      "9:\tlearn: 0.4489248\ttotal: 989ms\tremaining: 0us\n",
      "[10, 0.55, 13, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.75ms\tremaining: 78.7ms\n",
      "1:\tlearn: 0.4700386\ttotal: 125ms\tremaining: 502ms\n",
      "2:\tlearn: 0.4651124\ttotal: 264ms\tremaining: 616ms\n",
      "3:\tlearn: 0.4623159\ttotal: 392ms\tremaining: 588ms\n",
      "4:\tlearn: 0.4590456\ttotal: 447ms\tremaining: 447ms\n",
      "5:\tlearn: 0.4565869\ttotal: 553ms\tremaining: 369ms\n",
      "6:\tlearn: 0.4540567\ttotal: 664ms\tremaining: 284ms\n",
      "7:\tlearn: 0.4522890\ttotal: 817ms\tremaining: 204ms\n",
      "8:\tlearn: 0.4507350\ttotal: 852ms\tremaining: 94.7ms\n",
      "9:\tlearn: 0.4489248\ttotal: 968ms\tremaining: 0us\n",
      "[10, 0.42, 6, -0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.51ms\tremaining: 40.6ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.33ms\tremaining: 37.3ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13.9ms\tremaining: 32.3ms\n",
      "3:\tlearn: 0.4709457\ttotal: 18.2ms\tremaining: 27.3ms\n",
      "4:\tlearn: 0.4690547\ttotal: 22.7ms\tremaining: 22.7ms\n",
      "5:\tlearn: 0.4668601\ttotal: 27.1ms\tremaining: 18.1ms\n",
      "6:\tlearn: 0.4648543\ttotal: 31.4ms\tremaining: 13.5ms\n",
      "7:\tlearn: 0.4633314\ttotal: 45.7ms\tremaining: 11.4ms\n",
      "8:\tlearn: 0.4622989\ttotal: 50.1ms\tremaining: 5.57ms\n",
      "9:\tlearn: 0.4615122\ttotal: 58.4ms\tremaining: 0us\n",
      "[10, 0.42, 6, 0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.12ms\tremaining: 37.1ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.66ms\tremaining: 34.7ms\n",
      "2:\tlearn: 0.4730150\ttotal: 12.5ms\tremaining: 29.2ms\n",
      "3:\tlearn: 0.4709457\ttotal: 16.5ms\tremaining: 24.8ms\n",
      "4:\tlearn: 0.4690547\ttotal: 20.8ms\tremaining: 20.8ms\n",
      "5:\tlearn: 0.4668601\ttotal: 24.7ms\tremaining: 16.5ms\n",
      "6:\tlearn: 0.4648543\ttotal: 28.6ms\tremaining: 12.3ms\n",
      "7:\tlearn: 0.4633314\ttotal: 32.5ms\tremaining: 8.12ms\n",
      "8:\tlearn: 0.4622989\ttotal: 36.6ms\tremaining: 4.07ms\n",
      "9:\tlearn: 0.4615122\ttotal: 40.6ms\tremaining: 0us\n",
      "[10, 0.42, 6, 0.0]\n",
      "0:\tlearn: 0.4822549\ttotal: 5.73ms\tremaining: 51.5ms\n",
      "1:\tlearn: 0.4764006\ttotal: 10.9ms\tremaining: 43.6ms\n",
      "2:\tlearn: 0.4730150\ttotal: 15.5ms\tremaining: 36.1ms\n",
      "3:\tlearn: 0.4709457\ttotal: 20.4ms\tremaining: 30.6ms\n",
      "4:\tlearn: 0.4690547\ttotal: 26ms\tremaining: 26ms\n",
      "5:\tlearn: 0.4668601\ttotal: 30.7ms\tremaining: 20.5ms\n",
      "6:\tlearn: 0.4648543\ttotal: 35ms\tremaining: 15ms\n",
      "7:\tlearn: 0.4633314\ttotal: 42.3ms\tremaining: 10.6ms\n",
      "8:\tlearn: 0.4622989\ttotal: 46.3ms\tremaining: 5.14ms\n",
      "9:\tlearn: 0.4615122\ttotal: 50.4ms\tremaining: 0us\n",
      "[10, 0.42, 6, 0.15]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.43ms\tremaining: 39.8ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.06ms\tremaining: 36.2ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13.1ms\tremaining: 30.6ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17.5ms\tremaining: 26.3ms\n",
      "4:\tlearn: 0.4690547\ttotal: 21.9ms\tremaining: 21.9ms\n",
      "5:\tlearn: 0.4668601\ttotal: 26.2ms\tremaining: 17.4ms\n",
      "6:\tlearn: 0.4648543\ttotal: 31.9ms\tremaining: 13.7ms\n",
      "7:\tlearn: 0.4633314\ttotal: 36.9ms\tremaining: 9.23ms\n",
      "8:\tlearn: 0.4622989\ttotal: 41.2ms\tremaining: 4.58ms\n",
      "9:\tlearn: 0.4615122\ttotal: 46.2ms\tremaining: 0us\n",
      "[10, 0.42, 6, 0.2]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.45ms\tremaining: 40.1ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.91ms\tremaining: 35.6ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13.4ms\tremaining: 31.3ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17.9ms\tremaining: 26.8ms\n",
      "4:\tlearn: 0.4690547\ttotal: 22.5ms\tremaining: 22.5ms\n",
      "5:\tlearn: 0.4668601\ttotal: 30.3ms\tremaining: 20.2ms\n",
      "6:\tlearn: 0.4648543\ttotal: 34.5ms\tremaining: 14.8ms\n",
      "7:\tlearn: 0.4633314\ttotal: 38.6ms\tremaining: 9.66ms\n",
      "8:\tlearn: 0.4622989\ttotal: 43.5ms\tremaining: 4.84ms\n",
      "9:\tlearn: 0.4615122\ttotal: 48.6ms\tremaining: 0us\n",
      "[10, 0.42, 15, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.95ms\tremaining: 89.6ms\n",
      "1:\tlearn: 0.4725597\ttotal: 498ms\tremaining: 1.99s\n",
      "2:\tlearn: 0.4670568\ttotal: 965ms\tremaining: 2.25s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.45s\tremaining: 2.17s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.92s\tremaining: 1.92s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.4s\tremaining: 1.6s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.87s\tremaining: 1.23s\n",
      "7:\tlearn: 0.4540982\ttotal: 3.34s\tremaining: 835ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.81s\tremaining: 424ms\n",
      "9:\tlearn: 0.4505739\ttotal: 4.28s\tremaining: 0us\n",
      "[10, 0.42, 15, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.2ms\tremaining: 91.5ms\n",
      "1:\tlearn: 0.4725597\ttotal: 526ms\tremaining: 2.1s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.01s\tremaining: 2.35s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.51s\tremaining: 2.26s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.99s\tremaining: 1.99s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.48s\tremaining: 1.65s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.96s\tremaining: 1.27s\n",
      "7:\tlearn: 0.4540982\ttotal: 3.43s\tremaining: 858ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.9s\tremaining: 433ms\n",
      "9:\tlearn: 0.4505739\ttotal: 4.38s\tremaining: 0us\n",
      "[10, 0.42, 15, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.15ms\tremaining: 82.4ms\n",
      "1:\tlearn: 0.4725597\ttotal: 465ms\tremaining: 1.86s\n",
      "2:\tlearn: 0.4670568\ttotal: 931ms\tremaining: 2.17s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.4s\tremaining: 2.1s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.85s\tremaining: 1.85s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.31s\tremaining: 1.54s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.77s\tremaining: 1.19s\n",
      "7:\tlearn: 0.4540982\ttotal: 3.23s\tremaining: 807ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.69s\tremaining: 411ms\n",
      "9:\tlearn: 0.4505739\ttotal: 4.14s\tremaining: 0us\n",
      "[10, 0.42, 15, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.44ms\tremaining: 85ms\n",
      "1:\tlearn: 0.4725597\ttotal: 542ms\tremaining: 2.17s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.05s\tremaining: 2.46s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.53s\tremaining: 2.29s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.99s\tremaining: 1.99s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.48s\tremaining: 1.65s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.94s\tremaining: 1.26s\n",
      "7:\tlearn: 0.4540982\ttotal: 3.4s\tremaining: 851ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.86s\tremaining: 429ms\n",
      "9:\tlearn: 0.4505739\ttotal: 4.32s\tremaining: 0us\n",
      "[10, 0.42, 15, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.86ms\tremaining: 88.7ms\n",
      "1:\tlearn: 0.4725597\ttotal: 459ms\tremaining: 1.83s\n",
      "2:\tlearn: 0.4670568\ttotal: 909ms\tremaining: 2.12s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.36s\tremaining: 2.04s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.81s\tremaining: 1.81s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.26s\tremaining: 1.51s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.72s\tremaining: 1.16s\n",
      "7:\tlearn: 0.4540982\ttotal: 3.19s\tremaining: 797ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.65s\tremaining: 405ms\n",
      "9:\tlearn: 0.4505739\ttotal: 4.12s\tremaining: 0us\n",
      "[10, 0.42, 10, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.3ms\tremaining: 101ms\n",
      "1:\tlearn: 0.4747524\ttotal: 33.9ms\tremaining: 136ms\n",
      "2:\tlearn: 0.4704503\ttotal: 49.5ms\tremaining: 116ms\n",
      "3:\tlearn: 0.4672210\ttotal: 64.6ms\tremaining: 96.9ms\n",
      "4:\tlearn: 0.4648993\ttotal: 80.7ms\tremaining: 80.7ms\n",
      "5:\tlearn: 0.4625834\ttotal: 94.4ms\tremaining: 62.9ms\n",
      "6:\tlearn: 0.4610401\ttotal: 108ms\tremaining: 46.4ms\n",
      "7:\tlearn: 0.4600427\ttotal: 113ms\tremaining: 28.4ms\n",
      "8:\tlearn: 0.4589504\ttotal: 129ms\tremaining: 14.3ms\n",
      "9:\tlearn: 0.4573560\ttotal: 145ms\tremaining: 0us\n",
      "[10, 0.42, 10, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 13.1ms\tremaining: 118ms\n",
      "1:\tlearn: 0.4747524\ttotal: 29.1ms\tremaining: 116ms\n",
      "2:\tlearn: 0.4704503\ttotal: 44.7ms\tremaining: 104ms\n",
      "3:\tlearn: 0.4672210\ttotal: 61.2ms\tremaining: 91.8ms\n",
      "4:\tlearn: 0.4648993\ttotal: 78.6ms\tremaining: 78.6ms\n",
      "5:\tlearn: 0.4625834\ttotal: 93.9ms\tremaining: 62.6ms\n",
      "6:\tlearn: 0.4610401\ttotal: 108ms\tremaining: 46.2ms\n",
      "7:\tlearn: 0.4600427\ttotal: 112ms\tremaining: 28.1ms\n",
      "8:\tlearn: 0.4589504\ttotal: 126ms\tremaining: 14ms\n",
      "9:\tlearn: 0.4573560\ttotal: 140ms\tremaining: 0us\n",
      "[10, 0.42, 10, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.58ms\tremaining: 86.2ms\n",
      "1:\tlearn: 0.4747524\ttotal: 25.3ms\tremaining: 101ms\n",
      "2:\tlearn: 0.4704503\ttotal: 59.1ms\tremaining: 138ms\n",
      "3:\tlearn: 0.4672210\ttotal: 79.8ms\tremaining: 120ms\n",
      "4:\tlearn: 0.4648993\ttotal: 105ms\tremaining: 105ms\n",
      "5:\tlearn: 0.4625834\ttotal: 122ms\tremaining: 81.4ms\n",
      "6:\tlearn: 0.4610401\ttotal: 141ms\tremaining: 60.3ms\n",
      "7:\tlearn: 0.4600427\ttotal: 146ms\tremaining: 36.5ms\n",
      "8:\tlearn: 0.4589504\ttotal: 161ms\tremaining: 17.9ms\n",
      "9:\tlearn: 0.4573560\ttotal: 177ms\tremaining: 0us\n",
      "[10, 0.42, 10, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.3ms\tremaining: 110ms\n",
      "1:\tlearn: 0.4747524\ttotal: 27.6ms\tremaining: 111ms\n",
      "2:\tlearn: 0.4704503\ttotal: 43.8ms\tremaining: 102ms\n",
      "3:\tlearn: 0.4672210\ttotal: 85.6ms\tremaining: 128ms\n",
      "4:\tlearn: 0.4648993\ttotal: 104ms\tremaining: 104ms\n",
      "5:\tlearn: 0.4625834\ttotal: 126ms\tremaining: 84.3ms\n",
      "6:\tlearn: 0.4610401\ttotal: 152ms\tremaining: 65.3ms\n",
      "7:\tlearn: 0.4600427\ttotal: 158ms\tremaining: 39.6ms\n",
      "8:\tlearn: 0.4589504\ttotal: 175ms\tremaining: 19.4ms\n",
      "9:\tlearn: 0.4573560\ttotal: 192ms\tremaining: 0us\n",
      "[10, 0.42, 10, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.29ms\tremaining: 74.6ms\n",
      "1:\tlearn: 0.4747524\ttotal: 23.3ms\tremaining: 93.2ms\n",
      "2:\tlearn: 0.4704503\ttotal: 42ms\tremaining: 98.1ms\n",
      "3:\tlearn: 0.4672210\ttotal: 57.9ms\tremaining: 86.8ms\n",
      "4:\tlearn: 0.4648993\ttotal: 75.6ms\tremaining: 75.6ms\n",
      "5:\tlearn: 0.4625834\ttotal: 91.1ms\tremaining: 60.7ms\n",
      "6:\tlearn: 0.4610401\ttotal: 107ms\tremaining: 46ms\n",
      "7:\tlearn: 0.4600427\ttotal: 112ms\tremaining: 28ms\n",
      "8:\tlearn: 0.4589504\ttotal: 128ms\tremaining: 14.2ms\n",
      "9:\tlearn: 0.4573560\ttotal: 161ms\tremaining: 0us\n",
      "[10, 0.42, 12, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.62ms\tremaining: 77.6ms\n",
      "1:\tlearn: 0.4738094\ttotal: 60.3ms\tremaining: 241ms\n",
      "2:\tlearn: 0.4686075\ttotal: 111ms\tremaining: 260ms\n",
      "3:\tlearn: 0.4656476\ttotal: 168ms\tremaining: 252ms\n",
      "4:\tlearn: 0.4634402\ttotal: 249ms\tremaining: 249ms\n",
      "5:\tlearn: 0.4611150\ttotal: 327ms\tremaining: 218ms\n",
      "6:\tlearn: 0.4588698\ttotal: 396ms\tremaining: 170ms\n",
      "7:\tlearn: 0.4569792\ttotal: 450ms\tremaining: 112ms\n",
      "8:\tlearn: 0.4559460\ttotal: 505ms\tremaining: 56.1ms\n",
      "9:\tlearn: 0.4547932\ttotal: 563ms\tremaining: 0us\n",
      "[10, 0.42, 12, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.33ms\tremaining: 84ms\n",
      "1:\tlearn: 0.4738094\ttotal: 60.7ms\tremaining: 243ms\n",
      "2:\tlearn: 0.4686075\ttotal: 117ms\tremaining: 272ms\n",
      "3:\tlearn: 0.4656476\ttotal: 174ms\tremaining: 261ms\n",
      "4:\tlearn: 0.4634402\ttotal: 247ms\tremaining: 247ms\n",
      "5:\tlearn: 0.4611150\ttotal: 314ms\tremaining: 209ms\n",
      "6:\tlearn: 0.4588698\ttotal: 369ms\tremaining: 158ms\n",
      "7:\tlearn: 0.4569792\ttotal: 423ms\tremaining: 106ms\n",
      "8:\tlearn: 0.4559460\ttotal: 477ms\tremaining: 53ms\n",
      "9:\tlearn: 0.4547932\ttotal: 535ms\tremaining: 0us\n",
      "[10, 0.42, 12, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.77ms\tremaining: 78.9ms\n",
      "1:\tlearn: 0.4738094\ttotal: 62.2ms\tremaining: 249ms\n",
      "2:\tlearn: 0.4686075\ttotal: 114ms\tremaining: 267ms\n",
      "3:\tlearn: 0.4656476\ttotal: 171ms\tremaining: 257ms\n",
      "4:\tlearn: 0.4634402\ttotal: 271ms\tremaining: 271ms\n",
      "5:\tlearn: 0.4611150\ttotal: 334ms\tremaining: 222ms\n",
      "6:\tlearn: 0.4588698\ttotal: 391ms\tremaining: 167ms\n",
      "7:\tlearn: 0.4569792\ttotal: 453ms\tremaining: 113ms\n",
      "8:\tlearn: 0.4559460\ttotal: 507ms\tremaining: 56.4ms\n",
      "9:\tlearn: 0.4547932\ttotal: 561ms\tremaining: 0us\n",
      "[10, 0.42, 12, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.9ms\tremaining: 107ms\n",
      "1:\tlearn: 0.4738094\ttotal: 72.6ms\tremaining: 291ms\n",
      "2:\tlearn: 0.4686075\ttotal: 136ms\tremaining: 318ms\n",
      "3:\tlearn: 0.4656476\ttotal: 193ms\tremaining: 290ms\n",
      "4:\tlearn: 0.4634402\ttotal: 259ms\tremaining: 259ms\n",
      "5:\tlearn: 0.4611150\ttotal: 362ms\tremaining: 241ms\n",
      "6:\tlearn: 0.4588698\ttotal: 438ms\tremaining: 188ms\n",
      "7:\tlearn: 0.4569792\ttotal: 499ms\tremaining: 125ms\n",
      "8:\tlearn: 0.4559460\ttotal: 558ms\tremaining: 61.9ms\n",
      "9:\tlearn: 0.4547932\ttotal: 612ms\tremaining: 0us\n",
      "[10, 0.42, 12, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 17.6ms\tremaining: 158ms\n",
      "1:\tlearn: 0.4738094\ttotal: 92.3ms\tremaining: 369ms\n",
      "2:\tlearn: 0.4686075\ttotal: 154ms\tremaining: 359ms\n",
      "3:\tlearn: 0.4656476\ttotal: 214ms\tremaining: 321ms\n",
      "4:\tlearn: 0.4634402\ttotal: 265ms\tremaining: 265ms\n",
      "5:\tlearn: 0.4611150\ttotal: 320ms\tremaining: 213ms\n",
      "6:\tlearn: 0.4588698\ttotal: 386ms\tremaining: 166ms\n",
      "7:\tlearn: 0.4569792\ttotal: 454ms\tremaining: 114ms\n",
      "8:\tlearn: 0.4559460\ttotal: 542ms\tremaining: 60.2ms\n",
      "9:\tlearn: 0.4547932\ttotal: 602ms\tremaining: 0us\n",
      "[10, 0.42, 13, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.4734661\ttotal: 156ms\tremaining: 624ms\n",
      "2:\tlearn: 0.4690787\ttotal: 275ms\tremaining: 642ms\n",
      "3:\tlearn: 0.4660511\ttotal: 385ms\tremaining: 577ms\n",
      "4:\tlearn: 0.4628433\ttotal: 436ms\tremaining: 436ms\n",
      "5:\tlearn: 0.4605878\ttotal: 558ms\tremaining: 372ms\n",
      "6:\tlearn: 0.4583652\ttotal: 707ms\tremaining: 303ms\n",
      "7:\tlearn: 0.4568128\ttotal: 833ms\tremaining: 208ms\n",
      "8:\tlearn: 0.4552451\ttotal: 862ms\tremaining: 95.7ms\n",
      "9:\tlearn: 0.4537466\ttotal: 965ms\tremaining: 0us\n",
      "[10, 0.42, 13, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.74ms\tremaining: 87.7ms\n",
      "1:\tlearn: 0.4734661\ttotal: 159ms\tremaining: 636ms\n",
      "2:\tlearn: 0.4690787\ttotal: 278ms\tremaining: 648ms\n",
      "3:\tlearn: 0.4660511\ttotal: 386ms\tremaining: 580ms\n",
      "4:\tlearn: 0.4628433\ttotal: 444ms\tremaining: 444ms\n",
      "5:\tlearn: 0.4605878\ttotal: 608ms\tremaining: 405ms\n",
      "6:\tlearn: 0.4583652\ttotal: 721ms\tremaining: 309ms\n",
      "7:\tlearn: 0.4568128\ttotal: 831ms\tremaining: 208ms\n",
      "8:\tlearn: 0.4552451\ttotal: 867ms\tremaining: 96.3ms\n",
      "9:\tlearn: 0.4537466\ttotal: 1.01s\tremaining: 0us\n",
      "[10, 0.42, 13, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.22ms\tremaining: 74ms\n",
      "1:\tlearn: 0.4734661\ttotal: 143ms\tremaining: 572ms\n",
      "2:\tlearn: 0.4690787\ttotal: 277ms\tremaining: 647ms\n",
      "3:\tlearn: 0.4660511\ttotal: 400ms\tremaining: 599ms\n",
      "4:\tlearn: 0.4628433\ttotal: 452ms\tremaining: 452ms\n",
      "5:\tlearn: 0.4605878\ttotal: 561ms\tremaining: 374ms\n",
      "6:\tlearn: 0.4583652\ttotal: 704ms\tremaining: 302ms\n",
      "7:\tlearn: 0.4568128\ttotal: 829ms\tremaining: 207ms\n",
      "8:\tlearn: 0.4552451\ttotal: 861ms\tremaining: 95.7ms\n",
      "9:\tlearn: 0.4537466\ttotal: 980ms\tremaining: 0us\n",
      "[10, 0.42, 13, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.1ms\tremaining: 91.1ms\n",
      "1:\tlearn: 0.4734661\ttotal: 127ms\tremaining: 508ms\n",
      "2:\tlearn: 0.4690787\ttotal: 247ms\tremaining: 577ms\n",
      "3:\tlearn: 0.4660511\ttotal: 357ms\tremaining: 535ms\n",
      "4:\tlearn: 0.4628433\ttotal: 415ms\tremaining: 415ms\n",
      "5:\tlearn: 0.4605878\ttotal: 548ms\tremaining: 365ms\n",
      "6:\tlearn: 0.4583652\ttotal: 671ms\tremaining: 287ms\n",
      "7:\tlearn: 0.4568128\ttotal: 780ms\tremaining: 195ms\n",
      "8:\tlearn: 0.4552451\ttotal: 809ms\tremaining: 89.8ms\n",
      "9:\tlearn: 0.4537466\ttotal: 942ms\tremaining: 0us\n",
      "[10, 0.42, 13, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.53ms\tremaining: 76.8ms\n",
      "1:\tlearn: 0.4734661\ttotal: 118ms\tremaining: 473ms\n",
      "2:\tlearn: 0.4690787\ttotal: 248ms\tremaining: 578ms\n",
      "3:\tlearn: 0.4660511\ttotal: 387ms\tremaining: 581ms\n",
      "4:\tlearn: 0.4628433\ttotal: 442ms\tremaining: 442ms\n",
      "5:\tlearn: 0.4605878\ttotal: 550ms\tremaining: 367ms\n",
      "6:\tlearn: 0.4583652\ttotal: 671ms\tremaining: 287ms\n",
      "7:\tlearn: 0.4568128\ttotal: 824ms\tremaining: 206ms\n",
      "8:\tlearn: 0.4552451\ttotal: 859ms\tremaining: 95.4ms\n",
      "9:\tlearn: 0.4537466\ttotal: 974ms\tremaining: 0us\n",
      "[10, 0.48, 6, -0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.4742214\ttotal: 29ms\tremaining: 116ms\n",
      "2:\tlearn: 0.4707120\ttotal: 35.1ms\tremaining: 81.9ms\n",
      "3:\tlearn: 0.4683386\ttotal: 39.8ms\tremaining: 59.7ms\n",
      "4:\tlearn: 0.4663249\ttotal: 54.9ms\tremaining: 54.9ms\n",
      "5:\tlearn: 0.4646075\ttotal: 59.5ms\tremaining: 39.7ms\n",
      "6:\tlearn: 0.4624948\ttotal: 63.9ms\tremaining: 27.4ms\n",
      "7:\tlearn: 0.4613643\ttotal: 68.2ms\tremaining: 17.1ms\n",
      "8:\tlearn: 0.4601906\ttotal: 72.9ms\tremaining: 8.1ms\n",
      "9:\tlearn: 0.4591168\ttotal: 86.8ms\tremaining: 0us\n",
      "[10, 0.48, 6, 0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 4.07ms\tremaining: 36.7ms\n",
      "1:\tlearn: 0.4742214\ttotal: 7.83ms\tremaining: 31.3ms\n",
      "2:\tlearn: 0.4707120\ttotal: 11.8ms\tremaining: 27.6ms\n",
      "3:\tlearn: 0.4683386\ttotal: 15.8ms\tremaining: 23.7ms\n",
      "4:\tlearn: 0.4663249\ttotal: 19.6ms\tremaining: 19.6ms\n",
      "5:\tlearn: 0.4646075\ttotal: 23.4ms\tremaining: 15.6ms\n",
      "6:\tlearn: 0.4624948\ttotal: 27.5ms\tremaining: 11.8ms\n",
      "7:\tlearn: 0.4613643\ttotal: 31.4ms\tremaining: 7.86ms\n",
      "8:\tlearn: 0.4601906\ttotal: 35.3ms\tremaining: 3.93ms\n",
      "9:\tlearn: 0.4591168\ttotal: 39.2ms\tremaining: 0us\n",
      "[10, 0.48, 6, 0.0]\n",
      "0:\tlearn: 0.4809500\ttotal: 5.38ms\tremaining: 48.4ms\n",
      "1:\tlearn: 0.4742214\ttotal: 10.1ms\tremaining: 40.3ms\n",
      "2:\tlearn: 0.4707120\ttotal: 17.3ms\tremaining: 40.4ms\n",
      "3:\tlearn: 0.4683386\ttotal: 23.3ms\tremaining: 35ms\n",
      "4:\tlearn: 0.4663249\ttotal: 58.7ms\tremaining: 58.7ms\n",
      "5:\tlearn: 0.4646075\ttotal: 65.5ms\tremaining: 43.6ms\n",
      "6:\tlearn: 0.4624948\ttotal: 70.2ms\tremaining: 30.1ms\n",
      "7:\tlearn: 0.4613643\ttotal: 74.6ms\tremaining: 18.6ms\n",
      "8:\tlearn: 0.4601906\ttotal: 80.4ms\tremaining: 8.93ms\n",
      "9:\tlearn: 0.4591168\ttotal: 84.9ms\tremaining: 0us\n",
      "[10, 0.48, 6, 0.15]\n",
      "0:\tlearn: 0.4809500\ttotal: 3.81ms\tremaining: 34.3ms\n",
      "1:\tlearn: 0.4742214\ttotal: 7.6ms\tremaining: 30.4ms\n",
      "2:\tlearn: 0.4707120\ttotal: 11.5ms\tremaining: 26.7ms\n",
      "3:\tlearn: 0.4683386\ttotal: 15.3ms\tremaining: 23ms\n",
      "4:\tlearn: 0.4663249\ttotal: 19.2ms\tremaining: 19.2ms\n",
      "5:\tlearn: 0.4646075\ttotal: 23.1ms\tremaining: 15.4ms\n",
      "6:\tlearn: 0.4624948\ttotal: 27.1ms\tremaining: 11.6ms\n",
      "7:\tlearn: 0.4613643\ttotal: 31ms\tremaining: 7.75ms\n",
      "8:\tlearn: 0.4601906\ttotal: 34.9ms\tremaining: 3.88ms\n",
      "9:\tlearn: 0.4591168\ttotal: 38.7ms\tremaining: 0us\n",
      "[10, 0.48, 6, 0.2]\n",
      "0:\tlearn: 0.4809500\ttotal: 5.45ms\tremaining: 49.1ms\n",
      "1:\tlearn: 0.4742214\ttotal: 14.3ms\tremaining: 57.4ms\n",
      "2:\tlearn: 0.4707120\ttotal: 22ms\tremaining: 51.4ms\n",
      "3:\tlearn: 0.4683386\ttotal: 28ms\tremaining: 42.1ms\n",
      "4:\tlearn: 0.4663249\ttotal: 33.7ms\tremaining: 33.7ms\n",
      "5:\tlearn: 0.4646075\ttotal: 40.6ms\tremaining: 27.1ms\n",
      "6:\tlearn: 0.4624948\ttotal: 45.7ms\tremaining: 19.6ms\n",
      "7:\tlearn: 0.4613643\ttotal: 50.9ms\tremaining: 12.7ms\n",
      "8:\tlearn: 0.4601906\ttotal: 57.8ms\tremaining: 6.42ms\n",
      "9:\tlearn: 0.4591168\ttotal: 70.7ms\tremaining: 0us\n",
      "[10, 0.48, 15, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 8.51ms\tremaining: 76.6ms\n",
      "1:\tlearn: 0.4707499\ttotal: 500ms\tremaining: 2s\n",
      "2:\tlearn: 0.4660967\ttotal: 976ms\tremaining: 2.28s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.48s\tremaining: 2.22s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.97s\tremaining: 1.97s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.44s\tremaining: 1.63s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.9s\tremaining: 1.24s\n",
      "7:\tlearn: 0.4531603\ttotal: 3.35s\tremaining: 836ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.81s\tremaining: 424ms\n",
      "9:\tlearn: 0.4495817\ttotal: 4.27s\tremaining: 0us\n",
      "[10, 0.48, 15, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.7ms\tremaining: 96.3ms\n",
      "1:\tlearn: 0.4707499\ttotal: 477ms\tremaining: 1.91s\n",
      "2:\tlearn: 0.4660967\ttotal: 945ms\tremaining: 2.2s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.41s\tremaining: 2.12s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.91s\tremaining: 1.91s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.39s\tremaining: 1.6s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.87s\tremaining: 1.23s\n",
      "7:\tlearn: 0.4531603\ttotal: 3.33s\tremaining: 833ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.81s\tremaining: 424ms\n",
      "9:\tlearn: 0.4495817\ttotal: 4.28s\tremaining: 0us\n",
      "[10, 0.48, 15, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.4707499\ttotal: 499ms\tremaining: 2s\n",
      "2:\tlearn: 0.4660967\ttotal: 945ms\tremaining: 2.21s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.4s\tremaining: 2.11s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.89s\tremaining: 1.89s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.34s\tremaining: 1.56s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.81s\tremaining: 1.2s\n",
      "7:\tlearn: 0.4531603\ttotal: 3.26s\tremaining: 816ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.75s\tremaining: 416ms\n",
      "9:\tlearn: 0.4495817\ttotal: 4.23s\tremaining: 0us\n",
      "[10, 0.48, 15, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.41ms\tremaining: 84.7ms\n",
      "1:\tlearn: 0.4707499\ttotal: 504ms\tremaining: 2.02s\n",
      "2:\tlearn: 0.4660967\ttotal: 977ms\tremaining: 2.28s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.45s\tremaining: 2.17s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.92s\tremaining: 1.92s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.4s\tremaining: 1.6s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.87s\tremaining: 1.23s\n",
      "7:\tlearn: 0.4531603\ttotal: 3.33s\tremaining: 834ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.8s\tremaining: 423ms\n",
      "9:\tlearn: 0.4495817\ttotal: 4.25s\tremaining: 0us\n",
      "[10, 0.48, 15, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 8.84ms\tremaining: 79.5ms\n",
      "1:\tlearn: 0.4707499\ttotal: 505ms\tremaining: 2.02s\n",
      "2:\tlearn: 0.4660967\ttotal: 972ms\tremaining: 2.27s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.42s\tremaining: 2.13s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.88s\tremaining: 1.88s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.35s\tremaining: 1.57s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.82s\tremaining: 1.21s\n",
      "7:\tlearn: 0.4531603\ttotal: 3.28s\tremaining: 820ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.76s\tremaining: 418ms\n",
      "9:\tlearn: 0.4495817\ttotal: 4.24s\tremaining: 0us\n",
      "[10, 0.48, 10, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.4ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4731642\ttotal: 27.7ms\tremaining: 111ms\n",
      "2:\tlearn: 0.4688840\ttotal: 44.1ms\tremaining: 103ms\n",
      "3:\tlearn: 0.4676760\ttotal: 46.9ms\tremaining: 70.4ms\n",
      "4:\tlearn: 0.4647814\ttotal: 60.8ms\tremaining: 60.8ms\n",
      "5:\tlearn: 0.4606717\ttotal: 75.1ms\tremaining: 50.1ms\n",
      "6:\tlearn: 0.4587144\ttotal: 91.4ms\tremaining: 39.2ms\n",
      "7:\tlearn: 0.4569157\ttotal: 106ms\tremaining: 26.5ms\n",
      "8:\tlearn: 0.4555458\ttotal: 121ms\tremaining: 13.4ms\n",
      "9:\tlearn: 0.4544564\ttotal: 135ms\tremaining: 0us\n",
      "[10, 0.48, 10, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 18ms\tremaining: 162ms\n",
      "1:\tlearn: 0.4731642\ttotal: 35.5ms\tremaining: 142ms\n",
      "2:\tlearn: 0.4688840\ttotal: 52.3ms\tremaining: 122ms\n",
      "3:\tlearn: 0.4676760\ttotal: 55.4ms\tremaining: 83.2ms\n",
      "4:\tlearn: 0.4647814\ttotal: 69.8ms\tremaining: 69.8ms\n",
      "5:\tlearn: 0.4606717\ttotal: 83.4ms\tremaining: 55.6ms\n",
      "6:\tlearn: 0.4587144\ttotal: 97.5ms\tremaining: 41.8ms\n",
      "7:\tlearn: 0.4569157\ttotal: 112ms\tremaining: 28.1ms\n",
      "8:\tlearn: 0.4555458\ttotal: 128ms\tremaining: 14.2ms\n",
      "9:\tlearn: 0.4544564\ttotal: 144ms\tremaining: 0us\n",
      "[10, 0.48, 10, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.36ms\tremaining: 84.2ms\n",
      "1:\tlearn: 0.4731642\ttotal: 26.1ms\tremaining: 104ms\n",
      "2:\tlearn: 0.4688840\ttotal: 41.9ms\tremaining: 97.8ms\n",
      "3:\tlearn: 0.4676760\ttotal: 44.6ms\tremaining: 66.8ms\n",
      "4:\tlearn: 0.4647814\ttotal: 59.6ms\tremaining: 59.6ms\n",
      "5:\tlearn: 0.4606717\ttotal: 73.9ms\tremaining: 49.3ms\n",
      "6:\tlearn: 0.4587144\ttotal: 89.1ms\tremaining: 38.2ms\n",
      "7:\tlearn: 0.4569157\ttotal: 104ms\tremaining: 26.1ms\n",
      "8:\tlearn: 0.4555458\ttotal: 121ms\tremaining: 13.4ms\n",
      "9:\tlearn: 0.4544564\ttotal: 137ms\tremaining: 0us\n",
      "[10, 0.48, 10, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.6ms\tremaining: 104ms\n",
      "1:\tlearn: 0.4731642\ttotal: 27.9ms\tremaining: 112ms\n",
      "2:\tlearn: 0.4688840\ttotal: 44.5ms\tremaining: 104ms\n",
      "3:\tlearn: 0.4676760\ttotal: 47.4ms\tremaining: 71.1ms\n",
      "4:\tlearn: 0.4647814\ttotal: 63.8ms\tremaining: 63.8ms\n",
      "5:\tlearn: 0.4606717\ttotal: 79.7ms\tremaining: 53.2ms\n",
      "6:\tlearn: 0.4587144\ttotal: 93.7ms\tremaining: 40.2ms\n",
      "7:\tlearn: 0.4569157\ttotal: 108ms\tremaining: 26.9ms\n",
      "8:\tlearn: 0.4555458\ttotal: 122ms\tremaining: 13.5ms\n",
      "9:\tlearn: 0.4544564\ttotal: 136ms\tremaining: 0us\n",
      "[10, 0.48, 10, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 13.2ms\tremaining: 119ms\n",
      "1:\tlearn: 0.4731642\ttotal: 28.9ms\tremaining: 116ms\n",
      "2:\tlearn: 0.4688840\ttotal: 45.8ms\tremaining: 107ms\n",
      "3:\tlearn: 0.4676760\ttotal: 48.9ms\tremaining: 73.3ms\n",
      "4:\tlearn: 0.4647814\ttotal: 64.6ms\tremaining: 64.6ms\n",
      "5:\tlearn: 0.4606717\ttotal: 84.7ms\tremaining: 56.5ms\n",
      "6:\tlearn: 0.4587144\ttotal: 102ms\tremaining: 43.9ms\n",
      "7:\tlearn: 0.4569157\ttotal: 121ms\tremaining: 30.2ms\n",
      "8:\tlearn: 0.4555458\ttotal: 139ms\tremaining: 15.5ms\n",
      "9:\tlearn: 0.4544564\ttotal: 155ms\tremaining: 0us\n",
      "[10, 0.48, 12, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.8ms\tremaining: 106ms\n",
      "1:\tlearn: 0.4721464\ttotal: 68.9ms\tremaining: 276ms\n",
      "2:\tlearn: 0.4684998\ttotal: 176ms\tremaining: 411ms\n",
      "3:\tlearn: 0.4647972\ttotal: 241ms\tremaining: 361ms\n",
      "4:\tlearn: 0.4625394\ttotal: 300ms\tremaining: 300ms\n",
      "5:\tlearn: 0.4603377\ttotal: 357ms\tremaining: 238ms\n",
      "6:\tlearn: 0.4585216\ttotal: 413ms\tremaining: 177ms\n",
      "7:\tlearn: 0.4563298\ttotal: 466ms\tremaining: 116ms\n",
      "8:\tlearn: 0.4554812\ttotal: 525ms\tremaining: 58.3ms\n",
      "9:\tlearn: 0.4542995\ttotal: 593ms\tremaining: 0us\n",
      "[10, 0.48, 12, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 13.4ms\tremaining: 120ms\n",
      "1:\tlearn: 0.4721464\ttotal: 67ms\tremaining: 268ms\n",
      "2:\tlearn: 0.4684998\ttotal: 119ms\tremaining: 278ms\n",
      "3:\tlearn: 0.4647972\ttotal: 180ms\tremaining: 271ms\n",
      "4:\tlearn: 0.4625394\ttotal: 268ms\tremaining: 268ms\n",
      "5:\tlearn: 0.4603377\ttotal: 354ms\tremaining: 236ms\n",
      "6:\tlearn: 0.4585216\ttotal: 419ms\tremaining: 179ms\n",
      "7:\tlearn: 0.4563298\ttotal: 477ms\tremaining: 119ms\n",
      "8:\tlearn: 0.4554812\ttotal: 533ms\tremaining: 59.3ms\n",
      "9:\tlearn: 0.4542995\ttotal: 597ms\tremaining: 0us\n",
      "[10, 0.48, 12, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 15.3ms\tremaining: 138ms\n",
      "1:\tlearn: 0.4721464\ttotal: 74.7ms\tremaining: 299ms\n",
      "2:\tlearn: 0.4684998\ttotal: 130ms\tremaining: 304ms\n",
      "3:\tlearn: 0.4647972\ttotal: 194ms\tremaining: 291ms\n",
      "4:\tlearn: 0.4625394\ttotal: 276ms\tremaining: 276ms\n",
      "5:\tlearn: 0.4603377\ttotal: 356ms\tremaining: 238ms\n",
      "6:\tlearn: 0.4585216\ttotal: 431ms\tremaining: 185ms\n",
      "7:\tlearn: 0.4563298\ttotal: 500ms\tremaining: 125ms\n",
      "8:\tlearn: 0.4554812\ttotal: 557ms\tremaining: 61.9ms\n",
      "9:\tlearn: 0.4542995\ttotal: 615ms\tremaining: 0us\n",
      "[10, 0.48, 12, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.6ms\tremaining: 104ms\n",
      "1:\tlearn: 0.4721464\ttotal: 71.8ms\tremaining: 287ms\n",
      "2:\tlearn: 0.4684998\ttotal: 128ms\tremaining: 298ms\n",
      "3:\tlearn: 0.4647972\ttotal: 190ms\tremaining: 284ms\n",
      "4:\tlearn: 0.4625394\ttotal: 252ms\tremaining: 252ms\n",
      "5:\tlearn: 0.4603377\ttotal: 346ms\tremaining: 231ms\n",
      "6:\tlearn: 0.4585216\ttotal: 407ms\tremaining: 174ms\n",
      "7:\tlearn: 0.4563298\ttotal: 472ms\tremaining: 118ms\n",
      "8:\tlearn: 0.4554812\ttotal: 530ms\tremaining: 58.9ms\n",
      "9:\tlearn: 0.4542995\ttotal: 590ms\tremaining: 0us\n",
      "[10, 0.48, 12, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.35ms\tremaining: 84.2ms\n",
      "1:\tlearn: 0.4721464\ttotal: 61.9ms\tremaining: 247ms\n",
      "2:\tlearn: 0.4684998\ttotal: 118ms\tremaining: 276ms\n",
      "3:\tlearn: 0.4647972\ttotal: 177ms\tremaining: 265ms\n",
      "4:\tlearn: 0.4625394\ttotal: 249ms\tremaining: 249ms\n",
      "5:\tlearn: 0.4603377\ttotal: 313ms\tremaining: 208ms\n",
      "6:\tlearn: 0.4585216\ttotal: 377ms\tremaining: 162ms\n",
      "7:\tlearn: 0.4563298\ttotal: 430ms\tremaining: 107ms\n",
      "8:\tlearn: 0.4554812\ttotal: 488ms\tremaining: 54.2ms\n",
      "9:\tlearn: 0.4542995\ttotal: 547ms\tremaining: 0us\n",
      "[10, 0.48, 13, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.03ms\tremaining: 81.3ms\n",
      "1:\tlearn: 0.4717672\ttotal: 111ms\tremaining: 446ms\n",
      "2:\tlearn: 0.4670679\ttotal: 247ms\tremaining: 576ms\n",
      "3:\tlearn: 0.4643183\ttotal: 370ms\tremaining: 555ms\n",
      "4:\tlearn: 0.4617346\ttotal: 432ms\tremaining: 432ms\n",
      "5:\tlearn: 0.4593271\ttotal: 537ms\tremaining: 358ms\n",
      "6:\tlearn: 0.4571615\ttotal: 659ms\tremaining: 283ms\n",
      "7:\tlearn: 0.4551873\ttotal: 791ms\tremaining: 198ms\n",
      "8:\tlearn: 0.4536294\ttotal: 827ms\tremaining: 91.9ms\n",
      "9:\tlearn: 0.4524305\ttotal: 953ms\tremaining: 0us\n",
      "[10, 0.48, 13, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 8.87ms\tremaining: 79.8ms\n",
      "1:\tlearn: 0.4717672\ttotal: 121ms\tremaining: 483ms\n",
      "2:\tlearn: 0.4670679\ttotal: 235ms\tremaining: 548ms\n",
      "3:\tlearn: 0.4643183\ttotal: 346ms\tremaining: 519ms\n",
      "4:\tlearn: 0.4617346\ttotal: 408ms\tremaining: 408ms\n",
      "5:\tlearn: 0.4593271\ttotal: 559ms\tremaining: 373ms\n",
      "6:\tlearn: 0.4571615\ttotal: 678ms\tremaining: 291ms\n",
      "7:\tlearn: 0.4551873\ttotal: 788ms\tremaining: 197ms\n",
      "8:\tlearn: 0.4536294\ttotal: 819ms\tremaining: 91.1ms\n",
      "9:\tlearn: 0.4524305\ttotal: 962ms\tremaining: 0us\n",
      "[10, 0.48, 13, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 8.76ms\tremaining: 78.8ms\n",
      "1:\tlearn: 0.4717672\ttotal: 113ms\tremaining: 451ms\n",
      "2:\tlearn: 0.4670679\ttotal: 242ms\tremaining: 564ms\n",
      "3:\tlearn: 0.4643183\ttotal: 374ms\tremaining: 561ms\n",
      "4:\tlearn: 0.4617346\ttotal: 437ms\tremaining: 437ms\n",
      "5:\tlearn: 0.4593271\ttotal: 541ms\tremaining: 361ms\n",
      "6:\tlearn: 0.4571615\ttotal: 656ms\tremaining: 281ms\n",
      "7:\tlearn: 0.4551873\ttotal: 817ms\tremaining: 204ms\n",
      "8:\tlearn: 0.4536294\ttotal: 856ms\tremaining: 95.1ms\n",
      "9:\tlearn: 0.4524305\ttotal: 978ms\tremaining: 0us\n",
      "[10, 0.48, 13, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 16ms\tremaining: 144ms\n",
      "1:\tlearn: 0.4717672\ttotal: 156ms\tremaining: 623ms\n",
      "2:\tlearn: 0.4670679\ttotal: 274ms\tremaining: 639ms\n",
      "3:\tlearn: 0.4643183\ttotal: 386ms\tremaining: 579ms\n",
      "4:\tlearn: 0.4617346\ttotal: 454ms\tremaining: 454ms\n",
      "5:\tlearn: 0.4593271\ttotal: 589ms\tremaining: 393ms\n",
      "6:\tlearn: 0.4571615\ttotal: 720ms\tremaining: 309ms\n",
      "7:\tlearn: 0.4551873\ttotal: 832ms\tremaining: 208ms\n",
      "8:\tlearn: 0.4536294\ttotal: 861ms\tremaining: 95.7ms\n",
      "9:\tlearn: 0.4524305\ttotal: 1.03s\tremaining: 0us\n",
      "[10, 0.48, 13, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.7ms\tremaining: 96ms\n",
      "1:\tlearn: 0.4717672\ttotal: 144ms\tremaining: 577ms\n",
      "2:\tlearn: 0.4670679\ttotal: 305ms\tremaining: 712ms\n",
      "3:\tlearn: 0.4643183\ttotal: 414ms\tremaining: 621ms\n",
      "4:\tlearn: 0.4617346\ttotal: 464ms\tremaining: 464ms\n",
      "5:\tlearn: 0.4593271\ttotal: 575ms\tremaining: 383ms\n",
      "6:\tlearn: 0.4571615\ttotal: 716ms\tremaining: 307ms\n",
      "7:\tlearn: 0.4551873\ttotal: 856ms\tremaining: 214ms\n",
      "8:\tlearn: 0.4536294\ttotal: 888ms\tremaining: 98.6ms\n",
      "9:\tlearn: 0.4524305\ttotal: 996ms\tremaining: 0us\n",
      "[10, 0.51, 6, -0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 31.1ms\tremaining: 280ms\n",
      "1:\tlearn: 0.4736652\ttotal: 38.5ms\tremaining: 154ms\n",
      "2:\tlearn: 0.4703360\ttotal: 43.1ms\tremaining: 101ms\n",
      "3:\tlearn: 0.4678859\ttotal: 48.9ms\tremaining: 73.4ms\n",
      "4:\tlearn: 0.4662988\ttotal: 53.3ms\tremaining: 53.3ms\n",
      "5:\tlearn: 0.4640621\ttotal: 57.7ms\tremaining: 38.5ms\n",
      "6:\tlearn: 0.4617955\ttotal: 62.5ms\tremaining: 26.8ms\n",
      "7:\tlearn: 0.4601208\ttotal: 67.4ms\tremaining: 16.8ms\n",
      "8:\tlearn: 0.4590542\ttotal: 71.5ms\tremaining: 7.94ms\n",
      "9:\tlearn: 0.4578993\ttotal: 75.6ms\tremaining: 0us\n",
      "[10, 0.51, 6, 0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.22ms\tremaining: 38ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.31ms\tremaining: 33.3ms\n",
      "2:\tlearn: 0.4703360\ttotal: 12.5ms\tremaining: 29.1ms\n",
      "3:\tlearn: 0.4678859\ttotal: 16.5ms\tremaining: 24.7ms\n",
      "4:\tlearn: 0.4662988\ttotal: 20.6ms\tremaining: 20.6ms\n",
      "5:\tlearn: 0.4640621\ttotal: 27ms\tremaining: 18ms\n",
      "6:\tlearn: 0.4617955\ttotal: 31.4ms\tremaining: 13.5ms\n",
      "7:\tlearn: 0.4601208\ttotal: 35.8ms\tremaining: 8.94ms\n",
      "8:\tlearn: 0.4590542\ttotal: 40.1ms\tremaining: 4.45ms\n",
      "9:\tlearn: 0.4578993\ttotal: 45.3ms\tremaining: 0us\n",
      "[10, 0.51, 6, 0.0]\n",
      "0:\tlearn: 0.4803477\ttotal: 6.71ms\tremaining: 60.4ms\n",
      "1:\tlearn: 0.4736652\ttotal: 10.9ms\tremaining: 43.7ms\n",
      "2:\tlearn: 0.4703360\ttotal: 15.2ms\tremaining: 35.4ms\n",
      "3:\tlearn: 0.4678859\ttotal: 19.6ms\tremaining: 29.4ms\n",
      "4:\tlearn: 0.4662988\ttotal: 23.9ms\tremaining: 23.9ms\n",
      "5:\tlearn: 0.4640621\ttotal: 28ms\tremaining: 18.6ms\n",
      "6:\tlearn: 0.4617955\ttotal: 32.4ms\tremaining: 13.9ms\n",
      "7:\tlearn: 0.4601208\ttotal: 36.4ms\tremaining: 9.11ms\n",
      "8:\tlearn: 0.4590542\ttotal: 40.5ms\tremaining: 4.5ms\n",
      "9:\tlearn: 0.4578993\ttotal: 44.5ms\tremaining: 0us\n",
      "[10, 0.51, 6, 0.15]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.44ms\tremaining: 39.9ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.59ms\tremaining: 34.4ms\n",
      "2:\tlearn: 0.4703360\ttotal: 12.6ms\tremaining: 29.3ms\n",
      "3:\tlearn: 0.4678859\ttotal: 16.7ms\tremaining: 25.1ms\n",
      "4:\tlearn: 0.4662988\ttotal: 20.8ms\tremaining: 20.8ms\n",
      "5:\tlearn: 0.4640621\ttotal: 27.6ms\tremaining: 18.4ms\n",
      "6:\tlearn: 0.4617955\ttotal: 32ms\tremaining: 13.7ms\n",
      "7:\tlearn: 0.4601208\ttotal: 36.3ms\tremaining: 9.08ms\n",
      "8:\tlearn: 0.4590542\ttotal: 40.7ms\tremaining: 4.53ms\n",
      "9:\tlearn: 0.4578993\ttotal: 45.1ms\tremaining: 0us\n",
      "[10, 0.51, 6, 0.2]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.56ms\tremaining: 41ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.61ms\tremaining: 34.4ms\n",
      "2:\tlearn: 0.4703360\ttotal: 13.6ms\tremaining: 31.6ms\n",
      "3:\tlearn: 0.4678859\ttotal: 17.8ms\tremaining: 26.6ms\n",
      "4:\tlearn: 0.4662988\ttotal: 21.8ms\tremaining: 21.8ms\n",
      "5:\tlearn: 0.4640621\ttotal: 26.1ms\tremaining: 17.4ms\n",
      "6:\tlearn: 0.4617955\ttotal: 30.6ms\tremaining: 13.1ms\n",
      "7:\tlearn: 0.4601208\ttotal: 34.9ms\tremaining: 8.72ms\n",
      "8:\tlearn: 0.4590542\ttotal: 39.1ms\tremaining: 4.34ms\n",
      "9:\tlearn: 0.4578993\ttotal: 43ms\tremaining: 0us\n",
      "[10, 0.51, 15, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.81ms\tremaining: 88.3ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.9ms\tremaining: 79.5ms\n",
      "2:\tlearn: 0.4682843\ttotal: 483ms\tremaining: 1.13s\n",
      "3:\tlearn: 0.4637816\ttotal: 942ms\tremaining: 1.41s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.06s\tremaining: 1.06s\n",
      "5:\tlearn: 0.4588540\ttotal: 1.51s\tremaining: 1.01s\n",
      "6:\tlearn: 0.4565342\ttotal: 1.98s\tremaining: 850ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.48s\tremaining: 621ms\n",
      "8:\tlearn: 0.4530230\ttotal: 2.96s\tremaining: 329ms\n",
      "9:\tlearn: 0.4513033\ttotal: 3.44s\tremaining: 0us\n",
      "[10, 0.51, 15, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 13ms\tremaining: 117ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.9ms\tremaining: 91.7ms\n",
      "2:\tlearn: 0.4682843\ttotal: 484ms\tremaining: 1.13s\n",
      "3:\tlearn: 0.4637816\ttotal: 949ms\tremaining: 1.42s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.07s\tremaining: 1.07s\n",
      "5:\tlearn: 0.4588540\ttotal: 1.57s\tremaining: 1.04s\n",
      "6:\tlearn: 0.4565342\ttotal: 2.02s\tremaining: 864ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.48s\tremaining: 621ms\n",
      "8:\tlearn: 0.4530230\ttotal: 2.98s\tremaining: 331ms\n",
      "9:\tlearn: 0.4513033\ttotal: 3.45s\tremaining: 0us\n",
      "[10, 0.51, 15, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.5ms\tremaining: 94.2ms\n",
      "1:\tlearn: 0.4740807\ttotal: 20.3ms\tremaining: 81.2ms\n",
      "2:\tlearn: 0.4682843\ttotal: 536ms\tremaining: 1.25s\n",
      "3:\tlearn: 0.4637816\ttotal: 1.01s\tremaining: 1.51s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.15s\tremaining: 1.15s\n",
      "5:\tlearn: 0.4588540\ttotal: 1.62s\tremaining: 1.08s\n",
      "6:\tlearn: 0.4565342\ttotal: 2.08s\tremaining: 892ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.55s\tremaining: 637ms\n",
      "8:\tlearn: 0.4530230\ttotal: 3.02s\tremaining: 336ms\n",
      "9:\tlearn: 0.4513033\ttotal: 3.48s\tremaining: 0us\n",
      "[10, 0.51, 15, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.3ms\tremaining: 92.7ms\n",
      "1:\tlearn: 0.4740807\ttotal: 20.6ms\tremaining: 82.6ms\n",
      "2:\tlearn: 0.4682843\ttotal: 472ms\tremaining: 1.1s\n",
      "3:\tlearn: 0.4637816\ttotal: 924ms\tremaining: 1.39s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.05s\tremaining: 1.05s\n",
      "5:\tlearn: 0.4588540\ttotal: 1.57s\tremaining: 1.04s\n",
      "6:\tlearn: 0.4565342\ttotal: 2.01s\tremaining: 862ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.48s\tremaining: 619ms\n",
      "8:\tlearn: 0.4530230\ttotal: 2.94s\tremaining: 327ms\n",
      "9:\tlearn: 0.4513033\ttotal: 3.41s\tremaining: 0us\n",
      "[10, 0.51, 15, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.1ms\tremaining: 88.3ms\n",
      "2:\tlearn: 0.4682843\ttotal: 494ms\tremaining: 1.15s\n",
      "3:\tlearn: 0.4637816\ttotal: 956ms\tremaining: 1.43s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.08s\tremaining: 1.08s\n",
      "5:\tlearn: 0.4588540\ttotal: 1.57s\tremaining: 1.04s\n",
      "6:\tlearn: 0.4565342\ttotal: 2.04s\tremaining: 875ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.54s\tremaining: 634ms\n",
      "8:\tlearn: 0.4530230\ttotal: 3.02s\tremaining: 335ms\n",
      "9:\tlearn: 0.4513033\ttotal: 3.48s\tremaining: 0us\n",
      "[10, 0.51, 10, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.1ms\tremaining: 91.1ms\n",
      "1:\tlearn: 0.4740807\ttotal: 20ms\tremaining: 80ms\n",
      "2:\tlearn: 0.4695149\ttotal: 35.3ms\tremaining: 82.4ms\n",
      "3:\tlearn: 0.4663819\ttotal: 50.1ms\tremaining: 75.1ms\n",
      "4:\tlearn: 0.4637371\ttotal: 66.6ms\tremaining: 66.6ms\n",
      "5:\tlearn: 0.4620590\ttotal: 80.6ms\tremaining: 53.8ms\n",
      "6:\tlearn: 0.4601769\ttotal: 94.5ms\tremaining: 40.5ms\n",
      "7:\tlearn: 0.4571796\ttotal: 108ms\tremaining: 27.1ms\n",
      "8:\tlearn: 0.4555052\ttotal: 122ms\tremaining: 13.5ms\n",
      "9:\tlearn: 0.4548426\ttotal: 136ms\tremaining: 0us\n",
      "[10, 0.51, 10, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 16.2ms\tremaining: 146ms\n",
      "1:\tlearn: 0.4740807\ttotal: 27.1ms\tremaining: 108ms\n",
      "2:\tlearn: 0.4695149\ttotal: 54.2ms\tremaining: 127ms\n",
      "3:\tlearn: 0.4663819\ttotal: 82.4ms\tremaining: 124ms\n",
      "4:\tlearn: 0.4637371\ttotal: 98.5ms\tremaining: 98.5ms\n",
      "5:\tlearn: 0.4620590\ttotal: 114ms\tremaining: 76ms\n",
      "6:\tlearn: 0.4601769\ttotal: 130ms\tremaining: 55.6ms\n",
      "7:\tlearn: 0.4571796\ttotal: 149ms\tremaining: 37.3ms\n",
      "8:\tlearn: 0.4555052\ttotal: 166ms\tremaining: 18.4ms\n",
      "9:\tlearn: 0.4548426\ttotal: 182ms\tremaining: 0us\n",
      "[10, 0.51, 10, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.6ms\tremaining: 95.3ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.7ms\tremaining: 78.8ms\n",
      "2:\tlearn: 0.4695149\ttotal: 35.8ms\tremaining: 83.6ms\n",
      "3:\tlearn: 0.4663819\ttotal: 51.3ms\tremaining: 76.9ms\n",
      "4:\tlearn: 0.4637371\ttotal: 73.5ms\tremaining: 73.5ms\n",
      "5:\tlearn: 0.4620590\ttotal: 95.3ms\tremaining: 63.5ms\n",
      "6:\tlearn: 0.4601769\ttotal: 114ms\tremaining: 48.8ms\n",
      "7:\tlearn: 0.4571796\ttotal: 147ms\tremaining: 36.9ms\n",
      "8:\tlearn: 0.4555052\ttotal: 165ms\tremaining: 18.4ms\n",
      "9:\tlearn: 0.4548426\ttotal: 181ms\tremaining: 0us\n",
      "[10, 0.51, 10, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.5ms\tremaining: 85.5ms\n",
      "1:\tlearn: 0.4740807\ttotal: 21.5ms\tremaining: 85.8ms\n",
      "2:\tlearn: 0.4695149\ttotal: 38.3ms\tremaining: 89.3ms\n",
      "3:\tlearn: 0.4663819\ttotal: 54.9ms\tremaining: 82.4ms\n",
      "4:\tlearn: 0.4637371\ttotal: 70.2ms\tremaining: 70.2ms\n",
      "5:\tlearn: 0.4620590\ttotal: 86.1ms\tremaining: 57.4ms\n",
      "6:\tlearn: 0.4601769\ttotal: 120ms\tremaining: 51.3ms\n",
      "7:\tlearn: 0.4571796\ttotal: 139ms\tremaining: 34.9ms\n",
      "8:\tlearn: 0.4555052\ttotal: 168ms\tremaining: 18.7ms\n",
      "9:\tlearn: 0.4548426\ttotal: 186ms\tremaining: 0us\n",
      "[10, 0.51, 10, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 8.19ms\tremaining: 73.7ms\n",
      "1:\tlearn: 0.4740807\ttotal: 16.6ms\tremaining: 66.2ms\n",
      "2:\tlearn: 0.4695149\ttotal: 30.7ms\tremaining: 71.6ms\n",
      "3:\tlearn: 0.4663819\ttotal: 44.2ms\tremaining: 66.3ms\n",
      "4:\tlearn: 0.4637371\ttotal: 58.6ms\tremaining: 58.6ms\n",
      "5:\tlearn: 0.4620590\ttotal: 74.1ms\tremaining: 49.4ms\n",
      "6:\tlearn: 0.4601769\ttotal: 95.6ms\tremaining: 41ms\n",
      "7:\tlearn: 0.4571796\ttotal: 112ms\tremaining: 28ms\n",
      "8:\tlearn: 0.4555052\ttotal: 135ms\tremaining: 15ms\n",
      "9:\tlearn: 0.4548426\ttotal: 152ms\tremaining: 0us\n",
      "[10, 0.51, 8, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 8.88ms\tremaining: 79.9ms\n",
      "1:\tlearn: 0.4735886\ttotal: 15.6ms\tremaining: 62.3ms\n",
      "2:\tlearn: 0.4683373\ttotal: 22.5ms\tremaining: 52.5ms\n",
      "3:\tlearn: 0.4660754\ttotal: 29.3ms\tremaining: 43.9ms\n",
      "4:\tlearn: 0.4636280\ttotal: 36.7ms\tremaining: 36.7ms\n",
      "5:\tlearn: 0.4620627\ttotal: 43.7ms\tremaining: 29.2ms\n",
      "6:\tlearn: 0.4601948\ttotal: 51ms\tremaining: 21.8ms\n",
      "7:\tlearn: 0.4590473\ttotal: 57.9ms\tremaining: 14.5ms\n",
      "8:\tlearn: 0.4573523\ttotal: 67ms\tremaining: 7.45ms\n",
      "9:\tlearn: 0.4562852\ttotal: 74ms\tremaining: 0us\n",
      "[10, 0.51, 8, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 13.7ms\tremaining: 124ms\n",
      "1:\tlearn: 0.4735886\ttotal: 20.8ms\tremaining: 83.3ms\n",
      "2:\tlearn: 0.4683373\ttotal: 28.8ms\tremaining: 67.1ms\n",
      "3:\tlearn: 0.4660754\ttotal: 36.2ms\tremaining: 54.3ms\n",
      "4:\tlearn: 0.4636280\ttotal: 45ms\tremaining: 45ms\n",
      "5:\tlearn: 0.4620627\ttotal: 52ms\tremaining: 34.7ms\n",
      "6:\tlearn: 0.4601948\ttotal: 61.9ms\tremaining: 26.5ms\n",
      "7:\tlearn: 0.4590473\ttotal: 69.7ms\tremaining: 17.4ms\n",
      "8:\tlearn: 0.4573523\ttotal: 77.1ms\tremaining: 8.56ms\n",
      "9:\tlearn: 0.4562852\ttotal: 84.4ms\tremaining: 0us\n",
      "[10, 0.51, 8, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 6.82ms\tremaining: 61.4ms\n",
      "1:\tlearn: 0.4735886\ttotal: 13.7ms\tremaining: 54.7ms\n",
      "2:\tlearn: 0.4683373\ttotal: 20.7ms\tremaining: 48.3ms\n",
      "3:\tlearn: 0.4660754\ttotal: 28.9ms\tremaining: 43.4ms\n",
      "4:\tlearn: 0.4636280\ttotal: 36.6ms\tremaining: 36.6ms\n",
      "5:\tlearn: 0.4620627\ttotal: 61.8ms\tremaining: 41.2ms\n",
      "6:\tlearn: 0.4601948\ttotal: 73.1ms\tremaining: 31.3ms\n",
      "7:\tlearn: 0.4590473\ttotal: 94.9ms\tremaining: 23.7ms\n",
      "8:\tlearn: 0.4573523\ttotal: 117ms\tremaining: 13ms\n",
      "9:\tlearn: 0.4562852\ttotal: 124ms\tremaining: 0us\n",
      "[10, 0.51, 8, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.82ms\tremaining: 88.4ms\n",
      "1:\tlearn: 0.4735886\ttotal: 17ms\tremaining: 68.1ms\n",
      "2:\tlearn: 0.4683373\ttotal: 23.5ms\tremaining: 54.9ms\n",
      "3:\tlearn: 0.4660754\ttotal: 31.1ms\tremaining: 46.6ms\n",
      "4:\tlearn: 0.4636280\ttotal: 37.5ms\tremaining: 37.5ms\n",
      "5:\tlearn: 0.4620627\ttotal: 44.2ms\tremaining: 29.4ms\n",
      "6:\tlearn: 0.4601948\ttotal: 50.9ms\tremaining: 21.8ms\n",
      "7:\tlearn: 0.4590473\ttotal: 57.4ms\tremaining: 14.3ms\n",
      "8:\tlearn: 0.4573523\ttotal: 64.9ms\tremaining: 7.21ms\n",
      "9:\tlearn: 0.4562852\ttotal: 71.4ms\tremaining: 0us\n",
      "[10, 0.51, 8, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 22.9ms\tremaining: 206ms\n",
      "1:\tlearn: 0.4735886\ttotal: 30.6ms\tremaining: 122ms\n",
      "2:\tlearn: 0.4683373\ttotal: 38.4ms\tremaining: 89.5ms\n",
      "3:\tlearn: 0.4660754\ttotal: 50.5ms\tremaining: 75.8ms\n",
      "4:\tlearn: 0.4636280\ttotal: 58.7ms\tremaining: 58.7ms\n",
      "5:\tlearn: 0.4620627\ttotal: 66ms\tremaining: 44ms\n",
      "6:\tlearn: 0.4601948\ttotal: 72.9ms\tremaining: 31.3ms\n",
      "7:\tlearn: 0.4590473\ttotal: 80.1ms\tremaining: 20ms\n",
      "8:\tlearn: 0.4573523\ttotal: 87.2ms\tremaining: 9.69ms\n",
      "9:\tlearn: 0.4562852\ttotal: 95.1ms\tremaining: 0us\n",
      "[10, 0.51, 7, -0.3]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.74ms\tremaining: 51.6ms\n",
      "1:\tlearn: 0.4741799\ttotal: 11.4ms\tremaining: 45.7ms\n",
      "2:\tlearn: 0.4708424\ttotal: 17ms\tremaining: 39.8ms\n",
      "3:\tlearn: 0.4676883\ttotal: 22.2ms\tremaining: 33.3ms\n",
      "4:\tlearn: 0.4659630\ttotal: 28.7ms\tremaining: 28.7ms\n",
      "5:\tlearn: 0.4648851\ttotal: 34ms\tremaining: 22.6ms\n",
      "6:\tlearn: 0.4634152\ttotal: 39.3ms\tremaining: 16.8ms\n",
      "7:\tlearn: 0.4619064\ttotal: 44.9ms\tremaining: 11.2ms\n",
      "8:\tlearn: 0.4600105\ttotal: 50.7ms\tremaining: 5.63ms\n",
      "9:\tlearn: 0.4588753\ttotal: 57.1ms\tremaining: 0us\n",
      "[10, 0.51, 7, 0.3]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.36ms\tremaining: 48.3ms\n",
      "1:\tlearn: 0.4741799\ttotal: 10.9ms\tremaining: 43.5ms\n",
      "2:\tlearn: 0.4708424\ttotal: 16.3ms\tremaining: 38ms\n",
      "3:\tlearn: 0.4676883\ttotal: 21.3ms\tremaining: 31.9ms\n",
      "4:\tlearn: 0.4659630\ttotal: 26.4ms\tremaining: 26.4ms\n",
      "5:\tlearn: 0.4648851\ttotal: 32.6ms\tremaining: 21.7ms\n",
      "6:\tlearn: 0.4634152\ttotal: 37.7ms\tremaining: 16.1ms\n",
      "7:\tlearn: 0.4619064\ttotal: 43ms\tremaining: 10.7ms\n",
      "8:\tlearn: 0.4600105\ttotal: 48.1ms\tremaining: 5.34ms\n",
      "9:\tlearn: 0.4588753\ttotal: 53.2ms\tremaining: 0us\n",
      "[10, 0.51, 7, 0.0]\n",
      "0:\tlearn: 0.4803401\ttotal: 27.1ms\tremaining: 244ms\n",
      "1:\tlearn: 0.4741799\ttotal: 37.8ms\tremaining: 151ms\n",
      "2:\tlearn: 0.4708424\ttotal: 47.8ms\tremaining: 112ms\n",
      "3:\tlearn: 0.4676883\ttotal: 53.7ms\tremaining: 80.5ms\n",
      "4:\tlearn: 0.4659630\ttotal: 59.2ms\tremaining: 59.2ms\n",
      "5:\tlearn: 0.4648851\ttotal: 66.2ms\tremaining: 44.2ms\n",
      "6:\tlearn: 0.4634152\ttotal: 76.1ms\tremaining: 32.6ms\n",
      "7:\tlearn: 0.4619064\ttotal: 81.5ms\tremaining: 20.4ms\n",
      "8:\tlearn: 0.4600105\ttotal: 87.1ms\tremaining: 9.68ms\n",
      "9:\tlearn: 0.4588753\ttotal: 92.3ms\tremaining: 0us\n",
      "[10, 0.51, 7, 0.15]\n",
      "0:\tlearn: 0.4803401\ttotal: 4.86ms\tremaining: 43.7ms\n",
      "1:\tlearn: 0.4741799\ttotal: 10.1ms\tremaining: 40.6ms\n",
      "2:\tlearn: 0.4708424\ttotal: 15.2ms\tremaining: 35.4ms\n",
      "3:\tlearn: 0.4676883\ttotal: 20.9ms\tremaining: 31.4ms\n",
      "4:\tlearn: 0.4659630\ttotal: 27.5ms\tremaining: 27.5ms\n",
      "5:\tlearn: 0.4648851\ttotal: 33.1ms\tremaining: 22.1ms\n",
      "6:\tlearn: 0.4634152\ttotal: 39ms\tremaining: 16.7ms\n",
      "7:\tlearn: 0.4619064\ttotal: 44.3ms\tremaining: 11.1ms\n",
      "8:\tlearn: 0.4600105\ttotal: 50.2ms\tremaining: 5.58ms\n",
      "9:\tlearn: 0.4588753\ttotal: 55.8ms\tremaining: 0us\n",
      "[10, 0.51, 7, 0.2]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.32ms\tremaining: 47.9ms\n",
      "1:\tlearn: 0.4741799\ttotal: 11ms\tremaining: 44.1ms\n",
      "2:\tlearn: 0.4708424\ttotal: 16.4ms\tremaining: 38.2ms\n",
      "3:\tlearn: 0.4676883\ttotal: 21.7ms\tremaining: 32.5ms\n",
      "4:\tlearn: 0.4659630\ttotal: 27.3ms\tremaining: 27.3ms\n",
      "5:\tlearn: 0.4648851\ttotal: 32.6ms\tremaining: 21.7ms\n",
      "6:\tlearn: 0.4634152\ttotal: 38.6ms\tremaining: 16.6ms\n",
      "7:\tlearn: 0.4619064\ttotal: 43.9ms\tremaining: 11ms\n",
      "8:\tlearn: 0.4600105\ttotal: 52.2ms\tremaining: 5.8ms\n",
      "9:\tlearn: 0.4588753\ttotal: 57.6ms\tremaining: 0us\n",
      "[10, 0.49, 6, -0.3]\n",
      "0:\tlearn: 0.4807455\ttotal: 4.9ms\tremaining: 44.1ms\n",
      "1:\tlearn: 0.4740289\ttotal: 9.06ms\tremaining: 36.3ms\n",
      "2:\tlearn: 0.4705265\ttotal: 13.6ms\tremaining: 31.7ms\n",
      "3:\tlearn: 0.4681211\ttotal: 17.7ms\tremaining: 26.6ms\n",
      "4:\tlearn: 0.4661064\ttotal: 22.2ms\tremaining: 22.2ms\n",
      "5:\tlearn: 0.4643672\ttotal: 27.8ms\tremaining: 18.5ms\n",
      "6:\tlearn: 0.4622690\ttotal: 32ms\tremaining: 13.7ms\n",
      "7:\tlearn: 0.4611446\ttotal: 37ms\tremaining: 9.24ms\n",
      "8:\tlearn: 0.4599524\ttotal: 41.2ms\tremaining: 4.57ms\n",
      "9:\tlearn: 0.4588714\ttotal: 45.4ms\tremaining: 0us\n",
      "[10, 0.49, 6, 0.3]\n",
      "0:\tlearn: 0.4807455\ttotal: 6.76ms\tremaining: 60.8ms\n",
      "1:\tlearn: 0.4740289\ttotal: 11.5ms\tremaining: 45.9ms\n",
      "2:\tlearn: 0.4705265\ttotal: 16.3ms\tremaining: 38.1ms\n",
      "3:\tlearn: 0.4681211\ttotal: 20.7ms\tremaining: 31ms\n",
      "4:\tlearn: 0.4661064\ttotal: 25.1ms\tremaining: 25.1ms\n",
      "5:\tlearn: 0.4643672\ttotal: 31.5ms\tremaining: 21ms\n",
      "6:\tlearn: 0.4622690\ttotal: 35.9ms\tremaining: 15.4ms\n",
      "7:\tlearn: 0.4611446\ttotal: 40.3ms\tremaining: 10.1ms\n",
      "8:\tlearn: 0.4599524\ttotal: 45.6ms\tremaining: 5.07ms\n",
      "9:\tlearn: 0.4588714\ttotal: 54.8ms\tremaining: 0us\n",
      "[10, 0.49, 6, 0.0]\n",
      "0:\tlearn: 0.4807455\ttotal: 10ms\tremaining: 90ms\n",
      "1:\tlearn: 0.4740289\ttotal: 14.5ms\tremaining: 58.1ms\n",
      "2:\tlearn: 0.4705265\ttotal: 19.6ms\tremaining: 45.7ms\n",
      "3:\tlearn: 0.4681211\ttotal: 24.3ms\tremaining: 36.5ms\n",
      "4:\tlearn: 0.4661064\ttotal: 29.1ms\tremaining: 29.1ms\n",
      "5:\tlearn: 0.4643672\ttotal: 35.2ms\tremaining: 23.5ms\n",
      "6:\tlearn: 0.4622690\ttotal: 40.2ms\tremaining: 17.2ms\n",
      "7:\tlearn: 0.4611446\ttotal: 44.6ms\tremaining: 11.1ms\n",
      "8:\tlearn: 0.4599524\ttotal: 48.8ms\tremaining: 5.42ms\n",
      "9:\tlearn: 0.4588714\ttotal: 53.5ms\tremaining: 0us\n",
      "[10, 0.49, 6, 0.15]\n",
      "0:\tlearn: 0.4807455\ttotal: 7.3ms\tremaining: 65.7ms\n",
      "1:\tlearn: 0.4740289\ttotal: 11.6ms\tremaining: 46.6ms\n",
      "2:\tlearn: 0.4705265\ttotal: 16.2ms\tremaining: 37.9ms\n",
      "3:\tlearn: 0.4681211\ttotal: 20.6ms\tremaining: 31ms\n",
      "4:\tlearn: 0.4661064\ttotal: 24.6ms\tremaining: 24.6ms\n",
      "5:\tlearn: 0.4643672\ttotal: 29.4ms\tremaining: 19.6ms\n",
      "6:\tlearn: 0.4622690\ttotal: 33.9ms\tremaining: 14.5ms\n",
      "7:\tlearn: 0.4611446\ttotal: 37.9ms\tremaining: 9.46ms\n",
      "8:\tlearn: 0.4599524\ttotal: 42.1ms\tremaining: 4.67ms\n",
      "9:\tlearn: 0.4588714\ttotal: 46.4ms\tremaining: 0us\n",
      "[10, 0.49, 6, 0.2]\n",
      "0:\tlearn: 0.4807455\ttotal: 4.46ms\tremaining: 40.2ms\n",
      "1:\tlearn: 0.4740289\ttotal: 8.47ms\tremaining: 33.9ms\n",
      "2:\tlearn: 0.4705265\ttotal: 12.6ms\tremaining: 29.4ms\n",
      "3:\tlearn: 0.4681211\ttotal: 16.9ms\tremaining: 25.4ms\n",
      "4:\tlearn: 0.4661064\ttotal: 21.1ms\tremaining: 21.1ms\n",
      "5:\tlearn: 0.4643672\ttotal: 25.3ms\tremaining: 16.8ms\n",
      "6:\tlearn: 0.4622690\ttotal: 30.4ms\tremaining: 13ms\n",
      "7:\tlearn: 0.4611446\ttotal: 34.5ms\tremaining: 8.63ms\n",
      "8:\tlearn: 0.4599524\ttotal: 38.8ms\tremaining: 4.32ms\n",
      "9:\tlearn: 0.4588714\ttotal: 43.1ms\tremaining: 0us\n",
      "[10, 0.49, 15, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.9ms\tremaining: 107ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22.2ms\tremaining: 88.6ms\n",
      "2:\tlearn: 0.4686673\ttotal: 510ms\tremaining: 1.19s\n",
      "3:\tlearn: 0.4640224\ttotal: 974ms\tremaining: 1.46s\n",
      "4:\tlearn: 0.4613861\ttotal: 1.1s\tremaining: 1.1s\n",
      "5:\tlearn: 0.4585459\ttotal: 1.62s\tremaining: 1.08s\n",
      "6:\tlearn: 0.4569377\ttotal: 2.07s\tremaining: 889ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.54s\tremaining: 634ms\n",
      "8:\tlearn: 0.4533402\ttotal: 3.01s\tremaining: 335ms\n",
      "9:\tlearn: 0.4519004\ttotal: 3.46s\tremaining: 0us\n",
      "[10, 0.49, 15, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22ms\tremaining: 87.9ms\n",
      "2:\tlearn: 0.4686673\ttotal: 531ms\tremaining: 1.24s\n",
      "3:\tlearn: 0.4640224\ttotal: 988ms\tremaining: 1.48s\n",
      "4:\tlearn: 0.4613861\ttotal: 1.11s\tremaining: 1.11s\n",
      "5:\tlearn: 0.4585459\ttotal: 1.6s\tremaining: 1.06s\n",
      "6:\tlearn: 0.4569377\ttotal: 2.07s\tremaining: 886ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.56s\tremaining: 640ms\n",
      "8:\tlearn: 0.4533402\ttotal: 3.08s\tremaining: 343ms\n",
      "9:\tlearn: 0.4519004\ttotal: 3.55s\tremaining: 0us\n",
      "[10, 0.49, 15, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.53ms\tremaining: 76.7ms\n",
      "1:\tlearn: 0.4744785\ttotal: 16.8ms\tremaining: 67.1ms\n",
      "2:\tlearn: 0.4686673\ttotal: 527ms\tremaining: 1.23s\n",
      "3:\tlearn: 0.4640224\ttotal: 1.02s\tremaining: 1.52s\n",
      "4:\tlearn: 0.4613861\ttotal: 1.15s\tremaining: 1.15s\n",
      "5:\tlearn: 0.4585459\ttotal: 1.63s\tremaining: 1.09s\n",
      "6:\tlearn: 0.4569377\ttotal: 2.09s\tremaining: 897ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.58s\tremaining: 644ms\n",
      "8:\tlearn: 0.4533402\ttotal: 3.06s\tremaining: 340ms\n",
      "9:\tlearn: 0.4519004\ttotal: 3.51s\tremaining: 0us\n",
      "[10, 0.49, 15, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.2ms\tremaining: 110ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21.5ms\tremaining: 85.8ms\n",
      "2:\tlearn: 0.4686673\ttotal: 500ms\tremaining: 1.17s\n",
      "3:\tlearn: 0.4640224\ttotal: 962ms\tremaining: 1.44s\n",
      "4:\tlearn: 0.4613861\ttotal: 1.1s\tremaining: 1.1s\n",
      "5:\tlearn: 0.4585459\ttotal: 1.58s\tremaining: 1.05s\n",
      "6:\tlearn: 0.4569377\ttotal: 2.05s\tremaining: 878ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.51s\tremaining: 629ms\n",
      "8:\tlearn: 0.4533402\ttotal: 3s\tremaining: 333ms\n",
      "9:\tlearn: 0.4519004\ttotal: 3.49s\tremaining: 0us\n",
      "[10, 0.49, 15, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 13.8ms\tremaining: 124ms\n",
      "1:\tlearn: 0.4744785\ttotal: 23.4ms\tremaining: 93.7ms\n",
      "2:\tlearn: 0.4686673\ttotal: 497ms\tremaining: 1.16s\n",
      "3:\tlearn: 0.4640224\ttotal: 974ms\tremaining: 1.46s\n",
      "4:\tlearn: 0.4613861\ttotal: 1.11s\tremaining: 1.11s\n",
      "5:\tlearn: 0.4585459\ttotal: 1.59s\tremaining: 1.06s\n",
      "6:\tlearn: 0.4569377\ttotal: 2.08s\tremaining: 890ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.55s\tremaining: 639ms\n",
      "8:\tlearn: 0.4533402\ttotal: 3.02s\tremaining: 336ms\n",
      "9:\tlearn: 0.4519004\ttotal: 3.53s\tremaining: 0us\n",
      "[10, 0.49, 10, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 13.2ms\tremaining: 119ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22.8ms\tremaining: 91.3ms\n",
      "2:\tlearn: 0.4699228\ttotal: 40.8ms\tremaining: 95.2ms\n",
      "3:\tlearn: 0.4669696\ttotal: 55.9ms\tremaining: 83.8ms\n",
      "4:\tlearn: 0.4643800\ttotal: 71.1ms\tremaining: 71.1ms\n",
      "5:\tlearn: 0.4625508\ttotal: 87.3ms\tremaining: 58.2ms\n",
      "6:\tlearn: 0.4603707\ttotal: 102ms\tremaining: 43.5ms\n",
      "7:\tlearn: 0.4571873\ttotal: 115ms\tremaining: 28.9ms\n",
      "8:\tlearn: 0.4552197\ttotal: 131ms\tremaining: 14.5ms\n",
      "9:\tlearn: 0.4542315\ttotal: 148ms\tremaining: 0us\n",
      "[10, 0.49, 10, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 10ms\tremaining: 90.3ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.2ms\tremaining: 80.8ms\n",
      "2:\tlearn: 0.4699228\ttotal: 43.1ms\tremaining: 101ms\n",
      "3:\tlearn: 0.4669696\ttotal: 59.1ms\tremaining: 88.6ms\n",
      "4:\tlearn: 0.4643800\ttotal: 74.7ms\tremaining: 74.7ms\n",
      "5:\tlearn: 0.4625508\ttotal: 91.3ms\tremaining: 60.9ms\n",
      "6:\tlearn: 0.4603707\ttotal: 107ms\tremaining: 45.9ms\n",
      "7:\tlearn: 0.4571873\ttotal: 121ms\tremaining: 30.3ms\n",
      "8:\tlearn: 0.4552197\ttotal: 135ms\tremaining: 15.1ms\n",
      "9:\tlearn: 0.4542315\ttotal: 150ms\tremaining: 0us\n",
      "[10, 0.49, 10, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 15ms\tremaining: 135ms\n",
      "1:\tlearn: 0.4744785\ttotal: 24.2ms\tremaining: 96.7ms\n",
      "2:\tlearn: 0.4699228\ttotal: 41.9ms\tremaining: 97.7ms\n",
      "3:\tlearn: 0.4669696\ttotal: 61.2ms\tremaining: 91.8ms\n",
      "4:\tlearn: 0.4643800\ttotal: 80.3ms\tremaining: 80.3ms\n",
      "5:\tlearn: 0.4625508\ttotal: 97.2ms\tremaining: 64.8ms\n",
      "6:\tlearn: 0.4603707\ttotal: 116ms\tremaining: 49.6ms\n",
      "7:\tlearn: 0.4571873\ttotal: 133ms\tremaining: 33.2ms\n",
      "8:\tlearn: 0.4552197\ttotal: 151ms\tremaining: 16.7ms\n",
      "9:\tlearn: 0.4542315\ttotal: 166ms\tremaining: 0us\n",
      "[10, 0.49, 10, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.7ms\tremaining: 114ms\n",
      "1:\tlearn: 0.4744785\ttotal: 29.4ms\tremaining: 118ms\n",
      "2:\tlearn: 0.4699228\ttotal: 50ms\tremaining: 117ms\n",
      "3:\tlearn: 0.4669696\ttotal: 77.3ms\tremaining: 116ms\n",
      "4:\tlearn: 0.4643800\ttotal: 96.5ms\tremaining: 96.5ms\n",
      "5:\tlearn: 0.4625508\ttotal: 118ms\tremaining: 78.5ms\n",
      "6:\tlearn: 0.4603707\ttotal: 135ms\tremaining: 57.8ms\n",
      "7:\tlearn: 0.4571873\ttotal: 152ms\tremaining: 37.9ms\n",
      "8:\tlearn: 0.4552197\ttotal: 167ms\tremaining: 18.6ms\n",
      "9:\tlearn: 0.4542315\ttotal: 184ms\tremaining: 0us\n",
      "[10, 0.49, 10, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.59ms\tremaining: 86.3ms\n",
      "1:\tlearn: 0.4744785\ttotal: 19.3ms\tremaining: 77.3ms\n",
      "2:\tlearn: 0.4699228\ttotal: 35.9ms\tremaining: 83.7ms\n",
      "3:\tlearn: 0.4669696\ttotal: 53.2ms\tremaining: 79.8ms\n",
      "4:\tlearn: 0.4643800\ttotal: 72.9ms\tremaining: 72.9ms\n",
      "5:\tlearn: 0.4625508\ttotal: 96.4ms\tremaining: 64.3ms\n",
      "6:\tlearn: 0.4603707\ttotal: 142ms\tremaining: 60.7ms\n",
      "7:\tlearn: 0.4571873\ttotal: 168ms\tremaining: 41.9ms\n",
      "8:\tlearn: 0.4552197\ttotal: 184ms\tremaining: 20.4ms\n",
      "9:\tlearn: 0.4542315\ttotal: 201ms\tremaining: 0us\n",
      "[10, 0.49, 12, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.29ms\tremaining: 74.6ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18ms\tremaining: 71.9ms\n",
      "2:\tlearn: 0.4691204\ttotal: 82.3ms\tremaining: 192ms\n",
      "3:\tlearn: 0.4662521\ttotal: 146ms\tremaining: 219ms\n",
      "4:\tlearn: 0.4632297\ttotal: 219ms\tremaining: 219ms\n",
      "5:\tlearn: 0.4614380\ttotal: 297ms\tremaining: 198ms\n",
      "6:\tlearn: 0.4594949\ttotal: 375ms\tremaining: 161ms\n",
      "7:\tlearn: 0.4578565\ttotal: 449ms\tremaining: 112ms\n",
      "8:\tlearn: 0.4562044\ttotal: 517ms\tremaining: 57.5ms\n",
      "9:\tlearn: 0.4547202\ttotal: 580ms\tremaining: 0us\n",
      "[10, 0.49, 12, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 10.7ms\tremaining: 96.4ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.4ms\tremaining: 81.8ms\n",
      "2:\tlearn: 0.4691204\ttotal: 93.8ms\tremaining: 219ms\n",
      "3:\tlearn: 0.4662521\ttotal: 160ms\tremaining: 241ms\n",
      "4:\tlearn: 0.4632297\ttotal: 227ms\tremaining: 227ms\n",
      "5:\tlearn: 0.4614380\ttotal: 303ms\tremaining: 202ms\n",
      "6:\tlearn: 0.4594949\ttotal: 362ms\tremaining: 155ms\n",
      "7:\tlearn: 0.4578565\ttotal: 424ms\tremaining: 106ms\n",
      "8:\tlearn: 0.4562044\ttotal: 484ms\tremaining: 53.7ms\n",
      "9:\tlearn: 0.4547202\ttotal: 546ms\tremaining: 0us\n",
      "[10, 0.49, 12, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.32ms\tremaining: 83.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 17.7ms\tremaining: 70.8ms\n",
      "2:\tlearn: 0.4691204\ttotal: 81.7ms\tremaining: 191ms\n",
      "3:\tlearn: 0.4662521\ttotal: 151ms\tremaining: 226ms\n",
      "4:\tlearn: 0.4632297\ttotal: 211ms\tremaining: 211ms\n",
      "5:\tlearn: 0.4614380\ttotal: 269ms\tremaining: 179ms\n",
      "6:\tlearn: 0.4594949\ttotal: 323ms\tremaining: 138ms\n",
      "7:\tlearn: 0.4578565\ttotal: 377ms\tremaining: 94.3ms\n",
      "8:\tlearn: 0.4562044\ttotal: 445ms\tremaining: 49.4ms\n",
      "9:\tlearn: 0.4547202\ttotal: 524ms\tremaining: 0us\n",
      "[10, 0.49, 12, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.23ms\tremaining: 83ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18ms\tremaining: 72.1ms\n",
      "2:\tlearn: 0.4691204\ttotal: 71.2ms\tremaining: 166ms\n",
      "3:\tlearn: 0.4662521\ttotal: 127ms\tremaining: 191ms\n",
      "4:\tlearn: 0.4632297\ttotal: 190ms\tremaining: 190ms\n",
      "5:\tlearn: 0.4614380\ttotal: 286ms\tremaining: 191ms\n",
      "6:\tlearn: 0.4594949\ttotal: 355ms\tremaining: 152ms\n",
      "7:\tlearn: 0.4578565\ttotal: 423ms\tremaining: 106ms\n",
      "8:\tlearn: 0.4562044\ttotal: 479ms\tremaining: 53.3ms\n",
      "9:\tlearn: 0.4547202\ttotal: 539ms\tremaining: 0us\n",
      "[10, 0.49, 12, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.32ms\tremaining: 83.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 19.2ms\tremaining: 76.7ms\n",
      "2:\tlearn: 0.4691204\ttotal: 81.7ms\tremaining: 191ms\n",
      "3:\tlearn: 0.4662521\ttotal: 147ms\tremaining: 221ms\n",
      "4:\tlearn: 0.4632297\ttotal: 201ms\tremaining: 201ms\n",
      "5:\tlearn: 0.4614380\ttotal: 259ms\tremaining: 173ms\n",
      "6:\tlearn: 0.4594949\ttotal: 322ms\tremaining: 138ms\n",
      "7:\tlearn: 0.4578565\ttotal: 417ms\tremaining: 104ms\n",
      "8:\tlearn: 0.4562044\ttotal: 484ms\tremaining: 53.7ms\n",
      "9:\tlearn: 0.4547202\ttotal: 544ms\tremaining: 0us\n",
      "[10, 0.49, 13, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.3ms\tremaining: 111ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22.5ms\tremaining: 90.2ms\n",
      "2:\tlearn: 0.4688286\ttotal: 158ms\tremaining: 370ms\n",
      "3:\tlearn: 0.4660649\ttotal: 275ms\tremaining: 412ms\n",
      "4:\tlearn: 0.4613755\ttotal: 382ms\tremaining: 382ms\n",
      "5:\tlearn: 0.4593062\ttotal: 546ms\tremaining: 364ms\n",
      "6:\tlearn: 0.4570185\ttotal: 678ms\tremaining: 290ms\n",
      "7:\tlearn: 0.4553016\ttotal: 793ms\tremaining: 198ms\n",
      "8:\tlearn: 0.4535198\ttotal: 906ms\tremaining: 101ms\n",
      "9:\tlearn: 0.4522239\ttotal: 1.02s\tremaining: 0us\n",
      "[10, 0.49, 13, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 17.1ms\tremaining: 154ms\n",
      "1:\tlearn: 0.4744785\ttotal: 27ms\tremaining: 108ms\n",
      "2:\tlearn: 0.4688286\ttotal: 160ms\tremaining: 373ms\n",
      "3:\tlearn: 0.4660649\ttotal: 274ms\tremaining: 410ms\n",
      "4:\tlearn: 0.4613755\ttotal: 382ms\tremaining: 382ms\n",
      "5:\tlearn: 0.4593062\ttotal: 533ms\tremaining: 356ms\n",
      "6:\tlearn: 0.4570185\ttotal: 664ms\tremaining: 284ms\n",
      "7:\tlearn: 0.4553016\ttotal: 780ms\tremaining: 195ms\n",
      "8:\tlearn: 0.4535198\ttotal: 895ms\tremaining: 99.5ms\n",
      "9:\tlearn: 0.4522239\ttotal: 1.05s\tremaining: 0us\n",
      "[10, 0.49, 13, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.43ms\tremaining: 75.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18.2ms\tremaining: 72.8ms\n",
      "2:\tlearn: 0.4688286\ttotal: 135ms\tremaining: 315ms\n",
      "3:\tlearn: 0.4660649\ttotal: 262ms\tremaining: 393ms\n",
      "4:\tlearn: 0.4613755\ttotal: 381ms\tremaining: 381ms\n",
      "5:\tlearn: 0.4593062\ttotal: 514ms\tremaining: 342ms\n",
      "6:\tlearn: 0.4570185\ttotal: 644ms\tremaining: 276ms\n",
      "7:\tlearn: 0.4553016\ttotal: 766ms\tremaining: 192ms\n",
      "8:\tlearn: 0.4535198\ttotal: 878ms\tremaining: 97.6ms\n",
      "9:\tlearn: 0.4522239\ttotal: 1.03s\tremaining: 0us\n",
      "[10, 0.49, 13, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.5ms\tremaining: 76.5ms\n",
      "1:\tlearn: 0.4744785\ttotal: 17.1ms\tremaining: 68.4ms\n",
      "2:\tlearn: 0.4688286\ttotal: 122ms\tremaining: 284ms\n",
      "3:\tlearn: 0.4660649\ttotal: 278ms\tremaining: 417ms\n",
      "4:\tlearn: 0.4613755\ttotal: 402ms\tremaining: 402ms\n",
      "5:\tlearn: 0.4593062\ttotal: 512ms\tremaining: 342ms\n",
      "6:\tlearn: 0.4570185\ttotal: 616ms\tremaining: 264ms\n",
      "7:\tlearn: 0.4553016\ttotal: 784ms\tremaining: 196ms\n",
      "8:\tlearn: 0.4535198\ttotal: 913ms\tremaining: 101ms\n",
      "9:\tlearn: 0.4522239\ttotal: 1.03s\tremaining: 0us\n",
      "[10, 0.49, 13, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.79ms\tremaining: 79.1ms\n",
      "1:\tlearn: 0.4744785\ttotal: 17.3ms\tremaining: 69.2ms\n",
      "2:\tlearn: 0.4688286\ttotal: 123ms\tremaining: 287ms\n",
      "3:\tlearn: 0.4660649\ttotal: 245ms\tremaining: 368ms\n",
      "4:\tlearn: 0.4613755\ttotal: 398ms\tremaining: 398ms\n",
      "5:\tlearn: 0.4593062\ttotal: 522ms\tremaining: 348ms\n",
      "6:\tlearn: 0.4570185\ttotal: 630ms\tremaining: 270ms\n",
      "7:\tlearn: 0.4553016\ttotal: 752ms\tremaining: 188ms\n",
      "8:\tlearn: 0.4535198\ttotal: 902ms\tremaining: 100ms\n",
      "9:\tlearn: 0.4522239\ttotal: 1.01s\tremaining: 0us\n",
      "[10, 0.49, 14, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.5ms\tremaining: 103ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22.8ms\tremaining: 91.3ms\n",
      "2:\tlearn: 0.4686980\ttotal: 256ms\tremaining: 598ms\n",
      "3:\tlearn: 0.4656366\ttotal: 500ms\tremaining: 750ms\n",
      "4:\tlearn: 0.4629508\ttotal: 722ms\tremaining: 722ms\n",
      "5:\tlearn: 0.4604560\ttotal: 986ms\tremaining: 658ms\n",
      "6:\tlearn: 0.4592207\ttotal: 991ms\tremaining: 425ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.22s\tremaining: 305ms\n",
      "8:\tlearn: 0.4553812\ttotal: 1.49s\tremaining: 166ms\n",
      "9:\tlearn: 0.4538997\ttotal: 1.72s\tremaining: 0us\n",
      "[10, 0.49, 14, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 15.5ms\tremaining: 140ms\n",
      "1:\tlearn: 0.4744785\ttotal: 27ms\tremaining: 108ms\n",
      "2:\tlearn: 0.4686980\ttotal: 290ms\tremaining: 677ms\n",
      "3:\tlearn: 0.4656366\ttotal: 567ms\tremaining: 851ms\n",
      "4:\tlearn: 0.4629508\ttotal: 785ms\tremaining: 785ms\n",
      "5:\tlearn: 0.4604560\ttotal: 1.05s\tremaining: 702ms\n",
      "6:\tlearn: 0.4592207\ttotal: 1.06s\tremaining: 453ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.28s\tremaining: 321ms\n",
      "8:\tlearn: 0.4553812\ttotal: 1.54s\tremaining: 172ms\n",
      "9:\tlearn: 0.4538997\ttotal: 1.76s\tremaining: 0us\n",
      "[10, 0.49, 14, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.1ms\tremaining: 100ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21.8ms\tremaining: 87.2ms\n",
      "2:\tlearn: 0.4686980\ttotal: 278ms\tremaining: 648ms\n",
      "3:\tlearn: 0.4656366\ttotal: 549ms\tremaining: 823ms\n",
      "4:\tlearn: 0.4629508\ttotal: 766ms\tremaining: 766ms\n",
      "5:\tlearn: 0.4604560\ttotal: 1.03s\tremaining: 691ms\n",
      "6:\tlearn: 0.4592207\ttotal: 1.04s\tremaining: 446ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.27s\tremaining: 318ms\n",
      "8:\tlearn: 0.4553812\ttotal: 1.55s\tremaining: 172ms\n",
      "9:\tlearn: 0.4538997\ttotal: 1.78s\tremaining: 0us\n",
      "[10, 0.49, 14, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.25ms\tremaining: 83.3ms\n",
      "1:\tlearn: 0.4744785\ttotal: 19.4ms\tremaining: 77.6ms\n",
      "2:\tlearn: 0.4686980\ttotal: 277ms\tremaining: 647ms\n",
      "3:\tlearn: 0.4656366\ttotal: 559ms\tremaining: 839ms\n",
      "4:\tlearn: 0.4629508\ttotal: 776ms\tremaining: 776ms\n",
      "5:\tlearn: 0.4604560\ttotal: 1.04s\tremaining: 692ms\n",
      "6:\tlearn: 0.4592207\ttotal: 1.04s\tremaining: 448ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.28s\tremaining: 320ms\n",
      "8:\tlearn: 0.4553812\ttotal: 1.56s\tremaining: 173ms\n",
      "9:\tlearn: 0.4538997\ttotal: 1.79s\tremaining: 0us\n",
      "[10, 0.49, 14, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 10ms\tremaining: 90.3ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18.9ms\tremaining: 75.7ms\n",
      "2:\tlearn: 0.4686980\ttotal: 275ms\tremaining: 641ms\n",
      "3:\tlearn: 0.4656366\ttotal: 530ms\tremaining: 796ms\n",
      "4:\tlearn: 0.4629508\ttotal: 763ms\tremaining: 763ms\n",
      "5:\tlearn: 0.4604560\ttotal: 1.04s\tremaining: 693ms\n",
      "6:\tlearn: 0.4592207\ttotal: 1.04s\tremaining: 447ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.27s\tremaining: 318ms\n",
      "8:\tlearn: 0.4553812\ttotal: 1.55s\tremaining: 172ms\n",
      "9:\tlearn: 0.4538997\ttotal: 1.77s\tremaining: 0us\n",
      "[6, 0.3, 6, -0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 8.8ms\tremaining: 44ms\n",
      "1:\tlearn: 0.4796834\ttotal: 13.5ms\tremaining: 26.9ms\n",
      "2:\tlearn: 0.4757652\ttotal: 18.2ms\tremaining: 18.2ms\n",
      "3:\tlearn: 0.4737764\ttotal: 22.7ms\tremaining: 11.3ms\n",
      "4:\tlearn: 0.4716943\ttotal: 27.4ms\tremaining: 5.48ms\n",
      "5:\tlearn: 0.4696759\ttotal: 34.2ms\tremaining: 0us\n",
      "[6, 0.3, 6, 0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 4.61ms\tremaining: 23.1ms\n",
      "1:\tlearn: 0.4796834\ttotal: 9.02ms\tremaining: 18ms\n",
      "2:\tlearn: 0.4757652\ttotal: 13.9ms\tremaining: 13.9ms\n",
      "3:\tlearn: 0.4737764\ttotal: 18.6ms\tremaining: 9.31ms\n",
      "4:\tlearn: 0.4716943\ttotal: 23.6ms\tremaining: 4.71ms\n",
      "5:\tlearn: 0.4696759\ttotal: 29.6ms\tremaining: 0us\n",
      "[6, 0.3, 6, 0.0]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.21ms\tremaining: 26.1ms\n",
      "1:\tlearn: 0.4796834\ttotal: 9.45ms\tremaining: 18.9ms\n",
      "2:\tlearn: 0.4757652\ttotal: 13.7ms\tremaining: 13.7ms\n",
      "3:\tlearn: 0.4737764\ttotal: 17.9ms\tremaining: 8.97ms\n",
      "4:\tlearn: 0.4716943\ttotal: 22.2ms\tremaining: 4.43ms\n",
      "5:\tlearn: 0.4696759\ttotal: 26.2ms\tremaining: 0us\n",
      "[6, 0.3, 6, 0.15]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.2ms\tremaining: 26ms\n",
      "1:\tlearn: 0.4796834\ttotal: 9.49ms\tremaining: 19ms\n",
      "2:\tlearn: 0.4757652\ttotal: 13.8ms\tremaining: 13.8ms\n",
      "3:\tlearn: 0.4737764\ttotal: 18ms\tremaining: 8.99ms\n",
      "4:\tlearn: 0.4716943\ttotal: 22.1ms\tremaining: 4.41ms\n",
      "5:\tlearn: 0.4696759\ttotal: 26.1ms\tremaining: 0us\n",
      "[6, 0.3, 6, 0.2]\n",
      "0:\tlearn: 0.4852609\ttotal: 8.87ms\tremaining: 44.3ms\n",
      "1:\tlearn: 0.4796834\ttotal: 13.5ms\tremaining: 26.9ms\n",
      "2:\tlearn: 0.4757652\ttotal: 18.1ms\tremaining: 18.1ms\n",
      "3:\tlearn: 0.4737764\ttotal: 22.6ms\tremaining: 11.3ms\n",
      "4:\tlearn: 0.4716943\ttotal: 33.5ms\tremaining: 6.71ms\n",
      "5:\tlearn: 0.4696759\ttotal: 38.1ms\tremaining: 0us\n",
      "[6, 0.3, 15, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 13.9ms\tremaining: 69.3ms\n",
      "1:\tlearn: 0.4769595\ttotal: 537ms\tremaining: 1.07s\n",
      "2:\tlearn: 0.4714456\ttotal: 989ms\tremaining: 989ms\n",
      "3:\tlearn: 0.4677602\ttotal: 1.45s\tremaining: 725ms\n",
      "4:\tlearn: 0.4645800\ttotal: 1.93s\tremaining: 386ms\n",
      "5:\tlearn: 0.4621633\ttotal: 2.41s\tremaining: 0us\n",
      "[6, 0.3, 15, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.56ms\tremaining: 47.8ms\n",
      "1:\tlearn: 0.4769595\ttotal: 501ms\tremaining: 1s\n",
      "2:\tlearn: 0.4714456\ttotal: 960ms\tremaining: 960ms\n",
      "3:\tlearn: 0.4677602\ttotal: 1.43s\tremaining: 717ms\n",
      "4:\tlearn: 0.4645800\ttotal: 1.89s\tremaining: 378ms\n",
      "5:\tlearn: 0.4621633\ttotal: 2.39s\tremaining: 0us\n",
      "[6, 0.3, 15, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.46ms\tremaining: 42.3ms\n",
      "1:\tlearn: 0.4769595\ttotal: 452ms\tremaining: 905ms\n",
      "2:\tlearn: 0.4714456\ttotal: 908ms\tremaining: 908ms\n",
      "3:\tlearn: 0.4677602\ttotal: 1.39s\tremaining: 693ms\n",
      "4:\tlearn: 0.4645800\ttotal: 1.87s\tremaining: 375ms\n",
      "5:\tlearn: 0.4621633\ttotal: 2.37s\tremaining: 0us\n",
      "[6, 0.3, 15, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.9ms\tremaining: 54.7ms\n",
      "1:\tlearn: 0.4769595\ttotal: 510ms\tremaining: 1.02s\n",
      "2:\tlearn: 0.4714456\ttotal: 993ms\tremaining: 993ms\n",
      "3:\tlearn: 0.4677602\ttotal: 1.46s\tremaining: 730ms\n",
      "4:\tlearn: 0.4645800\ttotal: 1.92s\tremaining: 385ms\n",
      "5:\tlearn: 0.4621633\ttotal: 2.41s\tremaining: 0us\n",
      "[6, 0.3, 15, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.4ms\tremaining: 51.9ms\n",
      "1:\tlearn: 0.4769595\ttotal: 509ms\tremaining: 1.02s\n",
      "2:\tlearn: 0.4714456\ttotal: 991ms\tremaining: 991ms\n",
      "3:\tlearn: 0.4677602\ttotal: 1.45s\tremaining: 727ms\n",
      "4:\tlearn: 0.4645800\ttotal: 1.96s\tremaining: 391ms\n",
      "5:\tlearn: 0.4621633\ttotal: 2.42s\tremaining: 0us\n",
      "[6, 0.3, 10, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.5ms\tremaining: 52.4ms\n",
      "1:\tlearn: 0.4786840\ttotal: 25.7ms\tremaining: 51.4ms\n",
      "2:\tlearn: 0.4743082\ttotal: 47.2ms\tremaining: 47.2ms\n",
      "3:\tlearn: 0.4713878\ttotal: 63.1ms\tremaining: 31.6ms\n",
      "4:\tlearn: 0.4683005\ttotal: 78.4ms\tremaining: 15.7ms\n",
      "5:\tlearn: 0.4662774\ttotal: 94.2ms\tremaining: 0us\n",
      "[6, 0.3, 10, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.4ms\tremaining: 52.2ms\n",
      "1:\tlearn: 0.4786840\ttotal: 26.4ms\tremaining: 52.8ms\n",
      "2:\tlearn: 0.4743082\ttotal: 42.3ms\tremaining: 42.3ms\n",
      "3:\tlearn: 0.4713878\ttotal: 57.1ms\tremaining: 28.5ms\n",
      "4:\tlearn: 0.4683005\ttotal: 73.9ms\tremaining: 14.8ms\n",
      "5:\tlearn: 0.4662774\ttotal: 89.4ms\tremaining: 0us\n",
      "[6, 0.3, 10, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.8ms\tremaining: 64.1ms\n",
      "1:\tlearn: 0.4786840\ttotal: 28.4ms\tremaining: 56.8ms\n",
      "2:\tlearn: 0.4743082\ttotal: 49.8ms\tremaining: 49.8ms\n",
      "3:\tlearn: 0.4713878\ttotal: 68.4ms\tremaining: 34.2ms\n",
      "4:\tlearn: 0.4683005\ttotal: 90.1ms\tremaining: 18ms\n",
      "5:\tlearn: 0.4662774\ttotal: 114ms\tremaining: 0us\n",
      "[6, 0.3, 10, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 17.6ms\tremaining: 87.8ms\n",
      "1:\tlearn: 0.4786840\ttotal: 33.2ms\tremaining: 66.3ms\n",
      "2:\tlearn: 0.4743082\ttotal: 48.1ms\tremaining: 48.1ms\n",
      "3:\tlearn: 0.4713878\ttotal: 63.2ms\tremaining: 31.6ms\n",
      "4:\tlearn: 0.4683005\ttotal: 77.1ms\tremaining: 15.4ms\n",
      "5:\tlearn: 0.4662774\ttotal: 90.6ms\tremaining: 0us\n",
      "[6, 0.3, 10, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 16.8ms\tremaining: 84.2ms\n",
      "1:\tlearn: 0.4786840\ttotal: 34.5ms\tremaining: 68.9ms\n",
      "2:\tlearn: 0.4743082\ttotal: 61.5ms\tremaining: 61.5ms\n",
      "3:\tlearn: 0.4713878\ttotal: 76.9ms\tremaining: 38.5ms\n",
      "4:\tlearn: 0.4683005\ttotal: 92.7ms\tremaining: 18.5ms\n",
      "5:\tlearn: 0.4662774\ttotal: 108ms\tremaining: 0us\n",
      "[6, 0.3, 12, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.96ms\tremaining: 44.8ms\n",
      "1:\tlearn: 0.4778843\ttotal: 69.2ms\tremaining: 138ms\n",
      "2:\tlearn: 0.4738999\ttotal: 131ms\tremaining: 131ms\n",
      "3:\tlearn: 0.4696749\ttotal: 228ms\tremaining: 114ms\n",
      "4:\tlearn: 0.4678542\ttotal: 290ms\tremaining: 57.9ms\n",
      "5:\tlearn: 0.4655216\ttotal: 350ms\tremaining: 0us\n",
      "[6, 0.3, 12, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 18.8ms\tremaining: 93.9ms\n",
      "1:\tlearn: 0.4778843\ttotal: 88.9ms\tremaining: 178ms\n",
      "2:\tlearn: 0.4738999\ttotal: 148ms\tremaining: 148ms\n",
      "3:\tlearn: 0.4696749\ttotal: 207ms\tremaining: 104ms\n",
      "4:\tlearn: 0.4678542\ttotal: 264ms\tremaining: 52.9ms\n",
      "5:\tlearn: 0.4655216\ttotal: 332ms\tremaining: 0us\n",
      "[6, 0.3, 12, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.73ms\tremaining: 43.7ms\n",
      "1:\tlearn: 0.4778843\ttotal: 61.3ms\tremaining: 123ms\n",
      "2:\tlearn: 0.4738999\ttotal: 121ms\tremaining: 121ms\n",
      "3:\tlearn: 0.4696749\ttotal: 184ms\tremaining: 92.2ms\n",
      "4:\tlearn: 0.4678542\ttotal: 267ms\tremaining: 53.4ms\n",
      "5:\tlearn: 0.4655216\ttotal: 337ms\tremaining: 0us\n",
      "[6, 0.3, 12, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 14.7ms\tremaining: 73.5ms\n",
      "1:\tlearn: 0.4778843\ttotal: 90ms\tremaining: 180ms\n",
      "2:\tlearn: 0.4738999\ttotal: 160ms\tremaining: 160ms\n",
      "3:\tlearn: 0.4696749\ttotal: 219ms\tremaining: 110ms\n",
      "4:\tlearn: 0.4678542\ttotal: 276ms\tremaining: 55.2ms\n",
      "5:\tlearn: 0.4655216\ttotal: 330ms\tremaining: 0us\n",
      "[6, 0.3, 12, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.49ms\tremaining: 47.4ms\n",
      "1:\tlearn: 0.4778843\ttotal: 77.7ms\tremaining: 155ms\n",
      "2:\tlearn: 0.4738999\ttotal: 142ms\tremaining: 142ms\n",
      "3:\tlearn: 0.4696749\ttotal: 203ms\tremaining: 102ms\n",
      "4:\tlearn: 0.4678542\ttotal: 260ms\tremaining: 52ms\n",
      "5:\tlearn: 0.4655216\ttotal: 328ms\tremaining: 0us\n",
      "[6, 0.3, 13, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.57ms\tremaining: 47.8ms\n",
      "1:\tlearn: 0.4776303\ttotal: 116ms\tremaining: 231ms\n",
      "2:\tlearn: 0.4735011\ttotal: 232ms\tremaining: 232ms\n",
      "3:\tlearn: 0.4707331\ttotal: 332ms\tremaining: 166ms\n",
      "4:\tlearn: 0.4669265\ttotal: 470ms\tremaining: 93.9ms\n",
      "5:\tlearn: 0.4646028\ttotal: 525ms\tremaining: 0us\n",
      "[6, 0.3, 13, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.8ms\tremaining: 54.1ms\n",
      "1:\tlearn: 0.4776303\ttotal: 131ms\tremaining: 263ms\n",
      "2:\tlearn: 0.4735011\ttotal: 242ms\tremaining: 242ms\n",
      "3:\tlearn: 0.4707331\ttotal: 308ms\tremaining: 154ms\n",
      "4:\tlearn: 0.4669265\ttotal: 452ms\tremaining: 90.4ms\n",
      "5:\tlearn: 0.4646028\ttotal: 518ms\tremaining: 0us\n",
      "[6, 0.3, 13, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.72ms\tremaining: 48.6ms\n",
      "1:\tlearn: 0.4776303\ttotal: 132ms\tremaining: 264ms\n",
      "2:\tlearn: 0.4735011\ttotal: 286ms\tremaining: 286ms\n",
      "3:\tlearn: 0.4707331\ttotal: 347ms\tremaining: 173ms\n",
      "4:\tlearn: 0.4669265\ttotal: 458ms\tremaining: 91.5ms\n",
      "5:\tlearn: 0.4646028\ttotal: 512ms\tremaining: 0us\n",
      "[6, 0.3, 13, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.1ms\tremaining: 60.4ms\n",
      "1:\tlearn: 0.4776303\ttotal: 118ms\tremaining: 236ms\n",
      "2:\tlearn: 0.4735011\ttotal: 222ms\tremaining: 222ms\n",
      "3:\tlearn: 0.4707331\ttotal: 283ms\tremaining: 142ms\n",
      "4:\tlearn: 0.4669265\ttotal: 405ms\tremaining: 81ms\n",
      "5:\tlearn: 0.4646028\ttotal: 469ms\tremaining: 0us\n",
      "[6, 0.3, 13, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.7ms\tremaining: 53.4ms\n",
      "1:\tlearn: 0.4776303\ttotal: 128ms\tremaining: 255ms\n",
      "2:\tlearn: 0.4735011\ttotal: 239ms\tremaining: 239ms\n",
      "3:\tlearn: 0.4707331\ttotal: 337ms\tremaining: 168ms\n",
      "4:\tlearn: 0.4669265\ttotal: 461ms\tremaining: 92.1ms\n",
      "5:\tlearn: 0.4646028\ttotal: 524ms\tremaining: 0us\n",
      "[6, 0.3, 14, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.54ms\tremaining: 47.7ms\n",
      "1:\tlearn: 0.4773298\ttotal: 228ms\tremaining: 456ms\n",
      "2:\tlearn: 0.4728931\ttotal: 500ms\tremaining: 500ms\n",
      "3:\tlearn: 0.4683530\ttotal: 725ms\tremaining: 362ms\n",
      "4:\tlearn: 0.4655211\ttotal: 990ms\tremaining: 198ms\n",
      "5:\tlearn: 0.4621724\ttotal: 1.11s\tremaining: 0us\n",
      "[6, 0.3, 14, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 11.9ms\tremaining: 59.7ms\n",
      "1:\tlearn: 0.4773298\ttotal: 248ms\tremaining: 497ms\n",
      "2:\tlearn: 0.4728931\ttotal: 499ms\tremaining: 499ms\n",
      "3:\tlearn: 0.4683530\ttotal: 718ms\tremaining: 359ms\n",
      "4:\tlearn: 0.4655211\ttotal: 982ms\tremaining: 196ms\n",
      "5:\tlearn: 0.4621724\ttotal: 1.1s\tremaining: 0us\n",
      "[6, 0.3, 14, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 17.8ms\tremaining: 88.8ms\n",
      "1:\tlearn: 0.4773298\ttotal: 296ms\tremaining: 591ms\n",
      "2:\tlearn: 0.4728931\ttotal: 528ms\tremaining: 528ms\n",
      "3:\tlearn: 0.4683530\ttotal: 765ms\tremaining: 383ms\n",
      "4:\tlearn: 0.4655211\ttotal: 1.04s\tremaining: 208ms\n",
      "5:\tlearn: 0.4621724\ttotal: 1.15s\tremaining: 0us\n",
      "[6, 0.3, 14, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 23.1ms\tremaining: 115ms\n",
      "1:\tlearn: 0.4773298\ttotal: 269ms\tremaining: 537ms\n",
      "2:\tlearn: 0.4728931\ttotal: 502ms\tremaining: 502ms\n",
      "3:\tlearn: 0.4683530\ttotal: 722ms\tremaining: 361ms\n",
      "4:\tlearn: 0.4655211\ttotal: 981ms\tremaining: 196ms\n",
      "5:\tlearn: 0.4621724\ttotal: 1.1s\tremaining: 0us\n",
      "[6, 0.3, 14, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 17.1ms\tremaining: 85.3ms\n",
      "1:\tlearn: 0.4773298\ttotal: 240ms\tremaining: 481ms\n",
      "2:\tlearn: 0.4728931\ttotal: 483ms\tremaining: 483ms\n",
      "3:\tlearn: 0.4683530\ttotal: 714ms\tremaining: 357ms\n",
      "4:\tlearn: 0.4655211\ttotal: 965ms\tremaining: 193ms\n",
      "5:\tlearn: 0.4621724\ttotal: 1.08s\tremaining: 0us\n",
      "[6, 0.8, 6, -0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 13.2ms\tremaining: 66ms\n",
      "1:\tlearn: 0.4707614\ttotal: 20.9ms\tremaining: 41.8ms\n",
      "2:\tlearn: 0.4667365\ttotal: 25.3ms\tremaining: 25.3ms\n",
      "3:\tlearn: 0.4636906\ttotal: 32.4ms\tremaining: 16.2ms\n",
      "4:\tlearn: 0.4617121\ttotal: 46.3ms\tremaining: 9.26ms\n",
      "5:\tlearn: 0.4596172\ttotal: 51ms\tremaining: 0us\n",
      "[6, 0.8, 6, 0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.68ms\tremaining: 23.4ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.53ms\tremaining: 17.1ms\n",
      "2:\tlearn: 0.4667365\ttotal: 12.4ms\tremaining: 12.4ms\n",
      "3:\tlearn: 0.4636906\ttotal: 16.3ms\tremaining: 8.14ms\n",
      "4:\tlearn: 0.4617121\ttotal: 20.2ms\tremaining: 4.04ms\n",
      "5:\tlearn: 0.4596172\ttotal: 24ms\tremaining: 0us\n",
      "[6, 0.8, 6, 0.0]\n",
      "0:\tlearn: 0.4762695\ttotal: 5.74ms\tremaining: 28.7ms\n",
      "1:\tlearn: 0.4707614\ttotal: 10.1ms\tremaining: 20.3ms\n",
      "2:\tlearn: 0.4667365\ttotal: 14.1ms\tremaining: 14.1ms\n",
      "3:\tlearn: 0.4636906\ttotal: 18.1ms\tremaining: 9.04ms\n",
      "4:\tlearn: 0.4617121\ttotal: 22.5ms\tremaining: 4.49ms\n",
      "5:\tlearn: 0.4596172\ttotal: 26.7ms\tremaining: 0us\n",
      "[6, 0.8, 6, 0.15]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.84ms\tremaining: 24.2ms\n",
      "1:\tlearn: 0.4707614\ttotal: 19.4ms\tremaining: 38.8ms\n",
      "2:\tlearn: 0.4667365\ttotal: 23.8ms\tremaining: 23.8ms\n",
      "3:\tlearn: 0.4636906\ttotal: 28.2ms\tremaining: 14.1ms\n",
      "4:\tlearn: 0.4617121\ttotal: 32.8ms\tremaining: 6.55ms\n",
      "5:\tlearn: 0.4596172\ttotal: 56.3ms\tremaining: 0us\n",
      "[6, 0.8, 6, 0.2]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.38ms\tremaining: 21.9ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.89ms\tremaining: 17.8ms\n",
      "2:\tlearn: 0.4667365\ttotal: 14.2ms\tremaining: 14.2ms\n",
      "3:\tlearn: 0.4636906\ttotal: 18.4ms\tremaining: 9.2ms\n",
      "4:\tlearn: 0.4617121\ttotal: 23ms\tremaining: 4.61ms\n",
      "5:\tlearn: 0.4596172\ttotal: 28ms\tremaining: 0us\n",
      "[6, 0.8, 15, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.4ms\tremaining: 62.2ms\n",
      "1:\tlearn: 0.4658921\ttotal: 576ms\tremaining: 1.15s\n",
      "2:\tlearn: 0.4614984\ttotal: 1.08s\tremaining: 1.08s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.6s\tremaining: 800ms\n",
      "4:\tlearn: 0.4540621\ttotal: 2.12s\tremaining: 424ms\n",
      "5:\tlearn: 0.4519233\ttotal: 2.63s\tremaining: 0us\n",
      "[6, 0.8, 15, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.8ms\tremaining: 53.9ms\n",
      "1:\tlearn: 0.4658921\ttotal: 504ms\tremaining: 1.01s\n",
      "2:\tlearn: 0.4614984\ttotal: 961ms\tremaining: 961ms\n",
      "3:\tlearn: 0.4572383\ttotal: 1.42s\tremaining: 711ms\n",
      "4:\tlearn: 0.4540621\ttotal: 1.91s\tremaining: 382ms\n",
      "5:\tlearn: 0.4519233\ttotal: 2.4s\tremaining: 0us\n",
      "[6, 0.8, 15, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 16.4ms\tremaining: 82ms\n",
      "1:\tlearn: 0.4658921\ttotal: 501ms\tremaining: 1s\n",
      "2:\tlearn: 0.4614984\ttotal: 1.01s\tremaining: 1.01s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.52s\tremaining: 761ms\n",
      "4:\tlearn: 0.4540621\ttotal: 2.02s\tremaining: 405ms\n",
      "5:\tlearn: 0.4519233\ttotal: 2.5s\tremaining: 0us\n",
      "[6, 0.8, 15, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.6ms\tremaining: 52.8ms\n",
      "1:\tlearn: 0.4658921\ttotal: 474ms\tremaining: 948ms\n",
      "2:\tlearn: 0.4614984\ttotal: 966ms\tremaining: 966ms\n",
      "3:\tlearn: 0.4572383\ttotal: 1.47s\tremaining: 733ms\n",
      "4:\tlearn: 0.4540621\ttotal: 1.96s\tremaining: 392ms\n",
      "5:\tlearn: 0.4519233\ttotal: 2.44s\tremaining: 0us\n",
      "[6, 0.8, 15, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.7ms\tremaining: 58.4ms\n",
      "1:\tlearn: 0.4658921\ttotal: 541ms\tremaining: 1.08s\n",
      "2:\tlearn: 0.4614984\ttotal: 1.02s\tremaining: 1.02s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.53s\tremaining: 767ms\n",
      "4:\tlearn: 0.4540621\ttotal: 2s\tremaining: 401ms\n",
      "5:\tlearn: 0.4519233\ttotal: 2.49s\tremaining: 0us\n",
      "[6, 0.8, 10, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.9ms\tremaining: 49.5ms\n",
      "1:\tlearn: 0.4684354\ttotal: 26.5ms\tremaining: 53ms\n",
      "2:\tlearn: 0.4642800\ttotal: 42.3ms\tremaining: 42.3ms\n",
      "3:\tlearn: 0.4627032\ttotal: 45.3ms\tremaining: 22.7ms\n",
      "4:\tlearn: 0.4607357\ttotal: 60.9ms\tremaining: 12.2ms\n",
      "5:\tlearn: 0.4583929\ttotal: 76ms\tremaining: 0us\n",
      "[6, 0.8, 10, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 14.8ms\tremaining: 74.1ms\n",
      "1:\tlearn: 0.4684354\ttotal: 45.8ms\tremaining: 91.5ms\n",
      "2:\tlearn: 0.4642800\ttotal: 63.9ms\tremaining: 63.9ms\n",
      "3:\tlearn: 0.4627032\ttotal: 66.9ms\tremaining: 33.5ms\n",
      "4:\tlearn: 0.4607357\ttotal: 83.6ms\tremaining: 16.7ms\n",
      "5:\tlearn: 0.4583929\ttotal: 103ms\tremaining: 0us\n",
      "[6, 0.8, 10, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.87ms\tremaining: 44.4ms\n",
      "1:\tlearn: 0.4684354\ttotal: 24.1ms\tremaining: 48.3ms\n",
      "2:\tlearn: 0.4642800\ttotal: 42.4ms\tremaining: 42.4ms\n",
      "3:\tlearn: 0.4627032\ttotal: 45.4ms\tremaining: 22.7ms\n",
      "4:\tlearn: 0.4607357\ttotal: 61.5ms\tremaining: 12.3ms\n",
      "5:\tlearn: 0.4583929\ttotal: 78.9ms\tremaining: 0us\n",
      "[6, 0.8, 10, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.7ms\tremaining: 53.6ms\n",
      "1:\tlearn: 0.4684354\ttotal: 26.7ms\tremaining: 53.5ms\n",
      "2:\tlearn: 0.4642800\ttotal: 40.6ms\tremaining: 40.6ms\n",
      "3:\tlearn: 0.4627032\ttotal: 43.2ms\tremaining: 21.6ms\n",
      "4:\tlearn: 0.4607357\ttotal: 57.2ms\tremaining: 11.4ms\n",
      "5:\tlearn: 0.4583929\ttotal: 71ms\tremaining: 0us\n",
      "[6, 0.8, 10, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.2ms\tremaining: 56ms\n",
      "1:\tlearn: 0.4684354\ttotal: 27.9ms\tremaining: 55.8ms\n",
      "2:\tlearn: 0.4642800\ttotal: 45.7ms\tremaining: 45.7ms\n",
      "3:\tlearn: 0.4627032\ttotal: 48.9ms\tremaining: 24.4ms\n",
      "4:\tlearn: 0.4607357\ttotal: 65.8ms\tremaining: 13.2ms\n",
      "5:\tlearn: 0.4583929\ttotal: 82.6ms\tremaining: 0us\n",
      "[6, 0.8, 8, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.2ms\tremaining: 61.2ms\n",
      "1:\tlearn: 0.4682512\ttotal: 19.5ms\tremaining: 39ms\n",
      "2:\tlearn: 0.4650605\ttotal: 29.3ms\tremaining: 29.3ms\n",
      "3:\tlearn: 0.4630741\ttotal: 37.2ms\tremaining: 18.6ms\n",
      "4:\tlearn: 0.4600410\ttotal: 71.6ms\tremaining: 14.3ms\n",
      "5:\tlearn: 0.4577069\ttotal: 80.1ms\tremaining: 0us\n",
      "[6, 0.8, 8, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.15ms\tremaining: 40.7ms\n",
      "1:\tlearn: 0.4682512\ttotal: 15.3ms\tremaining: 30.6ms\n",
      "2:\tlearn: 0.4650605\ttotal: 22.2ms\tremaining: 22.2ms\n",
      "3:\tlearn: 0.4630741\ttotal: 29.2ms\tremaining: 14.6ms\n",
      "4:\tlearn: 0.4600410\ttotal: 36.5ms\tremaining: 7.29ms\n",
      "5:\tlearn: 0.4577069\ttotal: 44.6ms\tremaining: 0us\n",
      "[6, 0.8, 8, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 7.19ms\tremaining: 36ms\n",
      "1:\tlearn: 0.4682512\ttotal: 16.3ms\tremaining: 32.7ms\n",
      "2:\tlearn: 0.4650605\ttotal: 25.3ms\tremaining: 25.3ms\n",
      "3:\tlearn: 0.4630741\ttotal: 32.3ms\tremaining: 16.2ms\n",
      "4:\tlearn: 0.4600410\ttotal: 39.8ms\tremaining: 7.97ms\n",
      "5:\tlearn: 0.4577069\ttotal: 62.5ms\tremaining: 0us\n",
      "[6, 0.8, 8, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 7.51ms\tremaining: 37.6ms\n",
      "1:\tlearn: 0.4682512\ttotal: 15.6ms\tremaining: 31.2ms\n",
      "2:\tlearn: 0.4650605\ttotal: 22.2ms\tremaining: 22.2ms\n",
      "3:\tlearn: 0.4630741\ttotal: 28.6ms\tremaining: 14.3ms\n",
      "4:\tlearn: 0.4600410\ttotal: 35.2ms\tremaining: 7.04ms\n",
      "5:\tlearn: 0.4577069\ttotal: 41.9ms\tremaining: 0us\n",
      "[6, 0.8, 8, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.65ms\tremaining: 43.3ms\n",
      "1:\tlearn: 0.4682512\ttotal: 16.7ms\tremaining: 33.4ms\n",
      "2:\tlearn: 0.4650605\ttotal: 23.8ms\tremaining: 23.8ms\n",
      "3:\tlearn: 0.4630741\ttotal: 34.4ms\tremaining: 17.2ms\n",
      "4:\tlearn: 0.4600410\ttotal: 54.7ms\tremaining: 10.9ms\n",
      "5:\tlearn: 0.4577069\ttotal: 68.3ms\tremaining: 0us\n",
      "[6, 0.8, 8, 0.25]\n",
      "0:\tlearn: 0.4757928\ttotal: 7.2ms\tremaining: 36ms\n",
      "1:\tlearn: 0.4682512\ttotal: 13.8ms\tremaining: 27.6ms\n",
      "2:\tlearn: 0.4650605\ttotal: 20.3ms\tremaining: 20.3ms\n",
      "3:\tlearn: 0.4630741\ttotal: 26.7ms\tremaining: 13.4ms\n",
      "4:\tlearn: 0.4600410\ttotal: 33.7ms\tremaining: 6.75ms\n",
      "5:\tlearn: 0.4577069\ttotal: 40.2ms\tremaining: 0us\n",
      "[6, 0.8, 7, -0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 23.5ms\tremaining: 118ms\n",
      "1:\tlearn: 0.4687965\ttotal: 29.1ms\tremaining: 58.2ms\n",
      "2:\tlearn: 0.4653862\ttotal: 35ms\tremaining: 35ms\n",
      "3:\tlearn: 0.4622296\ttotal: 41.5ms\tremaining: 20.7ms\n",
      "4:\tlearn: 0.4598883\ttotal: 47ms\tremaining: 9.4ms\n",
      "5:\tlearn: 0.4581321\ttotal: 52.6ms\tremaining: 0us\n",
      "[6, 0.8, 7, 0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 16.1ms\tremaining: 80.6ms\n",
      "1:\tlearn: 0.4687965\ttotal: 22.4ms\tremaining: 44.7ms\n",
      "2:\tlearn: 0.4653862\ttotal: 27.5ms\tremaining: 27.5ms\n",
      "3:\tlearn: 0.4622296\ttotal: 33.3ms\tremaining: 16.6ms\n",
      "4:\tlearn: 0.4598883\ttotal: 38.9ms\tremaining: 7.79ms\n",
      "5:\tlearn: 0.4581321\ttotal: 44.2ms\tremaining: 0us\n",
      "[6, 0.8, 7, 0.0]\n",
      "0:\tlearn: 0.4762583\ttotal: 28.4ms\tremaining: 142ms\n",
      "1:\tlearn: 0.4687965\ttotal: 37.2ms\tremaining: 74.4ms\n",
      "2:\tlearn: 0.4653862\ttotal: 43ms\tremaining: 43ms\n",
      "3:\tlearn: 0.4622296\ttotal: 48.8ms\tremaining: 24.4ms\n",
      "4:\tlearn: 0.4598883\ttotal: 58.6ms\tremaining: 11.7ms\n",
      "5:\tlearn: 0.4581321\ttotal: 78ms\tremaining: 0us\n",
      "[6, 0.8, 7, 0.15]\n",
      "0:\tlearn: 0.4762583\ttotal: 4.88ms\tremaining: 24.4ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.3ms\tremaining: 20.6ms\n",
      "2:\tlearn: 0.4653862\ttotal: 15.4ms\tremaining: 15.4ms\n",
      "3:\tlearn: 0.4622296\ttotal: 20.6ms\tremaining: 10.3ms\n",
      "4:\tlearn: 0.4598883\ttotal: 26ms\tremaining: 5.2ms\n",
      "5:\tlearn: 0.4581321\ttotal: 31.5ms\tremaining: 0us\n",
      "[6, 0.8, 7, 0.2]\n",
      "0:\tlearn: 0.4762583\ttotal: 8.33ms\tremaining: 41.7ms\n",
      "1:\tlearn: 0.4687965\ttotal: 14.7ms\tremaining: 29.3ms\n",
      "2:\tlearn: 0.4653862\ttotal: 19.9ms\tremaining: 19.9ms\n",
      "3:\tlearn: 0.4622296\ttotal: 25.3ms\tremaining: 12.7ms\n",
      "4:\tlearn: 0.4598883\ttotal: 32.8ms\tremaining: 6.55ms\n",
      "5:\tlearn: 0.4581321\ttotal: 39ms\tremaining: 0us\n",
      "[6, 0.55, 6, -0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.57ms\tremaining: 22.9ms\n",
      "1:\tlearn: 0.4730186\ttotal: 9.63ms\tremaining: 19.3ms\n",
      "2:\tlearn: 0.4702860\ttotal: 13.9ms\tremaining: 13.9ms\n",
      "3:\tlearn: 0.4675422\ttotal: 18.5ms\tremaining: 9.25ms\n",
      "4:\tlearn: 0.4655547\ttotal: 22.5ms\tremaining: 4.51ms\n",
      "5:\tlearn: 0.4641129\ttotal: 27.1ms\tremaining: 0us\n",
      "[6, 0.55, 6, 0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 6.71ms\tremaining: 33.6ms\n",
      "1:\tlearn: 0.4730186\ttotal: 11ms\tremaining: 22ms\n",
      "2:\tlearn: 0.4702860\ttotal: 15.3ms\tremaining: 15.3ms\n",
      "3:\tlearn: 0.4675422\ttotal: 19.8ms\tremaining: 9.88ms\n",
      "4:\tlearn: 0.4655547\ttotal: 24.2ms\tremaining: 4.84ms\n",
      "5:\tlearn: 0.4641129\ttotal: 29.3ms\tremaining: 0us\n",
      "[6, 0.55, 6, 0.0]\n",
      "0:\tlearn: 0.4795967\ttotal: 7.16ms\tremaining: 35.8ms\n",
      "1:\tlearn: 0.4730186\ttotal: 11.6ms\tremaining: 23.2ms\n",
      "2:\tlearn: 0.4702860\ttotal: 15.9ms\tremaining: 15.9ms\n",
      "3:\tlearn: 0.4675422\ttotal: 20.5ms\tremaining: 10.3ms\n",
      "4:\tlearn: 0.4655547\ttotal: 25.1ms\tremaining: 5.01ms\n",
      "5:\tlearn: 0.4641129\ttotal: 31.7ms\tremaining: 0us\n",
      "[6, 0.55, 6, 0.15]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.25ms\tremaining: 21.3ms\n",
      "1:\tlearn: 0.4730186\ttotal: 10.5ms\tremaining: 20.9ms\n",
      "2:\tlearn: 0.4702860\ttotal: 15ms\tremaining: 15ms\n",
      "3:\tlearn: 0.4675422\ttotal: 19.3ms\tremaining: 9.65ms\n",
      "4:\tlearn: 0.4655547\ttotal: 23.5ms\tremaining: 4.71ms\n",
      "5:\tlearn: 0.4641129\ttotal: 28ms\tremaining: 0us\n",
      "[6, 0.55, 6, 0.2]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.24ms\tremaining: 21.2ms\n",
      "1:\tlearn: 0.4730186\ttotal: 8.43ms\tremaining: 16.9ms\n",
      "2:\tlearn: 0.4702860\ttotal: 12.4ms\tremaining: 12.4ms\n",
      "3:\tlearn: 0.4675422\ttotal: 17ms\tremaining: 8.5ms\n",
      "4:\tlearn: 0.4655547\ttotal: 21.5ms\tremaining: 4.3ms\n",
      "5:\tlearn: 0.4641129\ttotal: 26.1ms\tremaining: 0us\n",
      "[6, 0.55, 15, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.2ms\tremaining: 61ms\n",
      "1:\tlearn: 0.4689110\ttotal: 490ms\tremaining: 980ms\n",
      "2:\tlearn: 0.4640795\ttotal: 967ms\tremaining: 967ms\n",
      "3:\tlearn: 0.4604685\ttotal: 1.44s\tremaining: 718ms\n",
      "4:\tlearn: 0.4573812\ttotal: 1.94s\tremaining: 387ms\n",
      "5:\tlearn: 0.4546662\ttotal: 2.44s\tremaining: 0us\n",
      "[6, 0.55, 15, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.76ms\tremaining: 48.8ms\n",
      "1:\tlearn: 0.4689110\ttotal: 509ms\tremaining: 1.02s\n",
      "2:\tlearn: 0.4640795\ttotal: 975ms\tremaining: 975ms\n",
      "3:\tlearn: 0.4604685\ttotal: 1.46s\tremaining: 732ms\n",
      "4:\tlearn: 0.4573812\ttotal: 1.94s\tremaining: 388ms\n",
      "5:\tlearn: 0.4546662\ttotal: 2.44s\tremaining: 0us\n",
      "[6, 0.55, 15, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.1ms\tremaining: 50.3ms\n",
      "1:\tlearn: 0.4689110\ttotal: 504ms\tremaining: 1.01s\n",
      "2:\tlearn: 0.4640795\ttotal: 986ms\tremaining: 986ms\n",
      "3:\tlearn: 0.4604685\ttotal: 1.45s\tremaining: 724ms\n",
      "4:\tlearn: 0.4573812\ttotal: 1.91s\tremaining: 382ms\n",
      "5:\tlearn: 0.4546662\ttotal: 2.37s\tremaining: 0us\n",
      "[6, 0.55, 15, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 13.1ms\tremaining: 65.4ms\n",
      "1:\tlearn: 0.4689110\ttotal: 513ms\tremaining: 1.03s\n",
      "2:\tlearn: 0.4640795\ttotal: 966ms\tremaining: 966ms\n",
      "3:\tlearn: 0.4604685\ttotal: 1.44s\tremaining: 719ms\n",
      "4:\tlearn: 0.4573812\ttotal: 1.92s\tremaining: 385ms\n",
      "5:\tlearn: 0.4546662\ttotal: 2.39s\tremaining: 0us\n",
      "[6, 0.55, 15, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.44ms\tremaining: 47.2ms\n",
      "1:\tlearn: 0.4689110\ttotal: 482ms\tremaining: 964ms\n",
      "2:\tlearn: 0.4640795\ttotal: 954ms\tremaining: 954ms\n",
      "3:\tlearn: 0.4604685\ttotal: 1.43s\tremaining: 716ms\n",
      "4:\tlearn: 0.4573812\ttotal: 1.93s\tremaining: 386ms\n",
      "5:\tlearn: 0.4546662\ttotal: 2.41s\tremaining: 0us\n",
      "[6, 0.55, 10, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.8ms\tremaining: 53.9ms\n",
      "1:\tlearn: 0.4715198\ttotal: 26.6ms\tremaining: 53.2ms\n",
      "2:\tlearn: 0.4676485\ttotal: 44ms\tremaining: 44ms\n",
      "3:\tlearn: 0.4663151\ttotal: 46.7ms\tremaining: 23.4ms\n",
      "4:\tlearn: 0.4641480\ttotal: 61.7ms\tremaining: 12.3ms\n",
      "5:\tlearn: 0.4609741\ttotal: 78.8ms\tremaining: 0us\n",
      "[6, 0.55, 10, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.86ms\tremaining: 49.3ms\n",
      "1:\tlearn: 0.4715198\ttotal: 26.2ms\tremaining: 52.3ms\n",
      "2:\tlearn: 0.4676485\ttotal: 42ms\tremaining: 42ms\n",
      "3:\tlearn: 0.4663151\ttotal: 44.8ms\tremaining: 22.4ms\n",
      "4:\tlearn: 0.4641480\ttotal: 61.2ms\tremaining: 12.2ms\n",
      "5:\tlearn: 0.4609741\ttotal: 76.7ms\tremaining: 0us\n",
      "[6, 0.55, 10, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 15.9ms\tremaining: 79.5ms\n",
      "1:\tlearn: 0.4715198\ttotal: 33ms\tremaining: 66ms\n",
      "2:\tlearn: 0.4676485\ttotal: 49.7ms\tremaining: 49.7ms\n",
      "3:\tlearn: 0.4663151\ttotal: 52.5ms\tremaining: 26.3ms\n",
      "4:\tlearn: 0.4641480\ttotal: 67ms\tremaining: 13.4ms\n",
      "5:\tlearn: 0.4609741\ttotal: 83.3ms\tremaining: 0us\n",
      "[6, 0.55, 10, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 17ms\tremaining: 85ms\n",
      "1:\tlearn: 0.4715198\ttotal: 43.3ms\tremaining: 86.6ms\n",
      "2:\tlearn: 0.4676485\ttotal: 69.8ms\tremaining: 69.8ms\n",
      "3:\tlearn: 0.4663151\ttotal: 73.7ms\tremaining: 36.9ms\n",
      "4:\tlearn: 0.4641480\ttotal: 96.9ms\tremaining: 19.4ms\n",
      "5:\tlearn: 0.4609741\ttotal: 113ms\tremaining: 0us\n",
      "[6, 0.55, 10, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.89ms\tremaining: 49.4ms\n",
      "1:\tlearn: 0.4715198\ttotal: 29ms\tremaining: 58.1ms\n",
      "2:\tlearn: 0.4676485\ttotal: 45.6ms\tremaining: 45.6ms\n",
      "3:\tlearn: 0.4663151\ttotal: 48.9ms\tremaining: 24.4ms\n",
      "4:\tlearn: 0.4641480\ttotal: 65.5ms\tremaining: 13.1ms\n",
      "5:\tlearn: 0.4609741\ttotal: 84.9ms\tremaining: 0us\n",
      "[6, 0.55, 12, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10ms\tremaining: 50.2ms\n",
      "1:\tlearn: 0.4704514\ttotal: 71.6ms\tremaining: 143ms\n",
      "2:\tlearn: 0.4668875\ttotal: 132ms\tremaining: 132ms\n",
      "3:\tlearn: 0.4641234\ttotal: 206ms\tremaining: 103ms\n",
      "4:\tlearn: 0.4616543\ttotal: 292ms\tremaining: 58.5ms\n",
      "5:\tlearn: 0.4587449\ttotal: 364ms\tremaining: 0us\n",
      "[6, 0.55, 12, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.6ms\tremaining: 52.9ms\n",
      "1:\tlearn: 0.4704514\ttotal: 73.5ms\tremaining: 147ms\n",
      "2:\tlearn: 0.4668875\ttotal: 159ms\tremaining: 159ms\n",
      "3:\tlearn: 0.4641234\ttotal: 227ms\tremaining: 114ms\n",
      "4:\tlearn: 0.4616543\ttotal: 293ms\tremaining: 58.6ms\n",
      "5:\tlearn: 0.4587449\ttotal: 354ms\tremaining: 0us\n",
      "[6, 0.55, 12, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 17.6ms\tremaining: 88.2ms\n",
      "1:\tlearn: 0.4704514\ttotal: 119ms\tremaining: 237ms\n",
      "2:\tlearn: 0.4668875\ttotal: 186ms\tremaining: 186ms\n",
      "3:\tlearn: 0.4641234\ttotal: 255ms\tremaining: 127ms\n",
      "4:\tlearn: 0.4616543\ttotal: 312ms\tremaining: 62.4ms\n",
      "5:\tlearn: 0.4587449\ttotal: 377ms\tremaining: 0us\n",
      "[6, 0.55, 12, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 14ms\tremaining: 70.2ms\n",
      "1:\tlearn: 0.4704514\ttotal: 77.6ms\tremaining: 155ms\n",
      "2:\tlearn: 0.4668875\ttotal: 140ms\tremaining: 140ms\n",
      "3:\tlearn: 0.4641234\ttotal: 207ms\tremaining: 103ms\n",
      "4:\tlearn: 0.4616543\ttotal: 301ms\tremaining: 60.2ms\n",
      "5:\tlearn: 0.4587449\ttotal: 382ms\tremaining: 0us\n",
      "[6, 0.55, 12, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 13.9ms\tremaining: 69.7ms\n",
      "1:\tlearn: 0.4704514\ttotal: 82.3ms\tremaining: 165ms\n",
      "2:\tlearn: 0.4668875\ttotal: 169ms\tremaining: 169ms\n",
      "3:\tlearn: 0.4641234\ttotal: 244ms\tremaining: 122ms\n",
      "4:\tlearn: 0.4616543\ttotal: 311ms\tremaining: 62.2ms\n",
      "5:\tlearn: 0.4587449\ttotal: 367ms\tremaining: 0us\n",
      "[6, 0.55, 13, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 16.4ms\tremaining: 82.1ms\n",
      "1:\tlearn: 0.4700386\ttotal: 170ms\tremaining: 339ms\n",
      "2:\tlearn: 0.4651124\ttotal: 285ms\tremaining: 285ms\n",
      "3:\tlearn: 0.4623159\ttotal: 392ms\tremaining: 196ms\n",
      "4:\tlearn: 0.4590456\ttotal: 463ms\tremaining: 92.5ms\n",
      "5:\tlearn: 0.4565869\ttotal: 622ms\tremaining: 0us\n",
      "[6, 0.55, 13, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10ms\tremaining: 50.1ms\n",
      "1:\tlearn: 0.4700386\ttotal: 128ms\tremaining: 255ms\n",
      "2:\tlearn: 0.4651124\ttotal: 278ms\tremaining: 278ms\n",
      "3:\tlearn: 0.4623159\ttotal: 409ms\tremaining: 205ms\n",
      "4:\tlearn: 0.4590456\ttotal: 467ms\tremaining: 93.4ms\n",
      "5:\tlearn: 0.4565869\ttotal: 574ms\tremaining: 0us\n",
      "[6, 0.55, 13, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 17.8ms\tremaining: 88.9ms\n",
      "1:\tlearn: 0.4700386\ttotal: 139ms\tremaining: 278ms\n",
      "2:\tlearn: 0.4651124\ttotal: 263ms\tremaining: 263ms\n",
      "3:\tlearn: 0.4623159\ttotal: 377ms\tremaining: 188ms\n",
      "4:\tlearn: 0.4590456\ttotal: 440ms\tremaining: 88ms\n",
      "5:\tlearn: 0.4565869\ttotal: 606ms\tremaining: 0us\n",
      "[6, 0.55, 13, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.44ms\tremaining: 42.2ms\n",
      "1:\tlearn: 0.4700386\ttotal: 162ms\tremaining: 324ms\n",
      "2:\tlearn: 0.4651124\ttotal: 292ms\tremaining: 292ms\n",
      "3:\tlearn: 0.4623159\ttotal: 410ms\tremaining: 205ms\n",
      "4:\tlearn: 0.4590456\ttotal: 464ms\tremaining: 92.9ms\n",
      "5:\tlearn: 0.4565869\ttotal: 594ms\tremaining: 0us\n",
      "[6, 0.55, 13, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.2ms\tremaining: 50.8ms\n",
      "1:\tlearn: 0.4700386\ttotal: 122ms\tremaining: 244ms\n",
      "2:\tlearn: 0.4651124\ttotal: 251ms\tremaining: 251ms\n",
      "3:\tlearn: 0.4623159\ttotal: 385ms\tremaining: 193ms\n",
      "4:\tlearn: 0.4590456\ttotal: 446ms\tremaining: 89.2ms\n",
      "5:\tlearn: 0.4565869\ttotal: 557ms\tremaining: 0us\n",
      "[6, 0.55, 14, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 11.8ms\tremaining: 58.8ms\n",
      "1:\tlearn: 0.4695164\ttotal: 265ms\tremaining: 531ms\n",
      "2:\tlearn: 0.4654149\ttotal: 510ms\tremaining: 510ms\n",
      "3:\tlearn: 0.4619585\ttotal: 740ms\tremaining: 370ms\n",
      "4:\tlearn: 0.4580701\ttotal: 997ms\tremaining: 199ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.01s\tremaining: 0us\n",
      "[6, 0.55, 14, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.1ms\tremaining: 60.3ms\n",
      "1:\tlearn: 0.4695164\ttotal: 285ms\tremaining: 570ms\n",
      "2:\tlearn: 0.4654149\ttotal: 522ms\tremaining: 522ms\n",
      "3:\tlearn: 0.4619585\ttotal: 782ms\tremaining: 391ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.01s\tremaining: 201ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.02s\tremaining: 0us\n",
      "[6, 0.55, 14, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.98ms\tremaining: 44.9ms\n",
      "1:\tlearn: 0.4695164\ttotal: 260ms\tremaining: 519ms\n",
      "2:\tlearn: 0.4654149\ttotal: 550ms\tremaining: 550ms\n",
      "3:\tlearn: 0.4619585\ttotal: 780ms\tremaining: 390ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.06s\tremaining: 213ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.08s\tremaining: 0us\n",
      "[6, 0.55, 14, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.54ms\tremaining: 47.7ms\n",
      "1:\tlearn: 0.4695164\ttotal: 285ms\tremaining: 569ms\n",
      "2:\tlearn: 0.4654149\ttotal: 506ms\tremaining: 506ms\n",
      "3:\tlearn: 0.4619585\ttotal: 773ms\tremaining: 386ms\n",
      "4:\tlearn: 0.4580701\ttotal: 995ms\tremaining: 199ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.01s\tremaining: 0us\n",
      "[6, 0.55, 14, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.4ms\tremaining: 52.1ms\n",
      "1:\tlearn: 0.4695164\ttotal: 231ms\tremaining: 463ms\n",
      "2:\tlearn: 0.4654149\ttotal: 497ms\tremaining: 497ms\n",
      "3:\tlearn: 0.4619585\ttotal: 746ms\tremaining: 373ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.01s\tremaining: 202ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.03s\tremaining: 0us\n",
      "[6, 0.42, 6, -0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.25ms\tremaining: 21.3ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.76ms\tremaining: 17.5ms\n",
      "2:\tlearn: 0.4730150\ttotal: 12.8ms\tremaining: 12.8ms\n",
      "3:\tlearn: 0.4709457\ttotal: 16.9ms\tremaining: 8.43ms\n",
      "4:\tlearn: 0.4690547\ttotal: 20.8ms\tremaining: 4.16ms\n",
      "5:\tlearn: 0.4668601\ttotal: 25.1ms\tremaining: 0us\n",
      "[6, 0.42, 6, 0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.13ms\tremaining: 20.7ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.44ms\tremaining: 16.9ms\n",
      "2:\tlearn: 0.4730150\ttotal: 12.8ms\tremaining: 12.8ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17.2ms\tremaining: 8.58ms\n",
      "4:\tlearn: 0.4690547\ttotal: 21.4ms\tremaining: 4.29ms\n",
      "5:\tlearn: 0.4668601\ttotal: 25.7ms\tremaining: 0us\n",
      "[6, 0.42, 6, 0.0]\n",
      "0:\tlearn: 0.4822549\ttotal: 3.98ms\tremaining: 19.9ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.03ms\tremaining: 16.1ms\n",
      "2:\tlearn: 0.4730150\ttotal: 12.6ms\tremaining: 12.6ms\n",
      "3:\tlearn: 0.4709457\ttotal: 16.6ms\tremaining: 8.29ms\n",
      "4:\tlearn: 0.4690547\ttotal: 20.8ms\tremaining: 4.16ms\n",
      "5:\tlearn: 0.4668601\ttotal: 24.9ms\tremaining: 0us\n",
      "[6, 0.42, 6, 0.15]\n",
      "0:\tlearn: 0.4822549\ttotal: 6.51ms\tremaining: 32.6ms\n",
      "1:\tlearn: 0.4764006\ttotal: 11ms\tremaining: 22ms\n",
      "2:\tlearn: 0.4730150\ttotal: 15.5ms\tremaining: 15.5ms\n",
      "3:\tlearn: 0.4709457\ttotal: 20.1ms\tremaining: 10ms\n",
      "4:\tlearn: 0.4690547\ttotal: 24.3ms\tremaining: 4.87ms\n",
      "5:\tlearn: 0.4668601\ttotal: 29.4ms\tremaining: 0us\n",
      "[6, 0.42, 6, 0.2]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.03ms\tremaining: 20.2ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.95ms\tremaining: 19.9ms\n",
      "2:\tlearn: 0.4730150\ttotal: 16.6ms\tremaining: 16.6ms\n",
      "3:\tlearn: 0.4709457\ttotal: 22.7ms\tremaining: 11.3ms\n",
      "4:\tlearn: 0.4690547\ttotal: 27.2ms\tremaining: 5.45ms\n",
      "5:\tlearn: 0.4668601\ttotal: 32.2ms\tremaining: 0us\n",
      "[6, 0.42, 15, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.07ms\tremaining: 45.4ms\n",
      "1:\tlearn: 0.4725597\ttotal: 514ms\tremaining: 1.03s\n",
      "2:\tlearn: 0.4670568\ttotal: 983ms\tremaining: 983ms\n",
      "3:\tlearn: 0.4637925\ttotal: 1.45s\tremaining: 724ms\n",
      "4:\tlearn: 0.4605353\ttotal: 1.93s\tremaining: 385ms\n",
      "5:\tlearn: 0.4581353\ttotal: 2.4s\tremaining: 0us\n",
      "[6, 0.42, 15, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.5ms\tremaining: 57.7ms\n",
      "1:\tlearn: 0.4725597\ttotal: 557ms\tremaining: 1.11s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.04s\tremaining: 1.04s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.54s\tremaining: 769ms\n",
      "4:\tlearn: 0.4605353\ttotal: 2.02s\tremaining: 405ms\n",
      "5:\tlearn: 0.4581353\ttotal: 2.5s\tremaining: 0us\n",
      "[6, 0.42, 15, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.9ms\tremaining: 64.6ms\n",
      "1:\tlearn: 0.4725597\ttotal: 486ms\tremaining: 971ms\n",
      "2:\tlearn: 0.4670568\ttotal: 974ms\tremaining: 974ms\n",
      "3:\tlearn: 0.4637925\ttotal: 1.45s\tremaining: 725ms\n",
      "4:\tlearn: 0.4605353\ttotal: 1.93s\tremaining: 386ms\n",
      "5:\tlearn: 0.4581353\ttotal: 2.41s\tremaining: 0us\n",
      "[6, 0.42, 15, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.1ms\tremaining: 60.4ms\n",
      "1:\tlearn: 0.4725597\ttotal: 513ms\tremaining: 1.02s\n",
      "2:\tlearn: 0.4670568\ttotal: 985ms\tremaining: 985ms\n",
      "3:\tlearn: 0.4637925\ttotal: 1.47s\tremaining: 736ms\n",
      "4:\tlearn: 0.4605353\ttotal: 1.95s\tremaining: 389ms\n",
      "5:\tlearn: 0.4581353\ttotal: 2.46s\tremaining: 0us\n",
      "[6, 0.42, 15, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.6ms\tremaining: 58ms\n",
      "1:\tlearn: 0.4725597\ttotal: 531ms\tremaining: 1.06s\n",
      "2:\tlearn: 0.4670568\ttotal: 993ms\tremaining: 993ms\n",
      "3:\tlearn: 0.4637925\ttotal: 1.47s\tremaining: 734ms\n",
      "4:\tlearn: 0.4605353\ttotal: 1.95s\tremaining: 391ms\n",
      "5:\tlearn: 0.4581353\ttotal: 2.44s\tremaining: 0us\n",
      "[6, 0.42, 10, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.2ms\tremaining: 60.9ms\n",
      "1:\tlearn: 0.4747524\ttotal: 27.6ms\tremaining: 55.3ms\n",
      "2:\tlearn: 0.4704503\ttotal: 46.1ms\tremaining: 46.1ms\n",
      "3:\tlearn: 0.4672210\ttotal: 62.9ms\tremaining: 31.4ms\n",
      "4:\tlearn: 0.4648993\ttotal: 80.2ms\tremaining: 16ms\n",
      "5:\tlearn: 0.4625834\ttotal: 95.5ms\tremaining: 0us\n",
      "[6, 0.42, 10, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.5ms\tremaining: 57.6ms\n",
      "1:\tlearn: 0.4747524\ttotal: 30.1ms\tremaining: 60.3ms\n",
      "2:\tlearn: 0.4704503\ttotal: 49.4ms\tremaining: 49.4ms\n",
      "3:\tlearn: 0.4672210\ttotal: 67.1ms\tremaining: 33.5ms\n",
      "4:\tlearn: 0.4648993\ttotal: 86.8ms\tremaining: 17.4ms\n",
      "5:\tlearn: 0.4625834\ttotal: 106ms\tremaining: 0us\n",
      "[6, 0.42, 10, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.4ms\tremaining: 52.1ms\n",
      "1:\tlearn: 0.4747524\ttotal: 24.3ms\tremaining: 48.5ms\n",
      "2:\tlearn: 0.4704503\ttotal: 37.9ms\tremaining: 37.9ms\n",
      "3:\tlearn: 0.4672210\ttotal: 51.4ms\tremaining: 25.7ms\n",
      "4:\tlearn: 0.4648993\ttotal: 65.2ms\tremaining: 13ms\n",
      "5:\tlearn: 0.4625834\ttotal: 79.7ms\tremaining: 0us\n",
      "[6, 0.42, 10, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.5ms\tremaining: 52.4ms\n",
      "1:\tlearn: 0.4747524\ttotal: 28.3ms\tremaining: 56.5ms\n",
      "2:\tlearn: 0.4704503\ttotal: 44ms\tremaining: 44ms\n",
      "3:\tlearn: 0.4672210\ttotal: 60.1ms\tremaining: 30.1ms\n",
      "4:\tlearn: 0.4648993\ttotal: 79.6ms\tremaining: 15.9ms\n",
      "5:\tlearn: 0.4625834\ttotal: 95.8ms\tremaining: 0us\n",
      "[6, 0.42, 10, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.6ms\tremaining: 53.2ms\n",
      "1:\tlearn: 0.4747524\ttotal: 26.3ms\tremaining: 52.6ms\n",
      "2:\tlearn: 0.4704503\ttotal: 42.9ms\tremaining: 42.9ms\n",
      "3:\tlearn: 0.4672210\ttotal: 59.3ms\tremaining: 29.7ms\n",
      "4:\tlearn: 0.4648993\ttotal: 77.5ms\tremaining: 15.5ms\n",
      "5:\tlearn: 0.4625834\ttotal: 93.4ms\tremaining: 0us\n",
      "[6, 0.42, 8, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 7.49ms\tremaining: 37.4ms\n",
      "1:\tlearn: 0.4760374\ttotal: 14.5ms\tremaining: 28.9ms\n",
      "2:\tlearn: 0.4713865\ttotal: 21.3ms\tremaining: 21.3ms\n",
      "3:\tlearn: 0.4692463\ttotal: 28.4ms\tremaining: 14.2ms\n",
      "4:\tlearn: 0.4663280\ttotal: 35.7ms\tremaining: 7.15ms\n",
      "5:\tlearn: 0.4645192\ttotal: 43.4ms\tremaining: 0us\n",
      "[6, 0.42, 8, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 28.6ms\tremaining: 143ms\n",
      "1:\tlearn: 0.4760374\ttotal: 36.5ms\tremaining: 73ms\n",
      "2:\tlearn: 0.4713865\ttotal: 48.6ms\tremaining: 48.6ms\n",
      "3:\tlearn: 0.4692463\ttotal: 70.3ms\tremaining: 35.1ms\n",
      "4:\tlearn: 0.4663280\ttotal: 83.1ms\tremaining: 16.6ms\n",
      "5:\tlearn: 0.4645192\ttotal: 95.9ms\tremaining: 0us\n",
      "[6, 0.42, 8, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 6.68ms\tremaining: 33.4ms\n",
      "1:\tlearn: 0.4760374\ttotal: 13.5ms\tremaining: 27ms\n",
      "2:\tlearn: 0.4713865\ttotal: 20.6ms\tremaining: 20.6ms\n",
      "3:\tlearn: 0.4692463\ttotal: 27.2ms\tremaining: 13.6ms\n",
      "4:\tlearn: 0.4663280\ttotal: 34ms\tremaining: 6.79ms\n",
      "5:\tlearn: 0.4645192\ttotal: 41.6ms\tremaining: 0us\n",
      "[6, 0.42, 8, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.48ms\tremaining: 47.4ms\n",
      "1:\tlearn: 0.4760374\ttotal: 16.6ms\tremaining: 33.1ms\n",
      "2:\tlearn: 0.4713865\ttotal: 23.9ms\tremaining: 23.9ms\n",
      "3:\tlearn: 0.4692463\ttotal: 31.1ms\tremaining: 15.5ms\n",
      "4:\tlearn: 0.4663280\ttotal: 38.1ms\tremaining: 7.61ms\n",
      "5:\tlearn: 0.4645192\ttotal: 45.6ms\tremaining: 0us\n",
      "[6, 0.42, 8, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 7.26ms\tremaining: 36.3ms\n",
      "1:\tlearn: 0.4760374\ttotal: 15ms\tremaining: 29.9ms\n",
      "2:\tlearn: 0.4713865\ttotal: 22.5ms\tremaining: 22.5ms\n",
      "3:\tlearn: 0.4692463\ttotal: 30.1ms\tremaining: 15ms\n",
      "4:\tlearn: 0.4663280\ttotal: 37.2ms\tremaining: 7.44ms\n",
      "5:\tlearn: 0.4645192\ttotal: 44.6ms\tremaining: 0us\n",
      "[6, 0.42, 7, -0.3]\n",
      "0:\tlearn: 0.4822485\ttotal: 5.51ms\tremaining: 27.6ms\n",
      "1:\tlearn: 0.4758702\ttotal: 11ms\tremaining: 22ms\n",
      "2:\tlearn: 0.4720772\ttotal: 16.5ms\tremaining: 16.5ms\n",
      "3:\tlearn: 0.4693295\ttotal: 21.9ms\tremaining: 11ms\n",
      "4:\tlearn: 0.4677956\ttotal: 28.1ms\tremaining: 5.61ms\n",
      "5:\tlearn: 0.4666127\ttotal: 33.3ms\tremaining: 0us\n",
      "[6, 0.42, 7, 0.3]\n",
      "0:\tlearn: 0.4822485\ttotal: 25.5ms\tremaining: 128ms\n",
      "1:\tlearn: 0.4758702\ttotal: 43.3ms\tremaining: 86.6ms\n",
      "2:\tlearn: 0.4720772\ttotal: 49.8ms\tremaining: 49.8ms\n",
      "3:\tlearn: 0.4693295\ttotal: 55.7ms\tremaining: 27.9ms\n",
      "4:\tlearn: 0.4677956\ttotal: 61.1ms\tremaining: 12.2ms\n",
      "5:\tlearn: 0.4666127\ttotal: 66.6ms\tremaining: 0us\n",
      "[6, 0.42, 7, 0.0]\n",
      "0:\tlearn: 0.4822485\ttotal: 6.31ms\tremaining: 31.5ms\n",
      "1:\tlearn: 0.4758702\ttotal: 12.3ms\tremaining: 24.7ms\n",
      "2:\tlearn: 0.4720772\ttotal: 17.7ms\tremaining: 17.7ms\n",
      "3:\tlearn: 0.4693295\ttotal: 22.9ms\tremaining: 11.4ms\n",
      "4:\tlearn: 0.4677956\ttotal: 28ms\tremaining: 5.59ms\n",
      "5:\tlearn: 0.4666127\ttotal: 33.4ms\tremaining: 0us\n",
      "[6, 0.42, 7, 0.15]\n",
      "0:\tlearn: 0.4822485\ttotal: 5.53ms\tremaining: 27.6ms\n",
      "1:\tlearn: 0.4758702\ttotal: 11.1ms\tremaining: 22.2ms\n",
      "2:\tlearn: 0.4720772\ttotal: 16.1ms\tremaining: 16.1ms\n",
      "3:\tlearn: 0.4693295\ttotal: 21.5ms\tremaining: 10.7ms\n",
      "4:\tlearn: 0.4677956\ttotal: 28.4ms\tremaining: 5.67ms\n",
      "5:\tlearn: 0.4666127\ttotal: 33.6ms\tremaining: 0us\n",
      "[6, 0.42, 7, 0.2]\n",
      "0:\tlearn: 0.4822485\ttotal: 5.19ms\tremaining: 26ms\n",
      "1:\tlearn: 0.4758702\ttotal: 10.5ms\tremaining: 21ms\n",
      "2:\tlearn: 0.4720772\ttotal: 15.6ms\tremaining: 15.6ms\n",
      "3:\tlearn: 0.4693295\ttotal: 21ms\tremaining: 10.5ms\n",
      "4:\tlearn: 0.4677956\ttotal: 26.6ms\tremaining: 5.32ms\n",
      "5:\tlearn: 0.4666127\ttotal: 31.7ms\tremaining: 0us\n",
      "[6, 0.48, 6, -0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 5.41ms\tremaining: 27ms\n",
      "1:\tlearn: 0.4742214\ttotal: 9.84ms\tremaining: 19.7ms\n",
      "2:\tlearn: 0.4707120\ttotal: 14.5ms\tremaining: 14.5ms\n",
      "3:\tlearn: 0.4683386\ttotal: 18.7ms\tremaining: 9.34ms\n",
      "4:\tlearn: 0.4663249\ttotal: 23.2ms\tremaining: 4.65ms\n",
      "5:\tlearn: 0.4646075\ttotal: 29ms\tremaining: 0us\n",
      "[6, 0.48, 6, 0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 4.35ms\tremaining: 21.8ms\n",
      "1:\tlearn: 0.4742214\ttotal: 8.72ms\tremaining: 17.4ms\n",
      "2:\tlearn: 0.4707120\ttotal: 12.8ms\tremaining: 12.8ms\n",
      "3:\tlearn: 0.4683386\ttotal: 17ms\tremaining: 8.5ms\n",
      "4:\tlearn: 0.4663249\ttotal: 21.3ms\tremaining: 4.27ms\n",
      "5:\tlearn: 0.4646075\ttotal: 25.9ms\tremaining: 0us\n",
      "[6, 0.48, 6, 0.0]\n",
      "0:\tlearn: 0.4809500\ttotal: 4.87ms\tremaining: 24.3ms\n",
      "1:\tlearn: 0.4742214\ttotal: 9.2ms\tremaining: 18.4ms\n",
      "2:\tlearn: 0.4707120\ttotal: 13.6ms\tremaining: 13.6ms\n",
      "3:\tlearn: 0.4683386\ttotal: 18ms\tremaining: 8.98ms\n",
      "4:\tlearn: 0.4663249\ttotal: 22.1ms\tremaining: 4.42ms\n",
      "5:\tlearn: 0.4646075\ttotal: 27.4ms\tremaining: 0us\n",
      "[6, 0.48, 6, 0.15]\n",
      "0:\tlearn: 0.4809500\ttotal: 5.02ms\tremaining: 25.1ms\n",
      "1:\tlearn: 0.4742214\ttotal: 9.19ms\tremaining: 18.4ms\n",
      "2:\tlearn: 0.4707120\ttotal: 15.3ms\tremaining: 15.3ms\n",
      "3:\tlearn: 0.4683386\ttotal: 28.9ms\tremaining: 14.5ms\n",
      "4:\tlearn: 0.4663249\ttotal: 33.4ms\tremaining: 6.68ms\n",
      "5:\tlearn: 0.4646075\ttotal: 37.8ms\tremaining: 0us\n",
      "[6, 0.48, 6, 0.2]\n",
      "0:\tlearn: 0.4809500\ttotal: 4.94ms\tremaining: 24.7ms\n",
      "1:\tlearn: 0.4742214\ttotal: 9.07ms\tremaining: 18.1ms\n",
      "2:\tlearn: 0.4707120\ttotal: 13ms\tremaining: 13ms\n",
      "3:\tlearn: 0.4683386\ttotal: 17ms\tremaining: 8.51ms\n",
      "4:\tlearn: 0.4663249\ttotal: 21.1ms\tremaining: 4.22ms\n",
      "5:\tlearn: 0.4646075\ttotal: 25.3ms\tremaining: 0us\n",
      "[6, 0.48, 15, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.04ms\tremaining: 45.2ms\n",
      "1:\tlearn: 0.4707499\ttotal: 473ms\tremaining: 946ms\n",
      "2:\tlearn: 0.4660967\ttotal: 939ms\tremaining: 939ms\n",
      "3:\tlearn: 0.4627239\ttotal: 1.4s\tremaining: 700ms\n",
      "4:\tlearn: 0.4592968\ttotal: 1.86s\tremaining: 373ms\n",
      "5:\tlearn: 0.4571455\ttotal: 2.33s\tremaining: 0us\n",
      "[6, 0.48, 15, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.6ms\tremaining: 52.8ms\n",
      "1:\tlearn: 0.4707499\ttotal: 460ms\tremaining: 921ms\n",
      "2:\tlearn: 0.4660967\ttotal: 923ms\tremaining: 923ms\n",
      "3:\tlearn: 0.4627239\ttotal: 1.41s\tremaining: 703ms\n",
      "4:\tlearn: 0.4592968\ttotal: 1.9s\tremaining: 380ms\n",
      "5:\tlearn: 0.4571455\ttotal: 2.4s\tremaining: 0us\n",
      "[6, 0.48, 15, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 14.1ms\tremaining: 70.6ms\n",
      "1:\tlearn: 0.4707499\ttotal: 517ms\tremaining: 1.03s\n",
      "2:\tlearn: 0.4660967\ttotal: 985ms\tremaining: 985ms\n",
      "3:\tlearn: 0.4627239\ttotal: 1.48s\tremaining: 738ms\n",
      "4:\tlearn: 0.4592968\ttotal: 1.95s\tremaining: 390ms\n",
      "5:\tlearn: 0.4571455\ttotal: 2.43s\tremaining: 0us\n",
      "[6, 0.48, 15, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.77ms\tremaining: 48.8ms\n",
      "1:\tlearn: 0.4707499\ttotal: 558ms\tremaining: 1.12s\n",
      "2:\tlearn: 0.4660967\ttotal: 1.04s\tremaining: 1.04s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.51s\tremaining: 756ms\n",
      "4:\tlearn: 0.4592968\ttotal: 1.99s\tremaining: 399ms\n",
      "5:\tlearn: 0.4571455\ttotal: 2.47s\tremaining: 0us\n",
      "[6, 0.48, 15, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.2ms\tremaining: 56ms\n",
      "1:\tlearn: 0.4707499\ttotal: 508ms\tremaining: 1.02s\n",
      "2:\tlearn: 0.4660967\ttotal: 961ms\tremaining: 961ms\n",
      "3:\tlearn: 0.4627239\ttotal: 1.42s\tremaining: 709ms\n",
      "4:\tlearn: 0.4592968\ttotal: 1.91s\tremaining: 383ms\n",
      "5:\tlearn: 0.4571455\ttotal: 2.41s\tremaining: 0us\n",
      "[6, 0.48, 10, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 14.9ms\tremaining: 74.6ms\n",
      "1:\tlearn: 0.4731642\ttotal: 38.5ms\tremaining: 77ms\n",
      "2:\tlearn: 0.4688840\ttotal: 56.6ms\tremaining: 56.6ms\n",
      "3:\tlearn: 0.4676760\ttotal: 59.6ms\tremaining: 29.8ms\n",
      "4:\tlearn: 0.4647814\ttotal: 77.9ms\tremaining: 15.6ms\n",
      "5:\tlearn: 0.4606717\ttotal: 96.3ms\tremaining: 0us\n",
      "[6, 0.48, 10, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.84ms\tremaining: 49.2ms\n",
      "1:\tlearn: 0.4731642\ttotal: 26.5ms\tremaining: 53ms\n",
      "2:\tlearn: 0.4688840\ttotal: 50.8ms\tremaining: 50.8ms\n",
      "3:\tlearn: 0.4676760\ttotal: 54.4ms\tremaining: 27.2ms\n",
      "4:\tlearn: 0.4647814\ttotal: 75ms\tremaining: 15ms\n",
      "5:\tlearn: 0.4606717\ttotal: 94.4ms\tremaining: 0us\n",
      "[6, 0.48, 10, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.9ms\tremaining: 59.6ms\n",
      "1:\tlearn: 0.4731642\ttotal: 27.7ms\tremaining: 55.4ms\n",
      "2:\tlearn: 0.4688840\ttotal: 44.1ms\tremaining: 44.1ms\n",
      "3:\tlearn: 0.4676760\ttotal: 47.1ms\tremaining: 23.6ms\n",
      "4:\tlearn: 0.4647814\ttotal: 62.6ms\tremaining: 12.5ms\n",
      "5:\tlearn: 0.4606717\ttotal: 78.8ms\tremaining: 0us\n",
      "[6, 0.48, 10, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 21.3ms\tremaining: 107ms\n",
      "1:\tlearn: 0.4731642\ttotal: 67.8ms\tremaining: 136ms\n",
      "2:\tlearn: 0.4688840\ttotal: 88.8ms\tremaining: 88.8ms\n",
      "3:\tlearn: 0.4676760\ttotal: 92.1ms\tremaining: 46.1ms\n",
      "4:\tlearn: 0.4647814\ttotal: 108ms\tremaining: 21.7ms\n",
      "5:\tlearn: 0.4606717\ttotal: 123ms\tremaining: 0us\n",
      "[6, 0.48, 10, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.96ms\tremaining: 49.8ms\n",
      "1:\tlearn: 0.4731642\ttotal: 24.3ms\tremaining: 48.7ms\n",
      "2:\tlearn: 0.4688840\ttotal: 38.6ms\tremaining: 38.6ms\n",
      "3:\tlearn: 0.4676760\ttotal: 41.4ms\tremaining: 20.7ms\n",
      "4:\tlearn: 0.4647814\ttotal: 55.5ms\tremaining: 11.1ms\n",
      "5:\tlearn: 0.4606717\ttotal: 70.3ms\tremaining: 0us\n",
      "[6, 0.48, 12, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 8.38ms\tremaining: 41.9ms\n",
      "1:\tlearn: 0.4721464\ttotal: 75.3ms\tremaining: 151ms\n",
      "2:\tlearn: 0.4684998\ttotal: 138ms\tremaining: 138ms\n",
      "3:\tlearn: 0.4647972\ttotal: 201ms\tremaining: 101ms\n",
      "4:\tlearn: 0.4625394\ttotal: 262ms\tremaining: 52.4ms\n",
      "5:\tlearn: 0.4603377\ttotal: 322ms\tremaining: 0us\n",
      "[6, 0.48, 12, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.04ms\tremaining: 45.2ms\n",
      "1:\tlearn: 0.4721464\ttotal: 68.3ms\tremaining: 137ms\n",
      "2:\tlearn: 0.4684998\ttotal: 128ms\tremaining: 128ms\n",
      "3:\tlearn: 0.4647972\ttotal: 187ms\tremaining: 93.7ms\n",
      "4:\tlearn: 0.4625394\ttotal: 242ms\tremaining: 48.4ms\n",
      "5:\tlearn: 0.4603377\ttotal: 298ms\tremaining: 0us\n",
      "[6, 0.48, 12, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 12.1ms\tremaining: 60.3ms\n",
      "1:\tlearn: 0.4721464\ttotal: 75.8ms\tremaining: 152ms\n",
      "2:\tlearn: 0.4684998\ttotal: 138ms\tremaining: 138ms\n",
      "3:\tlearn: 0.4647972\ttotal: 193ms\tremaining: 96.7ms\n",
      "4:\tlearn: 0.4625394\ttotal: 265ms\tremaining: 53ms\n",
      "5:\tlearn: 0.4603377\ttotal: 324ms\tremaining: 0us\n",
      "[6, 0.48, 12, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.27ms\tremaining: 46.4ms\n",
      "1:\tlearn: 0.4721464\ttotal: 68.8ms\tremaining: 138ms\n",
      "2:\tlearn: 0.4684998\ttotal: 130ms\tremaining: 130ms\n",
      "3:\tlearn: 0.4647972\ttotal: 183ms\tremaining: 91.4ms\n",
      "4:\tlearn: 0.4625394\ttotal: 236ms\tremaining: 47.3ms\n",
      "5:\tlearn: 0.4603377\ttotal: 298ms\tremaining: 0us\n",
      "[6, 0.48, 12, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 14.2ms\tremaining: 71.1ms\n",
      "1:\tlearn: 0.4721464\ttotal: 76.7ms\tremaining: 153ms\n",
      "2:\tlearn: 0.4684998\ttotal: 135ms\tremaining: 135ms\n",
      "3:\tlearn: 0.4647972\ttotal: 199ms\tremaining: 99.4ms\n",
      "4:\tlearn: 0.4625394\ttotal: 267ms\tremaining: 53.4ms\n",
      "5:\tlearn: 0.4603377\ttotal: 327ms\tremaining: 0us\n",
      "[6, 0.48, 13, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 12ms\tremaining: 59.9ms\n",
      "1:\tlearn: 0.4717672\ttotal: 130ms\tremaining: 259ms\n",
      "2:\tlearn: 0.4670679\ttotal: 254ms\tremaining: 254ms\n",
      "3:\tlearn: 0.4643183\ttotal: 375ms\tremaining: 187ms\n",
      "4:\tlearn: 0.4617346\ttotal: 430ms\tremaining: 86ms\n",
      "5:\tlearn: 0.4593271\ttotal: 553ms\tremaining: 0us\n",
      "[6, 0.48, 13, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.8ms\tremaining: 59ms\n",
      "1:\tlearn: 0.4717672\ttotal: 135ms\tremaining: 271ms\n",
      "2:\tlearn: 0.4670679\ttotal: 251ms\tremaining: 251ms\n",
      "3:\tlearn: 0.4643183\ttotal: 375ms\tremaining: 188ms\n",
      "4:\tlearn: 0.4617346\ttotal: 436ms\tremaining: 87.2ms\n",
      "5:\tlearn: 0.4593271\ttotal: 551ms\tremaining: 0us\n",
      "[6, 0.48, 13, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 15.4ms\tremaining: 77.1ms\n",
      "1:\tlearn: 0.4717672\ttotal: 192ms\tremaining: 385ms\n",
      "2:\tlearn: 0.4670679\ttotal: 317ms\tremaining: 317ms\n",
      "3:\tlearn: 0.4643183\ttotal: 463ms\tremaining: 231ms\n",
      "4:\tlearn: 0.4617346\ttotal: 537ms\tremaining: 107ms\n",
      "5:\tlearn: 0.4593271\ttotal: 661ms\tremaining: 0us\n",
      "[6, 0.48, 13, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 11ms\tremaining: 55.2ms\n",
      "1:\tlearn: 0.4717672\ttotal: 145ms\tremaining: 290ms\n",
      "2:\tlearn: 0.4670679\ttotal: 268ms\tremaining: 268ms\n",
      "3:\tlearn: 0.4643183\ttotal: 380ms\tremaining: 190ms\n",
      "4:\tlearn: 0.4617346\ttotal: 443ms\tremaining: 88.6ms\n",
      "5:\tlearn: 0.4593271\ttotal: 577ms\tremaining: 0us\n",
      "[6, 0.48, 13, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 13.7ms\tremaining: 68.7ms\n",
      "1:\tlearn: 0.4717672\ttotal: 140ms\tremaining: 281ms\n",
      "2:\tlearn: 0.4670679\ttotal: 281ms\tremaining: 281ms\n",
      "3:\tlearn: 0.4643183\ttotal: 402ms\tremaining: 201ms\n",
      "4:\tlearn: 0.4617346\ttotal: 460ms\tremaining: 92ms\n",
      "5:\tlearn: 0.4593271\ttotal: 587ms\tremaining: 0us\n",
      "[6, 0.48, 14, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 8.92ms\tremaining: 44.6ms\n",
      "1:\tlearn: 0.4713115\ttotal: 281ms\tremaining: 563ms\n",
      "2:\tlearn: 0.4669856\ttotal: 522ms\tremaining: 522ms\n",
      "3:\tlearn: 0.4628131\ttotal: 751ms\tremaining: 376ms\n",
      "4:\tlearn: 0.4589769\ttotal: 1.01s\tremaining: 203ms\n",
      "5:\tlearn: 0.4572045\ttotal: 1.03s\tremaining: 0us\n",
      "[6, 0.48, 14, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.7ms\tremaining: 53.6ms\n",
      "1:\tlearn: 0.4713115\ttotal: 267ms\tremaining: 535ms\n",
      "2:\tlearn: 0.4669856\ttotal: 529ms\tremaining: 529ms\n",
      "3:\tlearn: 0.4628131\ttotal: 757ms\tremaining: 379ms\n",
      "4:\tlearn: 0.4589769\ttotal: 1.03s\tremaining: 207ms\n",
      "5:\tlearn: 0.4572045\ttotal: 1.05s\tremaining: 0us\n",
      "[6, 0.48, 14, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.35ms\tremaining: 46.7ms\n",
      "1:\tlearn: 0.4713115\ttotal: 248ms\tremaining: 496ms\n",
      "2:\tlearn: 0.4669856\ttotal: 488ms\tremaining: 488ms\n",
      "3:\tlearn: 0.4628131\ttotal: 737ms\tremaining: 368ms\n",
      "4:\tlearn: 0.4589769\ttotal: 999ms\tremaining: 200ms\n",
      "5:\tlearn: 0.4572045\ttotal: 1.01s\tremaining: 0us\n",
      "[6, 0.48, 14, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.21ms\tremaining: 46ms\n",
      "1:\tlearn: 0.4713115\ttotal: 280ms\tremaining: 560ms\n",
      "2:\tlearn: 0.4669856\ttotal: 542ms\tremaining: 542ms\n",
      "3:\tlearn: 0.4628131\ttotal: 803ms\tremaining: 401ms\n",
      "4:\tlearn: 0.4589769\ttotal: 1.04s\tremaining: 209ms\n",
      "5:\tlearn: 0.4572045\ttotal: 1.06s\tremaining: 0us\n",
      "[6, 0.48, 14, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.7ms\tremaining: 53.5ms\n",
      "1:\tlearn: 0.4713115\ttotal: 273ms\tremaining: 547ms\n",
      "2:\tlearn: 0.4669856\ttotal: 520ms\tremaining: 520ms\n",
      "3:\tlearn: 0.4628131\ttotal: 767ms\tremaining: 383ms\n",
      "4:\tlearn: 0.4589769\ttotal: 1.01s\tremaining: 202ms\n",
      "5:\tlearn: 0.4572045\ttotal: 1.03s\tremaining: 0us\n",
      "[6, 0.51, 6, -0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.7ms\tremaining: 23.5ms\n",
      "1:\tlearn: 0.4736652\ttotal: 9.26ms\tremaining: 18.5ms\n",
      "2:\tlearn: 0.4703360\ttotal: 15.1ms\tremaining: 15.1ms\n",
      "3:\tlearn: 0.4678859\ttotal: 20.1ms\tremaining: 10ms\n",
      "4:\tlearn: 0.4662988\ttotal: 24.7ms\tremaining: 4.95ms\n",
      "5:\tlearn: 0.4640621\ttotal: 29.2ms\tremaining: 0us\n",
      "[6, 0.51, 6, 0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 8.28ms\tremaining: 41.4ms\n",
      "1:\tlearn: 0.4736652\ttotal: 18.1ms\tremaining: 36.3ms\n",
      "2:\tlearn: 0.4703360\ttotal: 23.8ms\tremaining: 23.8ms\n",
      "3:\tlearn: 0.4678859\ttotal: 29.7ms\tremaining: 14.8ms\n",
      "4:\tlearn: 0.4662988\ttotal: 34.5ms\tremaining: 6.89ms\n",
      "5:\tlearn: 0.4640621\ttotal: 39ms\tremaining: 0us\n",
      "[6, 0.51, 6, 0.0]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.36ms\tremaining: 21.8ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.57ms\tremaining: 17.1ms\n",
      "2:\tlearn: 0.4703360\ttotal: 13ms\tremaining: 13ms\n",
      "3:\tlearn: 0.4678859\ttotal: 17.3ms\tremaining: 8.63ms\n",
      "4:\tlearn: 0.4662988\ttotal: 21.5ms\tremaining: 4.3ms\n",
      "5:\tlearn: 0.4640621\ttotal: 25.6ms\tremaining: 0us\n",
      "[6, 0.51, 6, 0.15]\n",
      "0:\tlearn: 0.4803477\ttotal: 5.85ms\tremaining: 29.2ms\n",
      "1:\tlearn: 0.4736652\ttotal: 10.5ms\tremaining: 21ms\n",
      "2:\tlearn: 0.4703360\ttotal: 14.9ms\tremaining: 14.9ms\n",
      "3:\tlearn: 0.4678859\ttotal: 19.4ms\tremaining: 9.69ms\n",
      "4:\tlearn: 0.4662988\ttotal: 24ms\tremaining: 4.79ms\n",
      "5:\tlearn: 0.4640621\ttotal: 28.5ms\tremaining: 0us\n",
      "[6, 0.51, 6, 0.2]\n",
      "0:\tlearn: 0.4803477\ttotal: 5.04ms\tremaining: 25.2ms\n",
      "1:\tlearn: 0.4736652\ttotal: 9.21ms\tremaining: 18.4ms\n",
      "2:\tlearn: 0.4703360\ttotal: 13.4ms\tremaining: 13.4ms\n",
      "3:\tlearn: 0.4678859\ttotal: 17.8ms\tremaining: 8.91ms\n",
      "4:\tlearn: 0.4662988\ttotal: 22.5ms\tremaining: 4.51ms\n",
      "5:\tlearn: 0.4640621\ttotal: 27.7ms\tremaining: 0us\n",
      "[6, 0.51, 15, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 13.2ms\tremaining: 66.1ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.2ms\tremaining: 44.4ms\n",
      "2:\tlearn: 0.4682843\ttotal: 651ms\tremaining: 651ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1.2s\tremaining: 601ms\n",
      "4:\tlearn: 0.4613151\ttotal: 1.37s\tremaining: 275ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.93s\tremaining: 0us\n",
      "[6, 0.51, 15, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.77ms\tremaining: 48.9ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19ms\tremaining: 38ms\n",
      "2:\tlearn: 0.4682843\ttotal: 938ms\tremaining: 938ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1.71s\tremaining: 856ms\n",
      "4:\tlearn: 0.4613151\ttotal: 1.96s\tremaining: 393ms\n",
      "5:\tlearn: 0.4588540\ttotal: 2.59s\tremaining: 0us\n",
      "[6, 0.51, 15, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.49ms\tremaining: 47.4ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.5ms\tremaining: 37.1ms\n",
      "2:\tlearn: 0.4682843\ttotal: 645ms\tremaining: 645ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1.26s\tremaining: 632ms\n",
      "4:\tlearn: 0.4613151\ttotal: 1.42s\tremaining: 284ms\n",
      "5:\tlearn: 0.4588540\ttotal: 2.08s\tremaining: 0us\n",
      "[6, 0.51, 15, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 11.9ms\tremaining: 59.4ms\n",
      "1:\tlearn: 0.4740807\ttotal: 21.6ms\tremaining: 43.3ms\n",
      "2:\tlearn: 0.4682843\ttotal: 489ms\tremaining: 489ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1.03s\tremaining: 515ms\n",
      "4:\tlearn: 0.4613151\ttotal: 1.2s\tremaining: 240ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.76s\tremaining: 0us\n",
      "[6, 0.51, 15, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 11.3ms\tremaining: 56.6ms\n",
      "1:\tlearn: 0.4740807\ttotal: 20.2ms\tremaining: 40.5ms\n",
      "2:\tlearn: 0.4682843\ttotal: 693ms\tremaining: 693ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1.23s\tremaining: 616ms\n",
      "4:\tlearn: 0.4613151\ttotal: 1.41s\tremaining: 283ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.98s\tremaining: 0us\n",
      "[6, 0.51, 10, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 11.1ms\tremaining: 55.6ms\n",
      "1:\tlearn: 0.4740807\ttotal: 21.6ms\tremaining: 43.2ms\n",
      "2:\tlearn: 0.4695149\ttotal: 38.6ms\tremaining: 38.6ms\n",
      "3:\tlearn: 0.4663819\ttotal: 54.8ms\tremaining: 27.4ms\n",
      "4:\tlearn: 0.4637371\ttotal: 71.4ms\tremaining: 14.3ms\n",
      "5:\tlearn: 0.4620590\ttotal: 87.3ms\tremaining: 0us\n",
      "[6, 0.51, 10, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.3ms\tremaining: 51.4ms\n",
      "1:\tlearn: 0.4740807\ttotal: 25.4ms\tremaining: 50.8ms\n",
      "2:\tlearn: 0.4695149\ttotal: 46.9ms\tremaining: 46.9ms\n",
      "3:\tlearn: 0.4663819\ttotal: 65.1ms\tremaining: 32.6ms\n",
      "4:\tlearn: 0.4637371\ttotal: 82.4ms\tremaining: 16.5ms\n",
      "5:\tlearn: 0.4620590\ttotal: 97.4ms\tremaining: 0us\n",
      "[6, 0.51, 10, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 17.9ms\tremaining: 89.7ms\n",
      "1:\tlearn: 0.4740807\ttotal: 29.7ms\tremaining: 59.3ms\n",
      "2:\tlearn: 0.4695149\ttotal: 48.1ms\tremaining: 48.1ms\n",
      "3:\tlearn: 0.4663819\ttotal: 64.4ms\tremaining: 32.2ms\n",
      "4:\tlearn: 0.4637371\ttotal: 82ms\tremaining: 16.4ms\n",
      "5:\tlearn: 0.4620590\ttotal: 99.5ms\tremaining: 0us\n",
      "[6, 0.51, 10, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.23ms\tremaining: 46.2ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.9ms\tremaining: 37.8ms\n",
      "2:\tlearn: 0.4695149\ttotal: 36.5ms\tremaining: 36.5ms\n",
      "3:\tlearn: 0.4663819\ttotal: 54.5ms\tremaining: 27.2ms\n",
      "4:\tlearn: 0.4637371\ttotal: 71.1ms\tremaining: 14.2ms\n",
      "5:\tlearn: 0.4620590\ttotal: 92.1ms\tremaining: 0us\n",
      "[6, 0.51, 10, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.62ms\tremaining: 48.1ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.8ms\tremaining: 37.6ms\n",
      "2:\tlearn: 0.4695149\ttotal: 58.2ms\tremaining: 58.2ms\n",
      "3:\tlearn: 0.4663819\ttotal: 89.6ms\tremaining: 44.8ms\n",
      "4:\tlearn: 0.4637371\ttotal: 109ms\tremaining: 21.8ms\n",
      "5:\tlearn: 0.4620590\ttotal: 135ms\tremaining: 0us\n",
      "[6, 0.51, 8, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 6.35ms\tremaining: 31.8ms\n",
      "1:\tlearn: 0.4735886\ttotal: 13.3ms\tremaining: 26.6ms\n",
      "2:\tlearn: 0.4683373\ttotal: 20.2ms\tremaining: 20.2ms\n",
      "3:\tlearn: 0.4660754\ttotal: 27.1ms\tremaining: 13.5ms\n",
      "4:\tlearn: 0.4636280\ttotal: 34ms\tremaining: 6.79ms\n",
      "5:\tlearn: 0.4620627\ttotal: 41.2ms\tremaining: 0us\n",
      "[6, 0.51, 8, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 15.3ms\tremaining: 76.3ms\n",
      "1:\tlearn: 0.4735886\ttotal: 22.5ms\tremaining: 45ms\n",
      "2:\tlearn: 0.4683373\ttotal: 29.8ms\tremaining: 29.8ms\n",
      "3:\tlearn: 0.4660754\ttotal: 36.7ms\tremaining: 18.4ms\n",
      "4:\tlearn: 0.4636280\ttotal: 44.1ms\tremaining: 8.81ms\n",
      "5:\tlearn: 0.4620627\ttotal: 51.4ms\tremaining: 0us\n",
      "[6, 0.51, 8, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 21.7ms\tremaining: 108ms\n",
      "1:\tlearn: 0.4735886\ttotal: 30.5ms\tremaining: 61ms\n",
      "2:\tlearn: 0.4683373\ttotal: 39.9ms\tremaining: 39.9ms\n",
      "3:\tlearn: 0.4660754\ttotal: 47.5ms\tremaining: 23.7ms\n",
      "4:\tlearn: 0.4636280\ttotal: 55.8ms\tremaining: 11.2ms\n",
      "5:\tlearn: 0.4620627\ttotal: 64.3ms\tremaining: 0us\n",
      "[6, 0.51, 8, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 14.5ms\tremaining: 72.3ms\n",
      "1:\tlearn: 0.4735886\ttotal: 23.2ms\tremaining: 46.3ms\n",
      "2:\tlearn: 0.4683373\ttotal: 31.6ms\tremaining: 31.6ms\n",
      "3:\tlearn: 0.4660754\ttotal: 39.1ms\tremaining: 19.5ms\n",
      "4:\tlearn: 0.4636280\ttotal: 48.1ms\tremaining: 9.63ms\n",
      "5:\tlearn: 0.4620627\ttotal: 55.5ms\tremaining: 0us\n",
      "[6, 0.51, 8, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 7.55ms\tremaining: 37.7ms\n",
      "1:\tlearn: 0.4735886\ttotal: 14.8ms\tremaining: 29.5ms\n",
      "2:\tlearn: 0.4683373\ttotal: 22.6ms\tremaining: 22.6ms\n",
      "3:\tlearn: 0.4660754\ttotal: 32.4ms\tremaining: 16.2ms\n",
      "4:\tlearn: 0.4636280\ttotal: 39.8ms\tremaining: 7.96ms\n",
      "5:\tlearn: 0.4620627\ttotal: 49.7ms\tremaining: 0us\n",
      "[6, 0.51, 7, -0.3]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.69ms\tremaining: 28.5ms\n",
      "1:\tlearn: 0.4741799\ttotal: 11ms\tremaining: 21.9ms\n",
      "2:\tlearn: 0.4708424\ttotal: 16.4ms\tremaining: 16.4ms\n",
      "3:\tlearn: 0.4676883\ttotal: 22.7ms\tremaining: 11.3ms\n",
      "4:\tlearn: 0.4659630\ttotal: 32.6ms\tremaining: 6.51ms\n",
      "5:\tlearn: 0.4648851\ttotal: 37.9ms\tremaining: 0us\n",
      "[6, 0.51, 7, 0.3]\n",
      "0:\tlearn: 0.4803401\ttotal: 6.4ms\tremaining: 32ms\n",
      "1:\tlearn: 0.4741799\ttotal: 12.7ms\tremaining: 25.3ms\n",
      "2:\tlearn: 0.4708424\ttotal: 23ms\tremaining: 23ms\n",
      "3:\tlearn: 0.4676883\ttotal: 28.3ms\tremaining: 14.2ms\n",
      "4:\tlearn: 0.4659630\ttotal: 35.4ms\tremaining: 7.08ms\n",
      "5:\tlearn: 0.4648851\ttotal: 40.8ms\tremaining: 0us\n",
      "[6, 0.51, 7, 0.0]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.09ms\tremaining: 25.4ms\n",
      "1:\tlearn: 0.4741799\ttotal: 10.1ms\tremaining: 20.2ms\n",
      "2:\tlearn: 0.4708424\ttotal: 15.4ms\tremaining: 15.4ms\n",
      "3:\tlearn: 0.4676883\ttotal: 20.3ms\tremaining: 10.1ms\n",
      "4:\tlearn: 0.4659630\ttotal: 25.4ms\tremaining: 5.07ms\n",
      "5:\tlearn: 0.4648851\ttotal: 31.1ms\tremaining: 0us\n",
      "[6, 0.51, 7, 0.15]\n",
      "0:\tlearn: 0.4803401\ttotal: 6.07ms\tremaining: 30.4ms\n",
      "1:\tlearn: 0.4741799\ttotal: 11.1ms\tremaining: 22.1ms\n",
      "2:\tlearn: 0.4708424\ttotal: 16.2ms\tremaining: 16.2ms\n",
      "3:\tlearn: 0.4676883\ttotal: 21.3ms\tremaining: 10.6ms\n",
      "4:\tlearn: 0.4659630\ttotal: 26.5ms\tremaining: 5.3ms\n",
      "5:\tlearn: 0.4648851\ttotal: 31.4ms\tremaining: 0us\n",
      "[6, 0.51, 7, 0.2]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.83ms\tremaining: 29.2ms\n",
      "1:\tlearn: 0.4741799\ttotal: 11.2ms\tremaining: 22.4ms\n",
      "2:\tlearn: 0.4708424\ttotal: 16.3ms\tremaining: 16.3ms\n",
      "3:\tlearn: 0.4676883\ttotal: 21.5ms\tremaining: 10.7ms\n",
      "4:\tlearn: 0.4659630\ttotal: 26.4ms\tremaining: 5.29ms\n",
      "5:\tlearn: 0.4648851\ttotal: 31.7ms\tremaining: 0us\n",
      "[6, 0.49, 6, -0.3]\n",
      "0:\tlearn: 0.4807455\ttotal: 4.6ms\tremaining: 23ms\n",
      "1:\tlearn: 0.4740289\ttotal: 8.71ms\tremaining: 17.4ms\n",
      "2:\tlearn: 0.4705265\ttotal: 12.8ms\tremaining: 12.8ms\n",
      "3:\tlearn: 0.4681211\ttotal: 16.9ms\tremaining: 8.44ms\n",
      "4:\tlearn: 0.4661064\ttotal: 20.9ms\tremaining: 4.19ms\n",
      "5:\tlearn: 0.4643672\ttotal: 25ms\tremaining: 0us\n",
      "[6, 0.49, 6, 0.3]\n",
      "0:\tlearn: 0.4807455\ttotal: 5.63ms\tremaining: 28.2ms\n",
      "1:\tlearn: 0.4740289\ttotal: 9.67ms\tremaining: 19.3ms\n",
      "2:\tlearn: 0.4705265\ttotal: 13.9ms\tremaining: 13.9ms\n",
      "3:\tlearn: 0.4681211\ttotal: 17.9ms\tremaining: 8.94ms\n",
      "4:\tlearn: 0.4661064\ttotal: 21.9ms\tremaining: 4.38ms\n",
      "5:\tlearn: 0.4643672\ttotal: 26ms\tremaining: 0us\n",
      "[6, 0.49, 6, 0.0]\n",
      "0:\tlearn: 0.4807455\ttotal: 5.03ms\tremaining: 25.1ms\n",
      "1:\tlearn: 0.4740289\ttotal: 9.68ms\tremaining: 19.4ms\n",
      "2:\tlearn: 0.4705265\ttotal: 14.4ms\tremaining: 14.4ms\n",
      "3:\tlearn: 0.4681211\ttotal: 18.9ms\tremaining: 9.45ms\n",
      "4:\tlearn: 0.4661064\ttotal: 23.5ms\tremaining: 4.69ms\n",
      "5:\tlearn: 0.4643672\ttotal: 28.7ms\tremaining: 0us\n",
      "[6, 0.49, 6, 0.15]\n",
      "0:\tlearn: 0.4807455\ttotal: 5.13ms\tremaining: 25.7ms\n",
      "1:\tlearn: 0.4740289\ttotal: 9.77ms\tremaining: 19.5ms\n",
      "2:\tlearn: 0.4705265\ttotal: 14.3ms\tremaining: 14.3ms\n",
      "3:\tlearn: 0.4681211\ttotal: 18.7ms\tremaining: 9.34ms\n",
      "4:\tlearn: 0.4661064\ttotal: 23ms\tremaining: 4.61ms\n",
      "5:\tlearn: 0.4643672\ttotal: 31ms\tremaining: 0us\n",
      "[6, 0.49, 6, 0.2]\n",
      "0:\tlearn: 0.4807455\ttotal: 7.49ms\tremaining: 37.4ms\n",
      "1:\tlearn: 0.4740289\ttotal: 11.9ms\tremaining: 23.8ms\n",
      "2:\tlearn: 0.4705265\ttotal: 16.5ms\tremaining: 16.5ms\n",
      "3:\tlearn: 0.4681211\ttotal: 21.4ms\tremaining: 10.7ms\n",
      "4:\tlearn: 0.4661064\ttotal: 26.9ms\tremaining: 5.38ms\n",
      "5:\tlearn: 0.4643672\ttotal: 31.8ms\tremaining: 0us\n",
      "[6, 0.49, 15, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.51ms\tremaining: 47.5ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18.6ms\tremaining: 37.3ms\n",
      "2:\tlearn: 0.4686673\ttotal: 512ms\tremaining: 512ms\n",
      "3:\tlearn: 0.4640224\ttotal: 989ms\tremaining: 495ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.12s\tremaining: 224ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.63s\tremaining: 0us\n",
      "[6, 0.49, 15, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.48ms\tremaining: 42.4ms\n",
      "1:\tlearn: 0.4744785\ttotal: 16.6ms\tremaining: 33.2ms\n",
      "2:\tlearn: 0.4686673\ttotal: 485ms\tremaining: 485ms\n",
      "3:\tlearn: 0.4640224\ttotal: 951ms\tremaining: 475ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.07s\tremaining: 215ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.55s\tremaining: 0us\n",
      "[6, 0.49, 15, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 12ms\tremaining: 59.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21.1ms\tremaining: 42.2ms\n",
      "2:\tlearn: 0.4686673\ttotal: 506ms\tremaining: 506ms\n",
      "3:\tlearn: 0.4640224\ttotal: 961ms\tremaining: 480ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.11s\tremaining: 221ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.58s\tremaining: 0us\n",
      "[6, 0.49, 15, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 16.5ms\tremaining: 82.5ms\n",
      "1:\tlearn: 0.4744785\ttotal: 26.5ms\tremaining: 53ms\n",
      "2:\tlearn: 0.4686673\ttotal: 534ms\tremaining: 534ms\n",
      "3:\tlearn: 0.4640224\ttotal: 997ms\tremaining: 499ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.13s\tremaining: 226ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.58s\tremaining: 0us\n",
      "[6, 0.49, 15, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.2ms\tremaining: 56.2ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21.2ms\tremaining: 42.4ms\n",
      "2:\tlearn: 0.4686673\ttotal: 537ms\tremaining: 537ms\n",
      "3:\tlearn: 0.4640224\ttotal: 1.01s\tremaining: 503ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.17s\tremaining: 233ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.63s\tremaining: 0us\n",
      "[6, 0.49, 10, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 10.7ms\tremaining: 53.7ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21ms\tremaining: 42ms\n",
      "2:\tlearn: 0.4699228\ttotal: 39.4ms\tremaining: 39.4ms\n",
      "3:\tlearn: 0.4669696\ttotal: 54.8ms\tremaining: 27.4ms\n",
      "4:\tlearn: 0.4643800\ttotal: 71.3ms\tremaining: 14.3ms\n",
      "5:\tlearn: 0.4625508\ttotal: 87.4ms\tremaining: 0us\n",
      "[6, 0.49, 10, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 13.1ms\tremaining: 65.3ms\n",
      "1:\tlearn: 0.4744785\ttotal: 24.3ms\tremaining: 48.7ms\n",
      "2:\tlearn: 0.4699228\ttotal: 50.1ms\tremaining: 50.1ms\n",
      "3:\tlearn: 0.4669696\ttotal: 68.5ms\tremaining: 34.2ms\n",
      "4:\tlearn: 0.4643800\ttotal: 92.8ms\tremaining: 18.6ms\n",
      "5:\tlearn: 0.4625508\ttotal: 112ms\tremaining: 0us\n",
      "[6, 0.49, 10, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.51ms\tremaining: 42.6ms\n",
      "1:\tlearn: 0.4744785\ttotal: 17.5ms\tremaining: 35ms\n",
      "2:\tlearn: 0.4699228\ttotal: 33.1ms\tremaining: 33.1ms\n",
      "3:\tlearn: 0.4669696\ttotal: 49.1ms\tremaining: 24.6ms\n",
      "4:\tlearn: 0.4643800\ttotal: 66.1ms\tremaining: 13.2ms\n",
      "5:\tlearn: 0.4625508\ttotal: 82.4ms\tremaining: 0us\n",
      "[6, 0.49, 10, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.7ms\tremaining: 48.5ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18.8ms\tremaining: 37.7ms\n",
      "2:\tlearn: 0.4699228\ttotal: 35ms\tremaining: 35ms\n",
      "3:\tlearn: 0.4669696\ttotal: 53.2ms\tremaining: 26.6ms\n",
      "4:\tlearn: 0.4643800\ttotal: 70ms\tremaining: 14ms\n",
      "5:\tlearn: 0.4625508\ttotal: 85.6ms\tremaining: 0us\n",
      "[6, 0.49, 10, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 14.3ms\tremaining: 71.7ms\n",
      "1:\tlearn: 0.4744785\ttotal: 23.5ms\tremaining: 47.1ms\n",
      "2:\tlearn: 0.4699228\ttotal: 42ms\tremaining: 42ms\n",
      "3:\tlearn: 0.4669696\ttotal: 58.1ms\tremaining: 29ms\n",
      "4:\tlearn: 0.4643800\ttotal: 75.1ms\tremaining: 15ms\n",
      "5:\tlearn: 0.4625508\ttotal: 91ms\tremaining: 0us\n",
      "[6, 0.49, 8, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 6.44ms\tremaining: 32.2ms\n",
      "1:\tlearn: 0.4740216\ttotal: 13.7ms\tremaining: 27.4ms\n",
      "2:\tlearn: 0.4687398\ttotal: 21.5ms\tremaining: 21.5ms\n",
      "3:\tlearn: 0.4665081\ttotal: 28.5ms\tremaining: 14.2ms\n",
      "4:\tlearn: 0.4642764\ttotal: 35.8ms\tremaining: 7.15ms\n",
      "5:\tlearn: 0.4627806\ttotal: 43.9ms\tremaining: 0us\n",
      "[6, 0.49, 8, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 10.7ms\tremaining: 53.4ms\n",
      "1:\tlearn: 0.4740216\ttotal: 18.6ms\tremaining: 37.2ms\n",
      "2:\tlearn: 0.4687398\ttotal: 25.6ms\tremaining: 25.6ms\n",
      "3:\tlearn: 0.4665081\ttotal: 32.5ms\tremaining: 16.2ms\n",
      "4:\tlearn: 0.4642764\ttotal: 39.7ms\tremaining: 7.94ms\n",
      "5:\tlearn: 0.4627806\ttotal: 46.5ms\tremaining: 0us\n",
      "[6, 0.49, 8, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 7.41ms\tremaining: 37ms\n",
      "1:\tlearn: 0.4740216\ttotal: 14.7ms\tremaining: 29.5ms\n",
      "2:\tlearn: 0.4687398\ttotal: 22.5ms\tremaining: 22.5ms\n",
      "3:\tlearn: 0.4665081\ttotal: 35.2ms\tremaining: 17.6ms\n",
      "4:\tlearn: 0.4642764\ttotal: 43.2ms\tremaining: 8.64ms\n",
      "5:\tlearn: 0.4627806\ttotal: 50.5ms\tremaining: 0us\n",
      "[6, 0.49, 8, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 8.2ms\tremaining: 41ms\n",
      "1:\tlearn: 0.4740216\ttotal: 15.3ms\tremaining: 30.6ms\n",
      "2:\tlearn: 0.4687398\ttotal: 23.2ms\tremaining: 23.2ms\n",
      "3:\tlearn: 0.4665081\ttotal: 30.1ms\tremaining: 15ms\n",
      "4:\tlearn: 0.4642764\ttotal: 37.9ms\tremaining: 7.58ms\n",
      "5:\tlearn: 0.4627806\ttotal: 46.3ms\tremaining: 0us\n",
      "[6, 0.49, 8, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 6.84ms\tremaining: 34.2ms\n",
      "1:\tlearn: 0.4740216\ttotal: 13.8ms\tremaining: 27.5ms\n",
      "2:\tlearn: 0.4687398\ttotal: 21.2ms\tremaining: 21.2ms\n",
      "3:\tlearn: 0.4665081\ttotal: 28.2ms\tremaining: 14.1ms\n",
      "4:\tlearn: 0.4642764\ttotal: 34.9ms\tremaining: 6.99ms\n",
      "5:\tlearn: 0.4627806\ttotal: 42.3ms\tremaining: 0us\n",
      "[6, 0.49, 9, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 46.3ms\tremaining: 232ms\n",
      "1:\tlearn: 0.4744785\ttotal: 62.3ms\tremaining: 125ms\n",
      "2:\tlearn: 0.4701611\ttotal: 75.4ms\tremaining: 75.4ms\n",
      "3:\tlearn: 0.4673069\ttotal: 86ms\tremaining: 43ms\n",
      "4:\tlearn: 0.4644208\ttotal: 96.4ms\tremaining: 19.3ms\n",
      "5:\tlearn: 0.4624880\ttotal: 108ms\tremaining: 0us\n",
      "[6, 0.49, 9, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.1ms\tremaining: 55.3ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21.4ms\tremaining: 42.8ms\n",
      "2:\tlearn: 0.4701611\ttotal: 32.4ms\tremaining: 32.4ms\n",
      "3:\tlearn: 0.4673069\ttotal: 42.8ms\tremaining: 21.4ms\n",
      "4:\tlearn: 0.4644208\ttotal: 54.4ms\tremaining: 10.9ms\n",
      "5:\tlearn: 0.4624880\ttotal: 66.3ms\tremaining: 0us\n",
      "[6, 0.49, 9, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.7ms\tremaining: 63.4ms\n",
      "1:\tlearn: 0.4744785\ttotal: 23ms\tremaining: 46ms\n",
      "2:\tlearn: 0.4701611\ttotal: 33.2ms\tremaining: 33.2ms\n",
      "3:\tlearn: 0.4673069\ttotal: 44.7ms\tremaining: 22.3ms\n",
      "4:\tlearn: 0.4644208\ttotal: 54.3ms\tremaining: 10.9ms\n",
      "5:\tlearn: 0.4624880\ttotal: 63.9ms\tremaining: 0us\n",
      "[6, 0.49, 9, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 17ms\tremaining: 84.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 27.5ms\tremaining: 55ms\n",
      "2:\tlearn: 0.4701611\ttotal: 37.9ms\tremaining: 37.9ms\n",
      "3:\tlearn: 0.4673069\ttotal: 48.3ms\tremaining: 24.1ms\n",
      "4:\tlearn: 0.4644208\ttotal: 58.5ms\tremaining: 11.7ms\n",
      "5:\tlearn: 0.4624880\ttotal: 69.1ms\tremaining: 0us\n",
      "[6, 0.49, 9, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.8ms\tremaining: 49ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.8ms\tremaining: 41.6ms\n",
      "2:\tlearn: 0.4701611\ttotal: 31.6ms\tremaining: 31.6ms\n",
      "3:\tlearn: 0.4673069\ttotal: 41.8ms\tremaining: 20.9ms\n",
      "4:\tlearn: 0.4644208\ttotal: 86.2ms\tremaining: 17.2ms\n",
      "5:\tlearn: 0.4624880\ttotal: 99.4ms\tremaining: 0us\n",
      "[8, 0.3, 6, -0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 4.69ms\tremaining: 32.8ms\n",
      "1:\tlearn: 0.4796834\ttotal: 8.71ms\tremaining: 26.1ms\n",
      "2:\tlearn: 0.4757652\ttotal: 12.8ms\tremaining: 21.4ms\n",
      "3:\tlearn: 0.4737764\ttotal: 17.2ms\tremaining: 17.2ms\n",
      "4:\tlearn: 0.4716943\ttotal: 21.4ms\tremaining: 12.8ms\n",
      "5:\tlearn: 0.4696759\ttotal: 25.8ms\tremaining: 8.6ms\n",
      "6:\tlearn: 0.4683623\ttotal: 29.8ms\tremaining: 4.26ms\n",
      "7:\tlearn: 0.4672969\ttotal: 34.1ms\tremaining: 0us\n",
      "[8, 0.3, 6, 0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.88ms\tremaining: 41.2ms\n",
      "1:\tlearn: 0.4796834\ttotal: 10.4ms\tremaining: 31.1ms\n",
      "2:\tlearn: 0.4757652\ttotal: 15.2ms\tremaining: 25.3ms\n",
      "3:\tlearn: 0.4737764\ttotal: 19.6ms\tremaining: 19.6ms\n",
      "4:\tlearn: 0.4716943\ttotal: 24.3ms\tremaining: 14.6ms\n",
      "5:\tlearn: 0.4696759\ttotal: 31.3ms\tremaining: 10.4ms\n",
      "6:\tlearn: 0.4683623\ttotal: 49ms\tremaining: 7ms\n",
      "7:\tlearn: 0.4672969\ttotal: 53.4ms\tremaining: 0us\n",
      "[8, 0.3, 6, 0.0]\n",
      "0:\tlearn: 0.4852609\ttotal: 4.17ms\tremaining: 29.2ms\n",
      "1:\tlearn: 0.4796834\ttotal: 8.24ms\tremaining: 24.7ms\n",
      "2:\tlearn: 0.4757652\ttotal: 12.7ms\tremaining: 21.1ms\n",
      "3:\tlearn: 0.4737764\ttotal: 17.2ms\tremaining: 17.2ms\n",
      "4:\tlearn: 0.4716943\ttotal: 21.4ms\tremaining: 12.8ms\n",
      "5:\tlearn: 0.4696759\ttotal: 25.7ms\tremaining: 8.55ms\n",
      "6:\tlearn: 0.4683623\ttotal: 30.1ms\tremaining: 4.29ms\n",
      "7:\tlearn: 0.4672969\ttotal: 34.7ms\tremaining: 0us\n",
      "[8, 0.3, 6, 0.15]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.86ms\tremaining: 41ms\n",
      "1:\tlearn: 0.4796834\ttotal: 9.91ms\tremaining: 29.7ms\n",
      "2:\tlearn: 0.4757652\ttotal: 14ms\tremaining: 23.3ms\n",
      "3:\tlearn: 0.4737764\ttotal: 18.3ms\tremaining: 18.3ms\n",
      "4:\tlearn: 0.4716943\ttotal: 22.6ms\tremaining: 13.6ms\n",
      "5:\tlearn: 0.4696759\ttotal: 27.3ms\tremaining: 9.09ms\n",
      "6:\tlearn: 0.4683623\ttotal: 32.4ms\tremaining: 4.62ms\n",
      "7:\tlearn: 0.4672969\ttotal: 36.5ms\tremaining: 0us\n",
      "[8, 0.3, 6, 0.2]\n",
      "0:\tlearn: 0.4852609\ttotal: 4.49ms\tremaining: 31.4ms\n",
      "1:\tlearn: 0.4796834\ttotal: 8.76ms\tremaining: 26.3ms\n",
      "2:\tlearn: 0.4757652\ttotal: 13.2ms\tremaining: 22ms\n",
      "3:\tlearn: 0.4737764\ttotal: 17.3ms\tremaining: 17.3ms\n",
      "4:\tlearn: 0.4716943\ttotal: 21.7ms\tremaining: 13ms\n",
      "5:\tlearn: 0.4696759\ttotal: 25.8ms\tremaining: 8.61ms\n",
      "6:\tlearn: 0.4683623\ttotal: 30.5ms\tremaining: 4.35ms\n",
      "7:\tlearn: 0.4672969\ttotal: 35ms\tremaining: 0us\n",
      "[8, 0.3, 15, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 12ms\tremaining: 83.7ms\n",
      "1:\tlearn: 0.4769595\ttotal: 519ms\tremaining: 1.56s\n",
      "2:\tlearn: 0.4714456\ttotal: 995ms\tremaining: 1.66s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.49s\tremaining: 1.49s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.99s\tremaining: 1.19s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.48s\tremaining: 825ms\n",
      "6:\tlearn: 0.4603088\ttotal: 2.93s\tremaining: 419ms\n",
      "7:\tlearn: 0.4589930\ttotal: 2.95s\tremaining: 0us\n",
      "[8, 0.3, 15, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.45ms\tremaining: 66.1ms\n",
      "1:\tlearn: 0.4769595\ttotal: 528ms\tremaining: 1.58s\n",
      "2:\tlearn: 0.4714456\ttotal: 1.01s\tremaining: 1.69s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.49s\tremaining: 1.49s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.96s\tremaining: 1.17s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.44s\tremaining: 814ms\n",
      "6:\tlearn: 0.4603088\ttotal: 2.92s\tremaining: 417ms\n",
      "7:\tlearn: 0.4589930\ttotal: 2.94s\tremaining: 0us\n",
      "[8, 0.3, 15, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.4ms\tremaining: 72.8ms\n",
      "1:\tlearn: 0.4769595\ttotal: 521ms\tremaining: 1.56s\n",
      "2:\tlearn: 0.4714456\ttotal: 1.04s\tremaining: 1.73s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.53s\tremaining: 1.53s\n",
      "4:\tlearn: 0.4645800\ttotal: 2.03s\tremaining: 1.22s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.52s\tremaining: 840ms\n",
      "6:\tlearn: 0.4603088\ttotal: 3.03s\tremaining: 433ms\n",
      "7:\tlearn: 0.4589930\ttotal: 3.06s\tremaining: 0us\n",
      "[8, 0.3, 15, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.37ms\tremaining: 65.6ms\n",
      "1:\tlearn: 0.4769595\ttotal: 538ms\tremaining: 1.61s\n",
      "2:\tlearn: 0.4714456\ttotal: 1.02s\tremaining: 1.7s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.51s\tremaining: 1.51s\n",
      "4:\tlearn: 0.4645800\ttotal: 2s\tremaining: 1.2s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.49s\tremaining: 832ms\n",
      "6:\tlearn: 0.4603088\ttotal: 3s\tremaining: 428ms\n",
      "7:\tlearn: 0.4589930\ttotal: 3.01s\tremaining: 0us\n",
      "[8, 0.3, 15, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.5ms\tremaining: 87.4ms\n",
      "1:\tlearn: 0.4769595\ttotal: 533ms\tremaining: 1.6s\n",
      "2:\tlearn: 0.4714456\ttotal: 1.06s\tremaining: 1.77s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.55s\tremaining: 1.55s\n",
      "4:\tlearn: 0.4645800\ttotal: 2.06s\tremaining: 1.23s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.59s\tremaining: 862ms\n",
      "6:\tlearn: 0.4603088\ttotal: 3.05s\tremaining: 436ms\n",
      "7:\tlearn: 0.4589930\ttotal: 3.06s\tremaining: 0us\n",
      "[8, 0.3, 10, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 13ms\tremaining: 91ms\n",
      "1:\tlearn: 0.4786840\ttotal: 30.6ms\tremaining: 91.8ms\n",
      "2:\tlearn: 0.4743082\ttotal: 46ms\tremaining: 76.6ms\n",
      "3:\tlearn: 0.4713878\ttotal: 61.6ms\tremaining: 61.6ms\n",
      "4:\tlearn: 0.4683005\ttotal: 77.9ms\tremaining: 46.7ms\n",
      "5:\tlearn: 0.4662774\ttotal: 93.3ms\tremaining: 31.1ms\n",
      "6:\tlearn: 0.4645284\ttotal: 109ms\tremaining: 15.6ms\n",
      "7:\tlearn: 0.4637179\ttotal: 114ms\tremaining: 0us\n",
      "[8, 0.3, 10, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 11.7ms\tremaining: 81.8ms\n",
      "1:\tlearn: 0.4786840\ttotal: 28.3ms\tremaining: 85ms\n",
      "2:\tlearn: 0.4743082\ttotal: 45ms\tremaining: 75ms\n",
      "3:\tlearn: 0.4713878\ttotal: 63.8ms\tremaining: 63.8ms\n",
      "4:\tlearn: 0.4683005\ttotal: 80.8ms\tremaining: 48.5ms\n",
      "5:\tlearn: 0.4662774\ttotal: 97ms\tremaining: 32.3ms\n",
      "6:\tlearn: 0.4645284\ttotal: 113ms\tremaining: 16.1ms\n",
      "7:\tlearn: 0.4637179\ttotal: 118ms\tremaining: 0us\n",
      "[8, 0.3, 10, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 16.3ms\tremaining: 114ms\n",
      "1:\tlearn: 0.4786840\ttotal: 42.8ms\tremaining: 128ms\n",
      "2:\tlearn: 0.4743082\ttotal: 61.6ms\tremaining: 103ms\n",
      "3:\tlearn: 0.4713878\ttotal: 80.6ms\tremaining: 80.6ms\n",
      "4:\tlearn: 0.4683005\ttotal: 98.4ms\tremaining: 59.1ms\n",
      "5:\tlearn: 0.4662774\ttotal: 116ms\tremaining: 38.8ms\n",
      "6:\tlearn: 0.4645284\ttotal: 134ms\tremaining: 19.2ms\n",
      "7:\tlearn: 0.4637179\ttotal: 140ms\tremaining: 0us\n",
      "[8, 0.3, 10, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.34ms\tremaining: 65.4ms\n",
      "1:\tlearn: 0.4786840\ttotal: 25ms\tremaining: 75.1ms\n",
      "2:\tlearn: 0.4743082\ttotal: 41.2ms\tremaining: 68.7ms\n",
      "3:\tlearn: 0.4713878\ttotal: 58.5ms\tremaining: 58.5ms\n",
      "4:\tlearn: 0.4683005\ttotal: 76.5ms\tremaining: 45.9ms\n",
      "5:\tlearn: 0.4662774\ttotal: 121ms\tremaining: 40.4ms\n",
      "6:\tlearn: 0.4645284\ttotal: 141ms\tremaining: 20.2ms\n",
      "7:\tlearn: 0.4637179\ttotal: 146ms\tremaining: 0us\n",
      "[8, 0.3, 10, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.88ms\tremaining: 62.1ms\n",
      "1:\tlearn: 0.4786840\ttotal: 24.4ms\tremaining: 73.1ms\n",
      "2:\tlearn: 0.4743082\ttotal: 40.2ms\tremaining: 67ms\n",
      "3:\tlearn: 0.4713878\ttotal: 54.2ms\tremaining: 54.2ms\n",
      "4:\tlearn: 0.4683005\ttotal: 69ms\tremaining: 41.4ms\n",
      "5:\tlearn: 0.4662774\ttotal: 83.5ms\tremaining: 27.8ms\n",
      "6:\tlearn: 0.4645284\ttotal: 97.4ms\tremaining: 13.9ms\n",
      "7:\tlearn: 0.4637179\ttotal: 102ms\tremaining: 0us\n",
      "[8, 0.3, 12, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 11.9ms\tremaining: 83.4ms\n",
      "1:\tlearn: 0.4778843\ttotal: 76.5ms\tremaining: 229ms\n",
      "2:\tlearn: 0.4738999\ttotal: 132ms\tremaining: 220ms\n",
      "3:\tlearn: 0.4696749\ttotal: 193ms\tremaining: 193ms\n",
      "4:\tlearn: 0.4678542\ttotal: 254ms\tremaining: 152ms\n",
      "5:\tlearn: 0.4655216\ttotal: 326ms\tremaining: 109ms\n",
      "6:\tlearn: 0.4639614\ttotal: 398ms\tremaining: 56.8ms\n",
      "7:\tlearn: 0.4618543\ttotal: 462ms\tremaining: 0us\n",
      "[8, 0.3, 12, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.67ms\tremaining: 67.7ms\n",
      "1:\tlearn: 0.4778843\ttotal: 101ms\tremaining: 302ms\n",
      "2:\tlearn: 0.4738999\ttotal: 170ms\tremaining: 283ms\n",
      "3:\tlearn: 0.4696749\ttotal: 238ms\tremaining: 238ms\n",
      "4:\tlearn: 0.4678542\ttotal: 303ms\tremaining: 182ms\n",
      "5:\tlearn: 0.4655216\ttotal: 364ms\tremaining: 121ms\n",
      "6:\tlearn: 0.4639614\ttotal: 422ms\tremaining: 60.3ms\n",
      "7:\tlearn: 0.4618543\ttotal: 481ms\tremaining: 0us\n",
      "[8, 0.3, 12, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.8ms\tremaining: 75.3ms\n",
      "1:\tlearn: 0.4778843\ttotal: 66ms\tremaining: 198ms\n",
      "2:\tlearn: 0.4738999\ttotal: 123ms\tremaining: 205ms\n",
      "3:\tlearn: 0.4696749\ttotal: 189ms\tremaining: 189ms\n",
      "4:\tlearn: 0.4678542\ttotal: 264ms\tremaining: 158ms\n",
      "5:\tlearn: 0.4655216\ttotal: 350ms\tremaining: 117ms\n",
      "6:\tlearn: 0.4639614\ttotal: 415ms\tremaining: 59.3ms\n",
      "7:\tlearn: 0.4618543\ttotal: 479ms\tremaining: 0us\n",
      "[8, 0.3, 12, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 17.2ms\tremaining: 120ms\n",
      "1:\tlearn: 0.4778843\ttotal: 116ms\tremaining: 348ms\n",
      "2:\tlearn: 0.4738999\ttotal: 175ms\tremaining: 292ms\n",
      "3:\tlearn: 0.4696749\ttotal: 234ms\tremaining: 234ms\n",
      "4:\tlearn: 0.4678542\ttotal: 296ms\tremaining: 177ms\n",
      "5:\tlearn: 0.4655216\ttotal: 359ms\tremaining: 120ms\n",
      "6:\tlearn: 0.4639614\ttotal: 442ms\tremaining: 63.1ms\n",
      "7:\tlearn: 0.4618543\ttotal: 527ms\tremaining: 0us\n",
      "[8, 0.3, 12, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.85ms\tremaining: 61.9ms\n",
      "1:\tlearn: 0.4778843\ttotal: 68.9ms\tremaining: 207ms\n",
      "2:\tlearn: 0.4738999\ttotal: 127ms\tremaining: 212ms\n",
      "3:\tlearn: 0.4696749\ttotal: 209ms\tremaining: 209ms\n",
      "4:\tlearn: 0.4678542\ttotal: 274ms\tremaining: 165ms\n",
      "5:\tlearn: 0.4655216\ttotal: 332ms\tremaining: 111ms\n",
      "6:\tlearn: 0.4639614\ttotal: 389ms\tremaining: 55.5ms\n",
      "7:\tlearn: 0.4618543\ttotal: 447ms\tremaining: 0us\n",
      "[8, 0.3, 13, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.3ms\tremaining: 85.8ms\n",
      "1:\tlearn: 0.4776303\ttotal: 133ms\tremaining: 399ms\n",
      "2:\tlearn: 0.4735011\ttotal: 242ms\tremaining: 404ms\n",
      "3:\tlearn: 0.4707331\ttotal: 304ms\tremaining: 304ms\n",
      "4:\tlearn: 0.4669265\ttotal: 487ms\tremaining: 292ms\n",
      "5:\tlearn: 0.4646028\ttotal: 553ms\tremaining: 184ms\n",
      "6:\tlearn: 0.4634280\ttotal: 559ms\tremaining: 79.9ms\n",
      "7:\tlearn: 0.4620786\ttotal: 672ms\tremaining: 0us\n",
      "[8, 0.3, 13, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 21.5ms\tremaining: 150ms\n",
      "1:\tlearn: 0.4776303\ttotal: 148ms\tremaining: 445ms\n",
      "2:\tlearn: 0.4735011\ttotal: 260ms\tremaining: 433ms\n",
      "3:\tlearn: 0.4707331\ttotal: 313ms\tremaining: 313ms\n",
      "4:\tlearn: 0.4669265\ttotal: 422ms\tremaining: 253ms\n",
      "5:\tlearn: 0.4646028\ttotal: 516ms\tremaining: 172ms\n",
      "6:\tlearn: 0.4634280\ttotal: 523ms\tremaining: 74.7ms\n",
      "7:\tlearn: 0.4620786\ttotal: 659ms\tremaining: 0us\n",
      "[8, 0.3, 13, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 8.9ms\tremaining: 62.3ms\n",
      "1:\tlearn: 0.4776303\ttotal: 132ms\tremaining: 395ms\n",
      "2:\tlearn: 0.4735011\ttotal: 262ms\tremaining: 436ms\n",
      "3:\tlearn: 0.4707331\ttotal: 321ms\tremaining: 321ms\n",
      "4:\tlearn: 0.4669265\ttotal: 435ms\tremaining: 261ms\n",
      "5:\tlearn: 0.4646028\ttotal: 489ms\tremaining: 163ms\n",
      "6:\tlearn: 0.4634280\ttotal: 496ms\tremaining: 70.9ms\n",
      "7:\tlearn: 0.4620786\ttotal: 629ms\tremaining: 0us\n",
      "[8, 0.3, 13, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.9ms\tremaining: 76.6ms\n",
      "1:\tlearn: 0.4776303\ttotal: 119ms\tremaining: 357ms\n",
      "2:\tlearn: 0.4735011\ttotal: 263ms\tremaining: 438ms\n",
      "3:\tlearn: 0.4707331\ttotal: 327ms\tremaining: 327ms\n",
      "4:\tlearn: 0.4669265\ttotal: 449ms\tremaining: 270ms\n",
      "5:\tlearn: 0.4646028\ttotal: 511ms\tremaining: 170ms\n",
      "6:\tlearn: 0.4634280\ttotal: 518ms\tremaining: 74ms\n",
      "7:\tlearn: 0.4620786\ttotal: 642ms\tremaining: 0us\n",
      "[8, 0.3, 13, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 11.1ms\tremaining: 77.7ms\n",
      "1:\tlearn: 0.4776303\ttotal: 121ms\tremaining: 362ms\n",
      "2:\tlearn: 0.4735011\ttotal: 275ms\tremaining: 458ms\n",
      "3:\tlearn: 0.4707331\ttotal: 336ms\tremaining: 336ms\n",
      "4:\tlearn: 0.4669265\ttotal: 460ms\tremaining: 276ms\n",
      "5:\tlearn: 0.4646028\ttotal: 518ms\tremaining: 173ms\n",
      "6:\tlearn: 0.4634280\ttotal: 525ms\tremaining: 74.9ms\n",
      "7:\tlearn: 0.4620786\ttotal: 649ms\tremaining: 0us\n",
      "[8, 0.8, 6, -0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.58ms\tremaining: 32.1ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.86ms\tremaining: 26.6ms\n",
      "2:\tlearn: 0.4667365\ttotal: 13ms\tremaining: 21.6ms\n",
      "3:\tlearn: 0.4636906\ttotal: 17ms\tremaining: 17ms\n",
      "4:\tlearn: 0.4617121\ttotal: 21.2ms\tremaining: 12.7ms\n",
      "5:\tlearn: 0.4596172\ttotal: 25.4ms\tremaining: 8.46ms\n",
      "6:\tlearn: 0.4582917\ttotal: 29.3ms\tremaining: 4.19ms\n",
      "7:\tlearn: 0.4560211\ttotal: 33.6ms\tremaining: 0us\n",
      "[8, 0.8, 6, 0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.53ms\tremaining: 31.7ms\n",
      "1:\tlearn: 0.4707614\ttotal: 9.15ms\tremaining: 27.5ms\n",
      "2:\tlearn: 0.4667365\ttotal: 13.6ms\tremaining: 22.6ms\n",
      "3:\tlearn: 0.4636906\ttotal: 20.4ms\tremaining: 20.4ms\n",
      "4:\tlearn: 0.4617121\ttotal: 24.7ms\tremaining: 14.8ms\n",
      "5:\tlearn: 0.4596172\ttotal: 33.9ms\tremaining: 11.3ms\n",
      "6:\tlearn: 0.4582917\ttotal: 38.3ms\tremaining: 5.46ms\n",
      "7:\tlearn: 0.4560211\ttotal: 42.6ms\tremaining: 0us\n",
      "[8, 0.8, 6, 0.0]\n",
      "0:\tlearn: 0.4762695\ttotal: 13.6ms\tremaining: 95ms\n",
      "1:\tlearn: 0.4707614\ttotal: 18.2ms\tremaining: 54.6ms\n",
      "2:\tlearn: 0.4667365\ttotal: 53.2ms\tremaining: 88.6ms\n",
      "3:\tlearn: 0.4636906\ttotal: 57.7ms\tremaining: 57.7ms\n",
      "4:\tlearn: 0.4617121\ttotal: 62.4ms\tremaining: 37.5ms\n",
      "5:\tlearn: 0.4596172\ttotal: 66.8ms\tremaining: 22.3ms\n",
      "6:\tlearn: 0.4582917\ttotal: 71.3ms\tremaining: 10.2ms\n",
      "7:\tlearn: 0.4560211\ttotal: 76.4ms\tremaining: 0us\n",
      "[8, 0.8, 6, 0.15]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.7ms\tremaining: 32.9ms\n",
      "1:\tlearn: 0.4707614\ttotal: 9.14ms\tremaining: 27.4ms\n",
      "2:\tlearn: 0.4667365\ttotal: 13.1ms\tremaining: 21.9ms\n",
      "3:\tlearn: 0.4636906\ttotal: 18.3ms\tremaining: 18.3ms\n",
      "4:\tlearn: 0.4617121\ttotal: 23ms\tremaining: 13.8ms\n",
      "5:\tlearn: 0.4596172\ttotal: 27.2ms\tremaining: 9.06ms\n",
      "6:\tlearn: 0.4582917\ttotal: 31.1ms\tremaining: 4.44ms\n",
      "7:\tlearn: 0.4560211\ttotal: 35.1ms\tremaining: 0us\n",
      "[8, 0.8, 6, 0.2]\n",
      "0:\tlearn: 0.4762695\ttotal: 9.34ms\tremaining: 65.4ms\n",
      "1:\tlearn: 0.4707614\ttotal: 14.5ms\tremaining: 43.4ms\n",
      "2:\tlearn: 0.4667365\ttotal: 19.6ms\tremaining: 32.6ms\n",
      "3:\tlearn: 0.4636906\ttotal: 24.1ms\tremaining: 24.1ms\n",
      "4:\tlearn: 0.4617121\ttotal: 28.5ms\tremaining: 17.1ms\n",
      "5:\tlearn: 0.4596172\ttotal: 33.7ms\tremaining: 11.2ms\n",
      "6:\tlearn: 0.4582917\ttotal: 38.9ms\tremaining: 5.56ms\n",
      "7:\tlearn: 0.4560211\ttotal: 43.4ms\tremaining: 0us\n",
      "[8, 0.8, 15, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.4ms\tremaining: 73ms\n",
      "1:\tlearn: 0.4658921\ttotal: 524ms\tremaining: 1.57s\n",
      "2:\tlearn: 0.4614984\ttotal: 1.02s\tremaining: 1.71s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.56s\tremaining: 1.56s\n",
      "4:\tlearn: 0.4540621\ttotal: 2.08s\tremaining: 1.25s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.58s\tremaining: 862ms\n",
      "6:\tlearn: 0.4499802\ttotal: 3.06s\tremaining: 437ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.54s\tremaining: 0us\n",
      "[8, 0.8, 15, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.84ms\tremaining: 68.9ms\n",
      "1:\tlearn: 0.4658921\ttotal: 511ms\tremaining: 1.53s\n",
      "2:\tlearn: 0.4614984\ttotal: 995ms\tremaining: 1.66s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.47s\tremaining: 1.47s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.93s\tremaining: 1.16s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.41s\tremaining: 803ms\n",
      "6:\tlearn: 0.4499802\ttotal: 2.89s\tremaining: 413ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.37s\tremaining: 0us\n",
      "[8, 0.8, 15, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.7ms\tremaining: 89.1ms\n",
      "1:\tlearn: 0.4658921\ttotal: 530ms\tremaining: 1.59s\n",
      "2:\tlearn: 0.4614984\ttotal: 1.02s\tremaining: 1.71s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.51s\tremaining: 1.51s\n",
      "4:\tlearn: 0.4540621\ttotal: 2.03s\tremaining: 1.22s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.49s\tremaining: 831ms\n",
      "6:\tlearn: 0.4499802\ttotal: 2.98s\tremaining: 426ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.46s\tremaining: 0us\n",
      "[8, 0.8, 15, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 13.6ms\tremaining: 95.2ms\n",
      "1:\tlearn: 0.4658921\ttotal: 512ms\tremaining: 1.53s\n",
      "2:\tlearn: 0.4614984\ttotal: 1s\tremaining: 1.67s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.49s\tremaining: 1.49s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.98s\tremaining: 1.19s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.43s\tremaining: 811ms\n",
      "6:\tlearn: 0.4499802\ttotal: 2.9s\tremaining: 415ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.39s\tremaining: 0us\n",
      "[8, 0.8, 15, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.3ms\tremaining: 78.8ms\n",
      "1:\tlearn: 0.4658921\ttotal: 474ms\tremaining: 1.42s\n",
      "2:\tlearn: 0.4614984\ttotal: 952ms\tremaining: 1.59s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.46s\tremaining: 1.46s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.95s\tremaining: 1.17s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.43s\tremaining: 809ms\n",
      "6:\tlearn: 0.4499802\ttotal: 2.92s\tremaining: 417ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.43s\tremaining: 0us\n",
      "[8, 0.8, 10, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.3ms\tremaining: 86ms\n",
      "1:\tlearn: 0.4684354\ttotal: 29.4ms\tremaining: 88.1ms\n",
      "2:\tlearn: 0.4642800\ttotal: 47.3ms\tremaining: 78.8ms\n",
      "3:\tlearn: 0.4627032\ttotal: 50.3ms\tremaining: 50.3ms\n",
      "4:\tlearn: 0.4607357\ttotal: 67.5ms\tremaining: 40.5ms\n",
      "5:\tlearn: 0.4583929\ttotal: 83.6ms\tremaining: 27.9ms\n",
      "6:\tlearn: 0.4565229\ttotal: 98.1ms\tremaining: 14ms\n",
      "7:\tlearn: 0.4531244\ttotal: 113ms\tremaining: 0us\n",
      "[8, 0.8, 10, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 12ms\tremaining: 83.8ms\n",
      "1:\tlearn: 0.4684354\ttotal: 28.2ms\tremaining: 84.5ms\n",
      "2:\tlearn: 0.4642800\ttotal: 49ms\tremaining: 81.6ms\n",
      "3:\tlearn: 0.4627032\ttotal: 53ms\tremaining: 53ms\n",
      "4:\tlearn: 0.4607357\ttotal: 77.9ms\tremaining: 46.7ms\n",
      "5:\tlearn: 0.4583929\ttotal: 96.2ms\tremaining: 32ms\n",
      "6:\tlearn: 0.4565229\ttotal: 113ms\tremaining: 16.2ms\n",
      "7:\tlearn: 0.4531244\ttotal: 131ms\tremaining: 0us\n",
      "[8, 0.8, 10, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.5ms\tremaining: 66.5ms\n",
      "1:\tlearn: 0.4684354\ttotal: 25.7ms\tremaining: 77ms\n",
      "2:\tlearn: 0.4642800\ttotal: 42.3ms\tremaining: 70.6ms\n",
      "3:\tlearn: 0.4627032\ttotal: 45.3ms\tremaining: 45.3ms\n",
      "4:\tlearn: 0.4607357\ttotal: 62.5ms\tremaining: 37.5ms\n",
      "5:\tlearn: 0.4583929\ttotal: 78.9ms\tremaining: 26.3ms\n",
      "6:\tlearn: 0.4565229\ttotal: 117ms\tremaining: 16.7ms\n",
      "7:\tlearn: 0.4531244\ttotal: 136ms\tremaining: 0us\n",
      "[8, 0.8, 10, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.95ms\tremaining: 69.7ms\n",
      "1:\tlearn: 0.4684354\ttotal: 26.6ms\tremaining: 79.9ms\n",
      "2:\tlearn: 0.4642800\ttotal: 40.4ms\tremaining: 67.3ms\n",
      "3:\tlearn: 0.4627032\ttotal: 43ms\tremaining: 43ms\n",
      "4:\tlearn: 0.4607357\ttotal: 56.7ms\tremaining: 34ms\n",
      "5:\tlearn: 0.4583929\ttotal: 70.1ms\tremaining: 23.4ms\n",
      "6:\tlearn: 0.4565229\ttotal: 84.1ms\tremaining: 12ms\n",
      "7:\tlearn: 0.4531244\ttotal: 97.6ms\tremaining: 0us\n",
      "[8, 0.8, 10, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.38ms\tremaining: 65.7ms\n",
      "1:\tlearn: 0.4684354\ttotal: 24.8ms\tremaining: 74.3ms\n",
      "2:\tlearn: 0.4642800\ttotal: 42.2ms\tremaining: 70.4ms\n",
      "3:\tlearn: 0.4627032\ttotal: 45.1ms\tremaining: 45.1ms\n",
      "4:\tlearn: 0.4607357\ttotal: 60.9ms\tremaining: 36.5ms\n",
      "5:\tlearn: 0.4583929\ttotal: 76.9ms\tremaining: 25.6ms\n",
      "6:\tlearn: 0.4565229\ttotal: 112ms\tremaining: 16ms\n",
      "7:\tlearn: 0.4531244\ttotal: 127ms\tremaining: 0us\n",
      "[8, 0.8, 8, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.21ms\tremaining: 43.5ms\n",
      "1:\tlearn: 0.4682512\ttotal: 13.1ms\tremaining: 39.3ms\n",
      "2:\tlearn: 0.4650605\ttotal: 19.8ms\tremaining: 33ms\n",
      "3:\tlearn: 0.4630741\ttotal: 26.3ms\tremaining: 26.3ms\n",
      "4:\tlearn: 0.4600410\ttotal: 33.6ms\tremaining: 20.1ms\n",
      "5:\tlearn: 0.4577069\ttotal: 41ms\tremaining: 13.7ms\n",
      "6:\tlearn: 0.4559546\ttotal: 48.2ms\tremaining: 6.88ms\n",
      "7:\tlearn: 0.4543265\ttotal: 55.2ms\tremaining: 0us\n",
      "[8, 0.8, 8, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 8.82ms\tremaining: 61.7ms\n",
      "1:\tlearn: 0.4682512\ttotal: 15.8ms\tremaining: 47.3ms\n",
      "2:\tlearn: 0.4650605\ttotal: 22.7ms\tremaining: 37.8ms\n",
      "3:\tlearn: 0.4630741\ttotal: 29.7ms\tremaining: 29.7ms\n",
      "4:\tlearn: 0.4600410\ttotal: 37.1ms\tremaining: 22.2ms\n",
      "5:\tlearn: 0.4577069\ttotal: 44.3ms\tremaining: 14.8ms\n",
      "6:\tlearn: 0.4559546\ttotal: 51.8ms\tremaining: 7.39ms\n",
      "7:\tlearn: 0.4543265\ttotal: 60.1ms\tremaining: 0us\n",
      "[8, 0.8, 8, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.87ms\tremaining: 48.1ms\n",
      "1:\tlearn: 0.4682512\ttotal: 14.8ms\tremaining: 44.4ms\n",
      "2:\tlearn: 0.4650605\ttotal: 21.9ms\tremaining: 36.4ms\n",
      "3:\tlearn: 0.4630741\ttotal: 29.4ms\tremaining: 29.4ms\n",
      "4:\tlearn: 0.4600410\ttotal: 36.9ms\tremaining: 22.1ms\n",
      "5:\tlearn: 0.4577069\ttotal: 44ms\tremaining: 14.7ms\n",
      "6:\tlearn: 0.4559546\ttotal: 51.2ms\tremaining: 7.31ms\n",
      "7:\tlearn: 0.4543265\ttotal: 59.2ms\tremaining: 0us\n",
      "[8, 0.8, 8, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.92ms\tremaining: 48.4ms\n",
      "1:\tlearn: 0.4682512\ttotal: 14.6ms\tremaining: 43.7ms\n",
      "2:\tlearn: 0.4650605\ttotal: 21.2ms\tremaining: 35.3ms\n",
      "3:\tlearn: 0.4630741\ttotal: 27.8ms\tremaining: 27.8ms\n",
      "4:\tlearn: 0.4600410\ttotal: 34.4ms\tremaining: 20.7ms\n",
      "5:\tlearn: 0.4577069\ttotal: 41ms\tremaining: 13.7ms\n",
      "6:\tlearn: 0.4559546\ttotal: 48ms\tremaining: 6.86ms\n",
      "7:\tlearn: 0.4543265\ttotal: 55.1ms\tremaining: 0us\n",
      "[8, 0.8, 8, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 30.3ms\tremaining: 212ms\n",
      "1:\tlearn: 0.4682512\ttotal: 40.5ms\tremaining: 121ms\n",
      "2:\tlearn: 0.4650605\ttotal: 56.3ms\tremaining: 93.8ms\n",
      "3:\tlearn: 0.4630741\ttotal: 78.7ms\tremaining: 78.7ms\n",
      "4:\tlearn: 0.4600410\ttotal: 86.9ms\tremaining: 52.1ms\n",
      "5:\tlearn: 0.4577069\ttotal: 94.6ms\tremaining: 31.5ms\n",
      "6:\tlearn: 0.4559546\ttotal: 102ms\tremaining: 14.6ms\n",
      "7:\tlearn: 0.4543265\ttotal: 109ms\tremaining: 0us\n",
      "[8, 0.8, 7, -0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.3ms\tremaining: 37.1ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.8ms\tremaining: 32.3ms\n",
      "2:\tlearn: 0.4653862\ttotal: 16.1ms\tremaining: 26.9ms\n",
      "3:\tlearn: 0.4622296\ttotal: 21.3ms\tremaining: 21.3ms\n",
      "4:\tlearn: 0.4598883\ttotal: 26.2ms\tremaining: 15.7ms\n",
      "5:\tlearn: 0.4581321\ttotal: 31.7ms\tremaining: 10.6ms\n",
      "6:\tlearn: 0.4567709\ttotal: 37ms\tremaining: 5.29ms\n",
      "7:\tlearn: 0.4533516\ttotal: 42.3ms\tremaining: 0us\n",
      "[8, 0.8, 7, 0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.79ms\tremaining: 40.5ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.9ms\tremaining: 32.6ms\n",
      "2:\tlearn: 0.4653862\ttotal: 16.3ms\tremaining: 27.2ms\n",
      "3:\tlearn: 0.4622296\ttotal: 21.7ms\tremaining: 21.7ms\n",
      "4:\tlearn: 0.4598883\ttotal: 26.9ms\tremaining: 16.2ms\n",
      "5:\tlearn: 0.4581321\ttotal: 33.6ms\tremaining: 11.2ms\n",
      "6:\tlearn: 0.4567709\ttotal: 38.7ms\tremaining: 5.53ms\n",
      "7:\tlearn: 0.4533516\ttotal: 43.9ms\tremaining: 0us\n",
      "[8, 0.8, 7, 0.0]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.07ms\tremaining: 35.5ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.4ms\tremaining: 31.1ms\n",
      "2:\tlearn: 0.4653862\ttotal: 16.1ms\tremaining: 26.9ms\n",
      "3:\tlearn: 0.4622296\ttotal: 21.3ms\tremaining: 21.3ms\n",
      "4:\tlearn: 0.4598883\ttotal: 27.3ms\tremaining: 16.4ms\n",
      "5:\tlearn: 0.4581321\ttotal: 32.5ms\tremaining: 10.8ms\n",
      "6:\tlearn: 0.4567709\ttotal: 37.9ms\tremaining: 5.42ms\n",
      "7:\tlearn: 0.4533516\ttotal: 43.2ms\tremaining: 0us\n",
      "[8, 0.8, 7, 0.15]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.34ms\tremaining: 37.4ms\n",
      "1:\tlearn: 0.4687965\ttotal: 10.9ms\tremaining: 32.8ms\n",
      "2:\tlearn: 0.4653862\ttotal: 16.4ms\tremaining: 27.3ms\n",
      "3:\tlearn: 0.4622296\ttotal: 22.2ms\tremaining: 22.2ms\n",
      "4:\tlearn: 0.4598883\ttotal: 27.7ms\tremaining: 16.6ms\n",
      "5:\tlearn: 0.4581321\ttotal: 32.7ms\tremaining: 10.9ms\n",
      "6:\tlearn: 0.4567709\ttotal: 37.8ms\tremaining: 5.41ms\n",
      "7:\tlearn: 0.4533516\ttotal: 43.1ms\tremaining: 0us\n",
      "[8, 0.8, 7, 0.2]\n",
      "0:\tlearn: 0.4762583\ttotal: 5.78ms\tremaining: 40.5ms\n",
      "1:\tlearn: 0.4687965\ttotal: 11ms\tremaining: 32.9ms\n",
      "2:\tlearn: 0.4653862\ttotal: 16ms\tremaining: 26.6ms\n",
      "3:\tlearn: 0.4622296\ttotal: 21ms\tremaining: 21ms\n",
      "4:\tlearn: 0.4598883\ttotal: 26.1ms\tremaining: 15.7ms\n",
      "5:\tlearn: 0.4581321\ttotal: 31.5ms\tremaining: 10.5ms\n",
      "6:\tlearn: 0.4567709\ttotal: 36.9ms\tremaining: 5.27ms\n",
      "7:\tlearn: 0.4533516\ttotal: 42.2ms\tremaining: 0us\n",
      "[8, 0.55, 6, -0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 8.52ms\tremaining: 59.6ms\n",
      "1:\tlearn: 0.4730186\ttotal: 12.6ms\tremaining: 37.7ms\n",
      "2:\tlearn: 0.4702860\ttotal: 17ms\tremaining: 28.4ms\n",
      "3:\tlearn: 0.4675422\ttotal: 21.3ms\tremaining: 21.3ms\n",
      "4:\tlearn: 0.4655547\ttotal: 25.7ms\tremaining: 15.4ms\n",
      "5:\tlearn: 0.4641129\ttotal: 30.1ms\tremaining: 10ms\n",
      "6:\tlearn: 0.4622549\ttotal: 34.1ms\tremaining: 4.87ms\n",
      "7:\tlearn: 0.4607061\ttotal: 38.1ms\tremaining: 0us\n",
      "[8, 0.55, 6, 0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 25.8ms\tremaining: 181ms\n",
      "1:\tlearn: 0.4730186\ttotal: 30.6ms\tremaining: 91.8ms\n",
      "2:\tlearn: 0.4702860\ttotal: 41.3ms\tremaining: 68.9ms\n",
      "3:\tlearn: 0.4675422\ttotal: 46ms\tremaining: 46ms\n",
      "4:\tlearn: 0.4655547\ttotal: 50.6ms\tremaining: 30.3ms\n",
      "5:\tlearn: 0.4641129\ttotal: 54.9ms\tremaining: 18.3ms\n",
      "6:\tlearn: 0.4622549\ttotal: 59.3ms\tremaining: 8.48ms\n",
      "7:\tlearn: 0.4607061\ttotal: 64.3ms\tremaining: 0us\n",
      "[8, 0.55, 6, 0.0]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.48ms\tremaining: 31.4ms\n",
      "1:\tlearn: 0.4730186\ttotal: 8.65ms\tremaining: 26ms\n",
      "2:\tlearn: 0.4702860\ttotal: 13.4ms\tremaining: 22.3ms\n",
      "3:\tlearn: 0.4675422\ttotal: 18.3ms\tremaining: 18.3ms\n",
      "4:\tlearn: 0.4655547\ttotal: 22.5ms\tremaining: 13.5ms\n",
      "5:\tlearn: 0.4641129\ttotal: 26.6ms\tremaining: 8.87ms\n",
      "6:\tlearn: 0.4622549\ttotal: 30.7ms\tremaining: 4.39ms\n",
      "7:\tlearn: 0.4607061\ttotal: 34.6ms\tremaining: 0us\n",
      "[8, 0.55, 6, 0.15]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.76ms\tremaining: 33.3ms\n",
      "1:\tlearn: 0.4730186\ttotal: 10.5ms\tremaining: 31.5ms\n",
      "2:\tlearn: 0.4702860\ttotal: 14.9ms\tremaining: 24.8ms\n",
      "3:\tlearn: 0.4675422\ttotal: 19.6ms\tremaining: 19.6ms\n",
      "4:\tlearn: 0.4655547\ttotal: 23.7ms\tremaining: 14.2ms\n",
      "5:\tlearn: 0.4641129\ttotal: 27.7ms\tremaining: 9.24ms\n",
      "6:\tlearn: 0.4622549\ttotal: 31.8ms\tremaining: 4.54ms\n",
      "7:\tlearn: 0.4607061\ttotal: 35.8ms\tremaining: 0us\n",
      "[8, 0.55, 6, 0.2]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.87ms\tremaining: 34.1ms\n",
      "1:\tlearn: 0.4730186\ttotal: 8.91ms\tremaining: 26.7ms\n",
      "2:\tlearn: 0.4702860\ttotal: 13ms\tremaining: 21.7ms\n",
      "3:\tlearn: 0.4675422\ttotal: 17.1ms\tremaining: 17.1ms\n",
      "4:\tlearn: 0.4655547\ttotal: 21.2ms\tremaining: 12.7ms\n",
      "5:\tlearn: 0.4641129\ttotal: 25.4ms\tremaining: 8.48ms\n",
      "6:\tlearn: 0.4622549\ttotal: 29.9ms\tremaining: 4.27ms\n",
      "7:\tlearn: 0.4607061\ttotal: 34.2ms\tremaining: 0us\n",
      "[8, 0.55, 15, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.2ms\tremaining: 85.3ms\n",
      "1:\tlearn: 0.4689110\ttotal: 482ms\tremaining: 1.45s\n",
      "2:\tlearn: 0.4640795\ttotal: 934ms\tremaining: 1.56s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.39s\tremaining: 1.39s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.85s\tremaining: 1.11s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.31s\tremaining: 770ms\n",
      "6:\tlearn: 0.4530263\ttotal: 2.77s\tremaining: 396ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.23s\tremaining: 0us\n",
      "[8, 0.55, 15, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.1ms\tremaining: 63.7ms\n",
      "1:\tlearn: 0.4689110\ttotal: 535ms\tremaining: 1.6s\n",
      "2:\tlearn: 0.4640795\ttotal: 1.01s\tremaining: 1.69s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.52s\tremaining: 1.52s\n",
      "4:\tlearn: 0.4573812\ttotal: 2s\tremaining: 1.2s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.49s\tremaining: 831ms\n",
      "6:\tlearn: 0.4530263\ttotal: 2.99s\tremaining: 427ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.47s\tremaining: 0us\n",
      "[8, 0.55, 15, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 14.4ms\tremaining: 101ms\n",
      "1:\tlearn: 0.4689110\ttotal: 651ms\tremaining: 1.95s\n",
      "2:\tlearn: 0.4640795\ttotal: 1.19s\tremaining: 1.98s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.68s\tremaining: 1.68s\n",
      "4:\tlearn: 0.4573812\ttotal: 2.2s\tremaining: 1.32s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.69s\tremaining: 895ms\n",
      "6:\tlearn: 0.4530263\ttotal: 3.19s\tremaining: 455ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.67s\tremaining: 0us\n",
      "[8, 0.55, 15, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.3ms\tremaining: 86.3ms\n",
      "1:\tlearn: 0.4689110\ttotal: 562ms\tremaining: 1.69s\n",
      "2:\tlearn: 0.4640795\ttotal: 1.1s\tremaining: 1.84s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.61s\tremaining: 1.61s\n",
      "4:\tlearn: 0.4573812\ttotal: 2.1s\tremaining: 1.26s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.58s\tremaining: 860ms\n",
      "6:\tlearn: 0.4530263\ttotal: 3.07s\tremaining: 438ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.59s\tremaining: 0us\n",
      "[8, 0.55, 15, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.5ms\tremaining: 73.5ms\n",
      "1:\tlearn: 0.4689110\ttotal: 516ms\tremaining: 1.55s\n",
      "2:\tlearn: 0.4640795\ttotal: 977ms\tremaining: 1.63s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.48s\tremaining: 1.48s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.99s\tremaining: 1.19s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.47s\tremaining: 824ms\n",
      "6:\tlearn: 0.4530263\ttotal: 2.96s\tremaining: 422ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.44s\tremaining: 0us\n",
      "[8, 0.55, 10, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.5ms\tremaining: 73.7ms\n",
      "1:\tlearn: 0.4715198\ttotal: 26.8ms\tremaining: 80.3ms\n",
      "2:\tlearn: 0.4676485\ttotal: 43.8ms\tremaining: 73ms\n",
      "3:\tlearn: 0.4663151\ttotal: 47ms\tremaining: 47ms\n",
      "4:\tlearn: 0.4641480\ttotal: 64.5ms\tremaining: 38.7ms\n",
      "5:\tlearn: 0.4609741\ttotal: 79.6ms\tremaining: 26.5ms\n",
      "6:\tlearn: 0.4590071\ttotal: 94.5ms\tremaining: 13.5ms\n",
      "7:\tlearn: 0.4568040\ttotal: 110ms\tremaining: 0us\n",
      "[8, 0.55, 10, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.97ms\tremaining: 69.8ms\n",
      "1:\tlearn: 0.4715198\ttotal: 25.5ms\tremaining: 76.4ms\n",
      "2:\tlearn: 0.4676485\ttotal: 43.1ms\tremaining: 71.8ms\n",
      "3:\tlearn: 0.4663151\ttotal: 46ms\tremaining: 46ms\n",
      "4:\tlearn: 0.4641480\ttotal: 61.9ms\tremaining: 37.1ms\n",
      "5:\tlearn: 0.4609741\ttotal: 108ms\tremaining: 35.9ms\n",
      "6:\tlearn: 0.4590071\ttotal: 130ms\tremaining: 18.5ms\n",
      "7:\tlearn: 0.4568040\ttotal: 147ms\tremaining: 0us\n",
      "[8, 0.55, 10, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.51ms\tremaining: 66.6ms\n",
      "1:\tlearn: 0.4715198\ttotal: 25.6ms\tremaining: 76.7ms\n",
      "2:\tlearn: 0.4676485\ttotal: 44.7ms\tremaining: 74.4ms\n",
      "3:\tlearn: 0.4663151\ttotal: 47.7ms\tremaining: 47.7ms\n",
      "4:\tlearn: 0.4641480\ttotal: 63.6ms\tremaining: 38.1ms\n",
      "5:\tlearn: 0.4609741\ttotal: 84.6ms\tremaining: 28.2ms\n",
      "6:\tlearn: 0.4590071\ttotal: 101ms\tremaining: 14.5ms\n",
      "7:\tlearn: 0.4568040\ttotal: 146ms\tremaining: 0us\n",
      "[8, 0.55, 10, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.6ms\tremaining: 74.2ms\n",
      "1:\tlearn: 0.4715198\ttotal: 26ms\tremaining: 77.9ms\n",
      "2:\tlearn: 0.4676485\ttotal: 41.4ms\tremaining: 69ms\n",
      "3:\tlearn: 0.4663151\ttotal: 44.3ms\tremaining: 44.3ms\n",
      "4:\tlearn: 0.4641480\ttotal: 60.1ms\tremaining: 36.1ms\n",
      "5:\tlearn: 0.4609741\ttotal: 76.5ms\tremaining: 25.5ms\n",
      "6:\tlearn: 0.4590071\ttotal: 91.6ms\tremaining: 13.1ms\n",
      "7:\tlearn: 0.4568040\ttotal: 107ms\tremaining: 0us\n",
      "[8, 0.55, 10, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 13.1ms\tremaining: 91.7ms\n",
      "1:\tlearn: 0.4715198\ttotal: 31.8ms\tremaining: 95.5ms\n",
      "2:\tlearn: 0.4676485\ttotal: 50.8ms\tremaining: 84.6ms\n",
      "3:\tlearn: 0.4663151\ttotal: 54.7ms\tremaining: 54.7ms\n",
      "4:\tlearn: 0.4641480\ttotal: 72.4ms\tremaining: 43.5ms\n",
      "5:\tlearn: 0.4609741\ttotal: 88.8ms\tremaining: 29.6ms\n",
      "6:\tlearn: 0.4590071\ttotal: 104ms\tremaining: 14.9ms\n",
      "7:\tlearn: 0.4568040\ttotal: 120ms\tremaining: 0us\n",
      "[8, 0.55, 12, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 16.1ms\tremaining: 112ms\n",
      "1:\tlearn: 0.4704514\ttotal: 86.6ms\tremaining: 260ms\n",
      "2:\tlearn: 0.4668875\ttotal: 149ms\tremaining: 249ms\n",
      "3:\tlearn: 0.4641234\ttotal: 213ms\tremaining: 213ms\n",
      "4:\tlearn: 0.4616543\ttotal: 271ms\tremaining: 162ms\n",
      "5:\tlearn: 0.4587449\ttotal: 333ms\tremaining: 111ms\n",
      "6:\tlearn: 0.4567311\ttotal: 395ms\tremaining: 56.4ms\n",
      "7:\tlearn: 0.4540933\ttotal: 500ms\tremaining: 0us\n",
      "[8, 0.55, 12, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.64ms\tremaining: 60.5ms\n",
      "1:\tlearn: 0.4704514\ttotal: 67.8ms\tremaining: 203ms\n",
      "2:\tlearn: 0.4668875\ttotal: 160ms\tremaining: 266ms\n",
      "3:\tlearn: 0.4641234\ttotal: 230ms\tremaining: 230ms\n",
      "4:\tlearn: 0.4616543\ttotal: 303ms\tremaining: 182ms\n",
      "5:\tlearn: 0.4587449\ttotal: 360ms\tremaining: 120ms\n",
      "6:\tlearn: 0.4567311\ttotal: 421ms\tremaining: 60.1ms\n",
      "7:\tlearn: 0.4540933\ttotal: 480ms\tremaining: 0us\n",
      "[8, 0.55, 12, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.14ms\tremaining: 64ms\n",
      "1:\tlearn: 0.4704514\ttotal: 67.6ms\tremaining: 203ms\n",
      "2:\tlearn: 0.4668875\ttotal: 122ms\tremaining: 203ms\n",
      "3:\tlearn: 0.4641234\ttotal: 182ms\tremaining: 182ms\n",
      "4:\tlearn: 0.4616543\ttotal: 282ms\tremaining: 169ms\n",
      "5:\tlearn: 0.4587449\ttotal: 352ms\tremaining: 117ms\n",
      "6:\tlearn: 0.4567311\ttotal: 411ms\tremaining: 58.8ms\n",
      "7:\tlearn: 0.4540933\ttotal: 468ms\tremaining: 0us\n",
      "[8, 0.55, 12, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 24.3ms\tremaining: 170ms\n",
      "1:\tlearn: 0.4704514\ttotal: 105ms\tremaining: 315ms\n",
      "2:\tlearn: 0.4668875\ttotal: 171ms\tremaining: 285ms\n",
      "3:\tlearn: 0.4641234\ttotal: 230ms\tremaining: 230ms\n",
      "4:\tlearn: 0.4616543\ttotal: 292ms\tremaining: 175ms\n",
      "5:\tlearn: 0.4587449\ttotal: 353ms\tremaining: 118ms\n",
      "6:\tlearn: 0.4567311\ttotal: 448ms\tremaining: 64ms\n",
      "7:\tlearn: 0.4540933\ttotal: 515ms\tremaining: 0us\n",
      "[8, 0.55, 12, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.2ms\tremaining: 64.4ms\n",
      "1:\tlearn: 0.4704514\ttotal: 65ms\tremaining: 195ms\n",
      "2:\tlearn: 0.4668875\ttotal: 126ms\tremaining: 210ms\n",
      "3:\tlearn: 0.4641234\ttotal: 221ms\tremaining: 221ms\n",
      "4:\tlearn: 0.4616543\ttotal: 299ms\tremaining: 179ms\n",
      "5:\tlearn: 0.4587449\ttotal: 359ms\tremaining: 120ms\n",
      "6:\tlearn: 0.4567311\ttotal: 417ms\tremaining: 59.5ms\n",
      "7:\tlearn: 0.4540933\ttotal: 477ms\tremaining: 0us\n",
      "[8, 0.55, 13, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 15ms\tremaining: 105ms\n",
      "1:\tlearn: 0.4700386\ttotal: 138ms\tremaining: 414ms\n",
      "2:\tlearn: 0.4651124\ttotal: 252ms\tremaining: 420ms\n",
      "3:\tlearn: 0.4623159\ttotal: 367ms\tremaining: 367ms\n",
      "4:\tlearn: 0.4590456\ttotal: 458ms\tremaining: 275ms\n",
      "5:\tlearn: 0.4565869\ttotal: 602ms\tremaining: 201ms\n",
      "6:\tlearn: 0.4540567\ttotal: 735ms\tremaining: 105ms\n",
      "7:\tlearn: 0.4522890\ttotal: 857ms\tremaining: 0us\n",
      "[8, 0.55, 13, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.84ms\tremaining: 68.9ms\n",
      "1:\tlearn: 0.4700386\ttotal: 128ms\tremaining: 383ms\n",
      "2:\tlearn: 0.4651124\ttotal: 248ms\tremaining: 414ms\n",
      "3:\tlearn: 0.4623159\ttotal: 402ms\tremaining: 402ms\n",
      "4:\tlearn: 0.4590456\ttotal: 470ms\tremaining: 282ms\n",
      "5:\tlearn: 0.4565869\ttotal: 588ms\tremaining: 196ms\n",
      "6:\tlearn: 0.4540567\ttotal: 702ms\tremaining: 100ms\n",
      "7:\tlearn: 0.4522890\ttotal: 859ms\tremaining: 0us\n",
      "[8, 0.55, 13, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.7ms\tremaining: 74.9ms\n",
      "1:\tlearn: 0.4700386\ttotal: 116ms\tremaining: 348ms\n",
      "2:\tlearn: 0.4651124\ttotal: 240ms\tremaining: 400ms\n",
      "3:\tlearn: 0.4623159\ttotal: 388ms\tremaining: 388ms\n",
      "4:\tlearn: 0.4590456\ttotal: 447ms\tremaining: 268ms\n",
      "5:\tlearn: 0.4565869\ttotal: 558ms\tremaining: 186ms\n",
      "6:\tlearn: 0.4540567\ttotal: 679ms\tremaining: 97ms\n",
      "7:\tlearn: 0.4522890\ttotal: 840ms\tremaining: 0us\n",
      "[8, 0.55, 13, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 11.3ms\tremaining: 79.5ms\n",
      "1:\tlearn: 0.4700386\ttotal: 118ms\tremaining: 355ms\n",
      "2:\tlearn: 0.4651124\ttotal: 273ms\tremaining: 456ms\n",
      "3:\tlearn: 0.4623159\ttotal: 405ms\tremaining: 405ms\n",
      "4:\tlearn: 0.4590456\ttotal: 465ms\tremaining: 279ms\n",
      "5:\tlearn: 0.4565869\ttotal: 579ms\tremaining: 193ms\n",
      "6:\tlearn: 0.4540567\ttotal: 692ms\tremaining: 98.8ms\n",
      "7:\tlearn: 0.4522890\ttotal: 834ms\tremaining: 0us\n",
      "[8, 0.55, 13, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.42ms\tremaining: 65.9ms\n",
      "1:\tlearn: 0.4700386\ttotal: 122ms\tremaining: 366ms\n",
      "2:\tlearn: 0.4651124\ttotal: 272ms\tremaining: 454ms\n",
      "3:\tlearn: 0.4623159\ttotal: 396ms\tremaining: 396ms\n",
      "4:\tlearn: 0.4590456\ttotal: 457ms\tremaining: 274ms\n",
      "5:\tlearn: 0.4565869\ttotal: 569ms\tremaining: 190ms\n",
      "6:\tlearn: 0.4540567\ttotal: 687ms\tremaining: 98.1ms\n",
      "7:\tlearn: 0.4522890\ttotal: 827ms\tremaining: 0us\n",
      "[8, 0.55, 14, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.64ms\tremaining: 67.5ms\n",
      "1:\tlearn: 0.4695164\ttotal: 254ms\tremaining: 761ms\n",
      "2:\tlearn: 0.4654149\ttotal: 540ms\tremaining: 901ms\n",
      "3:\tlearn: 0.4619585\ttotal: 774ms\tremaining: 774ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.05s\tremaining: 630ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.07s\tremaining: 356ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.07s\tremaining: 153ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.29s\tremaining: 0us\n",
      "[8, 0.55, 14, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.9ms\tremaining: 90.1ms\n",
      "1:\tlearn: 0.4695164\ttotal: 269ms\tremaining: 806ms\n",
      "2:\tlearn: 0.4654149\ttotal: 534ms\tremaining: 890ms\n",
      "3:\tlearn: 0.4619585\ttotal: 770ms\tremaining: 770ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.04s\tremaining: 623ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.05s\tremaining: 352ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.06s\tremaining: 151ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.28s\tremaining: 0us\n",
      "[8, 0.55, 14, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 14.9ms\tremaining: 104ms\n",
      "1:\tlearn: 0.4695164\ttotal: 242ms\tremaining: 727ms\n",
      "2:\tlearn: 0.4654149\ttotal: 540ms\tremaining: 900ms\n",
      "3:\tlearn: 0.4619585\ttotal: 757ms\tremaining: 757ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.05s\tremaining: 629ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.07s\tremaining: 356ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.07s\tremaining: 153ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.31s\tremaining: 0us\n",
      "[8, 0.55, 14, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 15ms\tremaining: 105ms\n",
      "1:\tlearn: 0.4695164\ttotal: 243ms\tremaining: 729ms\n",
      "2:\tlearn: 0.4654149\ttotal: 530ms\tremaining: 884ms\n",
      "3:\tlearn: 0.4619585\ttotal: 755ms\tremaining: 755ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.03s\tremaining: 619ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.05s\tremaining: 349ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.05s\tremaining: 150ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.27s\tremaining: 0us\n",
      "[8, 0.55, 14, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 13.2ms\tremaining: 92.6ms\n",
      "1:\tlearn: 0.4695164\ttotal: 247ms\tremaining: 741ms\n",
      "2:\tlearn: 0.4654149\ttotal: 491ms\tremaining: 819ms\n",
      "3:\tlearn: 0.4619585\ttotal: 727ms\tremaining: 727ms\n",
      "4:\tlearn: 0.4580701\ttotal: 988ms\tremaining: 593ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.01s\tremaining: 336ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.01s\tremaining: 145ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.25s\tremaining: 0us\n",
      "[8, 0.42, 6, -0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 5.22ms\tremaining: 36.5ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.53ms\tremaining: 28.6ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13.8ms\tremaining: 22.9ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17.9ms\tremaining: 17.9ms\n",
      "4:\tlearn: 0.4690547\ttotal: 22.4ms\tremaining: 13.4ms\n",
      "5:\tlearn: 0.4668601\ttotal: 28.6ms\tremaining: 9.54ms\n",
      "6:\tlearn: 0.4648543\ttotal: 33.2ms\tremaining: 4.75ms\n",
      "7:\tlearn: 0.4633314\ttotal: 37.6ms\tremaining: 0us\n",
      "[8, 0.42, 6, 0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.73ms\tremaining: 33.1ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.56ms\tremaining: 28.7ms\n",
      "2:\tlearn: 0.4730150\ttotal: 14.6ms\tremaining: 24.4ms\n",
      "3:\tlearn: 0.4709457\ttotal: 19.1ms\tremaining: 19.1ms\n",
      "4:\tlearn: 0.4690547\ttotal: 24.4ms\tremaining: 14.6ms\n",
      "5:\tlearn: 0.4668601\ttotal: 28.5ms\tremaining: 9.51ms\n",
      "6:\tlearn: 0.4648543\ttotal: 33.2ms\tremaining: 4.74ms\n",
      "7:\tlearn: 0.4633314\ttotal: 37.9ms\tremaining: 0us\n",
      "[8, 0.42, 6, 0.0]\n",
      "0:\tlearn: 0.4822549\ttotal: 6.37ms\tremaining: 44.6ms\n",
      "1:\tlearn: 0.4764006\ttotal: 11.1ms\tremaining: 33.2ms\n",
      "2:\tlearn: 0.4730150\ttotal: 15.7ms\tremaining: 26.2ms\n",
      "3:\tlearn: 0.4709457\ttotal: 20.2ms\tremaining: 20.2ms\n",
      "4:\tlearn: 0.4690547\ttotal: 24.8ms\tremaining: 14.9ms\n",
      "5:\tlearn: 0.4668601\ttotal: 29.2ms\tremaining: 9.75ms\n",
      "6:\tlearn: 0.4648543\ttotal: 33.7ms\tremaining: 4.81ms\n",
      "7:\tlearn: 0.4633314\ttotal: 38ms\tremaining: 0us\n",
      "[8, 0.42, 6, 0.15]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.21ms\tremaining: 29.5ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.44ms\tremaining: 25.3ms\n",
      "2:\tlearn: 0.4730150\ttotal: 12.9ms\tremaining: 21.4ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17.2ms\tremaining: 17.2ms\n",
      "4:\tlearn: 0.4690547\ttotal: 21.4ms\tremaining: 12.9ms\n",
      "5:\tlearn: 0.4668601\ttotal: 25.5ms\tremaining: 8.5ms\n",
      "6:\tlearn: 0.4648543\ttotal: 30.1ms\tremaining: 4.3ms\n",
      "7:\tlearn: 0.4633314\ttotal: 34.6ms\tremaining: 0us\n",
      "[8, 0.42, 6, 0.2]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.3ms\tremaining: 30.1ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.49ms\tremaining: 25.5ms\n",
      "2:\tlearn: 0.4730150\ttotal: 12.8ms\tremaining: 21.3ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17ms\tremaining: 17ms\n",
      "4:\tlearn: 0.4690547\ttotal: 21.4ms\tremaining: 12.8ms\n",
      "5:\tlearn: 0.4668601\ttotal: 25.6ms\tremaining: 8.54ms\n",
      "6:\tlearn: 0.4648543\ttotal: 30ms\tremaining: 4.28ms\n",
      "7:\tlearn: 0.4633314\ttotal: 34ms\tremaining: 0us\n",
      "[8, 0.42, 15, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.71ms\tremaining: 68ms\n",
      "1:\tlearn: 0.4725597\ttotal: 502ms\tremaining: 1.51s\n",
      "2:\tlearn: 0.4670568\ttotal: 983ms\tremaining: 1.64s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.47s\tremaining: 1.47s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.96s\tremaining: 1.17s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.41s\tremaining: 804ms\n",
      "6:\tlearn: 0.4558816\ttotal: 2.88s\tremaining: 411ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.35s\tremaining: 0us\n",
      "[8, 0.42, 15, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.83ms\tremaining: 68.8ms\n",
      "1:\tlearn: 0.4725597\ttotal: 503ms\tremaining: 1.51s\n",
      "2:\tlearn: 0.4670568\ttotal: 950ms\tremaining: 1.58s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.43s\tremaining: 1.43s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.9s\tremaining: 1.14s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.39s\tremaining: 797ms\n",
      "6:\tlearn: 0.4558816\ttotal: 2.88s\tremaining: 411ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.35s\tremaining: 0us\n",
      "[8, 0.42, 15, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 11ms\tremaining: 77ms\n",
      "1:\tlearn: 0.4725597\ttotal: 531ms\tremaining: 1.59s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.01s\tremaining: 1.68s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.49s\tremaining: 1.49s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.97s\tremaining: 1.18s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.46s\tremaining: 819ms\n",
      "6:\tlearn: 0.4558816\ttotal: 2.96s\tremaining: 423ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.46s\tremaining: 0us\n",
      "[8, 0.42, 15, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.2ms\tremaining: 71.5ms\n",
      "1:\tlearn: 0.4725597\ttotal: 521ms\tremaining: 1.56s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.01s\tremaining: 1.69s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.49s\tremaining: 1.49s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.99s\tremaining: 1.19s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.48s\tremaining: 827ms\n",
      "6:\tlearn: 0.4558816\ttotal: 2.97s\tremaining: 424ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.45s\tremaining: 0us\n",
      "[8, 0.42, 15, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.6ms\tremaining: 74.1ms\n",
      "1:\tlearn: 0.4725597\ttotal: 537ms\tremaining: 1.61s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.04s\tremaining: 1.74s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.52s\tremaining: 1.52s\n",
      "4:\tlearn: 0.4605353\ttotal: 2.02s\tremaining: 1.22s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.51s\tremaining: 836ms\n",
      "6:\tlearn: 0.4558816\ttotal: 3s\tremaining: 428ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.49s\tremaining: 0us\n",
      "[8, 0.42, 10, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.59ms\tremaining: 67.2ms\n",
      "1:\tlearn: 0.4747524\ttotal: 25ms\tremaining: 74.9ms\n",
      "2:\tlearn: 0.4704503\ttotal: 40ms\tremaining: 66.7ms\n",
      "3:\tlearn: 0.4672210\ttotal: 57.1ms\tremaining: 57.1ms\n",
      "4:\tlearn: 0.4648993\ttotal: 71.8ms\tremaining: 43.1ms\n",
      "5:\tlearn: 0.4625834\ttotal: 88.1ms\tremaining: 29.4ms\n",
      "6:\tlearn: 0.4610401\ttotal: 103ms\tremaining: 14.8ms\n",
      "7:\tlearn: 0.4600427\ttotal: 108ms\tremaining: 0us\n",
      "[8, 0.42, 10, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.95ms\tremaining: 69.7ms\n",
      "1:\tlearn: 0.4747524\ttotal: 26.2ms\tremaining: 78.6ms\n",
      "2:\tlearn: 0.4704503\ttotal: 40ms\tremaining: 66.7ms\n",
      "3:\tlearn: 0.4672210\ttotal: 54.4ms\tremaining: 54.4ms\n",
      "4:\tlearn: 0.4648993\ttotal: 70.2ms\tremaining: 42.1ms\n",
      "5:\tlearn: 0.4625834\ttotal: 85.4ms\tremaining: 28.5ms\n",
      "6:\tlearn: 0.4610401\ttotal: 106ms\tremaining: 15.2ms\n",
      "7:\tlearn: 0.4600427\ttotal: 112ms\tremaining: 0us\n",
      "[8, 0.42, 10, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.72ms\tremaining: 68.1ms\n",
      "1:\tlearn: 0.4747524\ttotal: 28ms\tremaining: 83.9ms\n",
      "2:\tlearn: 0.4704503\ttotal: 45ms\tremaining: 75ms\n",
      "3:\tlearn: 0.4672210\ttotal: 60.8ms\tremaining: 60.8ms\n",
      "4:\tlearn: 0.4648993\ttotal: 76.8ms\tremaining: 46.1ms\n",
      "5:\tlearn: 0.4625834\ttotal: 92.6ms\tremaining: 30.9ms\n",
      "6:\tlearn: 0.4610401\ttotal: 108ms\tremaining: 15.5ms\n",
      "7:\tlearn: 0.4600427\ttotal: 113ms\tremaining: 0us\n",
      "[8, 0.42, 10, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 15.9ms\tremaining: 111ms\n",
      "1:\tlearn: 0.4747524\ttotal: 59ms\tremaining: 177ms\n",
      "2:\tlearn: 0.4704503\ttotal: 76.8ms\tremaining: 128ms\n",
      "3:\tlearn: 0.4672210\ttotal: 94.8ms\tremaining: 94.8ms\n",
      "4:\tlearn: 0.4648993\ttotal: 112ms\tremaining: 66.9ms\n",
      "5:\tlearn: 0.4625834\ttotal: 128ms\tremaining: 42.6ms\n",
      "6:\tlearn: 0.4610401\ttotal: 144ms\tremaining: 20.6ms\n",
      "7:\tlearn: 0.4600427\ttotal: 150ms\tremaining: 0us\n",
      "[8, 0.42, 10, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.8ms\tremaining: 83ms\n",
      "1:\tlearn: 0.4747524\ttotal: 27.7ms\tremaining: 83ms\n",
      "2:\tlearn: 0.4704503\ttotal: 45.3ms\tremaining: 75.5ms\n",
      "3:\tlearn: 0.4672210\ttotal: 61.7ms\tremaining: 61.7ms\n",
      "4:\tlearn: 0.4648993\ttotal: 91.8ms\tremaining: 55.1ms\n",
      "5:\tlearn: 0.4625834\ttotal: 115ms\tremaining: 38.5ms\n",
      "6:\tlearn: 0.4610401\ttotal: 147ms\tremaining: 21ms\n",
      "7:\tlearn: 0.4600427\ttotal: 154ms\tremaining: 0us\n",
      "[8, 0.42, 12, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.3ms\tremaining: 72.2ms\n",
      "1:\tlearn: 0.4738094\ttotal: 64.8ms\tremaining: 194ms\n",
      "2:\tlearn: 0.4686075\ttotal: 119ms\tremaining: 199ms\n",
      "3:\tlearn: 0.4656476\ttotal: 175ms\tremaining: 175ms\n",
      "4:\tlearn: 0.4634402\ttotal: 276ms\tremaining: 166ms\n",
      "5:\tlearn: 0.4611150\ttotal: 343ms\tremaining: 114ms\n",
      "6:\tlearn: 0.4588698\ttotal: 405ms\tremaining: 57.9ms\n",
      "7:\tlearn: 0.4569792\ttotal: 466ms\tremaining: 0us\n",
      "[8, 0.42, 12, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 13.5ms\tremaining: 94.5ms\n",
      "1:\tlearn: 0.4738094\ttotal: 84.3ms\tremaining: 253ms\n",
      "2:\tlearn: 0.4686075\ttotal: 150ms\tremaining: 250ms\n",
      "3:\tlearn: 0.4656476\ttotal: 212ms\tremaining: 212ms\n",
      "4:\tlearn: 0.4634402\ttotal: 269ms\tremaining: 162ms\n",
      "5:\tlearn: 0.4611150\ttotal: 329ms\tremaining: 110ms\n",
      "6:\tlearn: 0.4588698\ttotal: 411ms\tremaining: 58.7ms\n",
      "7:\tlearn: 0.4569792\ttotal: 478ms\tremaining: 0us\n",
      "[8, 0.42, 12, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.79ms\tremaining: 68.5ms\n",
      "1:\tlearn: 0.4738094\ttotal: 68ms\tremaining: 204ms\n",
      "2:\tlearn: 0.4686075\ttotal: 128ms\tremaining: 214ms\n",
      "3:\tlearn: 0.4656476\ttotal: 223ms\tremaining: 223ms\n",
      "4:\tlearn: 0.4634402\ttotal: 287ms\tremaining: 172ms\n",
      "5:\tlearn: 0.4611150\ttotal: 347ms\tremaining: 116ms\n",
      "6:\tlearn: 0.4588698\ttotal: 404ms\tremaining: 57.7ms\n",
      "7:\tlearn: 0.4569792\ttotal: 465ms\tremaining: 0us\n",
      "[8, 0.42, 12, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.01ms\tremaining: 63.1ms\n",
      "1:\tlearn: 0.4738094\ttotal: 63.5ms\tremaining: 190ms\n",
      "2:\tlearn: 0.4686075\ttotal: 122ms\tremaining: 204ms\n",
      "3:\tlearn: 0.4656476\ttotal: 181ms\tremaining: 181ms\n",
      "4:\tlearn: 0.4634402\ttotal: 253ms\tremaining: 152ms\n",
      "5:\tlearn: 0.4611150\ttotal: 331ms\tremaining: 110ms\n",
      "6:\tlearn: 0.4588698\ttotal: 397ms\tremaining: 56.7ms\n",
      "7:\tlearn: 0.4569792\ttotal: 459ms\tremaining: 0us\n",
      "[8, 0.42, 12, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 17.2ms\tremaining: 120ms\n",
      "1:\tlearn: 0.4738094\ttotal: 84.2ms\tremaining: 253ms\n",
      "2:\tlearn: 0.4686075\ttotal: 145ms\tremaining: 242ms\n",
      "3:\tlearn: 0.4656476\ttotal: 206ms\tremaining: 206ms\n",
      "4:\tlearn: 0.4634402\ttotal: 263ms\tremaining: 158ms\n",
      "5:\tlearn: 0.4611150\ttotal: 330ms\tremaining: 110ms\n",
      "6:\tlearn: 0.4588698\ttotal: 395ms\tremaining: 56.5ms\n",
      "7:\tlearn: 0.4569792\ttotal: 475ms\tremaining: 0us\n",
      "[8, 0.42, 13, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 15.4ms\tremaining: 108ms\n",
      "1:\tlearn: 0.4734661\ttotal: 150ms\tremaining: 450ms\n",
      "2:\tlearn: 0.4690787\ttotal: 263ms\tremaining: 439ms\n",
      "3:\tlearn: 0.4660511\ttotal: 376ms\tremaining: 376ms\n",
      "4:\tlearn: 0.4628433\ttotal: 436ms\tremaining: 261ms\n",
      "5:\tlearn: 0.4605878\ttotal: 595ms\tremaining: 198ms\n",
      "6:\tlearn: 0.4583652\ttotal: 718ms\tremaining: 103ms\n",
      "7:\tlearn: 0.4568128\ttotal: 828ms\tremaining: 0us\n",
      "[8, 0.42, 13, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 13ms\tremaining: 91ms\n",
      "1:\tlearn: 0.4734661\ttotal: 136ms\tremaining: 408ms\n",
      "2:\tlearn: 0.4690787\ttotal: 245ms\tremaining: 408ms\n",
      "3:\tlearn: 0.4660511\ttotal: 398ms\tremaining: 398ms\n",
      "4:\tlearn: 0.4628433\ttotal: 460ms\tremaining: 276ms\n",
      "5:\tlearn: 0.4605878\ttotal: 582ms\tremaining: 194ms\n",
      "6:\tlearn: 0.4583652\ttotal: 698ms\tremaining: 99.7ms\n",
      "7:\tlearn: 0.4568128\ttotal: 852ms\tremaining: 0us\n",
      "[8, 0.42, 13, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.4ms\tremaining: 65.8ms\n",
      "1:\tlearn: 0.4734661\ttotal: 121ms\tremaining: 363ms\n",
      "2:\tlearn: 0.4690787\ttotal: 270ms\tremaining: 450ms\n",
      "3:\tlearn: 0.4660511\ttotal: 405ms\tremaining: 405ms\n",
      "4:\tlearn: 0.4628433\ttotal: 466ms\tremaining: 279ms\n",
      "5:\tlearn: 0.4605878\ttotal: 576ms\tremaining: 192ms\n",
      "6:\tlearn: 0.4583652\ttotal: 686ms\tremaining: 98ms\n",
      "7:\tlearn: 0.4568128\ttotal: 868ms\tremaining: 0us\n",
      "[8, 0.42, 13, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.9ms\tremaining: 76.4ms\n",
      "1:\tlearn: 0.4734661\ttotal: 243ms\tremaining: 728ms\n",
      "2:\tlearn: 0.4690787\ttotal: 387ms\tremaining: 645ms\n",
      "3:\tlearn: 0.4660511\ttotal: 527ms\tremaining: 527ms\n",
      "4:\tlearn: 0.4628433\ttotal: 586ms\tremaining: 351ms\n",
      "5:\tlearn: 0.4605878\ttotal: 701ms\tremaining: 234ms\n",
      "6:\tlearn: 0.4583652\ttotal: 849ms\tremaining: 121ms\n",
      "7:\tlearn: 0.4568128\ttotal: 964ms\tremaining: 0us\n",
      "[8, 0.42, 13, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.7ms\tremaining: 88.8ms\n",
      "1:\tlearn: 0.4734661\ttotal: 136ms\tremaining: 409ms\n",
      "2:\tlearn: 0.4690787\ttotal: 250ms\tremaining: 417ms\n",
      "3:\tlearn: 0.4660511\ttotal: 402ms\tremaining: 402ms\n",
      "4:\tlearn: 0.4628433\ttotal: 488ms\tremaining: 293ms\n",
      "5:\tlearn: 0.4605878\ttotal: 605ms\tremaining: 202ms\n",
      "6:\tlearn: 0.4583652\ttotal: 751ms\tremaining: 107ms\n",
      "7:\tlearn: 0.4568128\ttotal: 883ms\tremaining: 0us\n",
      "[8, 0.48, 6, -0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 9.54ms\tremaining: 66.8ms\n",
      "1:\tlearn: 0.4742214\ttotal: 13.9ms\tremaining: 41.6ms\n",
      "2:\tlearn: 0.4707120\ttotal: 18ms\tremaining: 30ms\n",
      "3:\tlearn: 0.4683386\ttotal: 22.4ms\tremaining: 22.4ms\n",
      "4:\tlearn: 0.4663249\ttotal: 27.4ms\tremaining: 16.4ms\n",
      "5:\tlearn: 0.4646075\ttotal: 32.1ms\tremaining: 10.7ms\n",
      "6:\tlearn: 0.4624948\ttotal: 36.7ms\tremaining: 5.25ms\n",
      "7:\tlearn: 0.4613643\ttotal: 42.4ms\tremaining: 0us\n",
      "[8, 0.48, 6, 0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 10.8ms\tremaining: 75.8ms\n",
      "1:\tlearn: 0.4742214\ttotal: 16.2ms\tremaining: 48.5ms\n",
      "2:\tlearn: 0.4707120\ttotal: 22.4ms\tremaining: 37.3ms\n",
      "3:\tlearn: 0.4683386\ttotal: 28.3ms\tremaining: 28.3ms\n",
      "4:\tlearn: 0.4663249\ttotal: 32.8ms\tremaining: 19.7ms\n",
      "5:\tlearn: 0.4646075\ttotal: 37.3ms\tremaining: 12.4ms\n",
      "6:\tlearn: 0.4624948\ttotal: 42.5ms\tremaining: 6.08ms\n",
      "7:\tlearn: 0.4613643\ttotal: 46.9ms\tremaining: 0us\n",
      "[8, 0.48, 6, 0.0]\n",
      "0:\tlearn: 0.4809500\ttotal: 5.98ms\tremaining: 41.9ms\n",
      "1:\tlearn: 0.4742214\ttotal: 10ms\tremaining: 30ms\n",
      "2:\tlearn: 0.4707120\ttotal: 14.9ms\tremaining: 24.8ms\n",
      "3:\tlearn: 0.4683386\ttotal: 19.3ms\tremaining: 19.3ms\n",
      "4:\tlearn: 0.4663249\ttotal: 24.3ms\tremaining: 14.6ms\n",
      "5:\tlearn: 0.4646075\ttotal: 29.6ms\tremaining: 9.85ms\n",
      "6:\tlearn: 0.4624948\ttotal: 34.2ms\tremaining: 4.88ms\n",
      "7:\tlearn: 0.4613643\ttotal: 39ms\tremaining: 0us\n",
      "[8, 0.48, 6, 0.15]\n",
      "0:\tlearn: 0.4809500\ttotal: 4.07ms\tremaining: 28.5ms\n",
      "1:\tlearn: 0.4742214\ttotal: 8.51ms\tremaining: 25.5ms\n",
      "2:\tlearn: 0.4707120\ttotal: 12.7ms\tremaining: 21.1ms\n",
      "3:\tlearn: 0.4683386\ttotal: 16.9ms\tremaining: 16.9ms\n",
      "4:\tlearn: 0.4663249\ttotal: 21.3ms\tremaining: 12.8ms\n",
      "5:\tlearn: 0.4646075\ttotal: 25.5ms\tremaining: 8.51ms\n",
      "6:\tlearn: 0.4624948\ttotal: 30.3ms\tremaining: 4.33ms\n",
      "7:\tlearn: 0.4613643\ttotal: 41ms\tremaining: 0us\n",
      "[8, 0.48, 6, 0.2]\n",
      "0:\tlearn: 0.4809500\ttotal: 5.04ms\tremaining: 35.3ms\n",
      "1:\tlearn: 0.4742214\ttotal: 9.04ms\tremaining: 27.1ms\n",
      "2:\tlearn: 0.4707120\ttotal: 13.4ms\tremaining: 22.4ms\n",
      "3:\tlearn: 0.4683386\ttotal: 17.6ms\tremaining: 17.6ms\n",
      "4:\tlearn: 0.4663249\ttotal: 21.9ms\tremaining: 13.1ms\n",
      "5:\tlearn: 0.4646075\ttotal: 26.6ms\tremaining: 8.86ms\n",
      "6:\tlearn: 0.4624948\ttotal: 30.8ms\tremaining: 4.4ms\n",
      "7:\tlearn: 0.4613643\ttotal: 35.1ms\tremaining: 0us\n",
      "[8, 0.48, 15, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 14.4ms\tremaining: 101ms\n",
      "1:\tlearn: 0.4707499\ttotal: 508ms\tremaining: 1.52s\n",
      "2:\tlearn: 0.4660967\ttotal: 959ms\tremaining: 1.6s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.46s\tremaining: 1.46s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.99s\tremaining: 1.19s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.52s\tremaining: 840ms\n",
      "6:\tlearn: 0.4551015\ttotal: 3.06s\tremaining: 438ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.55s\tremaining: 0us\n",
      "[8, 0.48, 15, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.4ms\tremaining: 72.8ms\n",
      "1:\tlearn: 0.4707499\ttotal: 501ms\tremaining: 1.5s\n",
      "2:\tlearn: 0.4660967\ttotal: 978ms\tremaining: 1.63s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.48s\tremaining: 1.48s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.94s\tremaining: 1.16s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.39s\tremaining: 796ms\n",
      "6:\tlearn: 0.4551015\ttotal: 2.89s\tremaining: 413ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.38s\tremaining: 0us\n",
      "[8, 0.48, 15, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.4ms\tremaining: 73ms\n",
      "1:\tlearn: 0.4707499\ttotal: 482ms\tremaining: 1.44s\n",
      "2:\tlearn: 0.4660967\ttotal: 979ms\tremaining: 1.63s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.46s\tremaining: 1.46s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.94s\tremaining: 1.16s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.43s\tremaining: 811ms\n",
      "6:\tlearn: 0.4551015\ttotal: 2.94s\tremaining: 421ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.44s\tremaining: 0us\n",
      "[8, 0.48, 15, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 8.97ms\tremaining: 62.8ms\n",
      "1:\tlearn: 0.4707499\ttotal: 488ms\tremaining: 1.46s\n",
      "2:\tlearn: 0.4660967\ttotal: 943ms\tremaining: 1.57s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.43s\tremaining: 1.43s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.91s\tremaining: 1.15s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.37s\tremaining: 791ms\n",
      "6:\tlearn: 0.4551015\ttotal: 2.84s\tremaining: 405ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.31s\tremaining: 0us\n",
      "[8, 0.48, 15, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.76ms\tremaining: 68.3ms\n",
      "1:\tlearn: 0.4707499\ttotal: 461ms\tremaining: 1.38s\n",
      "2:\tlearn: 0.4660967\ttotal: 969ms\tremaining: 1.61s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.46s\tremaining: 1.46s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.94s\tremaining: 1.17s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.42s\tremaining: 805ms\n",
      "6:\tlearn: 0.4551015\ttotal: 2.88s\tremaining: 411ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.39s\tremaining: 0us\n",
      "[8, 0.48, 10, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11ms\tremaining: 77ms\n",
      "1:\tlearn: 0.4731642\ttotal: 26.9ms\tremaining: 80.6ms\n",
      "2:\tlearn: 0.4688840\ttotal: 43.9ms\tremaining: 73.1ms\n",
      "3:\tlearn: 0.4676760\ttotal: 47.2ms\tremaining: 47.2ms\n",
      "4:\tlearn: 0.4647814\ttotal: 64.9ms\tremaining: 38.9ms\n",
      "5:\tlearn: 0.4606717\ttotal: 81.6ms\tremaining: 27.2ms\n",
      "6:\tlearn: 0.4587144\ttotal: 99.6ms\tremaining: 14.2ms\n",
      "7:\tlearn: 0.4569157\ttotal: 118ms\tremaining: 0us\n",
      "[8, 0.48, 10, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.7ms\tremaining: 74.9ms\n",
      "1:\tlearn: 0.4731642\ttotal: 26.5ms\tremaining: 79.6ms\n",
      "2:\tlearn: 0.4688840\ttotal: 43.2ms\tremaining: 72ms\n",
      "3:\tlearn: 0.4676760\ttotal: 46.9ms\tremaining: 46.9ms\n",
      "4:\tlearn: 0.4647814\ttotal: 64.4ms\tremaining: 38.6ms\n",
      "5:\tlearn: 0.4606717\ttotal: 80.5ms\tremaining: 26.8ms\n",
      "6:\tlearn: 0.4587144\ttotal: 96.7ms\tremaining: 13.8ms\n",
      "7:\tlearn: 0.4569157\ttotal: 116ms\tremaining: 0us\n",
      "[8, 0.48, 10, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.4ms\tremaining: 79.7ms\n",
      "1:\tlearn: 0.4731642\ttotal: 28.4ms\tremaining: 85.1ms\n",
      "2:\tlearn: 0.4688840\ttotal: 44.9ms\tremaining: 74.9ms\n",
      "3:\tlearn: 0.4676760\ttotal: 47.7ms\tremaining: 47.7ms\n",
      "4:\tlearn: 0.4647814\ttotal: 63.5ms\tremaining: 38.1ms\n",
      "5:\tlearn: 0.4606717\ttotal: 79.5ms\tremaining: 26.5ms\n",
      "6:\tlearn: 0.4587144\ttotal: 95.6ms\tremaining: 13.7ms\n",
      "7:\tlearn: 0.4569157\ttotal: 112ms\tremaining: 0us\n",
      "[8, 0.48, 10, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.7ms\tremaining: 81.6ms\n",
      "1:\tlearn: 0.4731642\ttotal: 28.3ms\tremaining: 85ms\n",
      "2:\tlearn: 0.4688840\ttotal: 48.2ms\tremaining: 80.3ms\n",
      "3:\tlearn: 0.4676760\ttotal: 51.5ms\tremaining: 51.5ms\n",
      "4:\tlearn: 0.4647814\ttotal: 68ms\tremaining: 40.8ms\n",
      "5:\tlearn: 0.4606717\ttotal: 88.4ms\tremaining: 29.5ms\n",
      "6:\tlearn: 0.4587144\ttotal: 104ms\tremaining: 14.9ms\n",
      "7:\tlearn: 0.4569157\ttotal: 121ms\tremaining: 0us\n",
      "[8, 0.48, 10, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 13.7ms\tremaining: 95.8ms\n",
      "1:\tlearn: 0.4731642\ttotal: 28.5ms\tremaining: 85.5ms\n",
      "2:\tlearn: 0.4688840\ttotal: 44ms\tremaining: 73.3ms\n",
      "3:\tlearn: 0.4676760\ttotal: 47.3ms\tremaining: 47.3ms\n",
      "4:\tlearn: 0.4647814\ttotal: 62.3ms\tremaining: 37.4ms\n",
      "5:\tlearn: 0.4606717\ttotal: 77.6ms\tremaining: 25.9ms\n",
      "6:\tlearn: 0.4587144\ttotal: 93.4ms\tremaining: 13.3ms\n",
      "7:\tlearn: 0.4569157\ttotal: 110ms\tremaining: 0us\n",
      "[8, 0.48, 12, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.5ms\tremaining: 80.4ms\n",
      "1:\tlearn: 0.4721464\ttotal: 71.8ms\tremaining: 216ms\n",
      "2:\tlearn: 0.4684998\ttotal: 128ms\tremaining: 214ms\n",
      "3:\tlearn: 0.4647972\ttotal: 185ms\tremaining: 185ms\n",
      "4:\tlearn: 0.4625394\ttotal: 250ms\tremaining: 150ms\n",
      "5:\tlearn: 0.4603377\ttotal: 322ms\tremaining: 107ms\n",
      "6:\tlearn: 0.4585216\ttotal: 386ms\tremaining: 55.2ms\n",
      "7:\tlearn: 0.4563298\ttotal: 446ms\tremaining: 0us\n",
      "[8, 0.48, 12, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.18ms\tremaining: 64.3ms\n",
      "1:\tlearn: 0.4721464\ttotal: 65.6ms\tremaining: 197ms\n",
      "2:\tlearn: 0.4684998\ttotal: 126ms\tremaining: 210ms\n",
      "3:\tlearn: 0.4647972\ttotal: 181ms\tremaining: 181ms\n",
      "4:\tlearn: 0.4625394\ttotal: 243ms\tremaining: 146ms\n",
      "5:\tlearn: 0.4603377\ttotal: 302ms\tremaining: 101ms\n",
      "6:\tlearn: 0.4585216\ttotal: 365ms\tremaining: 52.2ms\n",
      "7:\tlearn: 0.4563298\ttotal: 425ms\tremaining: 0us\n",
      "[8, 0.48, 12, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.72ms\tremaining: 68ms\n",
      "1:\tlearn: 0.4721464\ttotal: 75.1ms\tremaining: 225ms\n",
      "2:\tlearn: 0.4684998\ttotal: 132ms\tremaining: 220ms\n",
      "3:\tlearn: 0.4647972\ttotal: 190ms\tremaining: 190ms\n",
      "4:\tlearn: 0.4625394\ttotal: 250ms\tremaining: 150ms\n",
      "5:\tlearn: 0.4603377\ttotal: 309ms\tremaining: 103ms\n",
      "6:\tlearn: 0.4585216\ttotal: 369ms\tremaining: 52.6ms\n",
      "7:\tlearn: 0.4563298\ttotal: 425ms\tremaining: 0us\n",
      "[8, 0.48, 12, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.6ms\tremaining: 73.9ms\n",
      "1:\tlearn: 0.4721464\ttotal: 77.7ms\tremaining: 233ms\n",
      "2:\tlearn: 0.4684998\ttotal: 136ms\tremaining: 227ms\n",
      "3:\tlearn: 0.4647972\ttotal: 193ms\tremaining: 193ms\n",
      "4:\tlearn: 0.4625394\ttotal: 250ms\tremaining: 150ms\n",
      "5:\tlearn: 0.4603377\ttotal: 307ms\tremaining: 102ms\n",
      "6:\tlearn: 0.4585216\ttotal: 364ms\tremaining: 52ms\n",
      "7:\tlearn: 0.4563298\ttotal: 420ms\tremaining: 0us\n",
      "[8, 0.48, 12, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.7ms\tremaining: 74.7ms\n",
      "1:\tlearn: 0.4721464\ttotal: 81.3ms\tremaining: 244ms\n",
      "2:\tlearn: 0.4684998\ttotal: 147ms\tremaining: 244ms\n",
      "3:\tlearn: 0.4647972\ttotal: 215ms\tremaining: 215ms\n",
      "4:\tlearn: 0.4625394\ttotal: 274ms\tremaining: 164ms\n",
      "5:\tlearn: 0.4603377\ttotal: 331ms\tremaining: 110ms\n",
      "6:\tlearn: 0.4585216\ttotal: 394ms\tremaining: 56.3ms\n",
      "7:\tlearn: 0.4563298\ttotal: 458ms\tremaining: 0us\n",
      "[8, 0.48, 13, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.3ms\tremaining: 79.3ms\n",
      "1:\tlearn: 0.4717672\ttotal: 139ms\tremaining: 416ms\n",
      "2:\tlearn: 0.4670679\ttotal: 263ms\tremaining: 439ms\n",
      "3:\tlearn: 0.4643183\ttotal: 387ms\tremaining: 387ms\n",
      "4:\tlearn: 0.4617346\ttotal: 449ms\tremaining: 269ms\n",
      "5:\tlearn: 0.4593271\ttotal: 570ms\tremaining: 190ms\n",
      "6:\tlearn: 0.4571615\ttotal: 685ms\tremaining: 97.9ms\n",
      "7:\tlearn: 0.4551873\ttotal: 808ms\tremaining: 0us\n",
      "[8, 0.48, 13, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.37ms\tremaining: 65.6ms\n",
      "1:\tlearn: 0.4717672\ttotal: 132ms\tremaining: 397ms\n",
      "2:\tlearn: 0.4670679\ttotal: 243ms\tremaining: 404ms\n",
      "3:\tlearn: 0.4643183\ttotal: 368ms\tremaining: 368ms\n",
      "4:\tlearn: 0.4617346\ttotal: 428ms\tremaining: 257ms\n",
      "5:\tlearn: 0.4593271\ttotal: 549ms\tremaining: 183ms\n",
      "6:\tlearn: 0.4571615\ttotal: 697ms\tremaining: 99.5ms\n",
      "7:\tlearn: 0.4551873\ttotal: 807ms\tremaining: 0us\n",
      "[8, 0.48, 13, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.4ms\tremaining: 73ms\n",
      "1:\tlearn: 0.4717672\ttotal: 137ms\tremaining: 410ms\n",
      "2:\tlearn: 0.4670679\ttotal: 256ms\tremaining: 427ms\n",
      "3:\tlearn: 0.4643183\ttotal: 375ms\tremaining: 375ms\n",
      "4:\tlearn: 0.4617346\ttotal: 444ms\tremaining: 266ms\n",
      "5:\tlearn: 0.4593271\ttotal: 563ms\tremaining: 188ms\n",
      "6:\tlearn: 0.4571615\ttotal: 689ms\tremaining: 98.4ms\n",
      "7:\tlearn: 0.4551873\ttotal: 825ms\tremaining: 0us\n",
      "[8, 0.48, 13, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.73ms\tremaining: 68.1ms\n",
      "1:\tlearn: 0.4717672\ttotal: 128ms\tremaining: 384ms\n",
      "2:\tlearn: 0.4670679\ttotal: 242ms\tremaining: 403ms\n",
      "3:\tlearn: 0.4643183\ttotal: 372ms\tremaining: 372ms\n",
      "4:\tlearn: 0.4617346\ttotal: 434ms\tremaining: 261ms\n",
      "5:\tlearn: 0.4593271\ttotal: 555ms\tremaining: 185ms\n",
      "6:\tlearn: 0.4571615\ttotal: 680ms\tremaining: 97.1ms\n",
      "7:\tlearn: 0.4551873\ttotal: 796ms\tremaining: 0us\n",
      "[8, 0.48, 13, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.01ms\tremaining: 63ms\n",
      "1:\tlearn: 0.4717672\ttotal: 126ms\tremaining: 377ms\n",
      "2:\tlearn: 0.4670679\ttotal: 247ms\tremaining: 411ms\n",
      "3:\tlearn: 0.4643183\ttotal: 380ms\tremaining: 380ms\n",
      "4:\tlearn: 0.4617346\ttotal: 440ms\tremaining: 264ms\n",
      "5:\tlearn: 0.4593271\ttotal: 554ms\tremaining: 185ms\n",
      "6:\tlearn: 0.4571615\ttotal: 677ms\tremaining: 96.7ms\n",
      "7:\tlearn: 0.4551873\ttotal: 793ms\tremaining: 0us\n",
      "[8, 0.51, 6, -0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.87ms\tremaining: 34.1ms\n",
      "1:\tlearn: 0.4736652\ttotal: 9.13ms\tremaining: 27.4ms\n",
      "2:\tlearn: 0.4703360\ttotal: 13.3ms\tremaining: 22.1ms\n",
      "3:\tlearn: 0.4678859\ttotal: 17.4ms\tremaining: 17.4ms\n",
      "4:\tlearn: 0.4662988\ttotal: 21.8ms\tremaining: 13.1ms\n",
      "5:\tlearn: 0.4640621\ttotal: 26ms\tremaining: 8.65ms\n",
      "6:\tlearn: 0.4617955\ttotal: 30ms\tremaining: 4.29ms\n",
      "7:\tlearn: 0.4601208\ttotal: 34.7ms\tremaining: 0us\n",
      "[8, 0.51, 6, 0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.94ms\tremaining: 34.6ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.97ms\tremaining: 26.9ms\n",
      "2:\tlearn: 0.4703360\ttotal: 12.9ms\tremaining: 21.4ms\n",
      "3:\tlearn: 0.4678859\ttotal: 18ms\tremaining: 18ms\n",
      "4:\tlearn: 0.4662988\ttotal: 22.2ms\tremaining: 13.3ms\n",
      "5:\tlearn: 0.4640621\ttotal: 26.5ms\tremaining: 8.82ms\n",
      "6:\tlearn: 0.4617955\ttotal: 30.5ms\tremaining: 4.36ms\n",
      "7:\tlearn: 0.4601208\ttotal: 34.7ms\tremaining: 0us\n",
      "[8, 0.51, 6, 0.0]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.77ms\tremaining: 33.4ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.9ms\tremaining: 26.7ms\n",
      "2:\tlearn: 0.4703360\ttotal: 13.1ms\tremaining: 21.9ms\n",
      "3:\tlearn: 0.4678859\ttotal: 17.3ms\tremaining: 17.3ms\n",
      "4:\tlearn: 0.4662988\ttotal: 21.3ms\tremaining: 12.8ms\n",
      "5:\tlearn: 0.4640621\ttotal: 25.7ms\tremaining: 8.57ms\n",
      "6:\tlearn: 0.4617955\ttotal: 29.8ms\tremaining: 4.26ms\n",
      "7:\tlearn: 0.4601208\ttotal: 33.8ms\tremaining: 0us\n",
      "[8, 0.51, 6, 0.15]\n",
      "0:\tlearn: 0.4803477\ttotal: 5.54ms\tremaining: 38.8ms\n",
      "1:\tlearn: 0.4736652\ttotal: 9.59ms\tremaining: 28.8ms\n",
      "2:\tlearn: 0.4703360\ttotal: 13.7ms\tremaining: 22.8ms\n",
      "3:\tlearn: 0.4678859\ttotal: 18.3ms\tremaining: 18.3ms\n",
      "4:\tlearn: 0.4662988\ttotal: 22.8ms\tremaining: 13.7ms\n",
      "5:\tlearn: 0.4640621\ttotal: 26.9ms\tremaining: 8.97ms\n",
      "6:\tlearn: 0.4617955\ttotal: 31.4ms\tremaining: 4.48ms\n",
      "7:\tlearn: 0.4601208\ttotal: 35.6ms\tremaining: 0us\n",
      "[8, 0.51, 6, 0.2]\n",
      "0:\tlearn: 0.4803477\ttotal: 9.29ms\tremaining: 65ms\n",
      "1:\tlearn: 0.4736652\ttotal: 13.4ms\tremaining: 40.3ms\n",
      "2:\tlearn: 0.4703360\ttotal: 17.7ms\tremaining: 29.6ms\n",
      "3:\tlearn: 0.4678859\ttotal: 22ms\tremaining: 22ms\n",
      "4:\tlearn: 0.4662988\ttotal: 26.3ms\tremaining: 15.8ms\n",
      "5:\tlearn: 0.4640621\ttotal: 30.6ms\tremaining: 10.2ms\n",
      "6:\tlearn: 0.4617955\ttotal: 35.1ms\tremaining: 5.02ms\n",
      "7:\tlearn: 0.4601208\ttotal: 39.9ms\tremaining: 0us\n",
      "[8, 0.51, 15, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.82ms\tremaining: 68.7ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.4ms\tremaining: 58.3ms\n",
      "2:\tlearn: 0.4682843\ttotal: 520ms\tremaining: 867ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1.01s\tremaining: 1.01s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.12s\tremaining: 674ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.63s\tremaining: 542ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.14s\tremaining: 306ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.61s\tremaining: 0us\n",
      "[8, 0.51, 15, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.6ms\tremaining: 74ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.3ms\tremaining: 58ms\n",
      "2:\tlearn: 0.4682843\ttotal: 498ms\tremaining: 831ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1s\tremaining: 1s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.12s\tremaining: 674ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.59s\tremaining: 531ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.04s\tremaining: 292ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.52s\tremaining: 0us\n",
      "[8, 0.51, 15, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 12.9ms\tremaining: 90ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.8ms\tremaining: 68.4ms\n",
      "2:\tlearn: 0.4682843\ttotal: 494ms\tremaining: 823ms\n",
      "3:\tlearn: 0.4637816\ttotal: 970ms\tremaining: 970ms\n",
      "4:\tlearn: 0.4613151\ttotal: 1.1s\tremaining: 658ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.58s\tremaining: 527ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.06s\tremaining: 294ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.52s\tremaining: 0us\n",
      "[8, 0.51, 15, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.29ms\tremaining: 65ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.2ms\tremaining: 54.5ms\n",
      "2:\tlearn: 0.4682843\ttotal: 510ms\tremaining: 850ms\n",
      "3:\tlearn: 0.4637816\ttotal: 999ms\tremaining: 999ms\n",
      "4:\tlearn: 0.4613151\ttotal: 1.13s\tremaining: 675ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.6s\tremaining: 533ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.09s\tremaining: 299ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.56s\tremaining: 0us\n",
      "[8, 0.51, 15, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.29ms\tremaining: 65ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.1ms\tremaining: 54.4ms\n",
      "2:\tlearn: 0.4682843\ttotal: 516ms\tremaining: 860ms\n",
      "3:\tlearn: 0.4637816\ttotal: 1.01s\tremaining: 1.01s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.14s\tremaining: 684ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.64s\tremaining: 546ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.12s\tremaining: 303ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.6s\tremaining: 0us\n",
      "[8, 0.51, 10, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.5ms\tremaining: 73.3ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.1ms\tremaining: 57.4ms\n",
      "2:\tlearn: 0.4695149\ttotal: 33.5ms\tremaining: 55.9ms\n",
      "3:\tlearn: 0.4663819\ttotal: 48.7ms\tremaining: 48.7ms\n",
      "4:\tlearn: 0.4637371\ttotal: 64.4ms\tremaining: 38.6ms\n",
      "5:\tlearn: 0.4620590\ttotal: 80.6ms\tremaining: 26.9ms\n",
      "6:\tlearn: 0.4601769\ttotal: 97.7ms\tremaining: 14ms\n",
      "7:\tlearn: 0.4571796\ttotal: 114ms\tremaining: 0us\n",
      "[8, 0.51, 10, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.7ms\tremaining: 74.8ms\n",
      "1:\tlearn: 0.4740807\ttotal: 20ms\tremaining: 60.1ms\n",
      "2:\tlearn: 0.4695149\ttotal: 35.4ms\tremaining: 59ms\n",
      "3:\tlearn: 0.4663819\ttotal: 49.4ms\tremaining: 49.4ms\n",
      "4:\tlearn: 0.4637371\ttotal: 64.2ms\tremaining: 38.5ms\n",
      "5:\tlearn: 0.4620590\ttotal: 79.1ms\tremaining: 26.4ms\n",
      "6:\tlearn: 0.4601769\ttotal: 95.1ms\tremaining: 13.6ms\n",
      "7:\tlearn: 0.4571796\ttotal: 111ms\tremaining: 0us\n",
      "[8, 0.51, 10, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.27ms\tremaining: 64.9ms\n",
      "1:\tlearn: 0.4740807\ttotal: 17.6ms\tremaining: 52.9ms\n",
      "2:\tlearn: 0.4695149\ttotal: 31.6ms\tremaining: 52.7ms\n",
      "3:\tlearn: 0.4663819\ttotal: 47.1ms\tremaining: 47.1ms\n",
      "4:\tlearn: 0.4637371\ttotal: 62.5ms\tremaining: 37.5ms\n",
      "5:\tlearn: 0.4620590\ttotal: 81.8ms\tremaining: 27.3ms\n",
      "6:\tlearn: 0.4601769\ttotal: 101ms\tremaining: 14.4ms\n",
      "7:\tlearn: 0.4571796\ttotal: 118ms\tremaining: 0us\n",
      "[8, 0.51, 10, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 12.3ms\tremaining: 85.9ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.8ms\tremaining: 68.5ms\n",
      "2:\tlearn: 0.4695149\ttotal: 40.4ms\tremaining: 67.3ms\n",
      "3:\tlearn: 0.4663819\ttotal: 57.4ms\tremaining: 57.4ms\n",
      "4:\tlearn: 0.4637371\ttotal: 77.2ms\tremaining: 46.3ms\n",
      "5:\tlearn: 0.4620590\ttotal: 94.2ms\tremaining: 31.4ms\n",
      "6:\tlearn: 0.4601769\ttotal: 111ms\tremaining: 15.9ms\n",
      "7:\tlearn: 0.4571796\ttotal: 127ms\tremaining: 0us\n",
      "[8, 0.51, 10, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 11.2ms\tremaining: 78.1ms\n",
      "1:\tlearn: 0.4740807\ttotal: 21ms\tremaining: 63ms\n",
      "2:\tlearn: 0.4695149\ttotal: 38.5ms\tremaining: 64.1ms\n",
      "3:\tlearn: 0.4663819\ttotal: 55.3ms\tremaining: 55.3ms\n",
      "4:\tlearn: 0.4637371\ttotal: 73.2ms\tremaining: 43.9ms\n",
      "5:\tlearn: 0.4620590\ttotal: 89.9ms\tremaining: 30ms\n",
      "6:\tlearn: 0.4601769\ttotal: 105ms\tremaining: 15ms\n",
      "7:\tlearn: 0.4571796\ttotal: 120ms\tremaining: 0us\n",
      "[8, 0.51, 8, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.4ms\tremaining: 65.8ms\n",
      "1:\tlearn: 0.4735886\ttotal: 16.5ms\tremaining: 49.4ms\n",
      "2:\tlearn: 0.4683373\ttotal: 23.6ms\tremaining: 39.3ms\n",
      "3:\tlearn: 0.4660754\ttotal: 31ms\tremaining: 31ms\n",
      "4:\tlearn: 0.4636280\ttotal: 39.1ms\tremaining: 23.5ms\n",
      "5:\tlearn: 0.4620627\ttotal: 46.7ms\tremaining: 15.6ms\n",
      "6:\tlearn: 0.4601948\ttotal: 53.7ms\tremaining: 7.67ms\n",
      "7:\tlearn: 0.4590473\ttotal: 64.9ms\tremaining: 0us\n",
      "[8, 0.51, 8, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 10.1ms\tremaining: 70.4ms\n",
      "1:\tlearn: 0.4735886\ttotal: 17.3ms\tremaining: 52ms\n",
      "2:\tlearn: 0.4683373\ttotal: 25ms\tremaining: 41.6ms\n",
      "3:\tlearn: 0.4660754\ttotal: 34.7ms\tremaining: 34.7ms\n",
      "4:\tlearn: 0.4636280\ttotal: 42ms\tremaining: 25.2ms\n",
      "5:\tlearn: 0.4620627\ttotal: 49.4ms\tremaining: 16.5ms\n",
      "6:\tlearn: 0.4601948\ttotal: 56.6ms\tremaining: 8.09ms\n",
      "7:\tlearn: 0.4590473\ttotal: 65.2ms\tremaining: 0us\n",
      "[8, 0.51, 8, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 13.9ms\tremaining: 97.4ms\n",
      "1:\tlearn: 0.4735886\ttotal: 21.4ms\tremaining: 64.1ms\n",
      "2:\tlearn: 0.4683373\ttotal: 29.2ms\tremaining: 48.6ms\n",
      "3:\tlearn: 0.4660754\ttotal: 39.4ms\tremaining: 39.4ms\n",
      "4:\tlearn: 0.4636280\ttotal: 47.4ms\tremaining: 28.4ms\n",
      "5:\tlearn: 0.4620627\ttotal: 55.3ms\tremaining: 18.4ms\n",
      "6:\tlearn: 0.4601948\ttotal: 62.9ms\tremaining: 8.99ms\n",
      "7:\tlearn: 0.4590473\ttotal: 70.6ms\tremaining: 0us\n",
      "[8, 0.51, 8, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 16.2ms\tremaining: 113ms\n",
      "1:\tlearn: 0.4735886\ttotal: 24ms\tremaining: 72ms\n",
      "2:\tlearn: 0.4683373\ttotal: 31.7ms\tremaining: 52.9ms\n",
      "3:\tlearn: 0.4660754\ttotal: 44.8ms\tremaining: 44.8ms\n",
      "4:\tlearn: 0.4636280\ttotal: 52.8ms\tremaining: 31.6ms\n",
      "5:\tlearn: 0.4620627\ttotal: 60.4ms\tremaining: 20.1ms\n",
      "6:\tlearn: 0.4601948\ttotal: 67.6ms\tremaining: 9.65ms\n",
      "7:\tlearn: 0.4590473\ttotal: 75.2ms\tremaining: 0us\n",
      "[8, 0.51, 8, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 7.94ms\tremaining: 55.6ms\n",
      "1:\tlearn: 0.4735886\ttotal: 14.7ms\tremaining: 44.2ms\n",
      "2:\tlearn: 0.4683373\ttotal: 21.5ms\tremaining: 35.9ms\n",
      "3:\tlearn: 0.4660754\ttotal: 28.5ms\tremaining: 28.5ms\n",
      "4:\tlearn: 0.4636280\ttotal: 35.3ms\tremaining: 21.2ms\n",
      "5:\tlearn: 0.4620627\ttotal: 42.3ms\tremaining: 14.1ms\n",
      "6:\tlearn: 0.4601948\ttotal: 48.8ms\tremaining: 6.97ms\n",
      "7:\tlearn: 0.4590473\ttotal: 55.6ms\tremaining: 0us\n",
      "[8, 0.51, 7, -0.3]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.21ms\tremaining: 36.5ms\n",
      "1:\tlearn: 0.4741799\ttotal: 10.3ms\tremaining: 30.8ms\n",
      "2:\tlearn: 0.4708424\ttotal: 15.8ms\tremaining: 26.4ms\n",
      "3:\tlearn: 0.4676883\ttotal: 20.9ms\tremaining: 20.9ms\n",
      "4:\tlearn: 0.4659630\ttotal: 26.1ms\tremaining: 15.7ms\n",
      "5:\tlearn: 0.4648851\ttotal: 31.9ms\tremaining: 10.6ms\n",
      "6:\tlearn: 0.4634152\ttotal: 37.5ms\tremaining: 5.36ms\n",
      "7:\tlearn: 0.4619064\ttotal: 42.7ms\tremaining: 0us\n",
      "[8, 0.51, 7, 0.3]\n",
      "0:\tlearn: 0.4803401\ttotal: 7.15ms\tremaining: 50.1ms\n",
      "1:\tlearn: 0.4741799\ttotal: 12.3ms\tremaining: 37ms\n",
      "2:\tlearn: 0.4708424\ttotal: 17.4ms\tremaining: 29ms\n",
      "3:\tlearn: 0.4676883\ttotal: 23ms\tremaining: 23ms\n",
      "4:\tlearn: 0.4659630\ttotal: 29.7ms\tremaining: 17.8ms\n",
      "5:\tlearn: 0.4648851\ttotal: 35ms\tremaining: 11.7ms\n",
      "6:\tlearn: 0.4634152\ttotal: 40.4ms\tremaining: 5.77ms\n",
      "7:\tlearn: 0.4619064\ttotal: 45.5ms\tremaining: 0us\n",
      "[8, 0.51, 7, 0.0]\n",
      "0:\tlearn: 0.4803401\ttotal: 8.02ms\tremaining: 56.1ms\n",
      "1:\tlearn: 0.4741799\ttotal: 13.3ms\tremaining: 39.8ms\n",
      "2:\tlearn: 0.4708424\ttotal: 18.6ms\tremaining: 30.9ms\n",
      "3:\tlearn: 0.4676883\ttotal: 23.9ms\tremaining: 23.9ms\n",
      "4:\tlearn: 0.4659630\ttotal: 29.1ms\tremaining: 17.4ms\n",
      "5:\tlearn: 0.4648851\ttotal: 34.6ms\tremaining: 11.5ms\n",
      "6:\tlearn: 0.4634152\ttotal: 39.8ms\tremaining: 5.69ms\n",
      "7:\tlearn: 0.4619064\ttotal: 45.1ms\tremaining: 0us\n",
      "[8, 0.51, 7, 0.15]\n",
      "0:\tlearn: 0.4803401\ttotal: 6.19ms\tremaining: 43.4ms\n",
      "1:\tlearn: 0.4741799\ttotal: 11.5ms\tremaining: 34.6ms\n",
      "2:\tlearn: 0.4708424\ttotal: 17.1ms\tremaining: 28.4ms\n",
      "3:\tlearn: 0.4676883\ttotal: 22.5ms\tremaining: 22.5ms\n",
      "4:\tlearn: 0.4659630\ttotal: 28.3ms\tremaining: 17ms\n",
      "5:\tlearn: 0.4648851\ttotal: 33.6ms\tremaining: 11.2ms\n",
      "6:\tlearn: 0.4634152\ttotal: 39.1ms\tremaining: 5.59ms\n",
      "7:\tlearn: 0.4619064\ttotal: 44.3ms\tremaining: 0us\n",
      "[8, 0.51, 7, 0.2]\n",
      "0:\tlearn: 0.4803401\ttotal: 5.72ms\tremaining: 40ms\n",
      "1:\tlearn: 0.4741799\ttotal: 11.3ms\tremaining: 33.8ms\n",
      "2:\tlearn: 0.4708424\ttotal: 16.6ms\tremaining: 27.6ms\n",
      "3:\tlearn: 0.4676883\ttotal: 22.1ms\tremaining: 22.1ms\n",
      "4:\tlearn: 0.4659630\ttotal: 28.7ms\tremaining: 17.2ms\n",
      "5:\tlearn: 0.4648851\ttotal: 34ms\tremaining: 11.3ms\n",
      "6:\tlearn: 0.4634152\ttotal: 39.6ms\tremaining: 5.66ms\n",
      "7:\tlearn: 0.4619064\ttotal: 45.2ms\tremaining: 0us\n",
      "[8, 0.49, 6, -0.3]\n",
      "0:\tlearn: 0.4807455\ttotal: 8.39ms\tremaining: 58.7ms\n",
      "1:\tlearn: 0.4740289\ttotal: 12.9ms\tremaining: 38.8ms\n",
      "2:\tlearn: 0.4705265\ttotal: 17.3ms\tremaining: 28.9ms\n",
      "3:\tlearn: 0.4681211\ttotal: 21.6ms\tremaining: 21.6ms\n",
      "4:\tlearn: 0.4661064\ttotal: 26.1ms\tremaining: 15.6ms\n",
      "5:\tlearn: 0.4643672\ttotal: 30.7ms\tremaining: 10.2ms\n",
      "6:\tlearn: 0.4622690\ttotal: 35.4ms\tremaining: 5.05ms\n",
      "7:\tlearn: 0.4611446\ttotal: 40.1ms\tremaining: 0us\n",
      "[8, 0.49, 6, 0.3]\n",
      "0:\tlearn: 0.4807455\ttotal: 5.39ms\tremaining: 37.7ms\n",
      "1:\tlearn: 0.4740289\ttotal: 9.53ms\tremaining: 28.6ms\n",
      "2:\tlearn: 0.4705265\ttotal: 13.6ms\tremaining: 22.6ms\n",
      "3:\tlearn: 0.4681211\ttotal: 17.7ms\tremaining: 17.7ms\n",
      "4:\tlearn: 0.4661064\ttotal: 21.7ms\tremaining: 13ms\n",
      "5:\tlearn: 0.4643672\ttotal: 26.3ms\tremaining: 8.78ms\n",
      "6:\tlearn: 0.4622690\ttotal: 30.8ms\tremaining: 4.4ms\n",
      "7:\tlearn: 0.4611446\ttotal: 35.1ms\tremaining: 0us\n",
      "[8, 0.49, 6, 0.0]\n",
      "0:\tlearn: 0.4807455\ttotal: 8.43ms\tremaining: 59ms\n",
      "1:\tlearn: 0.4740289\ttotal: 12.5ms\tremaining: 37.6ms\n",
      "2:\tlearn: 0.4705265\ttotal: 16.8ms\tremaining: 27.9ms\n",
      "3:\tlearn: 0.4681211\ttotal: 21ms\tremaining: 21ms\n",
      "4:\tlearn: 0.4661064\ttotal: 25.3ms\tremaining: 15.2ms\n",
      "5:\tlearn: 0.4643672\ttotal: 29.6ms\tremaining: 9.87ms\n",
      "6:\tlearn: 0.4622690\ttotal: 36.1ms\tremaining: 5.15ms\n",
      "7:\tlearn: 0.4611446\ttotal: 40.7ms\tremaining: 0us\n",
      "[8, 0.49, 6, 0.15]\n",
      "0:\tlearn: 0.4807455\ttotal: 5.23ms\tremaining: 36.6ms\n",
      "1:\tlearn: 0.4740289\ttotal: 9.84ms\tremaining: 29.5ms\n",
      "2:\tlearn: 0.4705265\ttotal: 13.9ms\tremaining: 23.1ms\n",
      "3:\tlearn: 0.4681211\ttotal: 18ms\tremaining: 18ms\n",
      "4:\tlearn: 0.4661064\ttotal: 21.8ms\tremaining: 13.1ms\n",
      "5:\tlearn: 0.4643672\ttotal: 25.9ms\tremaining: 8.64ms\n",
      "6:\tlearn: 0.4622690\ttotal: 30.2ms\tremaining: 4.31ms\n",
      "7:\tlearn: 0.4611446\ttotal: 34.2ms\tremaining: 0us\n",
      "[8, 0.49, 6, 0.2]\n",
      "0:\tlearn: 0.4807455\ttotal: 7.49ms\tremaining: 52.4ms\n",
      "1:\tlearn: 0.4740289\ttotal: 11.7ms\tremaining: 35ms\n",
      "2:\tlearn: 0.4705265\ttotal: 15.8ms\tremaining: 26.4ms\n",
      "3:\tlearn: 0.4681211\ttotal: 20.3ms\tremaining: 20.3ms\n",
      "4:\tlearn: 0.4661064\ttotal: 24.7ms\tremaining: 14.8ms\n",
      "5:\tlearn: 0.4643672\ttotal: 28.7ms\tremaining: 9.57ms\n",
      "6:\tlearn: 0.4622690\ttotal: 33ms\tremaining: 4.71ms\n",
      "7:\tlearn: 0.4611446\ttotal: 36.9ms\tremaining: 0us\n",
      "[8, 0.49, 15, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 10ms\tremaining: 70.2ms\n",
      "1:\tlearn: 0.4744785\ttotal: 19.4ms\tremaining: 58.2ms\n",
      "2:\tlearn: 0.4686673\ttotal: 465ms\tremaining: 776ms\n",
      "3:\tlearn: 0.4640224\ttotal: 950ms\tremaining: 950ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.09s\tremaining: 656ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.57s\tremaining: 524ms\n",
      "6:\tlearn: 0.4569377\ttotal: 2.06s\tremaining: 294ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.53s\tremaining: 0us\n",
      "[8, 0.49, 15, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.1ms\tremaining: 77.8ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.9ms\tremaining: 62.6ms\n",
      "2:\tlearn: 0.4686673\ttotal: 478ms\tremaining: 797ms\n",
      "3:\tlearn: 0.4640224\ttotal: 940ms\tremaining: 940ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.06s\tremaining: 635ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.54s\tremaining: 514ms\n",
      "6:\tlearn: 0.4569377\ttotal: 2.04s\tremaining: 292ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.5s\tremaining: 0us\n",
      "[8, 0.49, 15, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 13.3ms\tremaining: 93ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22.1ms\tremaining: 66.4ms\n",
      "2:\tlearn: 0.4686673\ttotal: 470ms\tremaining: 784ms\n",
      "3:\tlearn: 0.4640224\ttotal: 975ms\tremaining: 975ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.1s\tremaining: 659ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.55s\tremaining: 518ms\n",
      "6:\tlearn: 0.4569377\ttotal: 2.01s\tremaining: 287ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.5s\tremaining: 0us\n",
      "[8, 0.49, 15, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.35ms\tremaining: 65.4ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18.5ms\tremaining: 55.4ms\n",
      "2:\tlearn: 0.4686673\ttotal: 499ms\tremaining: 832ms\n",
      "3:\tlearn: 0.4640224\ttotal: 981ms\tremaining: 981ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.09s\tremaining: 657ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.6s\tremaining: 534ms\n",
      "6:\tlearn: 0.4569377\ttotal: 2.09s\tremaining: 299ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.58s\tremaining: 0us\n",
      "[8, 0.49, 15, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 10.7ms\tremaining: 75ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20ms\tremaining: 60.1ms\n",
      "2:\tlearn: 0.4686673\ttotal: 472ms\tremaining: 787ms\n",
      "3:\tlearn: 0.4640224\ttotal: 963ms\tremaining: 963ms\n",
      "4:\tlearn: 0.4613861\ttotal: 1.08s\tremaining: 650ms\n",
      "5:\tlearn: 0.4585459\ttotal: 1.58s\tremaining: 527ms\n",
      "6:\tlearn: 0.4569377\ttotal: 2.05s\tremaining: 293ms\n",
      "7:\tlearn: 0.4546011\ttotal: 2.56s\tremaining: 0us\n",
      "[8, 0.49, 10, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.85ms\tremaining: 68.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 19.5ms\tremaining: 58.4ms\n",
      "2:\tlearn: 0.4699228\ttotal: 37.8ms\tremaining: 63ms\n",
      "3:\tlearn: 0.4669696\ttotal: 54.8ms\tremaining: 54.8ms\n",
      "4:\tlearn: 0.4643800\ttotal: 74.4ms\tremaining: 44.6ms\n",
      "5:\tlearn: 0.4625508\ttotal: 90.5ms\tremaining: 30.2ms\n",
      "6:\tlearn: 0.4603707\ttotal: 107ms\tremaining: 15.3ms\n",
      "7:\tlearn: 0.4571873\ttotal: 123ms\tremaining: 0us\n",
      "[8, 0.49, 10, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 11ms\tremaining: 76.7ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.9ms\tremaining: 62.6ms\n",
      "2:\tlearn: 0.4699228\ttotal: 39.9ms\tremaining: 66.4ms\n",
      "3:\tlearn: 0.4669696\ttotal: 55.9ms\tremaining: 55.9ms\n",
      "4:\tlearn: 0.4643800\ttotal: 73.1ms\tremaining: 43.8ms\n",
      "5:\tlearn: 0.4625508\ttotal: 89.7ms\tremaining: 29.9ms\n",
      "6:\tlearn: 0.4603707\ttotal: 105ms\tremaining: 15ms\n",
      "7:\tlearn: 0.4571873\ttotal: 121ms\tremaining: 0us\n",
      "[8, 0.49, 10, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 20.4ms\tremaining: 143ms\n",
      "1:\tlearn: 0.4744785\ttotal: 29.6ms\tremaining: 88.9ms\n",
      "2:\tlearn: 0.4699228\ttotal: 46.6ms\tremaining: 77.6ms\n",
      "3:\tlearn: 0.4669696\ttotal: 71.5ms\tremaining: 71.5ms\n",
      "4:\tlearn: 0.4643800\ttotal: 87.3ms\tremaining: 52.4ms\n",
      "5:\tlearn: 0.4625508\ttotal: 102ms\tremaining: 33.9ms\n",
      "6:\tlearn: 0.4603707\ttotal: 117ms\tremaining: 16.7ms\n",
      "7:\tlearn: 0.4571873\ttotal: 132ms\tremaining: 0us\n",
      "[8, 0.49, 10, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.3ms\tremaining: 65.1ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18.9ms\tremaining: 56.6ms\n",
      "2:\tlearn: 0.4699228\ttotal: 35.4ms\tremaining: 59ms\n",
      "3:\tlearn: 0.4669696\ttotal: 52.3ms\tremaining: 52.3ms\n",
      "4:\tlearn: 0.4643800\ttotal: 68.5ms\tremaining: 41.1ms\n",
      "5:\tlearn: 0.4625508\ttotal: 83.8ms\tremaining: 27.9ms\n",
      "6:\tlearn: 0.4603707\ttotal: 100ms\tremaining: 14.3ms\n",
      "7:\tlearn: 0.4571873\ttotal: 117ms\tremaining: 0us\n",
      "[8, 0.49, 10, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 12ms\tremaining: 83.8ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22.4ms\tremaining: 67.2ms\n",
      "2:\tlearn: 0.4699228\ttotal: 38.9ms\tremaining: 64.8ms\n",
      "3:\tlearn: 0.4669696\ttotal: 54.3ms\tremaining: 54.3ms\n",
      "4:\tlearn: 0.4643800\ttotal: 70.1ms\tremaining: 42.1ms\n",
      "5:\tlearn: 0.4625508\ttotal: 85.2ms\tremaining: 28.4ms\n",
      "6:\tlearn: 0.4603707\ttotal: 100ms\tremaining: 14.3ms\n",
      "7:\tlearn: 0.4571873\ttotal: 116ms\tremaining: 0us\n",
      "[8, 0.49, 12, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.5ms\tremaining: 87.2ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21.7ms\tremaining: 65.1ms\n",
      "2:\tlearn: 0.4691204\ttotal: 80.8ms\tremaining: 135ms\n",
      "3:\tlearn: 0.4662521\ttotal: 138ms\tremaining: 138ms\n",
      "4:\tlearn: 0.4632297\ttotal: 198ms\tremaining: 119ms\n",
      "5:\tlearn: 0.4614380\ttotal: 263ms\tremaining: 87.6ms\n",
      "6:\tlearn: 0.4594949\ttotal: 324ms\tremaining: 46.3ms\n",
      "7:\tlearn: 0.4578565\ttotal: 385ms\tremaining: 0us\n",
      "[8, 0.49, 12, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 10.7ms\tremaining: 75.1ms\n",
      "1:\tlearn: 0.4744785\ttotal: 19.7ms\tremaining: 59.2ms\n",
      "2:\tlearn: 0.4691204\ttotal: 74.5ms\tremaining: 124ms\n",
      "3:\tlearn: 0.4662521\ttotal: 135ms\tremaining: 135ms\n",
      "4:\tlearn: 0.4632297\ttotal: 194ms\tremaining: 116ms\n",
      "5:\tlearn: 0.4614380\ttotal: 256ms\tremaining: 85.5ms\n",
      "6:\tlearn: 0.4594949\ttotal: 317ms\tremaining: 45.2ms\n",
      "7:\tlearn: 0.4578565\ttotal: 374ms\tremaining: 0us\n",
      "[8, 0.49, 12, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.13ms\tremaining: 63.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 18.1ms\tremaining: 54.2ms\n",
      "2:\tlearn: 0.4691204\ttotal: 78.4ms\tremaining: 131ms\n",
      "3:\tlearn: 0.4662521\ttotal: 146ms\tremaining: 146ms\n",
      "4:\tlearn: 0.4632297\ttotal: 205ms\tremaining: 123ms\n",
      "5:\tlearn: 0.4614380\ttotal: 264ms\tremaining: 87.9ms\n",
      "6:\tlearn: 0.4594949\ttotal: 326ms\tremaining: 46.5ms\n",
      "7:\tlearn: 0.4578565\ttotal: 395ms\tremaining: 0us\n",
      "[8, 0.49, 12, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 15.8ms\tremaining: 111ms\n",
      "1:\tlearn: 0.4744785\ttotal: 25ms\tremaining: 75.1ms\n",
      "2:\tlearn: 0.4691204\ttotal: 84.5ms\tremaining: 141ms\n",
      "3:\tlearn: 0.4662521\ttotal: 144ms\tremaining: 144ms\n",
      "4:\tlearn: 0.4632297\ttotal: 201ms\tremaining: 121ms\n",
      "5:\tlearn: 0.4614380\ttotal: 257ms\tremaining: 85.7ms\n",
      "6:\tlearn: 0.4594949\ttotal: 320ms\tremaining: 45.7ms\n",
      "7:\tlearn: 0.4578565\ttotal: 387ms\tremaining: 0us\n",
      "[8, 0.49, 12, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 17.5ms\tremaining: 122ms\n",
      "1:\tlearn: 0.4744785\ttotal: 27.8ms\tremaining: 83.4ms\n",
      "2:\tlearn: 0.4691204\ttotal: 92ms\tremaining: 153ms\n",
      "3:\tlearn: 0.4662521\ttotal: 157ms\tremaining: 157ms\n",
      "4:\tlearn: 0.4632297\ttotal: 219ms\tremaining: 131ms\n",
      "5:\tlearn: 0.4614380\ttotal: 273ms\tremaining: 91.2ms\n",
      "6:\tlearn: 0.4594949\ttotal: 331ms\tremaining: 47.3ms\n",
      "7:\tlearn: 0.4578565\ttotal: 401ms\tremaining: 0us\n",
      "[8, 0.49, 13, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 10.4ms\tremaining: 73.1ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.5ms\tremaining: 61.4ms\n",
      "2:\tlearn: 0.4688286\ttotal: 140ms\tremaining: 233ms\n",
      "3:\tlearn: 0.4660649\ttotal: 265ms\tremaining: 265ms\n",
      "4:\tlearn: 0.4613755\ttotal: 383ms\tremaining: 230ms\n",
      "5:\tlearn: 0.4593062\ttotal: 506ms\tremaining: 169ms\n",
      "6:\tlearn: 0.4570185\ttotal: 620ms\tremaining: 88.6ms\n",
      "7:\tlearn: 0.4553016\ttotal: 729ms\tremaining: 0us\n",
      "[8, 0.49, 13, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.7ms\tremaining: 88.6ms\n",
      "1:\tlearn: 0.4744785\ttotal: 22.1ms\tremaining: 66.4ms\n",
      "2:\tlearn: 0.4688286\ttotal: 154ms\tremaining: 257ms\n",
      "3:\tlearn: 0.4660649\ttotal: 283ms\tremaining: 283ms\n",
      "4:\tlearn: 0.4613755\ttotal: 413ms\tremaining: 248ms\n",
      "5:\tlearn: 0.4593062\ttotal: 534ms\tremaining: 178ms\n",
      "6:\tlearn: 0.4570185\ttotal: 654ms\tremaining: 93.4ms\n",
      "7:\tlearn: 0.4553016\ttotal: 790ms\tremaining: 0us\n",
      "[8, 0.49, 13, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.4ms\tremaining: 79.8ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.7ms\tremaining: 62.1ms\n",
      "2:\tlearn: 0.4688286\ttotal: 142ms\tremaining: 237ms\n",
      "3:\tlearn: 0.4660649\ttotal: 254ms\tremaining: 254ms\n",
      "4:\tlearn: 0.4613755\ttotal: 377ms\tremaining: 226ms\n",
      "5:\tlearn: 0.4593062\ttotal: 499ms\tremaining: 166ms\n",
      "6:\tlearn: 0.4570185\ttotal: 621ms\tremaining: 88.7ms\n",
      "7:\tlearn: 0.4553016\ttotal: 753ms\tremaining: 0us\n",
      "[8, 0.49, 13, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 9.5ms\tremaining: 66.5ms\n",
      "1:\tlearn: 0.4744785\ttotal: 19.6ms\tremaining: 58.7ms\n",
      "2:\tlearn: 0.4688286\ttotal: 136ms\tremaining: 227ms\n",
      "3:\tlearn: 0.4660649\ttotal: 253ms\tremaining: 253ms\n",
      "4:\tlearn: 0.4613755\ttotal: 374ms\tremaining: 224ms\n",
      "5:\tlearn: 0.4593062\ttotal: 495ms\tremaining: 165ms\n",
      "6:\tlearn: 0.4570185\ttotal: 619ms\tremaining: 88.5ms\n",
      "7:\tlearn: 0.4553016\ttotal: 737ms\tremaining: 0us\n",
      "[8, 0.49, 13, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 13.7ms\tremaining: 96.1ms\n",
      "1:\tlearn: 0.4744785\ttotal: 23.2ms\tremaining: 69.6ms\n",
      "2:\tlearn: 0.4688286\ttotal: 140ms\tremaining: 234ms\n",
      "3:\tlearn: 0.4660649\ttotal: 257ms\tremaining: 257ms\n",
      "4:\tlearn: 0.4613755\ttotal: 379ms\tremaining: 227ms\n",
      "5:\tlearn: 0.4593062\ttotal: 514ms\tremaining: 171ms\n",
      "6:\tlearn: 0.4570185\ttotal: 627ms\tremaining: 89.5ms\n",
      "7:\tlearn: 0.4553016\ttotal: 754ms\tremaining: 0us\n",
      "[8, 0.49, 14, -0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.7ms\tremaining: 89ms\n",
      "1:\tlearn: 0.4744785\ttotal: 21.9ms\tremaining: 65.8ms\n",
      "2:\tlearn: 0.4686980\ttotal: 257ms\tremaining: 428ms\n",
      "3:\tlearn: 0.4656366\ttotal: 491ms\tremaining: 491ms\n",
      "4:\tlearn: 0.4629508\ttotal: 740ms\tremaining: 444ms\n",
      "5:\tlearn: 0.4604560\ttotal: 991ms\tremaining: 330ms\n",
      "6:\tlearn: 0.4592207\ttotal: 997ms\tremaining: 142ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.24s\tremaining: 0us\n",
      "[8, 0.49, 14, 0.3]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.2ms\tremaining: 78.1ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.4ms\tremaining: 61.3ms\n",
      "2:\tlearn: 0.4686980\ttotal: 253ms\tremaining: 421ms\n",
      "3:\tlearn: 0.4656366\ttotal: 491ms\tremaining: 491ms\n",
      "4:\tlearn: 0.4629508\ttotal: 744ms\tremaining: 447ms\n",
      "5:\tlearn: 0.4604560\ttotal: 990ms\tremaining: 330ms\n",
      "6:\tlearn: 0.4592207\ttotal: 995ms\tremaining: 142ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.24s\tremaining: 0us\n",
      "[8, 0.49, 14, 0.0]\n",
      "0:\tlearn: 0.4804207\ttotal: 12.8ms\tremaining: 89.8ms\n",
      "1:\tlearn: 0.4744785\ttotal: 23.8ms\tremaining: 71.3ms\n",
      "2:\tlearn: 0.4686980\ttotal: 266ms\tremaining: 443ms\n",
      "3:\tlearn: 0.4656366\ttotal: 512ms\tremaining: 512ms\n",
      "4:\tlearn: 0.4629508\ttotal: 744ms\tremaining: 446ms\n",
      "5:\tlearn: 0.4604560\ttotal: 998ms\tremaining: 333ms\n",
      "6:\tlearn: 0.4592207\ttotal: 1s\tremaining: 143ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.22s\tremaining: 0us\n",
      "[8, 0.49, 14, 0.15]\n",
      "0:\tlearn: 0.4804207\ttotal: 14ms\tremaining: 97.9ms\n",
      "1:\tlearn: 0.4744785\ttotal: 24.1ms\tremaining: 72.4ms\n",
      "2:\tlearn: 0.4686980\ttotal: 255ms\tremaining: 426ms\n",
      "3:\tlearn: 0.4656366\ttotal: 500ms\tremaining: 500ms\n",
      "4:\tlearn: 0.4629508\ttotal: 749ms\tremaining: 449ms\n",
      "5:\tlearn: 0.4604560\ttotal: 975ms\tremaining: 325ms\n",
      "6:\tlearn: 0.4592207\ttotal: 980ms\tremaining: 140ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.23s\tremaining: 0us\n",
      "[8, 0.49, 14, 0.2]\n",
      "0:\tlearn: 0.4804207\ttotal: 11.9ms\tremaining: 83.1ms\n",
      "1:\tlearn: 0.4744785\ttotal: 20.8ms\tremaining: 62.5ms\n",
      "2:\tlearn: 0.4686980\ttotal: 253ms\tremaining: 421ms\n",
      "3:\tlearn: 0.4656366\ttotal: 494ms\tremaining: 494ms\n",
      "4:\tlearn: 0.4629508\ttotal: 729ms\tremaining: 437ms\n",
      "5:\tlearn: 0.4604560\ttotal: 973ms\tremaining: 324ms\n",
      "6:\tlearn: 0.4592207\ttotal: 977ms\tremaining: 140ms\n",
      "7:\tlearn: 0.4572522\ttotal: 1.21s\tremaining: 0us\n",
      "[9, 0.3, 6, -0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.43ms\tremaining: 43.4ms\n",
      "1:\tlearn: 0.4796834\ttotal: 10.2ms\tremaining: 35.8ms\n",
      "2:\tlearn: 0.4757652\ttotal: 14.7ms\tremaining: 29.3ms\n",
      "3:\tlearn: 0.4737764\ttotal: 19ms\tremaining: 23.8ms\n",
      "4:\tlearn: 0.4716943\ttotal: 23.4ms\tremaining: 18.8ms\n",
      "5:\tlearn: 0.4696759\ttotal: 28.7ms\tremaining: 14.3ms\n",
      "6:\tlearn: 0.4683623\ttotal: 33.1ms\tremaining: 9.46ms\n",
      "7:\tlearn: 0.4672969\ttotal: 37.5ms\tremaining: 4.69ms\n",
      "8:\tlearn: 0.4661468\ttotal: 41.8ms\tremaining: 0us\n",
      "[9, 0.3, 6, 0.3]\n",
      "0:\tlearn: 0.4852609\ttotal: 12.7ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4796834\ttotal: 17.7ms\tremaining: 61.9ms\n",
      "2:\tlearn: 0.4757652\ttotal: 21.9ms\tremaining: 43.7ms\n",
      "3:\tlearn: 0.4737764\ttotal: 26.1ms\tremaining: 32.6ms\n",
      "4:\tlearn: 0.4716943\ttotal: 30.3ms\tremaining: 24.2ms\n",
      "5:\tlearn: 0.4696759\ttotal: 34.6ms\tremaining: 17.3ms\n",
      "6:\tlearn: 0.4683623\ttotal: 39ms\tremaining: 11.1ms\n",
      "7:\tlearn: 0.4672969\ttotal: 43.2ms\tremaining: 5.41ms\n",
      "8:\tlearn: 0.4661468\ttotal: 47.5ms\tremaining: 0us\n",
      "[9, 0.3, 6, 0.0]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.63ms\tremaining: 45ms\n",
      "1:\tlearn: 0.4796834\ttotal: 9.66ms\tremaining: 33.8ms\n",
      "2:\tlearn: 0.4757652\ttotal: 13.7ms\tremaining: 27.3ms\n",
      "3:\tlearn: 0.4737764\ttotal: 17.7ms\tremaining: 22.1ms\n",
      "4:\tlearn: 0.4716943\ttotal: 21.7ms\tremaining: 17.4ms\n",
      "5:\tlearn: 0.4696759\ttotal: 25.7ms\tremaining: 12.9ms\n",
      "6:\tlearn: 0.4683623\ttotal: 29.9ms\tremaining: 8.54ms\n",
      "7:\tlearn: 0.4672969\ttotal: 34.2ms\tremaining: 4.28ms\n",
      "8:\tlearn: 0.4661468\ttotal: 38.2ms\tremaining: 0us\n",
      "[9, 0.3, 6, 0.15]\n",
      "0:\tlearn: 0.4852609\ttotal: 6.14ms\tremaining: 49.1ms\n",
      "1:\tlearn: 0.4796834\ttotal: 10.6ms\tremaining: 37.2ms\n",
      "2:\tlearn: 0.4757652\ttotal: 15.1ms\tremaining: 30.3ms\n",
      "3:\tlearn: 0.4737764\ttotal: 19.5ms\tremaining: 24.4ms\n",
      "4:\tlearn: 0.4716943\ttotal: 23.9ms\tremaining: 19.1ms\n",
      "5:\tlearn: 0.4696759\ttotal: 28.6ms\tremaining: 14.3ms\n",
      "6:\tlearn: 0.4683623\ttotal: 33.3ms\tremaining: 9.52ms\n",
      "7:\tlearn: 0.4672969\ttotal: 37.8ms\tremaining: 4.72ms\n",
      "8:\tlearn: 0.4661468\ttotal: 42.2ms\tremaining: 0us\n",
      "[9, 0.3, 6, 0.2]\n",
      "0:\tlearn: 0.4852609\ttotal: 5.3ms\tremaining: 42.4ms\n",
      "1:\tlearn: 0.4796834\ttotal: 9.34ms\tremaining: 32.7ms\n",
      "2:\tlearn: 0.4757652\ttotal: 13.6ms\tremaining: 27.1ms\n",
      "3:\tlearn: 0.4737764\ttotal: 17.8ms\tremaining: 22.3ms\n",
      "4:\tlearn: 0.4716943\ttotal: 22ms\tremaining: 17.6ms\n",
      "5:\tlearn: 0.4696759\ttotal: 26.2ms\tremaining: 13.1ms\n",
      "6:\tlearn: 0.4683623\ttotal: 30.6ms\tremaining: 8.74ms\n",
      "7:\tlearn: 0.4672969\ttotal: 34.7ms\tremaining: 4.34ms\n",
      "8:\tlearn: 0.4661468\ttotal: 38.8ms\tremaining: 0us\n",
      "[9, 0.3, 15, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.4ms\tremaining: 99.5ms\n",
      "1:\tlearn: 0.4769595\ttotal: 472ms\tremaining: 1.65s\n",
      "2:\tlearn: 0.4714456\ttotal: 989ms\tremaining: 1.98s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.44s\tremaining: 1.8s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.91s\tremaining: 1.53s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.4s\tremaining: 1.2s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.9s\tremaining: 830ms\n",
      "7:\tlearn: 0.4589930\ttotal: 2.92s\tremaining: 365ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.38s\tremaining: 0us\n",
      "[9, 0.3, 15, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.9ms\tremaining: 87.1ms\n",
      "1:\tlearn: 0.4769595\ttotal: 478ms\tremaining: 1.67s\n",
      "2:\tlearn: 0.4714456\ttotal: 960ms\tremaining: 1.92s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.44s\tremaining: 1.8s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.92s\tremaining: 1.54s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.4s\tremaining: 1.2s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.88s\tremaining: 822ms\n",
      "7:\tlearn: 0.4589930\ttotal: 2.89s\tremaining: 362ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.39s\tremaining: 0us\n",
      "[9, 0.3, 15, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.18ms\tremaining: 73.5ms\n",
      "1:\tlearn: 0.4769595\ttotal: 462ms\tremaining: 1.61s\n",
      "2:\tlearn: 0.4714456\ttotal: 956ms\tremaining: 1.91s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.45s\tremaining: 1.81s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.94s\tremaining: 1.55s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.43s\tremaining: 1.22s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.9s\tremaining: 828ms\n",
      "7:\tlearn: 0.4589930\ttotal: 2.92s\tremaining: 364ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.4s\tremaining: 0us\n",
      "[9, 0.3, 15, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.5ms\tremaining: 84.3ms\n",
      "1:\tlearn: 0.4769595\ttotal: 475ms\tremaining: 1.66s\n",
      "2:\tlearn: 0.4714456\ttotal: 983ms\tremaining: 1.97s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.48s\tremaining: 1.85s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.95s\tremaining: 1.56s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.41s\tremaining: 1.21s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.94s\tremaining: 840ms\n",
      "7:\tlearn: 0.4589930\ttotal: 2.96s\tremaining: 369ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.43s\tremaining: 0us\n",
      "[9, 0.3, 15, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.68ms\tremaining: 77.4ms\n",
      "1:\tlearn: 0.4769595\ttotal: 496ms\tremaining: 1.74s\n",
      "2:\tlearn: 0.4714456\ttotal: 980ms\tremaining: 1.96s\n",
      "3:\tlearn: 0.4677602\ttotal: 1.49s\tremaining: 1.86s\n",
      "4:\tlearn: 0.4645800\ttotal: 1.96s\tremaining: 1.57s\n",
      "5:\tlearn: 0.4621633\ttotal: 2.44s\tremaining: 1.22s\n",
      "6:\tlearn: 0.4603088\ttotal: 2.9s\tremaining: 827ms\n",
      "7:\tlearn: 0.4589930\ttotal: 2.91s\tremaining: 364ms\n",
      "8:\tlearn: 0.4574082\ttotal: 3.39s\tremaining: 0us\n",
      "[9, 0.3, 10, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.56ms\tremaining: 76.5ms\n",
      "1:\tlearn: 0.4786840\ttotal: 23.7ms\tremaining: 83ms\n",
      "2:\tlearn: 0.4743082\ttotal: 38.9ms\tremaining: 77.8ms\n",
      "3:\tlearn: 0.4713878\ttotal: 53.9ms\tremaining: 67.4ms\n",
      "4:\tlearn: 0.4683005\ttotal: 71.4ms\tremaining: 57.1ms\n",
      "5:\tlearn: 0.4662774\ttotal: 87.4ms\tremaining: 43.7ms\n",
      "6:\tlearn: 0.4645284\ttotal: 104ms\tremaining: 29.8ms\n",
      "7:\tlearn: 0.4637179\ttotal: 110ms\tremaining: 13.7ms\n",
      "8:\tlearn: 0.4614943\ttotal: 120ms\tremaining: 0us\n",
      "[9, 0.3, 10, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 11.7ms\tremaining: 93.6ms\n",
      "1:\tlearn: 0.4786840\ttotal: 27ms\tremaining: 94.7ms\n",
      "2:\tlearn: 0.4743082\ttotal: 50.5ms\tremaining: 101ms\n",
      "3:\tlearn: 0.4713878\ttotal: 68.8ms\tremaining: 86ms\n",
      "4:\tlearn: 0.4683005\ttotal: 89.6ms\tremaining: 71.7ms\n",
      "5:\tlearn: 0.4662774\ttotal: 107ms\tremaining: 53.3ms\n",
      "6:\tlearn: 0.4645284\ttotal: 123ms\tremaining: 35.1ms\n",
      "7:\tlearn: 0.4637179\ttotal: 128ms\tremaining: 16ms\n",
      "8:\tlearn: 0.4614943\ttotal: 137ms\tremaining: 0us\n",
      "[9, 0.3, 10, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 14.7ms\tremaining: 118ms\n",
      "1:\tlearn: 0.4786840\ttotal: 32.1ms\tremaining: 112ms\n",
      "2:\tlearn: 0.4743082\ttotal: 54ms\tremaining: 108ms\n",
      "3:\tlearn: 0.4713878\ttotal: 70.5ms\tremaining: 88.2ms\n",
      "4:\tlearn: 0.4683005\ttotal: 91.5ms\tremaining: 73.2ms\n",
      "5:\tlearn: 0.4662774\ttotal: 108ms\tremaining: 54.1ms\n",
      "6:\tlearn: 0.4645284\ttotal: 130ms\tremaining: 37ms\n",
      "7:\tlearn: 0.4637179\ttotal: 135ms\tremaining: 16.9ms\n",
      "8:\tlearn: 0.4614943\ttotal: 146ms\tremaining: 0us\n",
      "[9, 0.3, 10, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 15.8ms\tremaining: 126ms\n",
      "1:\tlearn: 0.4786840\ttotal: 33.3ms\tremaining: 116ms\n",
      "2:\tlearn: 0.4743082\ttotal: 51.5ms\tremaining: 103ms\n",
      "3:\tlearn: 0.4713878\ttotal: 69.2ms\tremaining: 86.5ms\n",
      "4:\tlearn: 0.4683005\ttotal: 86.8ms\tremaining: 69.4ms\n",
      "5:\tlearn: 0.4662774\ttotal: 103ms\tremaining: 51.4ms\n",
      "6:\tlearn: 0.4645284\ttotal: 121ms\tremaining: 34.5ms\n",
      "7:\tlearn: 0.4637179\ttotal: 126ms\tremaining: 15.7ms\n",
      "8:\tlearn: 0.4614943\ttotal: 135ms\tremaining: 0us\n",
      "[9, 0.3, 10, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 14.5ms\tremaining: 116ms\n",
      "1:\tlearn: 0.4786840\ttotal: 30.6ms\tremaining: 107ms\n",
      "2:\tlearn: 0.4743082\ttotal: 47.7ms\tremaining: 95.4ms\n",
      "3:\tlearn: 0.4713878\ttotal: 63.2ms\tremaining: 79ms\n",
      "4:\tlearn: 0.4683005\ttotal: 80.2ms\tremaining: 64.1ms\n",
      "5:\tlearn: 0.4662774\ttotal: 96.2ms\tremaining: 48.1ms\n",
      "6:\tlearn: 0.4645284\ttotal: 111ms\tremaining: 31.6ms\n",
      "7:\tlearn: 0.4637179\ttotal: 116ms\tremaining: 14.5ms\n",
      "8:\tlearn: 0.4614943\ttotal: 126ms\tremaining: 0us\n",
      "[9, 0.3, 12, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.7ms\tremaining: 85.2ms\n",
      "1:\tlearn: 0.4778843\ttotal: 72.7ms\tremaining: 254ms\n",
      "2:\tlearn: 0.4738999\ttotal: 127ms\tremaining: 254ms\n",
      "3:\tlearn: 0.4696749\ttotal: 188ms\tremaining: 235ms\n",
      "4:\tlearn: 0.4678542\ttotal: 252ms\tremaining: 202ms\n",
      "5:\tlearn: 0.4655216\ttotal: 315ms\tremaining: 158ms\n",
      "6:\tlearn: 0.4639614\ttotal: 378ms\tremaining: 108ms\n",
      "7:\tlearn: 0.4618543\ttotal: 442ms\tremaining: 55.2ms\n",
      "8:\tlearn: 0.4604753\ttotal: 507ms\tremaining: 0us\n",
      "[9, 0.3, 12, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 9.53ms\tremaining: 76.2ms\n",
      "1:\tlearn: 0.4778843\ttotal: 65.2ms\tremaining: 228ms\n",
      "2:\tlearn: 0.4738999\ttotal: 124ms\tremaining: 248ms\n",
      "3:\tlearn: 0.4696749\ttotal: 206ms\tremaining: 257ms\n",
      "4:\tlearn: 0.4678542\ttotal: 264ms\tremaining: 211ms\n",
      "5:\tlearn: 0.4655216\ttotal: 326ms\tremaining: 163ms\n",
      "6:\tlearn: 0.4639614\ttotal: 391ms\tremaining: 112ms\n",
      "7:\tlearn: 0.4618543\ttotal: 448ms\tremaining: 56ms\n",
      "8:\tlearn: 0.4604753\ttotal: 508ms\tremaining: 0us\n",
      "[9, 0.3, 12, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.8ms\tremaining: 86.1ms\n",
      "1:\tlearn: 0.4778843\ttotal: 64.8ms\tremaining: 227ms\n",
      "2:\tlearn: 0.4738999\ttotal: 126ms\tremaining: 251ms\n",
      "3:\tlearn: 0.4696749\ttotal: 188ms\tremaining: 235ms\n",
      "4:\tlearn: 0.4678542\ttotal: 248ms\tremaining: 198ms\n",
      "5:\tlearn: 0.4655216\ttotal: 304ms\tremaining: 152ms\n",
      "6:\tlearn: 0.4639614\ttotal: 365ms\tremaining: 104ms\n",
      "7:\tlearn: 0.4618543\ttotal: 428ms\tremaining: 53.5ms\n",
      "8:\tlearn: 0.4604753\ttotal: 488ms\tremaining: 0us\n",
      "[9, 0.3, 12, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.2ms\tremaining: 97.7ms\n",
      "1:\tlearn: 0.4778843\ttotal: 75ms\tremaining: 263ms\n",
      "2:\tlearn: 0.4738999\ttotal: 136ms\tremaining: 271ms\n",
      "3:\tlearn: 0.4696749\ttotal: 199ms\tremaining: 249ms\n",
      "4:\tlearn: 0.4678542\ttotal: 263ms\tremaining: 210ms\n",
      "5:\tlearn: 0.4655216\ttotal: 321ms\tremaining: 161ms\n",
      "6:\tlearn: 0.4639614\ttotal: 379ms\tremaining: 108ms\n",
      "7:\tlearn: 0.4618543\ttotal: 439ms\tremaining: 54.9ms\n",
      "8:\tlearn: 0.4604753\ttotal: 505ms\tremaining: 0us\n",
      "[9, 0.3, 12, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 10ms\tremaining: 80.1ms\n",
      "1:\tlearn: 0.4778843\ttotal: 71.5ms\tremaining: 250ms\n",
      "2:\tlearn: 0.4738999\ttotal: 130ms\tremaining: 260ms\n",
      "3:\tlearn: 0.4696749\ttotal: 192ms\tremaining: 240ms\n",
      "4:\tlearn: 0.4678542\ttotal: 249ms\tremaining: 199ms\n",
      "5:\tlearn: 0.4655216\ttotal: 313ms\tremaining: 156ms\n",
      "6:\tlearn: 0.4639614\ttotal: 381ms\tremaining: 109ms\n",
      "7:\tlearn: 0.4618543\ttotal: 449ms\tremaining: 56.1ms\n",
      "8:\tlearn: 0.4604753\ttotal: 512ms\tremaining: 0us\n",
      "[9, 0.3, 13, -0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.2ms\tremaining: 81.8ms\n",
      "1:\tlearn: 0.4776303\ttotal: 128ms\tremaining: 448ms\n",
      "2:\tlearn: 0.4735011\ttotal: 251ms\tremaining: 501ms\n",
      "3:\tlearn: 0.4707331\ttotal: 308ms\tremaining: 385ms\n",
      "4:\tlearn: 0.4669265\ttotal: 435ms\tremaining: 348ms\n",
      "5:\tlearn: 0.4646028\ttotal: 499ms\tremaining: 249ms\n",
      "6:\tlearn: 0.4634280\ttotal: 506ms\tremaining: 144ms\n",
      "7:\tlearn: 0.4620786\ttotal: 629ms\tremaining: 78.6ms\n",
      "8:\tlearn: 0.4604731\ttotal: 750ms\tremaining: 0us\n",
      "[9, 0.3, 13, 0.3]\n",
      "0:\tlearn: 0.4850507\ttotal: 10.1ms\tremaining: 80.7ms\n",
      "1:\tlearn: 0.4776303\ttotal: 121ms\tremaining: 423ms\n",
      "2:\tlearn: 0.4735011\ttotal: 246ms\tremaining: 493ms\n",
      "3:\tlearn: 0.4707331\ttotal: 313ms\tremaining: 391ms\n",
      "4:\tlearn: 0.4669265\ttotal: 434ms\tremaining: 347ms\n",
      "5:\tlearn: 0.4646028\ttotal: 495ms\tremaining: 248ms\n",
      "6:\tlearn: 0.4634280\ttotal: 502ms\tremaining: 143ms\n",
      "7:\tlearn: 0.4620786\ttotal: 634ms\tremaining: 79.3ms\n",
      "8:\tlearn: 0.4604731\ttotal: 754ms\tremaining: 0us\n",
      "[9, 0.3, 13, 0.0]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.6ms\tremaining: 101ms\n",
      "1:\tlearn: 0.4776303\ttotal: 134ms\tremaining: 468ms\n",
      "2:\tlearn: 0.4735011\ttotal: 256ms\tremaining: 513ms\n",
      "3:\tlearn: 0.4707331\ttotal: 320ms\tremaining: 400ms\n",
      "4:\tlearn: 0.4669265\ttotal: 442ms\tremaining: 354ms\n",
      "5:\tlearn: 0.4646028\ttotal: 498ms\tremaining: 249ms\n",
      "6:\tlearn: 0.4634280\ttotal: 505ms\tremaining: 144ms\n",
      "7:\tlearn: 0.4620786\ttotal: 641ms\tremaining: 80.1ms\n",
      "8:\tlearn: 0.4604731\ttotal: 759ms\tremaining: 0us\n",
      "[9, 0.3, 13, 0.15]\n",
      "0:\tlearn: 0.4850507\ttotal: 12.4ms\tremaining: 99ms\n",
      "1:\tlearn: 0.4776303\ttotal: 126ms\tremaining: 441ms\n",
      "2:\tlearn: 0.4735011\ttotal: 252ms\tremaining: 503ms\n",
      "3:\tlearn: 0.4707331\ttotal: 320ms\tremaining: 400ms\n",
      "4:\tlearn: 0.4669265\ttotal: 454ms\tremaining: 363ms\n",
      "5:\tlearn: 0.4646028\ttotal: 509ms\tremaining: 255ms\n",
      "6:\tlearn: 0.4634280\ttotal: 516ms\tremaining: 147ms\n",
      "7:\tlearn: 0.4620786\ttotal: 641ms\tremaining: 80.1ms\n",
      "8:\tlearn: 0.4604731\ttotal: 776ms\tremaining: 0us\n",
      "[9, 0.3, 13, 0.2]\n",
      "0:\tlearn: 0.4850507\ttotal: 11.6ms\tremaining: 92.7ms\n",
      "1:\tlearn: 0.4776303\ttotal: 125ms\tremaining: 438ms\n",
      "2:\tlearn: 0.4735011\ttotal: 248ms\tremaining: 497ms\n",
      "3:\tlearn: 0.4707331\ttotal: 308ms\tremaining: 385ms\n",
      "4:\tlearn: 0.4669265\ttotal: 425ms\tremaining: 340ms\n",
      "5:\tlearn: 0.4646028\ttotal: 479ms\tremaining: 240ms\n",
      "6:\tlearn: 0.4634280\ttotal: 485ms\tremaining: 139ms\n",
      "7:\tlearn: 0.4620786\ttotal: 604ms\tremaining: 75.6ms\n",
      "8:\tlearn: 0.4604731\ttotal: 731ms\tremaining: 0us\n",
      "[9, 0.8, 6, -0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 9.79ms\tremaining: 78.3ms\n",
      "1:\tlearn: 0.4707614\ttotal: 14.4ms\tremaining: 50.4ms\n",
      "2:\tlearn: 0.4667365\ttotal: 19ms\tremaining: 38.1ms\n",
      "3:\tlearn: 0.4636906\ttotal: 23.9ms\tremaining: 29.9ms\n",
      "4:\tlearn: 0.4617121\ttotal: 28.2ms\tremaining: 22.6ms\n",
      "5:\tlearn: 0.4596172\ttotal: 34.9ms\tremaining: 17.5ms\n",
      "6:\tlearn: 0.4582917\ttotal: 39.5ms\tremaining: 11.3ms\n",
      "7:\tlearn: 0.4560211\ttotal: 43.6ms\tremaining: 5.45ms\n",
      "8:\tlearn: 0.4544331\ttotal: 47.6ms\tremaining: 0us\n",
      "[9, 0.8, 6, 0.3]\n",
      "0:\tlearn: 0.4762695\ttotal: 11.6ms\tremaining: 92.6ms\n",
      "1:\tlearn: 0.4707614\ttotal: 16.6ms\tremaining: 58ms\n",
      "2:\tlearn: 0.4667365\ttotal: 20.8ms\tremaining: 41.6ms\n",
      "3:\tlearn: 0.4636906\ttotal: 25ms\tremaining: 31.2ms\n",
      "4:\tlearn: 0.4617121\ttotal: 30ms\tremaining: 24ms\n",
      "5:\tlearn: 0.4596172\ttotal: 34.2ms\tremaining: 17.1ms\n",
      "6:\tlearn: 0.4582917\ttotal: 38.7ms\tremaining: 11.1ms\n",
      "7:\tlearn: 0.4560211\ttotal: 43.4ms\tremaining: 5.42ms\n",
      "8:\tlearn: 0.4544331\ttotal: 47.8ms\tremaining: 0us\n",
      "[9, 0.8, 6, 0.0]\n",
      "0:\tlearn: 0.4762695\ttotal: 5.08ms\tremaining: 40.6ms\n",
      "1:\tlearn: 0.4707614\ttotal: 9.13ms\tremaining: 32ms\n",
      "2:\tlearn: 0.4667365\ttotal: 13.9ms\tremaining: 27.8ms\n",
      "3:\tlearn: 0.4636906\ttotal: 19.9ms\tremaining: 24.9ms\n",
      "4:\tlearn: 0.4617121\ttotal: 24.3ms\tremaining: 19.5ms\n",
      "5:\tlearn: 0.4596172\ttotal: 33ms\tremaining: 16.5ms\n",
      "6:\tlearn: 0.4582917\ttotal: 38ms\tremaining: 10.9ms\n",
      "7:\tlearn: 0.4560211\ttotal: 43ms\tremaining: 5.38ms\n",
      "8:\tlearn: 0.4544331\ttotal: 47.9ms\tremaining: 0us\n",
      "[9, 0.8, 6, 0.15]\n",
      "0:\tlearn: 0.4762695\ttotal: 5.74ms\tremaining: 45.9ms\n",
      "1:\tlearn: 0.4707614\ttotal: 10.4ms\tremaining: 36.5ms\n",
      "2:\tlearn: 0.4667365\ttotal: 15.5ms\tremaining: 30.9ms\n",
      "3:\tlearn: 0.4636906\ttotal: 20.9ms\tremaining: 26.1ms\n",
      "4:\tlearn: 0.4617121\ttotal: 25.4ms\tremaining: 20.4ms\n",
      "5:\tlearn: 0.4596172\ttotal: 29.8ms\tremaining: 14.9ms\n",
      "6:\tlearn: 0.4582917\ttotal: 34.2ms\tremaining: 9.77ms\n",
      "7:\tlearn: 0.4560211\ttotal: 38.8ms\tremaining: 4.85ms\n",
      "8:\tlearn: 0.4544331\ttotal: 43.1ms\tremaining: 0us\n",
      "[9, 0.8, 6, 0.2]\n",
      "0:\tlearn: 0.4762695\ttotal: 4.15ms\tremaining: 33.2ms\n",
      "1:\tlearn: 0.4707614\ttotal: 8.35ms\tremaining: 29.2ms\n",
      "2:\tlearn: 0.4667365\ttotal: 12.7ms\tremaining: 25.4ms\n",
      "3:\tlearn: 0.4636906\ttotal: 17ms\tremaining: 21.2ms\n",
      "4:\tlearn: 0.4617121\ttotal: 21ms\tremaining: 16.8ms\n",
      "5:\tlearn: 0.4596172\ttotal: 25.1ms\tremaining: 12.6ms\n",
      "6:\tlearn: 0.4582917\ttotal: 29.7ms\tremaining: 8.49ms\n",
      "7:\tlearn: 0.4560211\ttotal: 34.5ms\tremaining: 4.32ms\n",
      "8:\tlearn: 0.4544331\ttotal: 39.9ms\tremaining: 0us\n",
      "[9, 0.8, 15, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.4ms\tremaining: 83.5ms\n",
      "1:\tlearn: 0.4658921\ttotal: 509ms\tremaining: 1.78s\n",
      "2:\tlearn: 0.4614984\ttotal: 990ms\tremaining: 1.98s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.49s\tremaining: 1.86s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.95s\tremaining: 1.56s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.51s\tremaining: 1.25s\n",
      "6:\tlearn: 0.4499802\ttotal: 3.01s\tremaining: 860ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.53s\tremaining: 442ms\n",
      "8:\tlearn: 0.4433315\ttotal: 4.17s\tremaining: 0us\n",
      "[9, 0.8, 15, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.8ms\tremaining: 86.3ms\n",
      "1:\tlearn: 0.4658921\ttotal: 516ms\tremaining: 1.8s\n",
      "2:\tlearn: 0.4614984\ttotal: 1.04s\tremaining: 2.07s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.53s\tremaining: 1.91s\n",
      "4:\tlearn: 0.4540621\ttotal: 2.13s\tremaining: 1.71s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.6s\tremaining: 1.3s\n",
      "6:\tlearn: 0.4499802\ttotal: 3.17s\tremaining: 907ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.79s\tremaining: 474ms\n",
      "8:\tlearn: 0.4433315\ttotal: 4.37s\tremaining: 0us\n",
      "[9, 0.8, 15, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.9ms\tremaining: 86.9ms\n",
      "1:\tlearn: 0.4658921\ttotal: 483ms\tremaining: 1.69s\n",
      "2:\tlearn: 0.4614984\ttotal: 974ms\tremaining: 1.95s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.47s\tremaining: 1.84s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.93s\tremaining: 1.54s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.47s\tremaining: 1.24s\n",
      "6:\tlearn: 0.4499802\ttotal: 3s\tremaining: 857ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.5s\tremaining: 437ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.99s\tremaining: 0us\n",
      "[9, 0.8, 15, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.5ms\tremaining: 84.1ms\n",
      "1:\tlearn: 0.4658921\ttotal: 472ms\tremaining: 1.65s\n",
      "2:\tlearn: 0.4614984\ttotal: 973ms\tremaining: 1.95s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.43s\tremaining: 1.78s\n",
      "4:\tlearn: 0.4540621\ttotal: 1.93s\tremaining: 1.54s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.42s\tremaining: 1.21s\n",
      "6:\tlearn: 0.4499802\ttotal: 2.89s\tremaining: 825ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.36s\tremaining: 420ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.83s\tremaining: 0us\n",
      "[9, 0.8, 15, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 15.6ms\tremaining: 125ms\n",
      "1:\tlearn: 0.4658921\ttotal: 522ms\tremaining: 1.83s\n",
      "2:\tlearn: 0.4614984\ttotal: 996ms\tremaining: 1.99s\n",
      "3:\tlearn: 0.4572383\ttotal: 1.5s\tremaining: 1.88s\n",
      "4:\tlearn: 0.4540621\ttotal: 2s\tremaining: 1.6s\n",
      "5:\tlearn: 0.4519233\ttotal: 2.47s\tremaining: 1.23s\n",
      "6:\tlearn: 0.4499802\ttotal: 2.95s\tremaining: 842ms\n",
      "7:\tlearn: 0.4479680\ttotal: 3.42s\tremaining: 428ms\n",
      "8:\tlearn: 0.4433315\ttotal: 3.91s\tremaining: 0us\n",
      "[9, 0.8, 10, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 10.6ms\tremaining: 84.8ms\n",
      "1:\tlearn: 0.4684354\ttotal: 26ms\tremaining: 91ms\n",
      "2:\tlearn: 0.4642800\ttotal: 40.3ms\tremaining: 80.6ms\n",
      "3:\tlearn: 0.4627032\ttotal: 43.1ms\tremaining: 53.9ms\n",
      "4:\tlearn: 0.4607357\ttotal: 57.9ms\tremaining: 46.3ms\n",
      "5:\tlearn: 0.4583929\ttotal: 73.9ms\tremaining: 37ms\n",
      "6:\tlearn: 0.4565229\ttotal: 93ms\tremaining: 26.6ms\n",
      "7:\tlearn: 0.4531244\ttotal: 111ms\tremaining: 13.8ms\n",
      "8:\tlearn: 0.4517706\ttotal: 128ms\tremaining: 0us\n",
      "[9, 0.8, 10, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.39ms\tremaining: 75.1ms\n",
      "1:\tlearn: 0.4684354\ttotal: 26.1ms\tremaining: 91.4ms\n",
      "2:\tlearn: 0.4642800\ttotal: 42.8ms\tremaining: 85.6ms\n",
      "3:\tlearn: 0.4627032\ttotal: 46.3ms\tremaining: 57.9ms\n",
      "4:\tlearn: 0.4607357\ttotal: 63.1ms\tremaining: 50.5ms\n",
      "5:\tlearn: 0.4583929\ttotal: 79.1ms\tremaining: 39.5ms\n",
      "6:\tlearn: 0.4565229\ttotal: 96.7ms\tremaining: 27.6ms\n",
      "7:\tlearn: 0.4531244\ttotal: 114ms\tremaining: 14.3ms\n",
      "8:\tlearn: 0.4517706\ttotal: 132ms\tremaining: 0us\n",
      "[9, 0.8, 10, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 12.1ms\tremaining: 97.2ms\n",
      "1:\tlearn: 0.4684354\ttotal: 27.2ms\tremaining: 95.2ms\n",
      "2:\tlearn: 0.4642800\ttotal: 44.3ms\tremaining: 88.5ms\n",
      "3:\tlearn: 0.4627032\ttotal: 47.4ms\tremaining: 59.3ms\n",
      "4:\tlearn: 0.4607357\ttotal: 63.2ms\tremaining: 50.6ms\n",
      "5:\tlearn: 0.4583929\ttotal: 79.1ms\tremaining: 39.6ms\n",
      "6:\tlearn: 0.4565229\ttotal: 95.1ms\tremaining: 27.2ms\n",
      "7:\tlearn: 0.4531244\ttotal: 114ms\tremaining: 14.3ms\n",
      "8:\tlearn: 0.4517706\ttotal: 131ms\tremaining: 0us\n",
      "[9, 0.8, 10, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 15.2ms\tremaining: 122ms\n",
      "1:\tlearn: 0.4684354\ttotal: 30.6ms\tremaining: 107ms\n",
      "2:\tlearn: 0.4642800\ttotal: 46.2ms\tremaining: 92.4ms\n",
      "3:\tlearn: 0.4627032\ttotal: 49.5ms\tremaining: 61.8ms\n",
      "4:\tlearn: 0.4607357\ttotal: 64.7ms\tremaining: 51.8ms\n",
      "5:\tlearn: 0.4583929\ttotal: 80.6ms\tremaining: 40.3ms\n",
      "6:\tlearn: 0.4565229\ttotal: 95.1ms\tremaining: 27.2ms\n",
      "7:\tlearn: 0.4531244\ttotal: 111ms\tremaining: 13.8ms\n",
      "8:\tlearn: 0.4517706\ttotal: 124ms\tremaining: 0us\n",
      "[9, 0.8, 10, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.5ms\tremaining: 91.7ms\n",
      "1:\tlearn: 0.4684354\ttotal: 29ms\tremaining: 101ms\n",
      "2:\tlearn: 0.4642800\ttotal: 46.2ms\tremaining: 92.4ms\n",
      "3:\tlearn: 0.4627032\ttotal: 49.7ms\tremaining: 62.1ms\n",
      "4:\tlearn: 0.4607357\ttotal: 66.4ms\tremaining: 53.1ms\n",
      "5:\tlearn: 0.4583929\ttotal: 81.9ms\tremaining: 40.9ms\n",
      "6:\tlearn: 0.4565229\ttotal: 95.7ms\tremaining: 27.4ms\n",
      "7:\tlearn: 0.4531244\ttotal: 111ms\tremaining: 13.8ms\n",
      "8:\tlearn: 0.4517706\ttotal: 126ms\tremaining: 0us\n",
      "[9, 0.8, 8, -0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 15.8ms\tremaining: 126ms\n",
      "1:\tlearn: 0.4682512\ttotal: 23.6ms\tremaining: 82.5ms\n",
      "2:\tlearn: 0.4650605\ttotal: 31.2ms\tremaining: 62.5ms\n",
      "3:\tlearn: 0.4630741\ttotal: 40.8ms\tremaining: 51ms\n",
      "4:\tlearn: 0.4600410\ttotal: 48.9ms\tremaining: 39.1ms\n",
      "5:\tlearn: 0.4577069\ttotal: 56.5ms\tremaining: 28.3ms\n",
      "6:\tlearn: 0.4559546\ttotal: 64.1ms\tremaining: 18.3ms\n",
      "7:\tlearn: 0.4543265\ttotal: 73.9ms\tremaining: 9.23ms\n",
      "8:\tlearn: 0.4528626\ttotal: 81.4ms\tremaining: 0us\n",
      "[9, 0.8, 8, 0.3]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.09ms\tremaining: 72.7ms\n",
      "1:\tlearn: 0.4682512\ttotal: 17.1ms\tremaining: 59.8ms\n",
      "2:\tlearn: 0.4650605\ttotal: 24.3ms\tremaining: 48.5ms\n",
      "3:\tlearn: 0.4630741\ttotal: 32.3ms\tremaining: 40.4ms\n",
      "4:\tlearn: 0.4600410\ttotal: 40.2ms\tremaining: 32.2ms\n",
      "5:\tlearn: 0.4577069\ttotal: 47.5ms\tremaining: 23.8ms\n",
      "6:\tlearn: 0.4559546\ttotal: 55.1ms\tremaining: 15.7ms\n",
      "7:\tlearn: 0.4543265\ttotal: 62ms\tremaining: 7.75ms\n",
      "8:\tlearn: 0.4528626\ttotal: 69.1ms\tremaining: 0us\n",
      "[9, 0.8, 8, 0.0]\n",
      "0:\tlearn: 0.4757928\ttotal: 11.3ms\tremaining: 90.5ms\n",
      "1:\tlearn: 0.4682512\ttotal: 19ms\tremaining: 66.4ms\n",
      "2:\tlearn: 0.4650605\ttotal: 26.4ms\tremaining: 52.9ms\n",
      "3:\tlearn: 0.4630741\ttotal: 34.8ms\tremaining: 43.5ms\n",
      "4:\tlearn: 0.4600410\ttotal: 42.4ms\tremaining: 33.9ms\n",
      "5:\tlearn: 0.4577069\ttotal: 49.8ms\tremaining: 24.9ms\n",
      "6:\tlearn: 0.4559546\ttotal: 56.9ms\tremaining: 16.3ms\n",
      "7:\tlearn: 0.4543265\ttotal: 65.4ms\tremaining: 8.17ms\n",
      "8:\tlearn: 0.4528626\ttotal: 72.5ms\tremaining: 0us\n",
      "[9, 0.8, 8, 0.15]\n",
      "0:\tlearn: 0.4757928\ttotal: 6.76ms\tremaining: 54.1ms\n",
      "1:\tlearn: 0.4682512\ttotal: 13.7ms\tremaining: 47.8ms\n",
      "2:\tlearn: 0.4650605\ttotal: 20.4ms\tremaining: 40.8ms\n",
      "3:\tlearn: 0.4630741\ttotal: 27.9ms\tremaining: 34.9ms\n",
      "4:\tlearn: 0.4600410\ttotal: 34.8ms\tremaining: 27.8ms\n",
      "5:\tlearn: 0.4577069\ttotal: 42.1ms\tremaining: 21.1ms\n",
      "6:\tlearn: 0.4559546\ttotal: 48.8ms\tremaining: 14ms\n",
      "7:\tlearn: 0.4543265\ttotal: 55.9ms\tremaining: 6.99ms\n",
      "8:\tlearn: 0.4528626\ttotal: 63ms\tremaining: 0us\n",
      "[9, 0.8, 8, 0.2]\n",
      "0:\tlearn: 0.4757928\ttotal: 9.45ms\tremaining: 75.6ms\n",
      "1:\tlearn: 0.4682512\ttotal: 16.3ms\tremaining: 56.9ms\n",
      "2:\tlearn: 0.4650605\ttotal: 23.5ms\tremaining: 47ms\n",
      "3:\tlearn: 0.4630741\ttotal: 30.9ms\tremaining: 38.7ms\n",
      "4:\tlearn: 0.4600410\ttotal: 37.9ms\tremaining: 30.3ms\n",
      "5:\tlearn: 0.4577069\ttotal: 44.9ms\tremaining: 22.4ms\n",
      "6:\tlearn: 0.4559546\ttotal: 52.4ms\tremaining: 15ms\n",
      "7:\tlearn: 0.4543265\ttotal: 60.2ms\tremaining: 7.53ms\n",
      "8:\tlearn: 0.4528626\ttotal: 66.8ms\tremaining: 0us\n",
      "[9, 0.8, 7, -0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 6.94ms\tremaining: 55.5ms\n",
      "1:\tlearn: 0.4687965\ttotal: 12.1ms\tremaining: 42.5ms\n",
      "2:\tlearn: 0.4653862\ttotal: 17.3ms\tremaining: 34.6ms\n",
      "3:\tlearn: 0.4622296\ttotal: 22.6ms\tremaining: 28.3ms\n",
      "4:\tlearn: 0.4598883\ttotal: 27.8ms\tremaining: 22.3ms\n",
      "5:\tlearn: 0.4581321\ttotal: 34.3ms\tremaining: 17.2ms\n",
      "6:\tlearn: 0.4567709\ttotal: 39.9ms\tremaining: 11.4ms\n",
      "7:\tlearn: 0.4533516\ttotal: 45.3ms\tremaining: 5.67ms\n",
      "8:\tlearn: 0.4517451\ttotal: 50.7ms\tremaining: 0us\n",
      "[9, 0.8, 7, 0.3]\n",
      "0:\tlearn: 0.4762583\ttotal: 7.18ms\tremaining: 57.5ms\n",
      "1:\tlearn: 0.4687965\ttotal: 12.4ms\tremaining: 43.2ms\n",
      "2:\tlearn: 0.4653862\ttotal: 17.7ms\tremaining: 35.3ms\n",
      "3:\tlearn: 0.4622296\ttotal: 22.9ms\tremaining: 28.6ms\n",
      "4:\tlearn: 0.4598883\ttotal: 28ms\tremaining: 22.4ms\n",
      "5:\tlearn: 0.4581321\ttotal: 33.1ms\tremaining: 16.5ms\n",
      "6:\tlearn: 0.4567709\ttotal: 39.4ms\tremaining: 11.3ms\n",
      "7:\tlearn: 0.4533516\ttotal: 44.7ms\tremaining: 5.59ms\n",
      "8:\tlearn: 0.4517451\ttotal: 49.8ms\tremaining: 0us\n",
      "[9, 0.8, 7, 0.0]\n",
      "0:\tlearn: 0.4762583\ttotal: 10ms\tremaining: 80ms\n",
      "1:\tlearn: 0.4687965\ttotal: 15.7ms\tremaining: 55ms\n",
      "2:\tlearn: 0.4653862\ttotal: 21.2ms\tremaining: 42.4ms\n",
      "3:\tlearn: 0.4622296\ttotal: 26.8ms\tremaining: 33.5ms\n",
      "4:\tlearn: 0.4598883\ttotal: 32.3ms\tremaining: 25.8ms\n",
      "5:\tlearn: 0.4581321\ttotal: 37.5ms\tremaining: 18.8ms\n",
      "6:\tlearn: 0.4567709\ttotal: 43.3ms\tremaining: 12.4ms\n",
      "7:\tlearn: 0.4533516\ttotal: 48.4ms\tremaining: 6.05ms\n",
      "8:\tlearn: 0.4517451\ttotal: 53.6ms\tremaining: 0us\n",
      "[9, 0.8, 7, 0.15]\n",
      "0:\tlearn: 0.4762583\ttotal: 6.1ms\tremaining: 48.8ms\n",
      "1:\tlearn: 0.4687965\ttotal: 11.4ms\tremaining: 40ms\n",
      "2:\tlearn: 0.4653862\ttotal: 16.4ms\tremaining: 32.8ms\n",
      "3:\tlearn: 0.4622296\ttotal: 21.6ms\tremaining: 27ms\n",
      "4:\tlearn: 0.4598883\ttotal: 26.5ms\tremaining: 21.2ms\n",
      "5:\tlearn: 0.4581321\ttotal: 32.3ms\tremaining: 16.1ms\n",
      "6:\tlearn: 0.4567709\ttotal: 37.6ms\tremaining: 10.7ms\n",
      "7:\tlearn: 0.4533516\ttotal: 43.9ms\tremaining: 5.48ms\n",
      "8:\tlearn: 0.4517451\ttotal: 49ms\tremaining: 0us\n",
      "[9, 0.8, 7, 0.2]\n",
      "0:\tlearn: 0.4762583\ttotal: 6.77ms\tremaining: 54.2ms\n",
      "1:\tlearn: 0.4687965\ttotal: 12.5ms\tremaining: 43.6ms\n",
      "2:\tlearn: 0.4653862\ttotal: 17.9ms\tremaining: 35.8ms\n",
      "3:\tlearn: 0.4622296\ttotal: 23.4ms\tremaining: 29.2ms\n",
      "4:\tlearn: 0.4598883\ttotal: 29.5ms\tremaining: 23.6ms\n",
      "5:\tlearn: 0.4581321\ttotal: 34.9ms\tremaining: 17.4ms\n",
      "6:\tlearn: 0.4567709\ttotal: 40.4ms\tremaining: 11.6ms\n",
      "7:\tlearn: 0.4533516\ttotal: 46.3ms\tremaining: 5.79ms\n",
      "8:\tlearn: 0.4517451\ttotal: 51.4ms\tremaining: 0us\n",
      "[9, 0.55, 6, -0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 8.08ms\tremaining: 64.6ms\n",
      "1:\tlearn: 0.4730186\ttotal: 12.8ms\tremaining: 44.8ms\n",
      "2:\tlearn: 0.4702860\ttotal: 18.7ms\tremaining: 37.4ms\n",
      "3:\tlearn: 0.4675422\ttotal: 23.3ms\tremaining: 29.1ms\n",
      "4:\tlearn: 0.4655547\ttotal: 28ms\tremaining: 22.4ms\n",
      "5:\tlearn: 0.4641129\ttotal: 36.2ms\tremaining: 18.1ms\n",
      "6:\tlearn: 0.4622549\ttotal: 40.8ms\tremaining: 11.7ms\n",
      "7:\tlearn: 0.4607061\ttotal: 45.5ms\tremaining: 5.68ms\n",
      "8:\tlearn: 0.4594070\ttotal: 49.8ms\tremaining: 0us\n",
      "[9, 0.55, 6, 0.3]\n",
      "0:\tlearn: 0.4795967\ttotal: 9.93ms\tremaining: 79.4ms\n",
      "1:\tlearn: 0.4730186\ttotal: 14.5ms\tremaining: 50.8ms\n",
      "2:\tlearn: 0.4702860\ttotal: 18.9ms\tremaining: 37.8ms\n",
      "3:\tlearn: 0.4675422\ttotal: 23.2ms\tremaining: 29ms\n",
      "4:\tlearn: 0.4655547\ttotal: 27.7ms\tremaining: 22.1ms\n",
      "5:\tlearn: 0.4641129\ttotal: 32.6ms\tremaining: 16.3ms\n",
      "6:\tlearn: 0.4622549\ttotal: 37.4ms\tremaining: 10.7ms\n",
      "7:\tlearn: 0.4607061\ttotal: 41.8ms\tremaining: 5.23ms\n",
      "8:\tlearn: 0.4594070\ttotal: 46.8ms\tremaining: 0us\n",
      "[9, 0.55, 6, 0.0]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.53ms\tremaining: 36.2ms\n",
      "1:\tlearn: 0.4730186\ttotal: 8.82ms\tremaining: 30.9ms\n",
      "2:\tlearn: 0.4702860\ttotal: 12.7ms\tremaining: 25.4ms\n",
      "3:\tlearn: 0.4675422\ttotal: 17.2ms\tremaining: 21.5ms\n",
      "4:\tlearn: 0.4655547\ttotal: 21.6ms\tremaining: 17.2ms\n",
      "5:\tlearn: 0.4641129\ttotal: 25.8ms\tremaining: 12.9ms\n",
      "6:\tlearn: 0.4622549\ttotal: 30.5ms\tremaining: 8.71ms\n",
      "7:\tlearn: 0.4607061\ttotal: 35.4ms\tremaining: 4.42ms\n",
      "8:\tlearn: 0.4594070\ttotal: 40.1ms\tremaining: 0us\n",
      "[9, 0.55, 6, 0.15]\n",
      "0:\tlearn: 0.4795967\ttotal: 4.32ms\tremaining: 34.6ms\n",
      "1:\tlearn: 0.4730186\ttotal: 9.37ms\tremaining: 32.8ms\n",
      "2:\tlearn: 0.4702860\ttotal: 14.2ms\tremaining: 28.3ms\n",
      "3:\tlearn: 0.4675422\ttotal: 19.1ms\tremaining: 23.9ms\n",
      "4:\tlearn: 0.4655547\ttotal: 24.7ms\tremaining: 19.8ms\n",
      "5:\tlearn: 0.4641129\ttotal: 33.6ms\tremaining: 16.8ms\n",
      "6:\tlearn: 0.4622549\ttotal: 38.4ms\tremaining: 11ms\n",
      "7:\tlearn: 0.4607061\ttotal: 42.7ms\tremaining: 5.34ms\n",
      "8:\tlearn: 0.4594070\ttotal: 47ms\tremaining: 0us\n",
      "[9, 0.55, 6, 0.2]\n",
      "0:\tlearn: 0.4795967\ttotal: 13ms\tremaining: 104ms\n",
      "1:\tlearn: 0.4730186\ttotal: 17.9ms\tremaining: 62.6ms\n",
      "2:\tlearn: 0.4702860\ttotal: 22.8ms\tremaining: 45.6ms\n",
      "3:\tlearn: 0.4675422\ttotal: 27.7ms\tremaining: 34.6ms\n",
      "4:\tlearn: 0.4655547\ttotal: 32.6ms\tremaining: 26.1ms\n",
      "5:\tlearn: 0.4641129\ttotal: 38.1ms\tremaining: 19.1ms\n",
      "6:\tlearn: 0.4622549\ttotal: 42.3ms\tremaining: 12.1ms\n",
      "7:\tlearn: 0.4607061\ttotal: 46.4ms\tremaining: 5.8ms\n",
      "8:\tlearn: 0.4594070\ttotal: 50.9ms\tremaining: 0us\n",
      "[9, 0.55, 15, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.1ms\tremaining: 81.2ms\n",
      "1:\tlearn: 0.4689110\ttotal: 517ms\tremaining: 1.81s\n",
      "2:\tlearn: 0.4640795\ttotal: 1.02s\tremaining: 2.04s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.54s\tremaining: 1.93s\n",
      "4:\tlearn: 0.4573812\ttotal: 2.07s\tremaining: 1.66s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.59s\tremaining: 1.29s\n",
      "6:\tlearn: 0.4530263\ttotal: 3.08s\tremaining: 881ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.58s\tremaining: 447ms\n",
      "8:\tlearn: 0.4477925\ttotal: 4.11s\tremaining: 0us\n",
      "[9, 0.55, 15, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.7ms\tremaining: 85.8ms\n",
      "1:\tlearn: 0.4689110\ttotal: 500ms\tremaining: 1.75s\n",
      "2:\tlearn: 0.4640795\ttotal: 969ms\tremaining: 1.94s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.44s\tremaining: 1.8s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.9s\tremaining: 1.52s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.4s\tremaining: 1.2s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.89s\tremaining: 827ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.39s\tremaining: 424ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.89s\tremaining: 0us\n",
      "[9, 0.55, 15, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.7ms\tremaining: 85.6ms\n",
      "1:\tlearn: 0.4689110\ttotal: 490ms\tremaining: 1.72s\n",
      "2:\tlearn: 0.4640795\ttotal: 944ms\tremaining: 1.89s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.42s\tremaining: 1.78s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.89s\tremaining: 1.51s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.37s\tremaining: 1.19s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.84s\tremaining: 811ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.31s\tremaining: 414ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.77s\tremaining: 0us\n",
      "[9, 0.55, 15, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 8.82ms\tremaining: 70.5ms\n",
      "1:\tlearn: 0.4689110\ttotal: 463ms\tremaining: 1.62s\n",
      "2:\tlearn: 0.4640795\ttotal: 921ms\tremaining: 1.84s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.41s\tremaining: 1.76s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.89s\tremaining: 1.51s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.37s\tremaining: 1.18s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.84s\tremaining: 811ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.32s\tremaining: 416ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.8s\tremaining: 0us\n",
      "[9, 0.55, 15, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.2ms\tremaining: 73.6ms\n",
      "1:\tlearn: 0.4689110\ttotal: 500ms\tremaining: 1.75s\n",
      "2:\tlearn: 0.4640795\ttotal: 999ms\tremaining: 2s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.45s\tremaining: 1.81s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.92s\tremaining: 1.54s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.38s\tremaining: 1.19s\n",
      "6:\tlearn: 0.4530263\ttotal: 2.84s\tremaining: 812ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.33s\tremaining: 416ms\n",
      "8:\tlearn: 0.4477925\ttotal: 3.83s\tremaining: 0us\n",
      "[9, 0.55, 10, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.46ms\tremaining: 75.7ms\n",
      "1:\tlearn: 0.4715198\ttotal: 24.1ms\tremaining: 84.5ms\n",
      "2:\tlearn: 0.4676485\ttotal: 39ms\tremaining: 78ms\n",
      "3:\tlearn: 0.4663151\ttotal: 41.5ms\tremaining: 51.9ms\n",
      "4:\tlearn: 0.4641480\ttotal: 55.9ms\tremaining: 44.8ms\n",
      "5:\tlearn: 0.4609741\ttotal: 70.7ms\tremaining: 35.4ms\n",
      "6:\tlearn: 0.4590071\ttotal: 85.9ms\tremaining: 24.5ms\n",
      "7:\tlearn: 0.4568040\ttotal: 104ms\tremaining: 13.1ms\n",
      "8:\tlearn: 0.4556349\ttotal: 121ms\tremaining: 0us\n",
      "[9, 0.55, 10, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 11.1ms\tremaining: 88.4ms\n",
      "1:\tlearn: 0.4715198\ttotal: 28.7ms\tremaining: 100ms\n",
      "2:\tlearn: 0.4676485\ttotal: 46.7ms\tremaining: 93.4ms\n",
      "3:\tlearn: 0.4663151\ttotal: 49.8ms\tremaining: 62.2ms\n",
      "4:\tlearn: 0.4641480\ttotal: 66.3ms\tremaining: 53ms\n",
      "5:\tlearn: 0.4609741\ttotal: 83.1ms\tremaining: 41.5ms\n",
      "6:\tlearn: 0.4590071\ttotal: 99.1ms\tremaining: 28.3ms\n",
      "7:\tlearn: 0.4568040\ttotal: 115ms\tremaining: 14.4ms\n",
      "8:\tlearn: 0.4556349\ttotal: 131ms\tremaining: 0us\n",
      "[9, 0.55, 10, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.5ms\tremaining: 84.4ms\n",
      "1:\tlearn: 0.4715198\ttotal: 27.2ms\tremaining: 95.3ms\n",
      "2:\tlearn: 0.4676485\ttotal: 45.1ms\tremaining: 90.3ms\n",
      "3:\tlearn: 0.4663151\ttotal: 48.4ms\tremaining: 60.5ms\n",
      "4:\tlearn: 0.4641480\ttotal: 65.3ms\tremaining: 52.2ms\n",
      "5:\tlearn: 0.4609741\ttotal: 81.4ms\tremaining: 40.7ms\n",
      "6:\tlearn: 0.4590071\ttotal: 96.6ms\tremaining: 27.6ms\n",
      "7:\tlearn: 0.4568040\ttotal: 112ms\tremaining: 14.1ms\n",
      "8:\tlearn: 0.4556349\ttotal: 128ms\tremaining: 0us\n",
      "[9, 0.55, 10, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 14.5ms\tremaining: 116ms\n",
      "1:\tlearn: 0.4715198\ttotal: 31.8ms\tremaining: 111ms\n",
      "2:\tlearn: 0.4676485\ttotal: 48ms\tremaining: 95.9ms\n",
      "3:\tlearn: 0.4663151\ttotal: 51.2ms\tremaining: 64ms\n",
      "4:\tlearn: 0.4641480\ttotal: 67.5ms\tremaining: 54ms\n",
      "5:\tlearn: 0.4609741\ttotal: 83.7ms\tremaining: 41.8ms\n",
      "6:\tlearn: 0.4590071\ttotal: 101ms\tremaining: 28.7ms\n",
      "7:\tlearn: 0.4568040\ttotal: 117ms\tremaining: 14.6ms\n",
      "8:\tlearn: 0.4556349\ttotal: 133ms\tremaining: 0us\n",
      "[9, 0.55, 10, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.89ms\tremaining: 79.1ms\n",
      "1:\tlearn: 0.4715198\ttotal: 26.1ms\tremaining: 91.2ms\n",
      "2:\tlearn: 0.4676485\ttotal: 42.7ms\tremaining: 85.3ms\n",
      "3:\tlearn: 0.4663151\ttotal: 45.5ms\tremaining: 56.9ms\n",
      "4:\tlearn: 0.4641480\ttotal: 60.8ms\tremaining: 48.6ms\n",
      "5:\tlearn: 0.4609741\ttotal: 77.1ms\tremaining: 38.6ms\n",
      "6:\tlearn: 0.4590071\ttotal: 92.9ms\tremaining: 26.5ms\n",
      "7:\tlearn: 0.4568040\ttotal: 109ms\tremaining: 13.6ms\n",
      "8:\tlearn: 0.4556349\ttotal: 124ms\tremaining: 0us\n",
      "[9, 0.55, 12, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.19ms\tremaining: 73.5ms\n",
      "1:\tlearn: 0.4704514\ttotal: 68.2ms\tremaining: 239ms\n",
      "2:\tlearn: 0.4668875\ttotal: 122ms\tremaining: 244ms\n",
      "3:\tlearn: 0.4641234\ttotal: 177ms\tremaining: 221ms\n",
      "4:\tlearn: 0.4616543\ttotal: 234ms\tremaining: 187ms\n",
      "5:\tlearn: 0.4587449\ttotal: 300ms\tremaining: 150ms\n",
      "6:\tlearn: 0.4567311\ttotal: 360ms\tremaining: 103ms\n",
      "7:\tlearn: 0.4540933\ttotal: 421ms\tremaining: 52.6ms\n",
      "8:\tlearn: 0.4532213\ttotal: 478ms\tremaining: 0us\n",
      "[9, 0.55, 12, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.5ms\tremaining: 100ms\n",
      "1:\tlearn: 0.4704514\ttotal: 76.3ms\tremaining: 267ms\n",
      "2:\tlearn: 0.4668875\ttotal: 131ms\tremaining: 262ms\n",
      "3:\tlearn: 0.4641234\ttotal: 194ms\tremaining: 242ms\n",
      "4:\tlearn: 0.4616543\ttotal: 257ms\tremaining: 206ms\n",
      "5:\tlearn: 0.4587449\ttotal: 317ms\tremaining: 158ms\n",
      "6:\tlearn: 0.4567311\ttotal: 378ms\tremaining: 108ms\n",
      "7:\tlearn: 0.4540933\ttotal: 439ms\tremaining: 54.9ms\n",
      "8:\tlearn: 0.4532213\ttotal: 495ms\tremaining: 0us\n",
      "[9, 0.55, 12, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.1ms\tremaining: 96.9ms\n",
      "1:\tlearn: 0.4704514\ttotal: 65.6ms\tremaining: 229ms\n",
      "2:\tlearn: 0.4668875\ttotal: 128ms\tremaining: 257ms\n",
      "3:\tlearn: 0.4641234\ttotal: 191ms\tremaining: 239ms\n",
      "4:\tlearn: 0.4616543\ttotal: 253ms\tremaining: 202ms\n",
      "5:\tlearn: 0.4587449\ttotal: 314ms\tremaining: 157ms\n",
      "6:\tlearn: 0.4567311\ttotal: 373ms\tremaining: 107ms\n",
      "7:\tlearn: 0.4540933\ttotal: 437ms\tremaining: 54.7ms\n",
      "8:\tlearn: 0.4532213\ttotal: 505ms\tremaining: 0us\n",
      "[9, 0.55, 12, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.2ms\tremaining: 97.8ms\n",
      "1:\tlearn: 0.4704514\ttotal: 71.7ms\tremaining: 251ms\n",
      "2:\tlearn: 0.4668875\ttotal: 134ms\tremaining: 267ms\n",
      "3:\tlearn: 0.4641234\ttotal: 195ms\tremaining: 244ms\n",
      "4:\tlearn: 0.4616543\ttotal: 250ms\tremaining: 200ms\n",
      "5:\tlearn: 0.4587449\ttotal: 320ms\tremaining: 160ms\n",
      "6:\tlearn: 0.4567311\ttotal: 384ms\tremaining: 110ms\n",
      "7:\tlearn: 0.4540933\ttotal: 445ms\tremaining: 55.6ms\n",
      "8:\tlearn: 0.4532213\ttotal: 503ms\tremaining: 0us\n",
      "[9, 0.55, 12, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.15ms\tremaining: 73.2ms\n",
      "1:\tlearn: 0.4704514\ttotal: 67.9ms\tremaining: 238ms\n",
      "2:\tlearn: 0.4668875\ttotal: 131ms\tremaining: 262ms\n",
      "3:\tlearn: 0.4641234\ttotal: 187ms\tremaining: 234ms\n",
      "4:\tlearn: 0.4616543\ttotal: 250ms\tremaining: 200ms\n",
      "5:\tlearn: 0.4587449\ttotal: 310ms\tremaining: 155ms\n",
      "6:\tlearn: 0.4567311\ttotal: 367ms\tremaining: 105ms\n",
      "7:\tlearn: 0.4540933\ttotal: 425ms\tremaining: 53.2ms\n",
      "8:\tlearn: 0.4532213\ttotal: 485ms\tremaining: 0us\n",
      "[9, 0.55, 13, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 16.4ms\tremaining: 131ms\n",
      "1:\tlearn: 0.4700386\ttotal: 152ms\tremaining: 531ms\n",
      "2:\tlearn: 0.4651124\ttotal: 273ms\tremaining: 547ms\n",
      "3:\tlearn: 0.4623159\ttotal: 397ms\tremaining: 496ms\n",
      "4:\tlearn: 0.4590456\ttotal: 455ms\tremaining: 364ms\n",
      "5:\tlearn: 0.4565869\ttotal: 579ms\tremaining: 290ms\n",
      "6:\tlearn: 0.4540567\ttotal: 690ms\tremaining: 197ms\n",
      "7:\tlearn: 0.4522890\ttotal: 807ms\tremaining: 101ms\n",
      "8:\tlearn: 0.4507350\ttotal: 836ms\tremaining: 0us\n",
      "[9, 0.55, 13, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.6ms\tremaining: 101ms\n",
      "1:\tlearn: 0.4700386\ttotal: 132ms\tremaining: 462ms\n",
      "2:\tlearn: 0.4651124\ttotal: 252ms\tremaining: 503ms\n",
      "3:\tlearn: 0.4623159\ttotal: 367ms\tremaining: 459ms\n",
      "4:\tlearn: 0.4590456\ttotal: 422ms\tremaining: 338ms\n",
      "5:\tlearn: 0.4565869\ttotal: 545ms\tremaining: 273ms\n",
      "6:\tlearn: 0.4540567\ttotal: 672ms\tremaining: 192ms\n",
      "7:\tlearn: 0.4522890\ttotal: 795ms\tremaining: 99.3ms\n",
      "8:\tlearn: 0.4507350\ttotal: 822ms\tremaining: 0us\n",
      "[9, 0.55, 13, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 11.2ms\tremaining: 89.8ms\n",
      "1:\tlearn: 0.4700386\ttotal: 144ms\tremaining: 504ms\n",
      "2:\tlearn: 0.4651124\ttotal: 269ms\tremaining: 539ms\n",
      "3:\tlearn: 0.4623159\ttotal: 396ms\tremaining: 495ms\n",
      "4:\tlearn: 0.4590456\ttotal: 468ms\tremaining: 374ms\n",
      "5:\tlearn: 0.4565869\ttotal: 584ms\tremaining: 292ms\n",
      "6:\tlearn: 0.4540567\ttotal: 699ms\tremaining: 200ms\n",
      "7:\tlearn: 0.4522890\ttotal: 825ms\tremaining: 103ms\n",
      "8:\tlearn: 0.4507350\ttotal: 854ms\tremaining: 0us\n",
      "[9, 0.55, 13, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 11.1ms\tremaining: 88.4ms\n",
      "1:\tlearn: 0.4700386\ttotal: 146ms\tremaining: 512ms\n",
      "2:\tlearn: 0.4651124\ttotal: 266ms\tremaining: 532ms\n",
      "3:\tlearn: 0.4623159\ttotal: 382ms\tremaining: 478ms\n",
      "4:\tlearn: 0.4590456\ttotal: 443ms\tremaining: 354ms\n",
      "5:\tlearn: 0.4565869\ttotal: 563ms\tremaining: 281ms\n",
      "6:\tlearn: 0.4540567\ttotal: 680ms\tremaining: 194ms\n",
      "7:\tlearn: 0.4522890\ttotal: 803ms\tremaining: 100ms\n",
      "8:\tlearn: 0.4507350\ttotal: 833ms\tremaining: 0us\n",
      "[9, 0.55, 13, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.72ms\tremaining: 77.8ms\n",
      "1:\tlearn: 0.4700386\ttotal: 135ms\tremaining: 471ms\n",
      "2:\tlearn: 0.4651124\ttotal: 257ms\tremaining: 514ms\n",
      "3:\tlearn: 0.4623159\ttotal: 367ms\tremaining: 459ms\n",
      "4:\tlearn: 0.4590456\ttotal: 427ms\tremaining: 341ms\n",
      "5:\tlearn: 0.4565869\ttotal: 554ms\tremaining: 277ms\n",
      "6:\tlearn: 0.4540567\ttotal: 674ms\tremaining: 193ms\n",
      "7:\tlearn: 0.4522890\ttotal: 788ms\tremaining: 98.4ms\n",
      "8:\tlearn: 0.4507350\ttotal: 818ms\tremaining: 0us\n",
      "[9, 0.55, 14, -0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 14.2ms\tremaining: 114ms\n",
      "1:\tlearn: 0.4695164\ttotal: 258ms\tremaining: 903ms\n",
      "2:\tlearn: 0.4654149\ttotal: 515ms\tremaining: 1.03s\n",
      "3:\tlearn: 0.4619585\ttotal: 782ms\tremaining: 978ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.02s\tremaining: 816ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.04s\tremaining: 519ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.04s\tremaining: 298ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.29s\tremaining: 161ms\n",
      "8:\tlearn: 0.4512984\ttotal: 1.3s\tremaining: 0us\n",
      "[9, 0.55, 14, 0.3]\n",
      "0:\tlearn: 0.4792390\ttotal: 10.3ms\tremaining: 82.2ms\n",
      "1:\tlearn: 0.4695164\ttotal: 237ms\tremaining: 829ms\n",
      "2:\tlearn: 0.4654149\ttotal: 485ms\tremaining: 971ms\n",
      "3:\tlearn: 0.4619585\ttotal: 719ms\tremaining: 899ms\n",
      "4:\tlearn: 0.4580701\ttotal: 962ms\tremaining: 770ms\n",
      "5:\tlearn: 0.4564419\ttotal: 983ms\tremaining: 491ms\n",
      "6:\tlearn: 0.4557130\ttotal: 987ms\tremaining: 282ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.22s\tremaining: 153ms\n",
      "8:\tlearn: 0.4512984\ttotal: 1.23s\tremaining: 0us\n",
      "[9, 0.55, 14, 0.0]\n",
      "0:\tlearn: 0.4792390\ttotal: 12.5ms\tremaining: 99.8ms\n",
      "1:\tlearn: 0.4695164\ttotal: 256ms\tremaining: 895ms\n",
      "2:\tlearn: 0.4654149\ttotal: 499ms\tremaining: 997ms\n",
      "3:\tlearn: 0.4619585\ttotal: 742ms\tremaining: 927ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.01s\tremaining: 809ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.03s\tremaining: 514ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.03s\tremaining: 295ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.27s\tremaining: 159ms\n",
      "8:\tlearn: 0.4512984\ttotal: 1.28s\tremaining: 0us\n",
      "[9, 0.55, 14, 0.15]\n",
      "0:\tlearn: 0.4792390\ttotal: 14.5ms\tremaining: 116ms\n",
      "1:\tlearn: 0.4695164\ttotal: 252ms\tremaining: 881ms\n",
      "2:\tlearn: 0.4654149\ttotal: 523ms\tremaining: 1.04s\n",
      "3:\tlearn: 0.4619585\ttotal: 780ms\tremaining: 975ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.03s\tremaining: 825ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.05s\tremaining: 525ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.05s\tremaining: 302ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.31s\tremaining: 163ms\n",
      "8:\tlearn: 0.4512984\ttotal: 1.32s\tremaining: 0us\n",
      "[9, 0.55, 14, 0.2]\n",
      "0:\tlearn: 0.4792390\ttotal: 9.14ms\tremaining: 73.1ms\n",
      "1:\tlearn: 0.4695164\ttotal: 266ms\tremaining: 931ms\n",
      "2:\tlearn: 0.4654149\ttotal: 495ms\tremaining: 990ms\n",
      "3:\tlearn: 0.4619585\ttotal: 737ms\tremaining: 921ms\n",
      "4:\tlearn: 0.4580701\ttotal: 976ms\tremaining: 781ms\n",
      "5:\tlearn: 0.4564419\ttotal: 994ms\tremaining: 497ms\n",
      "6:\tlearn: 0.4557130\ttotal: 998ms\tremaining: 285ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.24s\tremaining: 155ms\n",
      "8:\tlearn: 0.4512984\ttotal: 1.25s\tremaining: 0us\n",
      "[9, 0.42, 6, -0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 6.96ms\tremaining: 55.7ms\n",
      "1:\tlearn: 0.4764006\ttotal: 11.5ms\tremaining: 40.2ms\n",
      "2:\tlearn: 0.4730150\ttotal: 16ms\tremaining: 32ms\n",
      "3:\tlearn: 0.4709457\ttotal: 20.6ms\tremaining: 25.7ms\n",
      "4:\tlearn: 0.4690547\ttotal: 25ms\tremaining: 20ms\n",
      "5:\tlearn: 0.4668601\ttotal: 29.1ms\tremaining: 14.6ms\n",
      "6:\tlearn: 0.4648543\ttotal: 33.1ms\tremaining: 9.47ms\n",
      "7:\tlearn: 0.4633314\ttotal: 37.5ms\tremaining: 4.68ms\n",
      "8:\tlearn: 0.4622989\ttotal: 41.8ms\tremaining: 0us\n",
      "[9, 0.42, 6, 0.3]\n",
      "0:\tlearn: 0.4822549\ttotal: 5.03ms\tremaining: 40.2ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.03ms\tremaining: 31.6ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13.4ms\tremaining: 26.7ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17.9ms\tremaining: 22.3ms\n",
      "4:\tlearn: 0.4690547\ttotal: 22.3ms\tremaining: 17.8ms\n",
      "5:\tlearn: 0.4668601\ttotal: 26.4ms\tremaining: 13.2ms\n",
      "6:\tlearn: 0.4648543\ttotal: 30.9ms\tremaining: 8.82ms\n",
      "7:\tlearn: 0.4633314\ttotal: 35.3ms\tremaining: 4.41ms\n",
      "8:\tlearn: 0.4622989\ttotal: 39.2ms\tremaining: 0us\n",
      "[9, 0.42, 6, 0.0]\n",
      "0:\tlearn: 0.4822549\ttotal: 5.58ms\tremaining: 44.6ms\n",
      "1:\tlearn: 0.4764006\ttotal: 9.89ms\tremaining: 34.6ms\n",
      "2:\tlearn: 0.4730150\ttotal: 14.2ms\tremaining: 28.4ms\n",
      "3:\tlearn: 0.4709457\ttotal: 18.6ms\tremaining: 23.3ms\n",
      "4:\tlearn: 0.4690547\ttotal: 22.9ms\tremaining: 18.3ms\n",
      "5:\tlearn: 0.4668601\ttotal: 27.4ms\tremaining: 13.7ms\n",
      "6:\tlearn: 0.4648543\ttotal: 31.9ms\tremaining: 9.12ms\n",
      "7:\tlearn: 0.4633314\ttotal: 36.4ms\tremaining: 4.55ms\n",
      "8:\tlearn: 0.4622989\ttotal: 41.2ms\tremaining: 0us\n",
      "[9, 0.42, 6, 0.15]\n",
      "0:\tlearn: 0.4822549\ttotal: 6.25ms\tremaining: 50ms\n",
      "1:\tlearn: 0.4764006\ttotal: 10.7ms\tremaining: 37.4ms\n",
      "2:\tlearn: 0.4730150\ttotal: 15.1ms\tremaining: 30.2ms\n",
      "3:\tlearn: 0.4709457\ttotal: 19.4ms\tremaining: 24.3ms\n",
      "4:\tlearn: 0.4690547\ttotal: 23.6ms\tremaining: 18.8ms\n",
      "5:\tlearn: 0.4668601\ttotal: 28ms\tremaining: 14ms\n",
      "6:\tlearn: 0.4648543\ttotal: 32.7ms\tremaining: 9.35ms\n",
      "7:\tlearn: 0.4633314\ttotal: 37.1ms\tremaining: 4.63ms\n",
      "8:\tlearn: 0.4622989\ttotal: 41.7ms\tremaining: 0us\n",
      "[9, 0.42, 6, 0.2]\n",
      "0:\tlearn: 0.4822549\ttotal: 4.36ms\tremaining: 34.9ms\n",
      "1:\tlearn: 0.4764006\ttotal: 8.81ms\tremaining: 30.8ms\n",
      "2:\tlearn: 0.4730150\ttotal: 13ms\tremaining: 26.1ms\n",
      "3:\tlearn: 0.4709457\ttotal: 17.2ms\tremaining: 21.5ms\n",
      "4:\tlearn: 0.4690547\ttotal: 21.5ms\tremaining: 17.2ms\n",
      "5:\tlearn: 0.4668601\ttotal: 25.6ms\tremaining: 12.8ms\n",
      "6:\tlearn: 0.4648543\ttotal: 29.8ms\tremaining: 8.5ms\n",
      "7:\tlearn: 0.4633314\ttotal: 33.9ms\tremaining: 4.23ms\n",
      "8:\tlearn: 0.4622989\ttotal: 38.2ms\tremaining: 0us\n",
      "[9, 0.42, 15, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.79ms\tremaining: 78.3ms\n",
      "1:\tlearn: 0.4725597\ttotal: 523ms\tremaining: 1.83s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.02s\tremaining: 2.05s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.53s\tremaining: 1.92s\n",
      "4:\tlearn: 0.4605353\ttotal: 2.02s\tremaining: 1.61s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.51s\tremaining: 1.25s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.97s\tremaining: 848ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.43s\tremaining: 429ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.91s\tremaining: 0us\n",
      "[9, 0.42, 15, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.4ms\tremaining: 82.9ms\n",
      "1:\tlearn: 0.4725597\ttotal: 485ms\tremaining: 1.7s\n",
      "2:\tlearn: 0.4670568\ttotal: 979ms\tremaining: 1.96s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.46s\tremaining: 1.82s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.96s\tremaining: 1.57s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.44s\tremaining: 1.22s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.9s\tremaining: 829ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.41s\tremaining: 426ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.9s\tremaining: 0us\n",
      "[9, 0.42, 15, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.51ms\tremaining: 76.1ms\n",
      "1:\tlearn: 0.4725597\ttotal: 473ms\tremaining: 1.66s\n",
      "2:\tlearn: 0.4670568\ttotal: 1.01s\tremaining: 2.02s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.5s\tremaining: 1.88s\n",
      "4:\tlearn: 0.4605353\ttotal: 2s\tremaining: 1.6s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.48s\tremaining: 1.24s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.98s\tremaining: 852ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.47s\tremaining: 434ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.95s\tremaining: 0us\n",
      "[9, 0.42, 15, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.9ms\tremaining: 79.2ms\n",
      "1:\tlearn: 0.4725597\ttotal: 514ms\tremaining: 1.8s\n",
      "2:\tlearn: 0.4670568\ttotal: 983ms\tremaining: 1.97s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.5s\tremaining: 1.87s\n",
      "4:\tlearn: 0.4605353\ttotal: 2s\tremaining: 1.6s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.47s\tremaining: 1.24s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.96s\tremaining: 846ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.46s\tremaining: 432ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.95s\tremaining: 0us\n",
      "[9, 0.42, 15, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.96ms\tremaining: 71.7ms\n",
      "1:\tlearn: 0.4725597\ttotal: 479ms\tremaining: 1.68s\n",
      "2:\tlearn: 0.4670568\ttotal: 962ms\tremaining: 1.92s\n",
      "3:\tlearn: 0.4637925\ttotal: 1.43s\tremaining: 1.79s\n",
      "4:\tlearn: 0.4605353\ttotal: 1.9s\tremaining: 1.52s\n",
      "5:\tlearn: 0.4581353\ttotal: 2.38s\tremaining: 1.19s\n",
      "6:\tlearn: 0.4558816\ttotal: 2.87s\tremaining: 819ms\n",
      "7:\tlearn: 0.4540982\ttotal: 3.34s\tremaining: 417ms\n",
      "8:\tlearn: 0.4519462\ttotal: 3.82s\tremaining: 0us\n",
      "[9, 0.42, 10, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 14.9ms\tremaining: 120ms\n",
      "1:\tlearn: 0.4747524\ttotal: 31.5ms\tremaining: 110ms\n",
      "2:\tlearn: 0.4704503\ttotal: 50.4ms\tremaining: 101ms\n",
      "3:\tlearn: 0.4672210\ttotal: 67.2ms\tremaining: 84ms\n",
      "4:\tlearn: 0.4648993\ttotal: 82.8ms\tremaining: 66.2ms\n",
      "5:\tlearn: 0.4625834\ttotal: 99.6ms\tremaining: 49.8ms\n",
      "6:\tlearn: 0.4610401\ttotal: 116ms\tremaining: 33ms\n",
      "7:\tlearn: 0.4600427\ttotal: 120ms\tremaining: 15.1ms\n",
      "8:\tlearn: 0.4589504\ttotal: 135ms\tremaining: 0us\n",
      "[9, 0.42, 10, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.7ms\tremaining: 94ms\n",
      "1:\tlearn: 0.4747524\ttotal: 28ms\tremaining: 98ms\n",
      "2:\tlearn: 0.4704503\ttotal: 46.9ms\tremaining: 93.8ms\n",
      "3:\tlearn: 0.4672210\ttotal: 62.6ms\tremaining: 78.3ms\n",
      "4:\tlearn: 0.4648993\ttotal: 78.9ms\tremaining: 63.2ms\n",
      "5:\tlearn: 0.4625834\ttotal: 95.2ms\tremaining: 47.6ms\n",
      "6:\tlearn: 0.4610401\ttotal: 112ms\tremaining: 32.1ms\n",
      "7:\tlearn: 0.4600427\ttotal: 118ms\tremaining: 14.7ms\n",
      "8:\tlearn: 0.4589504\ttotal: 134ms\tremaining: 0us\n",
      "[9, 0.42, 10, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 8.71ms\tremaining: 69.7ms\n",
      "1:\tlearn: 0.4747524\ttotal: 23.4ms\tremaining: 82ms\n",
      "2:\tlearn: 0.4704503\ttotal: 39ms\tremaining: 78.1ms\n",
      "3:\tlearn: 0.4672210\ttotal: 57ms\tremaining: 71.3ms\n",
      "4:\tlearn: 0.4648993\ttotal: 78ms\tremaining: 62.4ms\n",
      "5:\tlearn: 0.4625834\ttotal: 98.1ms\tremaining: 49.1ms\n",
      "6:\tlearn: 0.4610401\ttotal: 115ms\tremaining: 33ms\n",
      "7:\tlearn: 0.4600427\ttotal: 121ms\tremaining: 15.1ms\n",
      "8:\tlearn: 0.4589504\ttotal: 137ms\tremaining: 0us\n",
      "[9, 0.42, 10, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.6ms\tremaining: 85ms\n",
      "1:\tlearn: 0.4747524\ttotal: 26.7ms\tremaining: 93.5ms\n",
      "2:\tlearn: 0.4704503\ttotal: 44ms\tremaining: 88ms\n",
      "3:\tlearn: 0.4672210\ttotal: 61.6ms\tremaining: 77ms\n",
      "4:\tlearn: 0.4648993\ttotal: 77.6ms\tremaining: 62.1ms\n",
      "5:\tlearn: 0.4625834\ttotal: 95.7ms\tremaining: 47.8ms\n",
      "6:\tlearn: 0.4610401\ttotal: 112ms\tremaining: 32.1ms\n",
      "7:\tlearn: 0.4600427\ttotal: 117ms\tremaining: 14.7ms\n",
      "8:\tlearn: 0.4589504\ttotal: 134ms\tremaining: 0us\n",
      "[9, 0.42, 10, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 11.3ms\tremaining: 90.4ms\n",
      "1:\tlearn: 0.4747524\ttotal: 26.6ms\tremaining: 93.3ms\n",
      "2:\tlearn: 0.4704503\ttotal: 42.5ms\tremaining: 85ms\n",
      "3:\tlearn: 0.4672210\ttotal: 58.8ms\tremaining: 73.5ms\n",
      "4:\tlearn: 0.4648993\ttotal: 77.6ms\tremaining: 62.1ms\n",
      "5:\tlearn: 0.4625834\ttotal: 93.9ms\tremaining: 47ms\n",
      "6:\tlearn: 0.4610401\ttotal: 112ms\tremaining: 32ms\n",
      "7:\tlearn: 0.4600427\ttotal: 117ms\tremaining: 14.7ms\n",
      "8:\tlearn: 0.4589504\ttotal: 134ms\tremaining: 0us\n",
      "[9, 0.42, 12, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.02ms\tremaining: 72.1ms\n",
      "1:\tlearn: 0.4738094\ttotal: 68.1ms\tremaining: 238ms\n",
      "2:\tlearn: 0.4686075\ttotal: 128ms\tremaining: 255ms\n",
      "3:\tlearn: 0.4656476\ttotal: 185ms\tremaining: 232ms\n",
      "4:\tlearn: 0.4634402\ttotal: 246ms\tremaining: 197ms\n",
      "5:\tlearn: 0.4611150\ttotal: 315ms\tremaining: 158ms\n",
      "6:\tlearn: 0.4588698\ttotal: 374ms\tremaining: 107ms\n",
      "7:\tlearn: 0.4569792\ttotal: 434ms\tremaining: 54.2ms\n",
      "8:\tlearn: 0.4559460\ttotal: 497ms\tremaining: 0us\n",
      "[9, 0.42, 12, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 12.7ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4738094\ttotal: 71.5ms\tremaining: 250ms\n",
      "2:\tlearn: 0.4686075\ttotal: 135ms\tremaining: 271ms\n",
      "3:\tlearn: 0.4656476\ttotal: 191ms\tremaining: 238ms\n",
      "4:\tlearn: 0.4634402\ttotal: 250ms\tremaining: 200ms\n",
      "5:\tlearn: 0.4611150\ttotal: 312ms\tremaining: 156ms\n",
      "6:\tlearn: 0.4588698\ttotal: 375ms\tremaining: 107ms\n",
      "7:\tlearn: 0.4569792\ttotal: 435ms\tremaining: 54.3ms\n",
      "8:\tlearn: 0.4559460\ttotal: 495ms\tremaining: 0us\n",
      "[9, 0.42, 12, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.45ms\tremaining: 75.6ms\n",
      "1:\tlearn: 0.4738094\ttotal: 67.6ms\tremaining: 237ms\n",
      "2:\tlearn: 0.4686075\ttotal: 130ms\tremaining: 260ms\n",
      "3:\tlearn: 0.4656476\ttotal: 188ms\tremaining: 235ms\n",
      "4:\tlearn: 0.4634402\ttotal: 247ms\tremaining: 198ms\n",
      "5:\tlearn: 0.4611150\ttotal: 309ms\tremaining: 154ms\n",
      "6:\tlearn: 0.4588698\ttotal: 368ms\tremaining: 105ms\n",
      "7:\tlearn: 0.4569792\ttotal: 428ms\tremaining: 53.6ms\n",
      "8:\tlearn: 0.4559460\ttotal: 488ms\tremaining: 0us\n",
      "[9, 0.42, 12, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 13.2ms\tremaining: 106ms\n",
      "1:\tlearn: 0.4738094\ttotal: 72.3ms\tremaining: 253ms\n",
      "2:\tlearn: 0.4686075\ttotal: 130ms\tremaining: 260ms\n",
      "3:\tlearn: 0.4656476\ttotal: 185ms\tremaining: 231ms\n",
      "4:\tlearn: 0.4634402\ttotal: 247ms\tremaining: 198ms\n",
      "5:\tlearn: 0.4611150\ttotal: 311ms\tremaining: 156ms\n",
      "6:\tlearn: 0.4588698\ttotal: 371ms\tremaining: 106ms\n",
      "7:\tlearn: 0.4569792\ttotal: 434ms\tremaining: 54.2ms\n",
      "8:\tlearn: 0.4559460\ttotal: 490ms\tremaining: 0us\n",
      "[9, 0.42, 12, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.47ms\tremaining: 75.8ms\n",
      "1:\tlearn: 0.4738094\ttotal: 69.2ms\tremaining: 242ms\n",
      "2:\tlearn: 0.4686075\ttotal: 126ms\tremaining: 251ms\n",
      "3:\tlearn: 0.4656476\ttotal: 183ms\tremaining: 229ms\n",
      "4:\tlearn: 0.4634402\ttotal: 248ms\tremaining: 198ms\n",
      "5:\tlearn: 0.4611150\ttotal: 310ms\tremaining: 155ms\n",
      "6:\tlearn: 0.4588698\ttotal: 370ms\tremaining: 106ms\n",
      "7:\tlearn: 0.4569792\ttotal: 430ms\tremaining: 53.8ms\n",
      "8:\tlearn: 0.4559460\ttotal: 489ms\tremaining: 0us\n",
      "[9, 0.42, 13, -0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 14.2ms\tremaining: 113ms\n",
      "1:\tlearn: 0.4734661\ttotal: 125ms\tremaining: 436ms\n",
      "2:\tlearn: 0.4690787\ttotal: 249ms\tremaining: 497ms\n",
      "3:\tlearn: 0.4660511\ttotal: 366ms\tremaining: 458ms\n",
      "4:\tlearn: 0.4628433\ttotal: 426ms\tremaining: 341ms\n",
      "5:\tlearn: 0.4605878\ttotal: 549ms\tremaining: 274ms\n",
      "6:\tlearn: 0.4583652\ttotal: 669ms\tremaining: 191ms\n",
      "7:\tlearn: 0.4568128\ttotal: 802ms\tremaining: 100ms\n",
      "8:\tlearn: 0.4552451\ttotal: 835ms\tremaining: 0us\n",
      "[9, 0.42, 13, 0.3]\n",
      "0:\tlearn: 0.4819705\ttotal: 16.6ms\tremaining: 133ms\n",
      "1:\tlearn: 0.4734661\ttotal: 130ms\tremaining: 455ms\n",
      "2:\tlearn: 0.4690787\ttotal: 256ms\tremaining: 512ms\n",
      "3:\tlearn: 0.4660511\ttotal: 372ms\tremaining: 465ms\n",
      "4:\tlearn: 0.4628433\ttotal: 431ms\tremaining: 345ms\n",
      "5:\tlearn: 0.4605878\ttotal: 546ms\tremaining: 273ms\n",
      "6:\tlearn: 0.4583652\ttotal: 667ms\tremaining: 190ms\n",
      "7:\tlearn: 0.4568128\ttotal: 787ms\tremaining: 98.4ms\n",
      "8:\tlearn: 0.4552451\ttotal: 817ms\tremaining: 0us\n",
      "[9, 0.42, 13, 0.0]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.34ms\tremaining: 74.7ms\n",
      "1:\tlearn: 0.4734661\ttotal: 127ms\tremaining: 445ms\n",
      "2:\tlearn: 0.4690787\ttotal: 247ms\tremaining: 495ms\n",
      "3:\tlearn: 0.4660511\ttotal: 364ms\tremaining: 454ms\n",
      "4:\tlearn: 0.4628433\ttotal: 420ms\tremaining: 336ms\n",
      "5:\tlearn: 0.4605878\ttotal: 543ms\tremaining: 271ms\n",
      "6:\tlearn: 0.4583652\ttotal: 659ms\tremaining: 188ms\n",
      "7:\tlearn: 0.4568128\ttotal: 782ms\tremaining: 97.8ms\n",
      "8:\tlearn: 0.4552451\ttotal: 814ms\tremaining: 0us\n",
      "[9, 0.42, 13, 0.15]\n",
      "0:\tlearn: 0.4819705\ttotal: 9.46ms\tremaining: 75.7ms\n",
      "1:\tlearn: 0.4734661\ttotal: 138ms\tremaining: 484ms\n",
      "2:\tlearn: 0.4690787\ttotal: 263ms\tremaining: 527ms\n",
      "3:\tlearn: 0.4660511\ttotal: 384ms\tremaining: 480ms\n",
      "4:\tlearn: 0.4628433\ttotal: 449ms\tremaining: 359ms\n",
      "5:\tlearn: 0.4605878\ttotal: 568ms\tremaining: 284ms\n",
      "6:\tlearn: 0.4583652\ttotal: 690ms\tremaining: 197ms\n",
      "7:\tlearn: 0.4568128\ttotal: 812ms\tremaining: 102ms\n",
      "8:\tlearn: 0.4552451\ttotal: 843ms\tremaining: 0us\n",
      "[9, 0.42, 13, 0.2]\n",
      "0:\tlearn: 0.4819705\ttotal: 10.3ms\tremaining: 82.6ms\n",
      "1:\tlearn: 0.4734661\ttotal: 132ms\tremaining: 461ms\n",
      "2:\tlearn: 0.4690787\ttotal: 259ms\tremaining: 519ms\n",
      "3:\tlearn: 0.4660511\ttotal: 373ms\tremaining: 466ms\n",
      "4:\tlearn: 0.4628433\ttotal: 441ms\tremaining: 353ms\n",
      "5:\tlearn: 0.4605878\ttotal: 565ms\tremaining: 282ms\n",
      "6:\tlearn: 0.4583652\ttotal: 688ms\tremaining: 197ms\n",
      "7:\tlearn: 0.4568128\ttotal: 812ms\tremaining: 101ms\n",
      "8:\tlearn: 0.4552451\ttotal: 844ms\tremaining: 0us\n",
      "[9, 0.48, 6, -0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 8.48ms\tremaining: 67.9ms\n",
      "1:\tlearn: 0.4742214\ttotal: 12.7ms\tremaining: 44.5ms\n",
      "2:\tlearn: 0.4707120\ttotal: 17.2ms\tremaining: 34.5ms\n",
      "3:\tlearn: 0.4683386\ttotal: 21.3ms\tremaining: 26.7ms\n",
      "4:\tlearn: 0.4663249\ttotal: 25.4ms\tremaining: 20.3ms\n",
      "5:\tlearn: 0.4646075\ttotal: 29.5ms\tremaining: 14.8ms\n",
      "6:\tlearn: 0.4624948\ttotal: 33.7ms\tremaining: 9.63ms\n",
      "7:\tlearn: 0.4613643\ttotal: 38ms\tremaining: 4.75ms\n",
      "8:\tlearn: 0.4601906\ttotal: 42.5ms\tremaining: 0us\n",
      "[9, 0.48, 6, 0.3]\n",
      "0:\tlearn: 0.4809500\ttotal: 4.75ms\tremaining: 38ms\n",
      "1:\tlearn: 0.4742214\ttotal: 9.13ms\tremaining: 32ms\n",
      "2:\tlearn: 0.4707120\ttotal: 13.3ms\tremaining: 26.6ms\n",
      "3:\tlearn: 0.4683386\ttotal: 18.3ms\tremaining: 22.9ms\n",
      "4:\tlearn: 0.4663249\ttotal: 23.2ms\tremaining: 18.6ms\n",
      "5:\tlearn: 0.4646075\ttotal: 34ms\tremaining: 17ms\n",
      "6:\tlearn: 0.4624948\ttotal: 39.1ms\tremaining: 11.2ms\n",
      "7:\tlearn: 0.4613643\ttotal: 43.5ms\tremaining: 5.44ms\n",
      "8:\tlearn: 0.4601906\ttotal: 48ms\tremaining: 0us\n",
      "[9, 0.48, 6, 0.0]\n",
      "0:\tlearn: 0.4809500\ttotal: 10.1ms\tremaining: 80.8ms\n",
      "1:\tlearn: 0.4742214\ttotal: 14.4ms\tremaining: 50.3ms\n",
      "2:\tlearn: 0.4707120\ttotal: 19.2ms\tremaining: 38.4ms\n",
      "3:\tlearn: 0.4683386\ttotal: 23.6ms\tremaining: 29.6ms\n",
      "4:\tlearn: 0.4663249\ttotal: 28.2ms\tremaining: 22.6ms\n",
      "5:\tlearn: 0.4646075\ttotal: 32.9ms\tremaining: 16.4ms\n",
      "6:\tlearn: 0.4624948\ttotal: 37.4ms\tremaining: 10.7ms\n",
      "7:\tlearn: 0.4613643\ttotal: 41.8ms\tremaining: 5.22ms\n",
      "8:\tlearn: 0.4601906\ttotal: 46.7ms\tremaining: 0us\n",
      "[9, 0.48, 6, 0.15]\n",
      "0:\tlearn: 0.4809500\ttotal: 6.06ms\tremaining: 48.5ms\n",
      "1:\tlearn: 0.4742214\ttotal: 10.3ms\tremaining: 36ms\n",
      "2:\tlearn: 0.4707120\ttotal: 14.4ms\tremaining: 28.7ms\n",
      "3:\tlearn: 0.4683386\ttotal: 18.5ms\tremaining: 23.1ms\n",
      "4:\tlearn: 0.4663249\ttotal: 22.6ms\tremaining: 18.1ms\n",
      "5:\tlearn: 0.4646075\ttotal: 28.2ms\tremaining: 14.1ms\n",
      "6:\tlearn: 0.4624948\ttotal: 32.4ms\tremaining: 9.25ms\n",
      "7:\tlearn: 0.4613643\ttotal: 36.5ms\tremaining: 4.56ms\n",
      "8:\tlearn: 0.4601906\ttotal: 40.8ms\tremaining: 0us\n",
      "[9, 0.48, 6, 0.2]\n",
      "0:\tlearn: 0.4809500\ttotal: 4.74ms\tremaining: 38ms\n",
      "1:\tlearn: 0.4742214\ttotal: 9.09ms\tremaining: 31.8ms\n",
      "2:\tlearn: 0.4707120\ttotal: 13.4ms\tremaining: 26.8ms\n",
      "3:\tlearn: 0.4683386\ttotal: 17.6ms\tremaining: 22ms\n",
      "4:\tlearn: 0.4663249\ttotal: 22ms\tremaining: 17.6ms\n",
      "5:\tlearn: 0.4646075\ttotal: 29.1ms\tremaining: 14.5ms\n",
      "6:\tlearn: 0.4624948\ttotal: 33.7ms\tremaining: 9.64ms\n",
      "7:\tlearn: 0.4613643\ttotal: 38.9ms\tremaining: 4.86ms\n",
      "8:\tlearn: 0.4601906\ttotal: 43.3ms\tremaining: 0us\n",
      "[9, 0.48, 15, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.9ms\tremaining: 87ms\n",
      "1:\tlearn: 0.4707499\ttotal: 486ms\tremaining: 1.7s\n",
      "2:\tlearn: 0.4660967\ttotal: 967ms\tremaining: 1.93s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.48s\tremaining: 1.85s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.95s\tremaining: 1.56s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.42s\tremaining: 1.21s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.88s\tremaining: 823ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.36s\tremaining: 421ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.86s\tremaining: 0us\n",
      "[9, 0.48, 15, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.11ms\tremaining: 72.8ms\n",
      "1:\tlearn: 0.4707499\ttotal: 481ms\tremaining: 1.68s\n",
      "2:\tlearn: 0.4660967\ttotal: 972ms\tremaining: 1.94s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.46s\tremaining: 1.82s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.94s\tremaining: 1.55s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.44s\tremaining: 1.22s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.93s\tremaining: 838ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.41s\tremaining: 426ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.91s\tremaining: 0us\n",
      "[9, 0.48, 15, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.17ms\tremaining: 73.4ms\n",
      "1:\tlearn: 0.4707499\ttotal: 493ms\tremaining: 1.73s\n",
      "2:\tlearn: 0.4660967\ttotal: 986ms\tremaining: 1.97s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.48s\tremaining: 1.85s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.97s\tremaining: 1.57s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.45s\tremaining: 1.23s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.93s\tremaining: 836ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.41s\tremaining: 426ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.88s\tremaining: 0us\n",
      "[9, 0.48, 15, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.9ms\tremaining: 87ms\n",
      "1:\tlearn: 0.4707499\ttotal: 462ms\tremaining: 1.62s\n",
      "2:\tlearn: 0.4660967\ttotal: 947ms\tremaining: 1.89s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.42s\tremaining: 1.77s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.88s\tremaining: 1.5s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.35s\tremaining: 1.18s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.82s\tremaining: 805ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.29s\tremaining: 411ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.74s\tremaining: 0us\n",
      "[9, 0.48, 15, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.27ms\tremaining: 74.1ms\n",
      "1:\tlearn: 0.4707499\ttotal: 482ms\tremaining: 1.69s\n",
      "2:\tlearn: 0.4660967\ttotal: 974ms\tremaining: 1.95s\n",
      "3:\tlearn: 0.4627239\ttotal: 1.46s\tremaining: 1.83s\n",
      "4:\tlearn: 0.4592968\ttotal: 1.94s\tremaining: 1.55s\n",
      "5:\tlearn: 0.4571455\ttotal: 2.4s\tremaining: 1.2s\n",
      "6:\tlearn: 0.4551015\ttotal: 2.9s\tremaining: 829ms\n",
      "7:\tlearn: 0.4531603\ttotal: 3.4s\tremaining: 425ms\n",
      "8:\tlearn: 0.4505676\ttotal: 3.88s\tremaining: 0us\n",
      "[9, 0.48, 10, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 12.2ms\tremaining: 97.7ms\n",
      "1:\tlearn: 0.4731642\ttotal: 30.1ms\tremaining: 105ms\n",
      "2:\tlearn: 0.4688840\ttotal: 44.5ms\tremaining: 88.9ms\n",
      "3:\tlearn: 0.4676760\ttotal: 47.3ms\tremaining: 59.1ms\n",
      "4:\tlearn: 0.4647814\ttotal: 62.8ms\tremaining: 50.2ms\n",
      "5:\tlearn: 0.4606717\ttotal: 78.4ms\tremaining: 39.2ms\n",
      "6:\tlearn: 0.4587144\ttotal: 97.1ms\tremaining: 27.8ms\n",
      "7:\tlearn: 0.4569157\ttotal: 114ms\tremaining: 14.3ms\n",
      "8:\tlearn: 0.4555458\ttotal: 133ms\tremaining: 0us\n",
      "[9, 0.48, 10, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 14.1ms\tremaining: 113ms\n",
      "1:\tlearn: 0.4731642\ttotal: 32.7ms\tremaining: 115ms\n",
      "2:\tlearn: 0.4688840\ttotal: 53.1ms\tremaining: 106ms\n",
      "3:\tlearn: 0.4676760\ttotal: 56.4ms\tremaining: 70.5ms\n",
      "4:\tlearn: 0.4647814\ttotal: 73.6ms\tremaining: 58.9ms\n",
      "5:\tlearn: 0.4606717\ttotal: 92ms\tremaining: 46ms\n",
      "6:\tlearn: 0.4587144\ttotal: 109ms\tremaining: 31.1ms\n",
      "7:\tlearn: 0.4569157\ttotal: 125ms\tremaining: 15.6ms\n",
      "8:\tlearn: 0.4555458\ttotal: 141ms\tremaining: 0us\n",
      "[9, 0.48, 10, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 13.2ms\tremaining: 105ms\n",
      "1:\tlearn: 0.4731642\ttotal: 31.2ms\tremaining: 109ms\n",
      "2:\tlearn: 0.4688840\ttotal: 48.5ms\tremaining: 97ms\n",
      "3:\tlearn: 0.4676760\ttotal: 51.3ms\tremaining: 64.2ms\n",
      "4:\tlearn: 0.4647814\ttotal: 66.2ms\tremaining: 52.9ms\n",
      "5:\tlearn: 0.4606717\ttotal: 83.7ms\tremaining: 41.8ms\n",
      "6:\tlearn: 0.4587144\ttotal: 99.5ms\tremaining: 28.4ms\n",
      "7:\tlearn: 0.4569157\ttotal: 115ms\tremaining: 14.4ms\n",
      "8:\tlearn: 0.4555458\ttotal: 130ms\tremaining: 0us\n",
      "[9, 0.48, 10, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.83ms\tremaining: 78.7ms\n",
      "1:\tlearn: 0.4731642\ttotal: 26.3ms\tremaining: 92.2ms\n",
      "2:\tlearn: 0.4688840\ttotal: 42.3ms\tremaining: 84.6ms\n",
      "3:\tlearn: 0.4676760\ttotal: 45.6ms\tremaining: 56.9ms\n",
      "4:\tlearn: 0.4647814\ttotal: 62ms\tremaining: 49.6ms\n",
      "5:\tlearn: 0.4606717\ttotal: 78.2ms\tremaining: 39.1ms\n",
      "6:\tlearn: 0.4587144\ttotal: 94.9ms\tremaining: 27.1ms\n",
      "7:\tlearn: 0.4569157\ttotal: 110ms\tremaining: 13.8ms\n",
      "8:\tlearn: 0.4555458\ttotal: 126ms\tremaining: 0us\n",
      "[9, 0.48, 10, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 12.8ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4731642\ttotal: 28.8ms\tremaining: 101ms\n",
      "2:\tlearn: 0.4688840\ttotal: 44.6ms\tremaining: 89.2ms\n",
      "3:\tlearn: 0.4676760\ttotal: 47.7ms\tremaining: 59.7ms\n",
      "4:\tlearn: 0.4647814\ttotal: 65.7ms\tremaining: 52.5ms\n",
      "5:\tlearn: 0.4606717\ttotal: 82.2ms\tremaining: 41.1ms\n",
      "6:\tlearn: 0.4587144\ttotal: 98.5ms\tremaining: 28.1ms\n",
      "7:\tlearn: 0.4569157\ttotal: 115ms\tremaining: 14.4ms\n",
      "8:\tlearn: 0.4555458\ttotal: 130ms\tremaining: 0us\n",
      "[9, 0.48, 12, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 12.2ms\tremaining: 97.8ms\n",
      "1:\tlearn: 0.4721464\ttotal: 74.9ms\tremaining: 262ms\n",
      "2:\tlearn: 0.4684998\ttotal: 137ms\tremaining: 273ms\n",
      "3:\tlearn: 0.4647972\ttotal: 193ms\tremaining: 241ms\n",
      "4:\tlearn: 0.4625394\ttotal: 251ms\tremaining: 201ms\n",
      "5:\tlearn: 0.4603377\ttotal: 321ms\tremaining: 160ms\n",
      "6:\tlearn: 0.4585216\ttotal: 374ms\tremaining: 107ms\n",
      "7:\tlearn: 0.4563298\ttotal: 440ms\tremaining: 55ms\n",
      "8:\tlearn: 0.4554812\ttotal: 499ms\tremaining: 0us\n",
      "[9, 0.48, 12, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.5ms\tremaining: 83.9ms\n",
      "1:\tlearn: 0.4721464\ttotal: 71.7ms\tremaining: 251ms\n",
      "2:\tlearn: 0.4684998\ttotal: 133ms\tremaining: 266ms\n",
      "3:\tlearn: 0.4647972\ttotal: 190ms\tremaining: 238ms\n",
      "4:\tlearn: 0.4625394\ttotal: 251ms\tremaining: 200ms\n",
      "5:\tlearn: 0.4603377\ttotal: 309ms\tremaining: 154ms\n",
      "6:\tlearn: 0.4585216\ttotal: 371ms\tremaining: 106ms\n",
      "7:\tlearn: 0.4563298\ttotal: 431ms\tremaining: 53.8ms\n",
      "8:\tlearn: 0.4554812\ttotal: 492ms\tremaining: 0us\n",
      "[9, 0.48, 12, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 13.8ms\tremaining: 110ms\n",
      "1:\tlearn: 0.4721464\ttotal: 72.8ms\tremaining: 255ms\n",
      "2:\tlearn: 0.4684998\ttotal: 134ms\tremaining: 267ms\n",
      "3:\tlearn: 0.4647972\ttotal: 194ms\tremaining: 243ms\n",
      "4:\tlearn: 0.4625394\ttotal: 252ms\tremaining: 202ms\n",
      "5:\tlearn: 0.4603377\ttotal: 312ms\tremaining: 156ms\n",
      "6:\tlearn: 0.4585216\ttotal: 377ms\tremaining: 108ms\n",
      "7:\tlearn: 0.4563298\ttotal: 439ms\tremaining: 54.8ms\n",
      "8:\tlearn: 0.4554812\ttotal: 500ms\tremaining: 0us\n",
      "[9, 0.48, 12, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.4ms\tremaining: 83ms\n",
      "1:\tlearn: 0.4721464\ttotal: 73.3ms\tremaining: 257ms\n",
      "2:\tlearn: 0.4684998\ttotal: 135ms\tremaining: 270ms\n",
      "3:\tlearn: 0.4647972\ttotal: 197ms\tremaining: 246ms\n",
      "4:\tlearn: 0.4625394\ttotal: 258ms\tremaining: 207ms\n",
      "5:\tlearn: 0.4603377\ttotal: 318ms\tremaining: 159ms\n",
      "6:\tlearn: 0.4585216\ttotal: 393ms\tremaining: 112ms\n",
      "7:\tlearn: 0.4563298\ttotal: 453ms\tremaining: 56.6ms\n",
      "8:\tlearn: 0.4554812\ttotal: 514ms\tremaining: 0us\n",
      "[9, 0.48, 12, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 9.46ms\tremaining: 75.7ms\n",
      "1:\tlearn: 0.4721464\ttotal: 69.7ms\tremaining: 244ms\n",
      "2:\tlearn: 0.4684998\ttotal: 127ms\tremaining: 253ms\n",
      "3:\tlearn: 0.4647972\ttotal: 184ms\tremaining: 230ms\n",
      "4:\tlearn: 0.4625394\ttotal: 246ms\tremaining: 197ms\n",
      "5:\tlearn: 0.4603377\ttotal: 304ms\tremaining: 152ms\n",
      "6:\tlearn: 0.4585216\ttotal: 367ms\tremaining: 105ms\n",
      "7:\tlearn: 0.4563298\ttotal: 434ms\tremaining: 54.2ms\n",
      "8:\tlearn: 0.4554812\ttotal: 495ms\tremaining: 0us\n",
      "[9, 0.48, 13, -0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.1ms\tremaining: 88.6ms\n",
      "1:\tlearn: 0.4717672\ttotal: 125ms\tremaining: 438ms\n",
      "2:\tlearn: 0.4670679\ttotal: 256ms\tremaining: 511ms\n",
      "3:\tlearn: 0.4643183\ttotal: 375ms\tremaining: 469ms\n",
      "4:\tlearn: 0.4617346\ttotal: 436ms\tremaining: 348ms\n",
      "5:\tlearn: 0.4593271\ttotal: 556ms\tremaining: 278ms\n",
      "6:\tlearn: 0.4571615\ttotal: 686ms\tremaining: 196ms\n",
      "7:\tlearn: 0.4551873\ttotal: 812ms\tremaining: 102ms\n",
      "8:\tlearn: 0.4536294\ttotal: 843ms\tremaining: 0us\n",
      "[9, 0.48, 13, 0.3]\n",
      "0:\tlearn: 0.4806309\ttotal: 11.7ms\tremaining: 93.6ms\n",
      "1:\tlearn: 0.4717672\ttotal: 133ms\tremaining: 465ms\n",
      "2:\tlearn: 0.4670679\ttotal: 251ms\tremaining: 503ms\n",
      "3:\tlearn: 0.4643183\ttotal: 370ms\tremaining: 463ms\n",
      "4:\tlearn: 0.4617346\ttotal: 435ms\tremaining: 348ms\n",
      "5:\tlearn: 0.4593271\ttotal: 552ms\tremaining: 276ms\n",
      "6:\tlearn: 0.4571615\ttotal: 668ms\tremaining: 191ms\n",
      "7:\tlearn: 0.4551873\ttotal: 786ms\tremaining: 98.2ms\n",
      "8:\tlearn: 0.4536294\ttotal: 817ms\tremaining: 0us\n",
      "[9, 0.48, 13, 0.0]\n",
      "0:\tlearn: 0.4806309\ttotal: 10.8ms\tremaining: 86.4ms\n",
      "1:\tlearn: 0.4717672\ttotal: 135ms\tremaining: 472ms\n",
      "2:\tlearn: 0.4670679\ttotal: 253ms\tremaining: 506ms\n",
      "3:\tlearn: 0.4643183\ttotal: 380ms\tremaining: 475ms\n",
      "4:\tlearn: 0.4617346\ttotal: 441ms\tremaining: 352ms\n",
      "5:\tlearn: 0.4593271\ttotal: 561ms\tremaining: 281ms\n",
      "6:\tlearn: 0.4571615\ttotal: 676ms\tremaining: 193ms\n",
      "7:\tlearn: 0.4551873\ttotal: 800ms\tremaining: 99.9ms\n",
      "8:\tlearn: 0.4536294\ttotal: 831ms\tremaining: 0us\n",
      "[9, 0.48, 13, 0.15]\n",
      "0:\tlearn: 0.4806309\ttotal: 12ms\tremaining: 95.9ms\n",
      "1:\tlearn: 0.4717672\ttotal: 135ms\tremaining: 474ms\n",
      "2:\tlearn: 0.4670679\ttotal: 260ms\tremaining: 521ms\n",
      "3:\tlearn: 0.4643183\ttotal: 400ms\tremaining: 500ms\n",
      "4:\tlearn: 0.4617346\ttotal: 464ms\tremaining: 371ms\n",
      "5:\tlearn: 0.4593271\ttotal: 591ms\tremaining: 295ms\n",
      "6:\tlearn: 0.4571615\ttotal: 711ms\tremaining: 203ms\n",
      "7:\tlearn: 0.4551873\ttotal: 835ms\tremaining: 104ms\n",
      "8:\tlearn: 0.4536294\ttotal: 869ms\tremaining: 0us\n",
      "[9, 0.48, 13, 0.2]\n",
      "0:\tlearn: 0.4806309\ttotal: 14ms\tremaining: 112ms\n",
      "1:\tlearn: 0.4717672\ttotal: 134ms\tremaining: 468ms\n",
      "2:\tlearn: 0.4670679\ttotal: 251ms\tremaining: 501ms\n",
      "3:\tlearn: 0.4643183\ttotal: 373ms\tremaining: 466ms\n",
      "4:\tlearn: 0.4617346\ttotal: 437ms\tremaining: 350ms\n",
      "5:\tlearn: 0.4593271\ttotal: 551ms\tremaining: 276ms\n",
      "6:\tlearn: 0.4571615\ttotal: 673ms\tremaining: 192ms\n",
      "7:\tlearn: 0.4551873\ttotal: 794ms\tremaining: 99.3ms\n",
      "8:\tlearn: 0.4536294\ttotal: 824ms\tremaining: 0us\n",
      "[9, 0.51, 6, -0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 5.76ms\tremaining: 46.1ms\n",
      "1:\tlearn: 0.4736652\ttotal: 10.3ms\tremaining: 35.9ms\n",
      "2:\tlearn: 0.4703360\ttotal: 14.8ms\tremaining: 29.5ms\n",
      "3:\tlearn: 0.4678859\ttotal: 19.3ms\tremaining: 24.2ms\n",
      "4:\tlearn: 0.4662988\ttotal: 23.9ms\tremaining: 19.1ms\n",
      "5:\tlearn: 0.4640621\ttotal: 28.4ms\tremaining: 14.2ms\n",
      "6:\tlearn: 0.4617955\ttotal: 33.3ms\tremaining: 9.52ms\n",
      "7:\tlearn: 0.4601208\ttotal: 37.9ms\tremaining: 4.73ms\n",
      "8:\tlearn: 0.4590542\ttotal: 42.6ms\tremaining: 0us\n",
      "[9, 0.51, 6, 0.3]\n",
      "0:\tlearn: 0.4803477\ttotal: 5.47ms\tremaining: 43.8ms\n",
      "1:\tlearn: 0.4736652\ttotal: 9.83ms\tremaining: 34.4ms\n",
      "2:\tlearn: 0.4703360\ttotal: 14ms\tremaining: 28.1ms\n",
      "3:\tlearn: 0.4678859\ttotal: 18.5ms\tremaining: 23.1ms\n",
      "4:\tlearn: 0.4662988\ttotal: 23.2ms\tremaining: 18.5ms\n",
      "5:\tlearn: 0.4640621\ttotal: 30.9ms\tremaining: 15.5ms\n",
      "6:\tlearn: 0.4617955\ttotal: 36.1ms\tremaining: 10.3ms\n",
      "7:\tlearn: 0.4601208\ttotal: 40.6ms\tremaining: 5.08ms\n",
      "8:\tlearn: 0.4590542\ttotal: 45.2ms\tremaining: 0us\n",
      "[9, 0.51, 6, 0.0]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.58ms\tremaining: 36.6ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.83ms\tremaining: 30.9ms\n",
      "2:\tlearn: 0.4703360\ttotal: 13.3ms\tremaining: 26.7ms\n",
      "3:\tlearn: 0.4678859\ttotal: 19.1ms\tremaining: 23.9ms\n",
      "4:\tlearn: 0.4662988\ttotal: 24.2ms\tremaining: 19.3ms\n",
      "5:\tlearn: 0.4640621\ttotal: 34.1ms\tremaining: 17.1ms\n",
      "6:\tlearn: 0.4617955\ttotal: 38.8ms\tremaining: 11.1ms\n",
      "7:\tlearn: 0.4601208\ttotal: 43.2ms\tremaining: 5.4ms\n",
      "8:\tlearn: 0.4590542\ttotal: 47.5ms\tremaining: 0us\n",
      "[9, 0.51, 6, 0.15]\n",
      "0:\tlearn: 0.4803477\ttotal: 4.05ms\tremaining: 32.4ms\n",
      "1:\tlearn: 0.4736652\ttotal: 8.22ms\tremaining: 28.8ms\n",
      "2:\tlearn: 0.4703360\ttotal: 12.3ms\tremaining: 24.6ms\n",
      "3:\tlearn: 0.4678859\ttotal: 16.4ms\tremaining: 20.6ms\n",
      "4:\tlearn: 0.4662988\ttotal: 20.7ms\tremaining: 16.5ms\n",
      "5:\tlearn: 0.4640621\ttotal: 25.4ms\tremaining: 12.7ms\n",
      "6:\tlearn: 0.4617955\ttotal: 29.5ms\tremaining: 8.43ms\n",
      "7:\tlearn: 0.4601208\ttotal: 33.7ms\tremaining: 4.21ms\n",
      "8:\tlearn: 0.4590542\ttotal: 38.3ms\tremaining: 0us\n",
      "[9, 0.51, 6, 0.2]\n",
      "0:\tlearn: 0.4803477\ttotal: 6.81ms\tremaining: 54.5ms\n",
      "1:\tlearn: 0.4736652\ttotal: 11.2ms\tremaining: 39.1ms\n",
      "2:\tlearn: 0.4703360\ttotal: 16ms\tremaining: 32ms\n",
      "3:\tlearn: 0.4678859\ttotal: 20.2ms\tremaining: 25.3ms\n",
      "4:\tlearn: 0.4662988\ttotal: 25.2ms\tremaining: 20.2ms\n",
      "5:\tlearn: 0.4640621\ttotal: 31.6ms\tremaining: 15.8ms\n",
      "6:\tlearn: 0.4617955\ttotal: 36.1ms\tremaining: 10.3ms\n",
      "7:\tlearn: 0.4601208\ttotal: 41.1ms\tremaining: 5.13ms\n",
      "8:\tlearn: 0.4590542\ttotal: 45.4ms\tremaining: 0us\n",
      "[9, 0.51, 15, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 12.6ms\tremaining: 101ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22ms\tremaining: 77.1ms\n",
      "2:\tlearn: 0.4682843\ttotal: 557ms\tremaining: 1.11s\n",
      "3:\tlearn: 0.4637816\ttotal: 1.07s\tremaining: 1.34s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.19s\tremaining: 954ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.7s\tremaining: 850ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.19s\tremaining: 624ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.69s\tremaining: 336ms\n",
      "8:\tlearn: 0.4530230\ttotal: 3.21s\tremaining: 0us\n",
      "[9, 0.51, 15, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 11.7ms\tremaining: 94ms\n",
      "1:\tlearn: 0.4740807\ttotal: 20.5ms\tremaining: 71.6ms\n",
      "2:\tlearn: 0.4682843\ttotal: 502ms\tremaining: 1s\n",
      "3:\tlearn: 0.4637816\ttotal: 962ms\tremaining: 1.2s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.09s\tremaining: 876ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.58s\tremaining: 793ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.13s\tremaining: 607ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.61s\tremaining: 326ms\n",
      "8:\tlearn: 0.4530230\ttotal: 3.11s\tremaining: 0us\n",
      "[9, 0.51, 15, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 12.3ms\tremaining: 98.7ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.6ms\tremaining: 79.2ms\n",
      "2:\tlearn: 0.4682843\ttotal: 507ms\tremaining: 1.01s\n",
      "3:\tlearn: 0.4637816\ttotal: 1.02s\tremaining: 1.28s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.14s\tremaining: 914ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.62s\tremaining: 811ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.13s\tremaining: 608ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.61s\tremaining: 326ms\n",
      "8:\tlearn: 0.4530230\ttotal: 3.09s\tremaining: 0us\n",
      "[9, 0.51, 15, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 12.7ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.2ms\tremaining: 77.8ms\n",
      "2:\tlearn: 0.4682843\ttotal: 528ms\tremaining: 1.05s\n",
      "3:\tlearn: 0.4637816\ttotal: 1.06s\tremaining: 1.32s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.18s\tremaining: 947ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.66s\tremaining: 829ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.13s\tremaining: 608ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.62s\tremaining: 328ms\n",
      "8:\tlearn: 0.4530230\ttotal: 3.14s\tremaining: 0us\n",
      "[9, 0.51, 15, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.39ms\tremaining: 75.1ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.5ms\tremaining: 64.9ms\n",
      "2:\tlearn: 0.4682843\ttotal: 503ms\tremaining: 1.01s\n",
      "3:\tlearn: 0.4637816\ttotal: 982ms\tremaining: 1.23s\n",
      "4:\tlearn: 0.4613151\ttotal: 1.13s\tremaining: 903ms\n",
      "5:\tlearn: 0.4588540\ttotal: 1.63s\tremaining: 813ms\n",
      "6:\tlearn: 0.4565342\ttotal: 2.14s\tremaining: 612ms\n",
      "7:\tlearn: 0.4547091\ttotal: 2.63s\tremaining: 329ms\n",
      "8:\tlearn: 0.4530230\ttotal: 3.17s\tremaining: 0us\n",
      "[9, 0.51, 10, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.39ms\tremaining: 75.1ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.3ms\tremaining: 64.2ms\n",
      "2:\tlearn: 0.4695149\ttotal: 33.5ms\tremaining: 67ms\n",
      "3:\tlearn: 0.4663819\ttotal: 47.5ms\tremaining: 59.3ms\n",
      "4:\tlearn: 0.4637371\ttotal: 63ms\tremaining: 50.4ms\n",
      "5:\tlearn: 0.4620590\ttotal: 79ms\tremaining: 39.5ms\n",
      "6:\tlearn: 0.4601769\ttotal: 96.7ms\tremaining: 27.6ms\n",
      "7:\tlearn: 0.4571796\ttotal: 113ms\tremaining: 14.1ms\n",
      "8:\tlearn: 0.4555052\ttotal: 131ms\tremaining: 0us\n",
      "[9, 0.51, 10, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 15.1ms\tremaining: 120ms\n",
      "1:\tlearn: 0.4740807\ttotal: 25.5ms\tremaining: 89.2ms\n",
      "2:\tlearn: 0.4695149\ttotal: 43.8ms\tremaining: 87.7ms\n",
      "3:\tlearn: 0.4663819\ttotal: 60.5ms\tremaining: 75.7ms\n",
      "4:\tlearn: 0.4637371\ttotal: 77.8ms\tremaining: 62.2ms\n",
      "5:\tlearn: 0.4620590\ttotal: 93.6ms\tremaining: 46.8ms\n",
      "6:\tlearn: 0.4601769\ttotal: 109ms\tremaining: 31.2ms\n",
      "7:\tlearn: 0.4571796\ttotal: 124ms\tremaining: 15.6ms\n",
      "8:\tlearn: 0.4555052\ttotal: 140ms\tremaining: 0us\n",
      "[9, 0.51, 10, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 11.4ms\tremaining: 91.1ms\n",
      "1:\tlearn: 0.4740807\ttotal: 21ms\tremaining: 73.5ms\n",
      "2:\tlearn: 0.4695149\ttotal: 36.5ms\tremaining: 72.9ms\n",
      "3:\tlearn: 0.4663819\ttotal: 51.7ms\tremaining: 64.6ms\n",
      "4:\tlearn: 0.4637371\ttotal: 67.4ms\tremaining: 53.9ms\n",
      "5:\tlearn: 0.4620590\ttotal: 83.1ms\tremaining: 41.5ms\n",
      "6:\tlearn: 0.4601769\ttotal: 99.6ms\tremaining: 28.5ms\n",
      "7:\tlearn: 0.4571796\ttotal: 116ms\tremaining: 14.5ms\n",
      "8:\tlearn: 0.4555052\ttotal: 133ms\tremaining: 0us\n",
      "[9, 0.51, 10, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.02ms\tremaining: 72.2ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.3ms\tremaining: 64.2ms\n",
      "2:\tlearn: 0.4695149\ttotal: 36.4ms\tremaining: 72.8ms\n",
      "3:\tlearn: 0.4663819\ttotal: 54.4ms\tremaining: 68ms\n",
      "4:\tlearn: 0.4637371\ttotal: 73ms\tremaining: 58.4ms\n",
      "5:\tlearn: 0.4620590\ttotal: 89.2ms\tremaining: 44.6ms\n",
      "6:\tlearn: 0.4601769\ttotal: 107ms\tremaining: 30.5ms\n",
      "7:\tlearn: 0.4571796\ttotal: 124ms\tremaining: 15.4ms\n",
      "8:\tlearn: 0.4555052\ttotal: 140ms\tremaining: 0us\n",
      "[9, 0.51, 10, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 14.1ms\tremaining: 113ms\n",
      "1:\tlearn: 0.4740807\ttotal: 23.1ms\tremaining: 81ms\n",
      "2:\tlearn: 0.4695149\ttotal: 39.5ms\tremaining: 79ms\n",
      "3:\tlearn: 0.4663819\ttotal: 56.5ms\tremaining: 70.6ms\n",
      "4:\tlearn: 0.4637371\ttotal: 72.5ms\tremaining: 58ms\n",
      "5:\tlearn: 0.4620590\ttotal: 88.8ms\tremaining: 44.4ms\n",
      "6:\tlearn: 0.4601769\ttotal: 104ms\tremaining: 29.8ms\n",
      "7:\tlearn: 0.4571796\ttotal: 119ms\tremaining: 14.9ms\n",
      "8:\tlearn: 0.4555052\ttotal: 135ms\tremaining: 0us\n",
      "[9, 0.51, 12, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 12.9ms\tremaining: 104ms\n",
      "1:\tlearn: 0.4740807\ttotal: 22.9ms\tremaining: 80.1ms\n",
      "2:\tlearn: 0.4687383\ttotal: 80.3ms\tremaining: 161ms\n",
      "3:\tlearn: 0.4654186\ttotal: 139ms\tremaining: 174ms\n",
      "4:\tlearn: 0.4626390\ttotal: 199ms\tremaining: 159ms\n",
      "5:\tlearn: 0.4611188\ttotal: 254ms\tremaining: 127ms\n",
      "6:\tlearn: 0.4591529\ttotal: 316ms\tremaining: 90.2ms\n",
      "7:\tlearn: 0.4574815\ttotal: 377ms\tremaining: 47.1ms\n",
      "8:\tlearn: 0.4557570\ttotal: 434ms\tremaining: 0us\n",
      "[9, 0.51, 12, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.81ms\tremaining: 78.5ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.3ms\tremaining: 67.6ms\n",
      "2:\tlearn: 0.4687383\ttotal: 80.7ms\tremaining: 161ms\n",
      "3:\tlearn: 0.4654186\ttotal: 141ms\tremaining: 176ms\n",
      "4:\tlearn: 0.4626390\ttotal: 212ms\tremaining: 170ms\n",
      "5:\tlearn: 0.4611188\ttotal: 271ms\tremaining: 135ms\n",
      "6:\tlearn: 0.4591529\ttotal: 326ms\tremaining: 93.1ms\n",
      "7:\tlearn: 0.4574815\ttotal: 389ms\tremaining: 48.7ms\n",
      "8:\tlearn: 0.4557570\ttotal: 456ms\tremaining: 0us\n",
      "[9, 0.51, 12, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.77ms\tremaining: 78.2ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.4ms\tremaining: 68ms\n",
      "2:\tlearn: 0.4687383\ttotal: 86.1ms\tremaining: 172ms\n",
      "3:\tlearn: 0.4654186\ttotal: 145ms\tremaining: 182ms\n",
      "4:\tlearn: 0.4626390\ttotal: 209ms\tremaining: 167ms\n",
      "5:\tlearn: 0.4611188\ttotal: 273ms\tremaining: 136ms\n",
      "6:\tlearn: 0.4591529\ttotal: 331ms\tremaining: 94.5ms\n",
      "7:\tlearn: 0.4574815\ttotal: 388ms\tremaining: 48.5ms\n",
      "8:\tlearn: 0.4557570\ttotal: 446ms\tremaining: 0us\n",
      "[9, 0.51, 12, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.41ms\tremaining: 75.3ms\n",
      "1:\tlearn: 0.4740807\ttotal: 18.6ms\tremaining: 65ms\n",
      "2:\tlearn: 0.4687383\ttotal: 80.4ms\tremaining: 161ms\n",
      "3:\tlearn: 0.4654186\ttotal: 146ms\tremaining: 182ms\n",
      "4:\tlearn: 0.4626390\ttotal: 213ms\tremaining: 171ms\n",
      "5:\tlearn: 0.4611188\ttotal: 275ms\tremaining: 137ms\n",
      "6:\tlearn: 0.4591529\ttotal: 335ms\tremaining: 95.7ms\n",
      "7:\tlearn: 0.4574815\ttotal: 397ms\tremaining: 49.6ms\n",
      "8:\tlearn: 0.4557570\ttotal: 463ms\tremaining: 0us\n",
      "[9, 0.51, 12, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 14.2ms\tremaining: 114ms\n",
      "1:\tlearn: 0.4740807\ttotal: 23.4ms\tremaining: 81.8ms\n",
      "2:\tlearn: 0.4687383\ttotal: 86.9ms\tremaining: 174ms\n",
      "3:\tlearn: 0.4654186\ttotal: 147ms\tremaining: 184ms\n",
      "4:\tlearn: 0.4626390\ttotal: 210ms\tremaining: 168ms\n",
      "5:\tlearn: 0.4611188\ttotal: 278ms\tremaining: 139ms\n",
      "6:\tlearn: 0.4591529\ttotal: 339ms\tremaining: 96.7ms\n",
      "7:\tlearn: 0.4574815\ttotal: 398ms\tremaining: 49.8ms\n",
      "8:\tlearn: 0.4557570\ttotal: 458ms\tremaining: 0us\n",
      "[9, 0.51, 13, -0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 15.2ms\tremaining: 121ms\n",
      "1:\tlearn: 0.4740807\ttotal: 24.9ms\tremaining: 87.1ms\n",
      "2:\tlearn: 0.4684527\ttotal: 138ms\tremaining: 277ms\n",
      "3:\tlearn: 0.4656625\ttotal: 280ms\tremaining: 350ms\n",
      "4:\tlearn: 0.4608922\ttotal: 405ms\tremaining: 324ms\n",
      "5:\tlearn: 0.4588359\ttotal: 530ms\tremaining: 265ms\n",
      "6:\tlearn: 0.4565252\ttotal: 660ms\tremaining: 188ms\n",
      "7:\tlearn: 0.4547902\ttotal: 780ms\tremaining: 97.5ms\n",
      "8:\tlearn: 0.4529607\ttotal: 908ms\tremaining: 0us\n",
      "[9, 0.51, 13, 0.3]\n",
      "0:\tlearn: 0.4800117\ttotal: 9.96ms\tremaining: 79.7ms\n",
      "1:\tlearn: 0.4740807\ttotal: 19.4ms\tremaining: 67.7ms\n",
      "2:\tlearn: 0.4684527\ttotal: 138ms\tremaining: 276ms\n",
      "3:\tlearn: 0.4656625\ttotal: 255ms\tremaining: 319ms\n",
      "4:\tlearn: 0.4608922\ttotal: 374ms\tremaining: 299ms\n",
      "5:\tlearn: 0.4588359\ttotal: 495ms\tremaining: 247ms\n",
      "6:\tlearn: 0.4565252\ttotal: 629ms\tremaining: 180ms\n",
      "7:\tlearn: 0.4547902\ttotal: 745ms\tremaining: 93.2ms\n",
      "8:\tlearn: 0.4529607\ttotal: 868ms\tremaining: 0us\n",
      "[9, 0.51, 13, 0.0]\n",
      "0:\tlearn: 0.4800117\ttotal: 11.5ms\tremaining: 92.3ms\n",
      "1:\tlearn: 0.4740807\ttotal: 21.9ms\tremaining: 76.7ms\n",
      "2:\tlearn: 0.4684527\ttotal: 154ms\tremaining: 307ms\n",
      "3:\tlearn: 0.4656625\ttotal: 277ms\tremaining: 346ms\n",
      "4:\tlearn: 0.4608922\ttotal: 397ms\tremaining: 317ms\n",
      "5:\tlearn: 0.4588359\ttotal: 523ms\tremaining: 261ms\n",
      "6:\tlearn: 0.4565252\ttotal: 639ms\tremaining: 183ms\n",
      "7:\tlearn: 0.4547902\ttotal: 774ms\tremaining: 96.7ms\n",
      "8:\tlearn: 0.4529607\ttotal: 891ms\tremaining: 0us\n",
      "[9, 0.51, 13, 0.15]\n",
      "0:\tlearn: 0.4800117\ttotal: 13.5ms\tremaining: 108ms\n",
      "1:\tlearn: 0.4740807\ttotal: 23.4ms\tremaining: 81.8ms\n",
      "2:\tlearn: 0.4684527\ttotal: 145ms\tremaining: 289ms\n",
      "3:\tlearn: 0.4656625\ttotal: 263ms\tremaining: 329ms\n",
      "4:\tlearn: 0.4608922\ttotal: 383ms\tremaining: 306ms\n",
      "5:\tlearn: 0.4588359\ttotal: 501ms\tremaining: 251ms\n",
      "6:\tlearn: 0.4565252\ttotal: 620ms\tremaining: 177ms\n",
      "7:\tlearn: 0.4547902\ttotal: 733ms\tremaining: 91.6ms\n",
      "8:\tlearn: 0.4529607\ttotal: 861ms\tremaining: 0us\n",
      "[9, 0.51, 13, 0.2]\n",
      "0:\tlearn: 0.4800117\ttotal: 15.1ms\tremaining: 121ms\n",
      "1:\tlearn: 0.4740807\ttotal: 25ms\tremaining: 87.6ms\n",
      "2:\tlearn: 0.4684527\ttotal: 159ms\tremaining: 318ms\n",
      "3:\tlearn: 0.4656625\ttotal: 285ms\tremaining: 356ms\n",
      "4:\tlearn: 0.4608922\ttotal: 410ms\tremaining: 328ms\n",
      "5:\tlearn: 0.4588359\ttotal: 535ms\tremaining: 268ms\n",
      "6:\tlearn: 0.4565252\ttotal: 661ms\tremaining: 189ms\n",
      "7:\tlearn: 0.4547902\ttotal: 781ms\tremaining: 97.6ms\n",
      "8:\tlearn: 0.4529607\ttotal: 916ms\tremaining: 0us\n",
      "[9, 0.53, 6, -0.3]\n",
      "0:\tlearn: 0.4799647\ttotal: 4.15ms\tremaining: 33.2ms\n",
      "1:\tlearn: 0.4733288\ttotal: 9.33ms\tremaining: 32.7ms\n",
      "2:\tlearn: 0.4706074\ttotal: 13.8ms\tremaining: 27.6ms\n",
      "3:\tlearn: 0.4678897\ttotal: 18.5ms\tremaining: 23.2ms\n",
      "4:\tlearn: 0.4663042\ttotal: 23.2ms\tremaining: 18.6ms\n",
      "5:\tlearn: 0.4644419\ttotal: 27.8ms\tremaining: 13.9ms\n",
      "6:\tlearn: 0.4623845\ttotal: 32.3ms\tremaining: 9.23ms\n",
      "7:\tlearn: 0.4608343\ttotal: 36.8ms\tremaining: 4.6ms\n",
      "8:\tlearn: 0.4595897\ttotal: 41.2ms\tremaining: 0us\n",
      "[9, 0.53, 6, 0.3]\n",
      "0:\tlearn: 0.4799647\ttotal: 4.52ms\tremaining: 36.2ms\n",
      "1:\tlearn: 0.4733288\ttotal: 8.74ms\tremaining: 30.6ms\n",
      "2:\tlearn: 0.4706074\ttotal: 12.8ms\tremaining: 25.7ms\n",
      "3:\tlearn: 0.4678897\ttotal: 17.3ms\tremaining: 21.6ms\n",
      "4:\tlearn: 0.4663042\ttotal: 23.1ms\tremaining: 18.5ms\n",
      "5:\tlearn: 0.4644419\ttotal: 27.5ms\tremaining: 13.8ms\n",
      "6:\tlearn: 0.4623845\ttotal: 32.2ms\tremaining: 9.2ms\n",
      "7:\tlearn: 0.4608343\ttotal: 36.4ms\tremaining: 4.55ms\n",
      "8:\tlearn: 0.4595897\ttotal: 40.5ms\tremaining: 0us\n",
      "[9, 0.53, 6, 0.0]\n",
      "0:\tlearn: 0.4799647\ttotal: 4.8ms\tremaining: 38.4ms\n",
      "1:\tlearn: 0.4733288\ttotal: 9.42ms\tremaining: 33ms\n",
      "2:\tlearn: 0.4706074\ttotal: 13.8ms\tremaining: 27.5ms\n",
      "3:\tlearn: 0.4678897\ttotal: 18.1ms\tremaining: 22.7ms\n",
      "4:\tlearn: 0.4663042\ttotal: 22.5ms\tremaining: 18ms\n",
      "5:\tlearn: 0.4644419\ttotal: 29.8ms\tremaining: 14.9ms\n",
      "6:\tlearn: 0.4623845\ttotal: 34ms\tremaining: 9.71ms\n",
      "7:\tlearn: 0.4608343\ttotal: 39.2ms\tremaining: 4.89ms\n",
      "8:\tlearn: 0.4595897\ttotal: 43.8ms\tremaining: 0us\n",
      "[9, 0.53, 6, 0.15]\n",
      "0:\tlearn: 0.4799647\ttotal: 10.7ms\tremaining: 85.2ms\n",
      "1:\tlearn: 0.4733288\ttotal: 15.2ms\tremaining: 53.3ms\n",
      "2:\tlearn: 0.4706074\ttotal: 19.9ms\tremaining: 39.7ms\n",
      "3:\tlearn: 0.4678897\ttotal: 25.1ms\tremaining: 31.3ms\n",
      "4:\tlearn: 0.4663042\ttotal: 29.7ms\tremaining: 23.8ms\n",
      "5:\tlearn: 0.4644419\ttotal: 34.3ms\tremaining: 17.1ms\n",
      "6:\tlearn: 0.4623845\ttotal: 39ms\tremaining: 11.2ms\n",
      "7:\tlearn: 0.4608343\ttotal: 43.8ms\tremaining: 5.47ms\n",
      "8:\tlearn: 0.4595897\ttotal: 48.4ms\tremaining: 0us\n",
      "[9, 0.53, 6, 0.2]\n",
      "0:\tlearn: 0.4799647\ttotal: 4.29ms\tremaining: 34.3ms\n",
      "1:\tlearn: 0.4733288\ttotal: 8.35ms\tremaining: 29.2ms\n",
      "2:\tlearn: 0.4706074\ttotal: 12.7ms\tremaining: 25.4ms\n",
      "3:\tlearn: 0.4678897\ttotal: 17.4ms\tremaining: 21.8ms\n",
      "4:\tlearn: 0.4663042\ttotal: 22.9ms\tremaining: 18.3ms\n",
      "5:\tlearn: 0.4644419\ttotal: 27.5ms\tremaining: 13.7ms\n",
      "6:\tlearn: 0.4623845\ttotal: 32.5ms\tremaining: 9.3ms\n",
      "7:\tlearn: 0.4608343\ttotal: 37.1ms\tremaining: 4.64ms\n",
      "8:\tlearn: 0.4595897\ttotal: 41.4ms\tremaining: 0us\n",
      "[9, 0.53, 15, -0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.15ms\tremaining: 73.2ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18.2ms\tremaining: 63.7ms\n",
      "2:\tlearn: 0.4679294\ttotal: 495ms\tremaining: 989ms\n",
      "3:\tlearn: 0.4633466\ttotal: 977ms\tremaining: 1.22s\n",
      "4:\tlearn: 0.4608528\ttotal: 1.11s\tremaining: 887ms\n",
      "5:\tlearn: 0.4583235\ttotal: 1.56s\tremaining: 779ms\n",
      "6:\tlearn: 0.4556306\ttotal: 2.01s\tremaining: 574ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.49s\tremaining: 312ms\n",
      "8:\tlearn: 0.4518134\ttotal: 2.96s\tremaining: 0us\n",
      "[9, 0.53, 15, 0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.22ms\tremaining: 73.8ms\n",
      "1:\tlearn: 0.4737091\ttotal: 17.9ms\tremaining: 62.8ms\n",
      "2:\tlearn: 0.4679294\ttotal: 474ms\tremaining: 948ms\n",
      "3:\tlearn: 0.4633466\ttotal: 948ms\tremaining: 1.19s\n",
      "4:\tlearn: 0.4608528\ttotal: 1.07s\tremaining: 861ms\n",
      "5:\tlearn: 0.4583235\ttotal: 1.53s\tremaining: 766ms\n",
      "6:\tlearn: 0.4556306\ttotal: 2.04s\tremaining: 583ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.52s\tremaining: 314ms\n",
      "8:\tlearn: 0.4518134\ttotal: 3s\tremaining: 0us\n",
      "[9, 0.53, 15, 0.0]\n",
      "0:\tlearn: 0.4796178\ttotal: 8.96ms\tremaining: 71.7ms\n",
      "1:\tlearn: 0.4737091\ttotal: 17.5ms\tremaining: 61.4ms\n",
      "2:\tlearn: 0.4679294\ttotal: 481ms\tremaining: 961ms\n",
      "3:\tlearn: 0.4633466\ttotal: 959ms\tremaining: 1.2s\n",
      "4:\tlearn: 0.4608528\ttotal: 1.08s\tremaining: 864ms\n",
      "5:\tlearn: 0.4583235\ttotal: 1.6s\tremaining: 800ms\n",
      "6:\tlearn: 0.4556306\ttotal: 2.11s\tremaining: 602ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.59s\tremaining: 323ms\n",
      "8:\tlearn: 0.4518134\ttotal: 3.1s\tremaining: 0us\n",
      "[9, 0.53, 15, 0.15]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.69ms\tremaining: 77.5ms\n",
      "1:\tlearn: 0.4737091\ttotal: 19.2ms\tremaining: 67.3ms\n",
      "2:\tlearn: 0.4679294\ttotal: 505ms\tremaining: 1.01s\n",
      "3:\tlearn: 0.4633466\ttotal: 1.01s\tremaining: 1.26s\n",
      "4:\tlearn: 0.4608528\ttotal: 1.13s\tremaining: 902ms\n",
      "5:\tlearn: 0.4583235\ttotal: 1.63s\tremaining: 814ms\n",
      "6:\tlearn: 0.4556306\ttotal: 2.17s\tremaining: 619ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.62s\tremaining: 327ms\n",
      "8:\tlearn: 0.4518134\ttotal: 3.16s\tremaining: 0us\n",
      "[9, 0.53, 15, 0.2]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.75ms\tremaining: 78ms\n",
      "1:\tlearn: 0.4737091\ttotal: 19ms\tremaining: 66.5ms\n",
      "2:\tlearn: 0.4679294\ttotal: 489ms\tremaining: 978ms\n",
      "3:\tlearn: 0.4633466\ttotal: 954ms\tremaining: 1.19s\n",
      "4:\tlearn: 0.4608528\ttotal: 1.08s\tremaining: 866ms\n",
      "5:\tlearn: 0.4583235\ttotal: 1.54s\tremaining: 772ms\n",
      "6:\tlearn: 0.4556306\ttotal: 2.09s\tremaining: 597ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.58s\tremaining: 323ms\n",
      "8:\tlearn: 0.4518134\ttotal: 3.05s\tremaining: 0us\n",
      "[9, 0.53, 10, -0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.05ms\tremaining: 72.4ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18ms\tremaining: 63.1ms\n",
      "2:\tlearn: 0.4691361\ttotal: 33.3ms\tremaining: 66.6ms\n",
      "3:\tlearn: 0.4664327\ttotal: 48.3ms\tremaining: 60.3ms\n",
      "4:\tlearn: 0.4640170\ttotal: 63.7ms\tremaining: 50.9ms\n",
      "5:\tlearn: 0.4619731\ttotal: 82.5ms\tremaining: 41.3ms\n",
      "6:\tlearn: 0.4595664\ttotal: 101ms\tremaining: 28.8ms\n",
      "7:\tlearn: 0.4567217\ttotal: 117ms\tremaining: 14.7ms\n",
      "8:\tlearn: 0.4552574\ttotal: 133ms\tremaining: 0us\n",
      "[9, 0.53, 10, 0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.94ms\tremaining: 79.5ms\n",
      "1:\tlearn: 0.4737091\ttotal: 19.6ms\tremaining: 68.5ms\n",
      "2:\tlearn: 0.4691361\ttotal: 37.8ms\tremaining: 75.6ms\n",
      "3:\tlearn: 0.4664327\ttotal: 54.8ms\tremaining: 68.5ms\n",
      "4:\tlearn: 0.4640170\ttotal: 73.1ms\tremaining: 58.4ms\n",
      "5:\tlearn: 0.4619731\ttotal: 89.2ms\tremaining: 44.6ms\n",
      "6:\tlearn: 0.4595664\ttotal: 105ms\tremaining: 30.1ms\n",
      "7:\tlearn: 0.4567217\ttotal: 121ms\tremaining: 15.1ms\n",
      "8:\tlearn: 0.4552574\ttotal: 138ms\tremaining: 0us\n",
      "[9, 0.53, 10, 0.0]\n",
      "0:\tlearn: 0.4796178\ttotal: 11.8ms\tremaining: 94.2ms\n",
      "1:\tlearn: 0.4737091\ttotal: 21.2ms\tremaining: 74.1ms\n",
      "2:\tlearn: 0.4691361\ttotal: 35.8ms\tremaining: 71.6ms\n",
      "3:\tlearn: 0.4664327\ttotal: 50.7ms\tremaining: 63.4ms\n",
      "4:\tlearn: 0.4640170\ttotal: 65.5ms\tremaining: 52.4ms\n",
      "5:\tlearn: 0.4619731\ttotal: 80ms\tremaining: 40ms\n",
      "6:\tlearn: 0.4595664\ttotal: 94.8ms\tremaining: 27.1ms\n",
      "7:\tlearn: 0.4567217\ttotal: 111ms\tremaining: 13.8ms\n",
      "8:\tlearn: 0.4552574\ttotal: 127ms\tremaining: 0us\n",
      "[9, 0.53, 10, 0.15]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.79ms\tremaining: 78.3ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18.9ms\tremaining: 66.3ms\n",
      "2:\tlearn: 0.4691361\ttotal: 34.4ms\tremaining: 68.8ms\n",
      "3:\tlearn: 0.4664327\ttotal: 49.3ms\tremaining: 61.6ms\n",
      "4:\tlearn: 0.4640170\ttotal: 64.8ms\tremaining: 51.8ms\n",
      "5:\tlearn: 0.4619731\ttotal: 81.4ms\tremaining: 40.7ms\n",
      "6:\tlearn: 0.4595664\ttotal: 96.7ms\tremaining: 27.6ms\n",
      "7:\tlearn: 0.4567217\ttotal: 112ms\tremaining: 14ms\n",
      "8:\tlearn: 0.4552574\ttotal: 126ms\tremaining: 0us\n",
      "[9, 0.53, 10, 0.2]\n",
      "0:\tlearn: 0.4796178\ttotal: 10.3ms\tremaining: 82ms\n",
      "1:\tlearn: 0.4737091\ttotal: 19.3ms\tremaining: 67.6ms\n",
      "2:\tlearn: 0.4691361\ttotal: 36.6ms\tremaining: 73.1ms\n",
      "3:\tlearn: 0.4664327\ttotal: 51.2ms\tremaining: 64ms\n",
      "4:\tlearn: 0.4640170\ttotal: 66.7ms\tremaining: 53.4ms\n",
      "5:\tlearn: 0.4619731\ttotal: 81.7ms\tremaining: 40.8ms\n",
      "6:\tlearn: 0.4595664\ttotal: 96ms\tremaining: 27.4ms\n",
      "7:\tlearn: 0.4567217\ttotal: 119ms\tremaining: 14.8ms\n",
      "8:\tlearn: 0.4552574\ttotal: 135ms\tremaining: 0us\n",
      "[9, 0.53, 12, -0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 12.8ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4737091\ttotal: 23.3ms\tremaining: 81.7ms\n",
      "2:\tlearn: 0.4683837\ttotal: 81.1ms\tremaining: 162ms\n",
      "3:\tlearn: 0.4650366\ttotal: 136ms\tremaining: 170ms\n",
      "4:\tlearn: 0.4622467\ttotal: 200ms\tremaining: 160ms\n",
      "5:\tlearn: 0.4590824\ttotal: 260ms\tremaining: 130ms\n",
      "6:\tlearn: 0.4574354\ttotal: 326ms\tremaining: 93.1ms\n",
      "7:\tlearn: 0.4555682\ttotal: 386ms\tremaining: 48.2ms\n",
      "8:\tlearn: 0.4547833\ttotal: 402ms\tremaining: 0us\n",
      "[9, 0.53, 12, 0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 11.8ms\tremaining: 94.5ms\n",
      "1:\tlearn: 0.4737091\ttotal: 21.2ms\tremaining: 74.1ms\n",
      "2:\tlearn: 0.4683837\ttotal: 78.7ms\tremaining: 157ms\n",
      "3:\tlearn: 0.4650366\ttotal: 140ms\tremaining: 174ms\n",
      "4:\tlearn: 0.4622467\ttotal: 199ms\tremaining: 160ms\n",
      "5:\tlearn: 0.4590824\ttotal: 259ms\tremaining: 130ms\n",
      "6:\tlearn: 0.4574354\ttotal: 324ms\tremaining: 92.5ms\n",
      "7:\tlearn: 0.4555682\ttotal: 387ms\tremaining: 48.4ms\n",
      "8:\tlearn: 0.4547833\ttotal: 404ms\tremaining: 0us\n",
      "[9, 0.53, 12, 0.0]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.26ms\tremaining: 74.1ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18.4ms\tremaining: 64.5ms\n",
      "2:\tlearn: 0.4683837\ttotal: 77.8ms\tremaining: 156ms\n",
      "3:\tlearn: 0.4650366\ttotal: 137ms\tremaining: 171ms\n",
      "4:\tlearn: 0.4622467\ttotal: 195ms\tremaining: 156ms\n",
      "5:\tlearn: 0.4590824\ttotal: 255ms\tremaining: 127ms\n",
      "6:\tlearn: 0.4574354\ttotal: 313ms\tremaining: 89.3ms\n",
      "7:\tlearn: 0.4555682\ttotal: 379ms\tremaining: 47.4ms\n",
      "8:\tlearn: 0.4547833\ttotal: 394ms\tremaining: 0us\n",
      "[9, 0.53, 12, 0.15]\n",
      "0:\tlearn: 0.4796178\ttotal: 12.7ms\tremaining: 101ms\n",
      "1:\tlearn: 0.4737091\ttotal: 23ms\tremaining: 80.6ms\n",
      "2:\tlearn: 0.4683837\ttotal: 83.7ms\tremaining: 167ms\n",
      "3:\tlearn: 0.4650366\ttotal: 150ms\tremaining: 188ms\n",
      "4:\tlearn: 0.4622467\ttotal: 211ms\tremaining: 168ms\n",
      "5:\tlearn: 0.4590824\ttotal: 273ms\tremaining: 136ms\n",
      "6:\tlearn: 0.4574354\ttotal: 335ms\tremaining: 95.6ms\n",
      "7:\tlearn: 0.4555682\ttotal: 394ms\tremaining: 49.3ms\n",
      "8:\tlearn: 0.4547833\ttotal: 412ms\tremaining: 0us\n",
      "[9, 0.53, 12, 0.2]\n",
      "0:\tlearn: 0.4796178\ttotal: 10.4ms\tremaining: 83ms\n",
      "1:\tlearn: 0.4737091\ttotal: 19.5ms\tremaining: 68.3ms\n",
      "2:\tlearn: 0.4683837\ttotal: 85.6ms\tremaining: 171ms\n",
      "3:\tlearn: 0.4650366\ttotal: 153ms\tremaining: 191ms\n",
      "4:\tlearn: 0.4622467\ttotal: 215ms\tremaining: 172ms\n",
      "5:\tlearn: 0.4590824\ttotal: 279ms\tremaining: 139ms\n",
      "6:\tlearn: 0.4574354\ttotal: 340ms\tremaining: 97.2ms\n",
      "7:\tlearn: 0.4555682\ttotal: 401ms\tremaining: 50.1ms\n",
      "8:\tlearn: 0.4547833\ttotal: 417ms\tremaining: 0us\n",
      "[9, 0.53, 13, -0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 10.3ms\tremaining: 82.7ms\n",
      "1:\tlearn: 0.4737091\ttotal: 20ms\tremaining: 69.8ms\n",
      "2:\tlearn: 0.4681049\ttotal: 139ms\tremaining: 279ms\n",
      "3:\tlearn: 0.4652893\ttotal: 260ms\tremaining: 325ms\n",
      "4:\tlearn: 0.4604401\ttotal: 385ms\tremaining: 308ms\n",
      "5:\tlearn: 0.4583924\ttotal: 512ms\tremaining: 256ms\n",
      "6:\tlearn: 0.4560713\ttotal: 638ms\tremaining: 182ms\n",
      "7:\tlearn: 0.4543157\ttotal: 753ms\tremaining: 94.1ms\n",
      "8:\tlearn: 0.4524415\ttotal: 881ms\tremaining: 0us\n",
      "[9, 0.53, 13, 0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 10.9ms\tremaining: 87.6ms\n",
      "1:\tlearn: 0.4737091\ttotal: 20.1ms\tremaining: 70.2ms\n",
      "2:\tlearn: 0.4681049\ttotal: 131ms\tremaining: 262ms\n",
      "3:\tlearn: 0.4652893\ttotal: 253ms\tremaining: 316ms\n",
      "4:\tlearn: 0.4604401\ttotal: 369ms\tremaining: 295ms\n",
      "5:\tlearn: 0.4583924\ttotal: 490ms\tremaining: 245ms\n",
      "6:\tlearn: 0.4560713\ttotal: 609ms\tremaining: 174ms\n",
      "7:\tlearn: 0.4543157\ttotal: 723ms\tremaining: 90.4ms\n",
      "8:\tlearn: 0.4524415\ttotal: 849ms\tremaining: 0us\n",
      "[9, 0.53, 13, 0.0]\n",
      "0:\tlearn: 0.4796178\ttotal: 9.29ms\tremaining: 74.3ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18.5ms\tremaining: 64.7ms\n",
      "2:\tlearn: 0.4681049\ttotal: 146ms\tremaining: 292ms\n",
      "3:\tlearn: 0.4652893\ttotal: 269ms\tremaining: 336ms\n",
      "4:\tlearn: 0.4604401\ttotal: 392ms\tremaining: 314ms\n",
      "5:\tlearn: 0.4583924\ttotal: 518ms\tremaining: 259ms\n",
      "6:\tlearn: 0.4560713\ttotal: 652ms\tremaining: 186ms\n",
      "7:\tlearn: 0.4543157\ttotal: 766ms\tremaining: 95.7ms\n",
      "8:\tlearn: 0.4524415\ttotal: 886ms\tremaining: 0us\n",
      "[9, 0.53, 13, 0.15]\n",
      "0:\tlearn: 0.4796178\ttotal: 10.5ms\tremaining: 84.3ms\n",
      "1:\tlearn: 0.4737091\ttotal: 20.3ms\tremaining: 70.9ms\n",
      "2:\tlearn: 0.4681049\ttotal: 166ms\tremaining: 332ms\n",
      "3:\tlearn: 0.4652893\ttotal: 293ms\tremaining: 367ms\n",
      "4:\tlearn: 0.4604401\ttotal: 410ms\tremaining: 328ms\n",
      "5:\tlearn: 0.4583924\ttotal: 529ms\tremaining: 264ms\n",
      "6:\tlearn: 0.4560713\ttotal: 650ms\tremaining: 186ms\n",
      "7:\tlearn: 0.4543157\ttotal: 771ms\tremaining: 96.3ms\n",
      "8:\tlearn: 0.4524415\ttotal: 897ms\tremaining: 0us\n",
      "[9, 0.53, 13, 0.2]\n",
      "0:\tlearn: 0.4796178\ttotal: 12.4ms\tremaining: 99.5ms\n",
      "1:\tlearn: 0.4737091\ttotal: 21ms\tremaining: 73.6ms\n",
      "2:\tlearn: 0.4681049\ttotal: 144ms\tremaining: 288ms\n",
      "3:\tlearn: 0.4652893\ttotal: 259ms\tremaining: 324ms\n",
      "4:\tlearn: 0.4604401\ttotal: 375ms\tremaining: 300ms\n",
      "5:\tlearn: 0.4583924\ttotal: 494ms\tremaining: 247ms\n",
      "6:\tlearn: 0.4560713\ttotal: 617ms\tremaining: 176ms\n",
      "7:\tlearn: 0.4543157\ttotal: 735ms\tremaining: 91.8ms\n",
      "8:\tlearn: 0.4524415\ttotal: 852ms\tremaining: 0us\n",
      "[9, 0.53, 14, -0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 11.3ms\tremaining: 90.7ms\n",
      "1:\tlearn: 0.4737091\ttotal: 19.4ms\tremaining: 68ms\n",
      "2:\tlearn: 0.4679636\ttotal: 262ms\tremaining: 524ms\n",
      "3:\tlearn: 0.4643845\ttotal: 499ms\tremaining: 623ms\n",
      "4:\tlearn: 0.4615630\ttotal: 738ms\tremaining: 590ms\n",
      "5:\tlearn: 0.4590014\ttotal: 987ms\tremaining: 494ms\n",
      "6:\tlearn: 0.4577257\ttotal: 994ms\tremaining: 284ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.26s\tremaining: 157ms\n",
      "8:\tlearn: 0.4536621\ttotal: 1.51s\tremaining: 0us\n",
      "[9, 0.53, 14, 0.3]\n",
      "0:\tlearn: 0.4796178\ttotal: 14.3ms\tremaining: 114ms\n",
      "1:\tlearn: 0.4737091\ttotal: 25.3ms\tremaining: 88.7ms\n",
      "2:\tlearn: 0.4679636\ttotal: 276ms\tremaining: 552ms\n",
      "3:\tlearn: 0.4643845\ttotal: 531ms\tremaining: 664ms\n",
      "4:\tlearn: 0.4615630\ttotal: 783ms\tremaining: 626ms\n",
      "5:\tlearn: 0.4590014\ttotal: 1.02s\tremaining: 511ms\n",
      "6:\tlearn: 0.4577257\ttotal: 1.02s\tremaining: 293ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.27s\tremaining: 159ms\n",
      "8:\tlearn: 0.4536621\ttotal: 1.52s\tremaining: 0us\n",
      "[9, 0.53, 14, 0.0]\n",
      "0:\tlearn: 0.4796178\ttotal: 14.6ms\tremaining: 117ms\n",
      "1:\tlearn: 0.4737091\ttotal: 25.4ms\tremaining: 88.8ms\n",
      "2:\tlearn: 0.4679636\ttotal: 255ms\tremaining: 511ms\n",
      "3:\tlearn: 0.4643845\ttotal: 504ms\tremaining: 630ms\n",
      "4:\tlearn: 0.4615630\ttotal: 745ms\tremaining: 596ms\n",
      "5:\tlearn: 0.4590014\ttotal: 994ms\tremaining: 497ms\n",
      "6:\tlearn: 0.4577257\ttotal: 998ms\tremaining: 285ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.24s\tremaining: 155ms\n",
      "8:\tlearn: 0.4536621\ttotal: 1.49s\tremaining: 0us\n",
      "[9, 0.53, 14, 0.15]\n",
      "0:\tlearn: 0.4796178\ttotal: 13.2ms\tremaining: 105ms\n",
      "1:\tlearn: 0.4737091\ttotal: 23.4ms\tremaining: 81.8ms\n",
      "2:\tlearn: 0.4679636\ttotal: 277ms\tremaining: 553ms\n",
      "3:\tlearn: 0.4643845\ttotal: 513ms\tremaining: 641ms\n",
      "4:\tlearn: 0.4615630\ttotal: 754ms\tremaining: 604ms\n",
      "5:\tlearn: 0.4590014\ttotal: 1.01s\tremaining: 506ms\n",
      "6:\tlearn: 0.4577257\ttotal: 1.02s\tremaining: 291ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.26s\tremaining: 158ms\n",
      "8:\tlearn: 0.4536621\ttotal: 1.53s\tremaining: 0us\n",
      "[9, 0.53, 14, 0.2]\n",
      "0:\tlearn: 0.4796178\ttotal: 16.3ms\tremaining: 130ms\n",
      "1:\tlearn: 0.4737091\ttotal: 25.9ms\tremaining: 90.7ms\n",
      "2:\tlearn: 0.4679636\ttotal: 268ms\tremaining: 537ms\n",
      "3:\tlearn: 0.4643845\ttotal: 538ms\tremaining: 673ms\n",
      "4:\tlearn: 0.4615630\ttotal: 787ms\tremaining: 630ms\n",
      "5:\tlearn: 0.4590014\ttotal: 1.03s\tremaining: 513ms\n",
      "6:\tlearn: 0.4577257\ttotal: 1.03s\tremaining: 295ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.27s\tremaining: 159ms\n",
      "8:\tlearn: 0.4536621\ttotal: 1.51s\tremaining: 0us\n",
      "[9, 0.54, 6, -0.3]\n",
      "0:\tlearn: 0.4797789\ttotal: 7.28ms\tremaining: 58.2ms\n",
      "1:\tlearn: 0.4731705\ttotal: 11.5ms\tremaining: 40.2ms\n",
      "2:\tlearn: 0.4704434\ttotal: 16ms\tremaining: 31.9ms\n",
      "3:\tlearn: 0.4677125\ttotal: 20.3ms\tremaining: 25.4ms\n",
      "4:\tlearn: 0.4661362\ttotal: 24.5ms\tremaining: 19.6ms\n",
      "5:\tlearn: 0.4642593\ttotal: 29.2ms\tremaining: 14.6ms\n",
      "6:\tlearn: 0.4622214\ttotal: 33.7ms\tremaining: 9.63ms\n",
      "7:\tlearn: 0.4608701\ttotal: 38ms\tremaining: 4.74ms\n",
      "8:\tlearn: 0.4597302\ttotal: 42.3ms\tremaining: 0us\n",
      "[9, 0.54, 6, 0.3]\n",
      "0:\tlearn: 0.4797789\ttotal: 10.5ms\tremaining: 83.9ms\n",
      "1:\tlearn: 0.4731705\ttotal: 14.6ms\tremaining: 51.1ms\n",
      "2:\tlearn: 0.4704434\ttotal: 18.6ms\tremaining: 37.3ms\n",
      "3:\tlearn: 0.4677125\ttotal: 23.2ms\tremaining: 29ms\n",
      "4:\tlearn: 0.4661362\ttotal: 27.4ms\tremaining: 21.9ms\n",
      "5:\tlearn: 0.4642593\ttotal: 31.5ms\tremaining: 15.8ms\n",
      "6:\tlearn: 0.4622214\ttotal: 35.9ms\tremaining: 10.2ms\n",
      "7:\tlearn: 0.4608701\ttotal: 40.3ms\tremaining: 5.04ms\n",
      "8:\tlearn: 0.4597302\ttotal: 44.4ms\tremaining: 0us\n",
      "[9, 0.54, 6, 0.0]\n",
      "0:\tlearn: 0.4797789\ttotal: 5.54ms\tremaining: 44.3ms\n",
      "1:\tlearn: 0.4731705\ttotal: 10ms\tremaining: 35.1ms\n",
      "2:\tlearn: 0.4704434\ttotal: 14.4ms\tremaining: 28.7ms\n",
      "3:\tlearn: 0.4677125\ttotal: 18.8ms\tremaining: 23.5ms\n",
      "4:\tlearn: 0.4661362\ttotal: 23.5ms\tremaining: 18.8ms\n",
      "5:\tlearn: 0.4642593\ttotal: 28.3ms\tremaining: 14.2ms\n",
      "6:\tlearn: 0.4622214\ttotal: 32.8ms\tremaining: 9.37ms\n",
      "7:\tlearn: 0.4608701\ttotal: 37.5ms\tremaining: 4.69ms\n",
      "8:\tlearn: 0.4597302\ttotal: 41.7ms\tremaining: 0us\n",
      "[9, 0.54, 6, 0.15]\n",
      "0:\tlearn: 0.4797789\ttotal: 5.43ms\tremaining: 43.5ms\n",
      "1:\tlearn: 0.4731705\ttotal: 9.88ms\tremaining: 34.6ms\n",
      "2:\tlearn: 0.4704434\ttotal: 14ms\tremaining: 27.9ms\n",
      "3:\tlearn: 0.4677125\ttotal: 18.5ms\tremaining: 23.1ms\n",
      "4:\tlearn: 0.4661362\ttotal: 22.8ms\tremaining: 18.2ms\n",
      "5:\tlearn: 0.4642593\ttotal: 29.1ms\tremaining: 14.6ms\n",
      "6:\tlearn: 0.4622214\ttotal: 33.5ms\tremaining: 9.56ms\n",
      "7:\tlearn: 0.4608701\ttotal: 37.6ms\tremaining: 4.71ms\n",
      "8:\tlearn: 0.4597302\ttotal: 41.8ms\tremaining: 0us\n",
      "[9, 0.54, 6, 0.2]\n",
      "0:\tlearn: 0.4797789\ttotal: 6.89ms\tremaining: 55.1ms\n",
      "1:\tlearn: 0.4731705\ttotal: 11.8ms\tremaining: 41.2ms\n",
      "2:\tlearn: 0.4704434\ttotal: 16ms\tremaining: 32ms\n",
      "3:\tlearn: 0.4677125\ttotal: 20.1ms\tremaining: 25.1ms\n",
      "4:\tlearn: 0.4661362\ttotal: 25ms\tremaining: 20ms\n",
      "5:\tlearn: 0.4642593\ttotal: 29.4ms\tremaining: 14.7ms\n",
      "6:\tlearn: 0.4622214\ttotal: 33.6ms\tremaining: 9.61ms\n",
      "7:\tlearn: 0.4608701\ttotal: 38.1ms\tremaining: 4.76ms\n",
      "8:\tlearn: 0.4597302\ttotal: 43.1ms\tremaining: 0us\n",
      "[9, 0.54, 15, -0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 10.3ms\tremaining: 82.2ms\n",
      "1:\tlearn: 0.4691330\ttotal: 510ms\tremaining: 1.78s\n",
      "2:\tlearn: 0.4642986\ttotal: 1.01s\tremaining: 2.03s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.5s\tremaining: 1.88s\n",
      "4:\tlearn: 0.4576322\ttotal: 2s\tremaining: 1.6s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.51s\tremaining: 1.26s\n",
      "6:\tlearn: 0.4532838\ttotal: 3.09s\tremaining: 882ms\n",
      "7:\tlearn: 0.4512076\ttotal: 3.57s\tremaining: 446ms\n",
      "8:\tlearn: 0.4480762\ttotal: 4.04s\tremaining: 0us\n",
      "[9, 0.54, 15, 0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 11.5ms\tremaining: 92ms\n",
      "1:\tlearn: 0.4691330\ttotal: 486ms\tremaining: 1.7s\n",
      "2:\tlearn: 0.4642986\ttotal: 984ms\tremaining: 1.97s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.46s\tremaining: 1.83s\n",
      "4:\tlearn: 0.4576322\ttotal: 1.96s\tremaining: 1.57s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.44s\tremaining: 1.22s\n",
      "6:\tlearn: 0.4532838\ttotal: 2.95s\tremaining: 844ms\n",
      "7:\tlearn: 0.4512076\ttotal: 3.43s\tremaining: 429ms\n",
      "8:\tlearn: 0.4480762\ttotal: 3.91s\tremaining: 0us\n",
      "[9, 0.54, 15, 0.0]\n",
      "0:\tlearn: 0.4794265\ttotal: 10.7ms\tremaining: 85.5ms\n",
      "1:\tlearn: 0.4691330\ttotal: 528ms\tremaining: 1.85s\n",
      "2:\tlearn: 0.4642986\ttotal: 1.03s\tremaining: 2.06s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.52s\tremaining: 1.91s\n",
      "4:\tlearn: 0.4576322\ttotal: 2.01s\tremaining: 1.61s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.48s\tremaining: 1.24s\n",
      "6:\tlearn: 0.4532838\ttotal: 2.94s\tremaining: 840ms\n",
      "7:\tlearn: 0.4512076\ttotal: 3.43s\tremaining: 428ms\n",
      "8:\tlearn: 0.4480762\ttotal: 3.93s\tremaining: 0us\n",
      "[9, 0.54, 15, 0.15]\n",
      "0:\tlearn: 0.4794265\ttotal: 8.83ms\tremaining: 70.7ms\n",
      "1:\tlearn: 0.4691330\ttotal: 496ms\tremaining: 1.74s\n",
      "2:\tlearn: 0.4642986\ttotal: 961ms\tremaining: 1.92s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.43s\tremaining: 1.79s\n",
      "4:\tlearn: 0.4576322\ttotal: 1.95s\tremaining: 1.56s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.42s\tremaining: 1.21s\n",
      "6:\tlearn: 0.4532838\ttotal: 2.91s\tremaining: 831ms\n",
      "7:\tlearn: 0.4512076\ttotal: 3.41s\tremaining: 426ms\n",
      "8:\tlearn: 0.4480762\ttotal: 3.91s\tremaining: 0us\n",
      "[9, 0.54, 15, 0.2]\n",
      "0:\tlearn: 0.4794265\ttotal: 9.48ms\tremaining: 75.8ms\n",
      "1:\tlearn: 0.4691330\ttotal: 484ms\tremaining: 1.69s\n",
      "2:\tlearn: 0.4642986\ttotal: 992ms\tremaining: 1.98s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.5s\tremaining: 1.87s\n",
      "4:\tlearn: 0.4576322\ttotal: 1.96s\tremaining: 1.57s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.44s\tremaining: 1.22s\n",
      "6:\tlearn: 0.4532838\ttotal: 2.9s\tremaining: 829ms\n",
      "7:\tlearn: 0.4512076\ttotal: 3.4s\tremaining: 425ms\n",
      "8:\tlearn: 0.4480762\ttotal: 3.9s\tremaining: 0us\n",
      "[9, 0.54, 10, -0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 11.7ms\tremaining: 93.6ms\n",
      "1:\tlearn: 0.4717138\ttotal: 29.6ms\tremaining: 104ms\n",
      "2:\tlearn: 0.4680797\ttotal: 47.2ms\tremaining: 94.3ms\n",
      "3:\tlearn: 0.4667614\ttotal: 50.2ms\tremaining: 62.8ms\n",
      "4:\tlearn: 0.4641401\ttotal: 68.7ms\tremaining: 55ms\n",
      "5:\tlearn: 0.4609643\ttotal: 87ms\tremaining: 43.5ms\n",
      "6:\tlearn: 0.4589193\ttotal: 106ms\tremaining: 30.2ms\n",
      "7:\tlearn: 0.4567924\ttotal: 123ms\tremaining: 15.3ms\n",
      "8:\tlearn: 0.4555838\ttotal: 140ms\tremaining: 0us\n",
      "[9, 0.54, 10, 0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 12.9ms\tremaining: 103ms\n",
      "1:\tlearn: 0.4717138\ttotal: 29.1ms\tremaining: 102ms\n",
      "2:\tlearn: 0.4680797\ttotal: 48.9ms\tremaining: 97.9ms\n",
      "3:\tlearn: 0.4667614\ttotal: 51.8ms\tremaining: 64.8ms\n",
      "4:\tlearn: 0.4641401\ttotal: 68ms\tremaining: 54.4ms\n",
      "5:\tlearn: 0.4609643\ttotal: 84.6ms\tremaining: 42.3ms\n",
      "6:\tlearn: 0.4589193\ttotal: 99.6ms\tremaining: 28.4ms\n",
      "7:\tlearn: 0.4567924\ttotal: 116ms\tremaining: 14.5ms\n",
      "8:\tlearn: 0.4555838\ttotal: 132ms\tremaining: 0us\n",
      "[9, 0.54, 10, 0.0]\n",
      "0:\tlearn: 0.4794265\ttotal: 12.9ms\tremaining: 103ms\n",
      "1:\tlearn: 0.4717138\ttotal: 28.7ms\tremaining: 100ms\n",
      "2:\tlearn: 0.4680797\ttotal: 44.5ms\tremaining: 89.1ms\n",
      "3:\tlearn: 0.4667614\ttotal: 47.4ms\tremaining: 59.2ms\n",
      "4:\tlearn: 0.4641401\ttotal: 64.2ms\tremaining: 51.4ms\n",
      "5:\tlearn: 0.4609643\ttotal: 82.1ms\tremaining: 41.1ms\n",
      "6:\tlearn: 0.4589193\ttotal: 97.4ms\tremaining: 27.8ms\n",
      "7:\tlearn: 0.4567924\ttotal: 114ms\tremaining: 14.2ms\n",
      "8:\tlearn: 0.4555838\ttotal: 130ms\tremaining: 0us\n",
      "[9, 0.54, 10, 0.15]\n",
      "0:\tlearn: 0.4794265\ttotal: 13.3ms\tremaining: 107ms\n",
      "1:\tlearn: 0.4717138\ttotal: 29.1ms\tremaining: 102ms\n",
      "2:\tlearn: 0.4680797\ttotal: 46.4ms\tremaining: 92.8ms\n",
      "3:\tlearn: 0.4667614\ttotal: 49.5ms\tremaining: 61.9ms\n",
      "4:\tlearn: 0.4641401\ttotal: 65ms\tremaining: 52ms\n",
      "5:\tlearn: 0.4609643\ttotal: 81.6ms\tremaining: 40.8ms\n",
      "6:\tlearn: 0.4589193\ttotal: 98ms\tremaining: 28ms\n",
      "7:\tlearn: 0.4567924\ttotal: 116ms\tremaining: 14.5ms\n",
      "8:\tlearn: 0.4555838\ttotal: 132ms\tremaining: 0us\n",
      "[9, 0.54, 10, 0.2]\n",
      "0:\tlearn: 0.4794265\ttotal: 17ms\tremaining: 136ms\n",
      "1:\tlearn: 0.4717138\ttotal: 33.9ms\tremaining: 119ms\n",
      "2:\tlearn: 0.4680797\ttotal: 50.1ms\tremaining: 100ms\n",
      "3:\tlearn: 0.4667614\ttotal: 53.3ms\tremaining: 66.7ms\n",
      "4:\tlearn: 0.4641401\ttotal: 71ms\tremaining: 56.8ms\n",
      "5:\tlearn: 0.4609643\ttotal: 93.9ms\tremaining: 47ms\n",
      "6:\tlearn: 0.4589193\ttotal: 111ms\tremaining: 31.9ms\n",
      "7:\tlearn: 0.4567924\ttotal: 129ms\tremaining: 16.2ms\n",
      "8:\tlearn: 0.4555838\ttotal: 148ms\tremaining: 0us\n",
      "[9, 0.54, 12, -0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 10.8ms\tremaining: 86.1ms\n",
      "1:\tlearn: 0.4706493\ttotal: 73ms\tremaining: 255ms\n",
      "2:\tlearn: 0.4670578\ttotal: 130ms\tremaining: 261ms\n",
      "3:\tlearn: 0.4648193\ttotal: 193ms\tremaining: 242ms\n",
      "4:\tlearn: 0.4624751\ttotal: 258ms\tremaining: 207ms\n",
      "5:\tlearn: 0.4598250\ttotal: 317ms\tremaining: 158ms\n",
      "6:\tlearn: 0.4575876\ttotal: 380ms\tremaining: 109ms\n",
      "7:\tlearn: 0.4553161\ttotal: 443ms\tremaining: 55.4ms\n",
      "8:\tlearn: 0.4536202\ttotal: 501ms\tremaining: 0us\n",
      "[9, 0.54, 12, 0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 9.64ms\tremaining: 77.1ms\n",
      "1:\tlearn: 0.4706493\ttotal: 66.9ms\tremaining: 234ms\n",
      "2:\tlearn: 0.4670578\ttotal: 127ms\tremaining: 253ms\n",
      "3:\tlearn: 0.4648193\ttotal: 184ms\tremaining: 229ms\n",
      "4:\tlearn: 0.4624751\ttotal: 241ms\tremaining: 193ms\n",
      "5:\tlearn: 0.4598250\ttotal: 296ms\tremaining: 148ms\n",
      "6:\tlearn: 0.4575876\ttotal: 359ms\tremaining: 103ms\n",
      "7:\tlearn: 0.4553161\ttotal: 420ms\tremaining: 52.5ms\n",
      "8:\tlearn: 0.4536202\ttotal: 478ms\tremaining: 0us\n",
      "[9, 0.54, 12, 0.0]\n",
      "0:\tlearn: 0.4794265\ttotal: 14.4ms\tremaining: 115ms\n",
      "1:\tlearn: 0.4706493\ttotal: 76.6ms\tremaining: 268ms\n",
      "2:\tlearn: 0.4670578\ttotal: 138ms\tremaining: 276ms\n",
      "3:\tlearn: 0.4648193\ttotal: 204ms\tremaining: 255ms\n",
      "4:\tlearn: 0.4624751\ttotal: 262ms\tremaining: 210ms\n",
      "5:\tlearn: 0.4598250\ttotal: 331ms\tremaining: 165ms\n",
      "6:\tlearn: 0.4575876\ttotal: 397ms\tremaining: 113ms\n",
      "7:\tlearn: 0.4553161\ttotal: 460ms\tremaining: 57.6ms\n",
      "8:\tlearn: 0.4536202\ttotal: 527ms\tremaining: 0us\n",
      "[9, 0.54, 12, 0.15]\n",
      "0:\tlearn: 0.4794265\ttotal: 14.2ms\tremaining: 113ms\n",
      "1:\tlearn: 0.4706493\ttotal: 87.6ms\tremaining: 307ms\n",
      "2:\tlearn: 0.4670578\ttotal: 153ms\tremaining: 307ms\n",
      "3:\tlearn: 0.4648193\ttotal: 216ms\tremaining: 270ms\n",
      "4:\tlearn: 0.4624751\ttotal: 274ms\tremaining: 219ms\n",
      "5:\tlearn: 0.4598250\ttotal: 340ms\tremaining: 170ms\n",
      "6:\tlearn: 0.4575876\ttotal: 405ms\tremaining: 116ms\n",
      "7:\tlearn: 0.4553161\ttotal: 469ms\tremaining: 58.6ms\n",
      "8:\tlearn: 0.4536202\ttotal: 528ms\tremaining: 0us\n",
      "[9, 0.54, 12, 0.2]\n",
      "0:\tlearn: 0.4794265\ttotal: 11.5ms\tremaining: 91.9ms\n",
      "1:\tlearn: 0.4706493\ttotal: 73.8ms\tremaining: 258ms\n",
      "2:\tlearn: 0.4670578\ttotal: 137ms\tremaining: 274ms\n",
      "3:\tlearn: 0.4648193\ttotal: 199ms\tremaining: 249ms\n",
      "4:\tlearn: 0.4624751\ttotal: 256ms\tremaining: 205ms\n",
      "5:\tlearn: 0.4598250\ttotal: 324ms\tremaining: 162ms\n",
      "6:\tlearn: 0.4575876\ttotal: 383ms\tremaining: 109ms\n",
      "7:\tlearn: 0.4553161\ttotal: 443ms\tremaining: 55.3ms\n",
      "8:\tlearn: 0.4536202\ttotal: 502ms\tremaining: 0us\n",
      "[9, 0.54, 13, -0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 12.1ms\tremaining: 96.6ms\n",
      "1:\tlearn: 0.4702429\ttotal: 142ms\tremaining: 498ms\n",
      "2:\tlearn: 0.4653252\ttotal: 279ms\tremaining: 558ms\n",
      "3:\tlearn: 0.4625253\ttotal: 396ms\tremaining: 496ms\n",
      "4:\tlearn: 0.4592922\ttotal: 458ms\tremaining: 366ms\n",
      "5:\tlearn: 0.4568415\ttotal: 579ms\tremaining: 290ms\n",
      "6:\tlearn: 0.4543909\ttotal: 698ms\tremaining: 199ms\n",
      "7:\tlearn: 0.4525563\ttotal: 816ms\tremaining: 102ms\n",
      "8:\tlearn: 0.4511959\ttotal: 847ms\tremaining: 0us\n",
      "[9, 0.54, 13, 0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 14.2ms\tremaining: 114ms\n",
      "1:\tlearn: 0.4702429\ttotal: 145ms\tremaining: 507ms\n",
      "2:\tlearn: 0.4653252\ttotal: 268ms\tremaining: 537ms\n",
      "3:\tlearn: 0.4625253\ttotal: 393ms\tremaining: 492ms\n",
      "4:\tlearn: 0.4592922\ttotal: 463ms\tremaining: 370ms\n",
      "5:\tlearn: 0.4568415\ttotal: 586ms\tremaining: 293ms\n",
      "6:\tlearn: 0.4543909\ttotal: 708ms\tremaining: 202ms\n",
      "7:\tlearn: 0.4525563\ttotal: 831ms\tremaining: 104ms\n",
      "8:\tlearn: 0.4511959\ttotal: 867ms\tremaining: 0us\n",
      "[9, 0.54, 13, 0.0]\n",
      "0:\tlearn: 0.4794265\ttotal: 13.5ms\tremaining: 108ms\n",
      "1:\tlearn: 0.4702429\ttotal: 144ms\tremaining: 505ms\n",
      "2:\tlearn: 0.4653252\ttotal: 280ms\tremaining: 560ms\n",
      "3:\tlearn: 0.4625253\ttotal: 401ms\tremaining: 502ms\n",
      "4:\tlearn: 0.4592922\ttotal: 459ms\tremaining: 368ms\n",
      "5:\tlearn: 0.4568415\ttotal: 600ms\tremaining: 300ms\n",
      "6:\tlearn: 0.4543909\ttotal: 718ms\tremaining: 205ms\n",
      "7:\tlearn: 0.4525563\ttotal: 840ms\tremaining: 105ms\n",
      "8:\tlearn: 0.4511959\ttotal: 872ms\tremaining: 0us\n",
      "[9, 0.54, 13, 0.15]\n",
      "0:\tlearn: 0.4794265\ttotal: 10.8ms\tremaining: 86ms\n",
      "1:\tlearn: 0.4702429\ttotal: 136ms\tremaining: 477ms\n",
      "2:\tlearn: 0.4653252\ttotal: 261ms\tremaining: 521ms\n",
      "3:\tlearn: 0.4625253\ttotal: 384ms\tremaining: 480ms\n",
      "4:\tlearn: 0.4592922\ttotal: 449ms\tremaining: 359ms\n",
      "5:\tlearn: 0.4568415\ttotal: 572ms\tremaining: 286ms\n",
      "6:\tlearn: 0.4543909\ttotal: 688ms\tremaining: 197ms\n",
      "7:\tlearn: 0.4525563\ttotal: 813ms\tremaining: 102ms\n",
      "8:\tlearn: 0.4511959\ttotal: 843ms\tremaining: 0us\n",
      "[9, 0.54, 13, 0.2]\n",
      "0:\tlearn: 0.4794265\ttotal: 13.1ms\tremaining: 105ms\n",
      "1:\tlearn: 0.4702429\ttotal: 135ms\tremaining: 473ms\n",
      "2:\tlearn: 0.4653252\ttotal: 261ms\tremaining: 522ms\n",
      "3:\tlearn: 0.4625253\ttotal: 383ms\tremaining: 479ms\n",
      "4:\tlearn: 0.4592922\ttotal: 445ms\tremaining: 356ms\n",
      "5:\tlearn: 0.4568415\ttotal: 576ms\tremaining: 288ms\n",
      "6:\tlearn: 0.4543909\ttotal: 703ms\tremaining: 201ms\n",
      "7:\tlearn: 0.4525563\ttotal: 820ms\tremaining: 102ms\n",
      "8:\tlearn: 0.4511959\ttotal: 849ms\tremaining: 0us\n",
      "[9, 0.54, 14, -0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 17.2ms\tremaining: 137ms\n",
      "1:\tlearn: 0.4697296\ttotal: 266ms\tremaining: 932ms\n",
      "2:\tlearn: 0.4655942\ttotal: 514ms\tremaining: 1.03s\n",
      "3:\tlearn: 0.4618172\ttotal: 749ms\tremaining: 937ms\n",
      "4:\tlearn: 0.4578563\ttotal: 995ms\tremaining: 796ms\n",
      "5:\tlearn: 0.4562841\ttotal: 1.01s\tremaining: 505ms\n",
      "6:\tlearn: 0.4556288\ttotal: 1.01s\tremaining: 290ms\n",
      "7:\tlearn: 0.4538749\ttotal: 1.02s\tremaining: 128ms\n",
      "8:\tlearn: 0.4513073\ttotal: 1.26s\tremaining: 0us\n",
      "[9, 0.54, 14, 0.3]\n",
      "0:\tlearn: 0.4794265\ttotal: 12.7ms\tremaining: 102ms\n",
      "1:\tlearn: 0.4697296\ttotal: 253ms\tremaining: 884ms\n",
      "2:\tlearn: 0.4655942\ttotal: 503ms\tremaining: 1.01s\n",
      "3:\tlearn: 0.4618172\ttotal: 742ms\tremaining: 927ms\n",
      "4:\tlearn: 0.4578563\ttotal: 993ms\tremaining: 795ms\n",
      "5:\tlearn: 0.4562841\ttotal: 1.01s\tremaining: 504ms\n",
      "6:\tlearn: 0.4556288\ttotal: 1.01s\tremaining: 289ms\n",
      "7:\tlearn: 0.4538749\ttotal: 1.02s\tremaining: 127ms\n",
      "8:\tlearn: 0.4513073\ttotal: 1.27s\tremaining: 0us\n",
      "[9, 0.54, 14, 0.0]\n",
      "0:\tlearn: 0.4794265\ttotal: 11.2ms\tremaining: 89.6ms\n",
      "1:\tlearn: 0.4697296\ttotal: 265ms\tremaining: 927ms\n",
      "2:\tlearn: 0.4655942\ttotal: 494ms\tremaining: 987ms\n",
      "3:\tlearn: 0.4618172\ttotal: 728ms\tremaining: 910ms\n",
      "4:\tlearn: 0.4578563\ttotal: 978ms\tremaining: 783ms\n",
      "5:\tlearn: 0.4562841\ttotal: 995ms\tremaining: 498ms\n",
      "6:\tlearn: 0.4556288\ttotal: 1000ms\tremaining: 286ms\n",
      "7:\tlearn: 0.4538749\ttotal: 1.01s\tremaining: 126ms\n",
      "8:\tlearn: 0.4513073\ttotal: 1.24s\tremaining: 0us\n",
      "[9, 0.54, 14, 0.15]\n",
      "0:\tlearn: 0.4794265\ttotal: 10.5ms\tremaining: 83.7ms\n",
      "1:\tlearn: 0.4697296\ttotal: 238ms\tremaining: 833ms\n",
      "2:\tlearn: 0.4655942\ttotal: 464ms\tremaining: 928ms\n",
      "3:\tlearn: 0.4618172\ttotal: 708ms\tremaining: 884ms\n",
      "4:\tlearn: 0.4578563\ttotal: 942ms\tremaining: 753ms\n",
      "5:\tlearn: 0.4562841\ttotal: 961ms\tremaining: 480ms\n",
      "6:\tlearn: 0.4556288\ttotal: 965ms\tremaining: 276ms\n",
      "7:\tlearn: 0.4538749\ttotal: 972ms\tremaining: 122ms\n",
      "8:\tlearn: 0.4513073\ttotal: 1.22s\tremaining: 0us\n",
      "[9, 0.54, 14, 0.2]\n",
      "0:\tlearn: 0.4794265\ttotal: 10.9ms\tremaining: 87.2ms\n",
      "1:\tlearn: 0.4697296\ttotal: 244ms\tremaining: 853ms\n",
      "2:\tlearn: 0.4655942\ttotal: 493ms\tremaining: 985ms\n",
      "3:\tlearn: 0.4618172\ttotal: 738ms\tremaining: 923ms\n",
      "4:\tlearn: 0.4578563\ttotal: 980ms\tremaining: 784ms\n",
      "5:\tlearn: 0.4562841\ttotal: 996ms\tremaining: 498ms\n",
      "6:\tlearn: 0.4556288\ttotal: 1000ms\tremaining: 286ms\n",
      "7:\tlearn: 0.4538749\ttotal: 1.01s\tremaining: 126ms\n",
      "8:\tlearn: 0.4513073\ttotal: 1.25s\tremaining: 0us\n",
      "maximo 0.6393442622950819 parametros (iter,learning,profundidad) [9, 0.54, 14, 0.2]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "5B3T5v-dP4T6",
    "colab_type": "code",
    "colab": {},
    "outputId": "7501c473-60f6-40d7-e77e-328ce104d625"
   },
   "source": [
    "resultados_de_prediccion = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "cantidadDePredicciones = 0\n",
    "#catboost\n",
    "for iter in range(8,11,1):\n",
    "    for lR in range(53,56,1):\n",
    "        learningRate = lR / 100\n",
    "        for profundidad in range(13,16):\n",
    "            # Initialize CatBoostRegressor\n",
    "            model = CatBoostRegressor(iterations=iter,\n",
    "                                      learning_rate=learningRate,\n",
    "                                      depth=profundidad)\n",
    "            # Fit model\n",
    "            model.fit(train_set, train_label)\n",
    "            # Get predictions\n",
    "            predicion = model.predict(test_set)\n",
    "            cantidadDePredicciones,resultados_de_prediccion = ensamble(resultados_de_prediccion,cantidadDePredicciones,predicion)\n",
    "            print(\"prediccion = \",cantidadDePredicciones)\n",
    "\n",
    "cantidadDePredicciones,resultados_de_prediccion = ensamble(resultados_de_prediccion,cantidadDePredicciones,predicion,0.2)\n",
    "print(F1(resultados_de_prediccion))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4796178\ttotal: 10.4ms\tremaining: 72.7ms\n",
      "1:\tlearn: 0.4737091\ttotal: 19.8ms\tremaining: 59.4ms\n",
      "2:\tlearn: 0.4681049\ttotal: 163ms\tremaining: 272ms\n",
      "3:\tlearn: 0.4652893\ttotal: 289ms\tremaining: 289ms\n",
      "4:\tlearn: 0.4604401\ttotal: 407ms\tremaining: 244ms\n",
      "5:\tlearn: 0.4583924\ttotal: 514ms\tremaining: 171ms\n",
      "6:\tlearn: 0.4560713\ttotal: 642ms\tremaining: 91.7ms\n",
      "7:\tlearn: 0.4543157\ttotal: 795ms\tremaining: 0us\n",
      "prediccion =  1\n",
      "0:\tlearn: 0.4796178\ttotal: 9.47ms\tremaining: 66.3ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18.6ms\tremaining: 55.8ms\n",
      "2:\tlearn: 0.4679636\ttotal: 279ms\tremaining: 465ms\n",
      "3:\tlearn: 0.4643845\ttotal: 494ms\tremaining: 494ms\n",
      "4:\tlearn: 0.4615630\ttotal: 777ms\tremaining: 466ms\n",
      "5:\tlearn: 0.4590014\ttotal: 996ms\tremaining: 332ms\n",
      "6:\tlearn: 0.4577257\ttotal: 1s\tremaining: 143ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.31s\tremaining: 0us\n",
      "prediccion =  2\n",
      "0:\tlearn: 0.4796178\ttotal: 9.19ms\tremaining: 64.3ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18.2ms\tremaining: 54.6ms\n",
      "2:\tlearn: 0.4679294\ttotal: 505ms\tremaining: 842ms\n",
      "3:\tlearn: 0.4633466\ttotal: 998ms\tremaining: 998ms\n",
      "4:\tlearn: 0.4608528\ttotal: 1.17s\tremaining: 703ms\n",
      "5:\tlearn: 0.4583235\ttotal: 1.64s\tremaining: 548ms\n",
      "6:\tlearn: 0.4556306\ttotal: 2.12s\tremaining: 303ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.63s\tremaining: 0us\n",
      "prediccion =  3\n",
      "0:\tlearn: 0.4794265\ttotal: 10ms\tremaining: 70.3ms\n",
      "1:\tlearn: 0.4702429\ttotal: 121ms\tremaining: 364ms\n",
      "2:\tlearn: 0.4653252\ttotal: 224ms\tremaining: 374ms\n",
      "3:\tlearn: 0.4625253\ttotal: 343ms\tremaining: 343ms\n",
      "4:\tlearn: 0.4592922\ttotal: 460ms\tremaining: 276ms\n",
      "5:\tlearn: 0.4568415\ttotal: 572ms\tremaining: 191ms\n",
      "6:\tlearn: 0.4543909\ttotal: 675ms\tremaining: 96.4ms\n",
      "7:\tlearn: 0.4525563\ttotal: 802ms\tremaining: 0us\n",
      "prediccion =  4\n",
      "0:\tlearn: 0.4794265\ttotal: 8.9ms\tremaining: 62.3ms\n",
      "1:\tlearn: 0.4697296\ttotal: 247ms\tremaining: 740ms\n",
      "2:\tlearn: 0.4655942\ttotal: 529ms\tremaining: 882ms\n",
      "3:\tlearn: 0.4618172\ttotal: 767ms\tremaining: 767ms\n",
      "4:\tlearn: 0.4578563\ttotal: 1.1s\tremaining: 658ms\n",
      "5:\tlearn: 0.4562841\ttotal: 1.11s\tremaining: 371ms\n",
      "6:\tlearn: 0.4556288\ttotal: 1.12s\tremaining: 160ms\n",
      "7:\tlearn: 0.4538749\ttotal: 1.12s\tremaining: 0us\n",
      "prediccion =  5\n",
      "0:\tlearn: 0.4794265\ttotal: 8.99ms\tremaining: 62.9ms\n",
      "1:\tlearn: 0.4691330\ttotal: 495ms\tremaining: 1.49s\n",
      "2:\tlearn: 0.4642986\ttotal: 1.06s\tremaining: 1.77s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.54s\tremaining: 1.54s\n",
      "4:\tlearn: 0.4576322\ttotal: 2.02s\tremaining: 1.21s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.5s\tremaining: 833ms\n",
      "6:\tlearn: 0.4532838\ttotal: 3.03s\tremaining: 432ms\n",
      "7:\tlearn: 0.4512076\ttotal: 3.52s\tremaining: 0us\n",
      "prediccion =  6\n",
      "0:\tlearn: 0.4792390\ttotal: 10.7ms\tremaining: 75.2ms\n",
      "1:\tlearn: 0.4700386\ttotal: 115ms\tremaining: 346ms\n",
      "2:\tlearn: 0.4651124\ttotal: 220ms\tremaining: 366ms\n",
      "3:\tlearn: 0.4623159\ttotal: 334ms\tremaining: 334ms\n",
      "4:\tlearn: 0.4590456\ttotal: 387ms\tremaining: 232ms\n",
      "5:\tlearn: 0.4565869\ttotal: 499ms\tremaining: 166ms\n",
      "6:\tlearn: 0.4540567\ttotal: 681ms\tremaining: 97.3ms\n",
      "7:\tlearn: 0.4522890\ttotal: 801ms\tremaining: 0us\n",
      "prediccion =  7\n",
      "0:\tlearn: 0.4792390\ttotal: 29.8ms\tremaining: 208ms\n",
      "1:\tlearn: 0.4695164\ttotal: 277ms\tremaining: 832ms\n",
      "2:\tlearn: 0.4654149\ttotal: 571ms\tremaining: 952ms\n",
      "3:\tlearn: 0.4619585\ttotal: 776ms\tremaining: 776ms\n",
      "4:\tlearn: 0.4580701\ttotal: 1.04s\tremaining: 627ms\n",
      "5:\tlearn: 0.4564419\ttotal: 1.06s\tremaining: 353ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.06s\tremaining: 152ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.29s\tremaining: 0us\n",
      "prediccion =  8\n",
      "0:\tlearn: 0.4792390\ttotal: 11.8ms\tremaining: 82.6ms\n",
      "1:\tlearn: 0.4689110\ttotal: 481ms\tremaining: 1.44s\n",
      "2:\tlearn: 0.4640795\ttotal: 936ms\tremaining: 1.56s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.39s\tremaining: 1.39s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.88s\tremaining: 1.13s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.36s\tremaining: 787ms\n",
      "6:\tlearn: 0.4530263\ttotal: 2.86s\tremaining: 408ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.38s\tremaining: 0us\n",
      "prediccion =  9\n",
      "0:\tlearn: 0.4796178\ttotal: 10.6ms\tremaining: 84.4ms\n",
      "1:\tlearn: 0.4737091\ttotal: 20.2ms\tremaining: 70.7ms\n",
      "2:\tlearn: 0.4681049\ttotal: 134ms\tremaining: 269ms\n",
      "3:\tlearn: 0.4652893\ttotal: 243ms\tremaining: 304ms\n",
      "4:\tlearn: 0.4604401\ttotal: 408ms\tremaining: 327ms\n",
      "5:\tlearn: 0.4583924\ttotal: 548ms\tremaining: 274ms\n",
      "6:\tlearn: 0.4560713\ttotal: 660ms\tremaining: 188ms\n",
      "7:\tlearn: 0.4543157\ttotal: 766ms\tremaining: 95.7ms\n",
      "8:\tlearn: 0.4524415\ttotal: 882ms\tremaining: 0us\n",
      "prediccion =  10\n",
      "0:\tlearn: 0.4796178\ttotal: 11.5ms\tremaining: 92ms\n",
      "1:\tlearn: 0.4737091\ttotal: 22.8ms\tremaining: 79.8ms\n",
      "2:\tlearn: 0.4679636\ttotal: 283ms\tremaining: 566ms\n",
      "3:\tlearn: 0.4643845\ttotal: 515ms\tremaining: 644ms\n",
      "4:\tlearn: 0.4615630\ttotal: 729ms\tremaining: 583ms\n",
      "5:\tlearn: 0.4590014\ttotal: 1s\tremaining: 503ms\n",
      "6:\tlearn: 0.4577257\ttotal: 1.01s\tremaining: 288ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.22s\tremaining: 153ms\n",
      "8:\tlearn: 0.4536621\ttotal: 1.49s\tremaining: 0us\n",
      "prediccion =  11\n",
      "0:\tlearn: 0.4796178\ttotal: 9.32ms\tremaining: 74.6ms\n",
      "1:\tlearn: 0.4737091\ttotal: 18.6ms\tremaining: 65ms\n",
      "2:\tlearn: 0.4679294\ttotal: 501ms\tremaining: 1s\n",
      "3:\tlearn: 0.4633466\ttotal: 1.03s\tremaining: 1.29s\n",
      "4:\tlearn: 0.4608528\ttotal: 1.21s\tremaining: 972ms\n",
      "5:\tlearn: 0.4583235\ttotal: 1.77s\tremaining: 887ms\n",
      "6:\tlearn: 0.4556306\ttotal: 2.25s\tremaining: 642ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.73s\tremaining: 342ms\n",
      "8:\tlearn: 0.4518134\ttotal: 3.23s\tremaining: 0us\n",
      "prediccion =  12\n",
      "0:\tlearn: 0.4794265\ttotal: 11ms\tremaining: 88.2ms\n",
      "1:\tlearn: 0.4702429\ttotal: 122ms\tremaining: 429ms\n",
      "2:\tlearn: 0.4653252\ttotal: 225ms\tremaining: 451ms\n",
      "3:\tlearn: 0.4625253\ttotal: 346ms\tremaining: 432ms\n",
      "4:\tlearn: 0.4592922\ttotal: 461ms\tremaining: 369ms\n",
      "5:\tlearn: 0.4568415\ttotal: 577ms\tremaining: 288ms\n",
      "6:\tlearn: 0.4543909\ttotal: 681ms\tremaining: 195ms\n",
      "7:\tlearn: 0.4525563\ttotal: 803ms\tremaining: 100ms\n",
      "8:\tlearn: 0.4511959\ttotal: 863ms\tremaining: 0us\n",
      "prediccion =  13\n",
      "0:\tlearn: 0.4794265\ttotal: 8.64ms\tremaining: 69.1ms\n",
      "1:\tlearn: 0.4697296\ttotal: 223ms\tremaining: 779ms\n",
      "2:\tlearn: 0.4655942\ttotal: 488ms\tremaining: 975ms\n",
      "3:\tlearn: 0.4618172\ttotal: 697ms\tremaining: 871ms\n",
      "4:\tlearn: 0.4578563\ttotal: 971ms\tremaining: 777ms\n",
      "5:\tlearn: 0.4562841\ttotal: 991ms\tremaining: 495ms\n",
      "6:\tlearn: 0.4556288\ttotal: 995ms\tremaining: 284ms\n",
      "7:\tlearn: 0.4538749\ttotal: 1s\tremaining: 125ms\n",
      "8:\tlearn: 0.4513073\ttotal: 1.22s\tremaining: 0us\n",
      "prediccion =  14\n",
      "0:\tlearn: 0.4794265\ttotal: 11.6ms\tremaining: 92.7ms\n",
      "1:\tlearn: 0.4691330\ttotal: 531ms\tremaining: 1.86s\n",
      "2:\tlearn: 0.4642986\ttotal: 1.02s\tremaining: 2.03s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.52s\tremaining: 1.9s\n",
      "4:\tlearn: 0.4576322\ttotal: 2.02s\tremaining: 1.62s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.52s\tremaining: 1.26s\n",
      "6:\tlearn: 0.4532838\ttotal: 3.02s\tremaining: 864ms\n",
      "7:\tlearn: 0.4512076\ttotal: 3.52s\tremaining: 441ms\n",
      "8:\tlearn: 0.4480762\ttotal: 4.04s\tremaining: 0us\n",
      "prediccion =  15\n",
      "0:\tlearn: 0.4792390\ttotal: 11ms\tremaining: 88.1ms\n",
      "1:\tlearn: 0.4700386\ttotal: 135ms\tremaining: 474ms\n",
      "2:\tlearn: 0.4651124\ttotal: 247ms\tremaining: 494ms\n",
      "3:\tlearn: 0.4623159\ttotal: 435ms\tremaining: 543ms\n",
      "4:\tlearn: 0.4590456\ttotal: 495ms\tremaining: 396ms\n",
      "5:\tlearn: 0.4565869\ttotal: 607ms\tremaining: 303ms\n",
      "6:\tlearn: 0.4540567\ttotal: 720ms\tremaining: 206ms\n",
      "7:\tlearn: 0.4522890\ttotal: 892ms\tremaining: 112ms\n",
      "8:\tlearn: 0.4507350\ttotal: 925ms\tremaining: 0us\n",
      "prediccion =  16\n",
      "0:\tlearn: 0.4792390\ttotal: 8.29ms\tremaining: 66.3ms\n",
      "1:\tlearn: 0.4695164\ttotal: 266ms\tremaining: 932ms\n",
      "2:\tlearn: 0.4654149\ttotal: 477ms\tremaining: 954ms\n",
      "3:\tlearn: 0.4619585\ttotal: 713ms\tremaining: 891ms\n",
      "4:\tlearn: 0.4580701\ttotal: 948ms\tremaining: 759ms\n",
      "5:\tlearn: 0.4564419\ttotal: 966ms\tremaining: 483ms\n",
      "6:\tlearn: 0.4557130\ttotal: 970ms\tremaining: 277ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.27s\tremaining: 159ms\n",
      "8:\tlearn: 0.4512984\ttotal: 1.28s\tremaining: 0us\n",
      "prediccion =  17\n",
      "0:\tlearn: 0.4792390\ttotal: 9.94ms\tremaining: 79.5ms\n",
      "1:\tlearn: 0.4689110\ttotal: 526ms\tremaining: 1.84s\n",
      "2:\tlearn: 0.4640795\ttotal: 990ms\tremaining: 1.98s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.49s\tremaining: 1.86s\n",
      "4:\tlearn: 0.4573812\ttotal: 1.99s\tremaining: 1.59s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.54s\tremaining: 1.27s\n",
      "6:\tlearn: 0.4530263\ttotal: 3.04s\tremaining: 867ms\n",
      "7:\tlearn: 0.4509348\ttotal: 3.6s\tremaining: 449ms\n",
      "8:\tlearn: 0.4477925\ttotal: 4.08s\tremaining: 0us\n",
      "prediccion =  18\n",
      "0:\tlearn: 0.4796178\ttotal: 13.3ms\tremaining: 120ms\n",
      "1:\tlearn: 0.4737091\ttotal: 28.5ms\tremaining: 114ms\n",
      "2:\tlearn: 0.4681049\ttotal: 144ms\tremaining: 336ms\n",
      "3:\tlearn: 0.4652893\ttotal: 257ms\tremaining: 386ms\n",
      "4:\tlearn: 0.4604401\ttotal: 434ms\tremaining: 434ms\n",
      "5:\tlearn: 0.4583924\ttotal: 565ms\tremaining: 377ms\n",
      "6:\tlearn: 0.4560713\ttotal: 674ms\tremaining: 289ms\n",
      "7:\tlearn: 0.4543157\ttotal: 782ms\tremaining: 195ms\n",
      "8:\tlearn: 0.4524415\ttotal: 902ms\tremaining: 100ms\n",
      "9:\tlearn: 0.4511492\ttotal: 1.01s\tremaining: 0us\n",
      "prediccion =  19\n",
      "0:\tlearn: 0.4796178\ttotal: 11.1ms\tremaining: 99.7ms\n",
      "1:\tlearn: 0.4737091\ttotal: 21ms\tremaining: 84.2ms\n",
      "2:\tlearn: 0.4679636\ttotal: 235ms\tremaining: 548ms\n",
      "3:\tlearn: 0.4643845\ttotal: 513ms\tremaining: 769ms\n",
      "4:\tlearn: 0.4615630\ttotal: 731ms\tremaining: 731ms\n",
      "5:\tlearn: 0.4590014\ttotal: 1.01s\tremaining: 676ms\n",
      "6:\tlearn: 0.4577257\ttotal: 1.02s\tremaining: 437ms\n",
      "7:\tlearn: 0.4556550\ttotal: 1.23s\tremaining: 308ms\n",
      "8:\tlearn: 0.4536621\ttotal: 1.51s\tremaining: 168ms\n",
      "9:\tlearn: 0.4518939\ttotal: 1.73s\tremaining: 0us\n",
      "prediccion =  20\n",
      "0:\tlearn: 0.4796178\ttotal: 13.2ms\tremaining: 119ms\n",
      "1:\tlearn: 0.4737091\ttotal: 25.1ms\tremaining: 100ms\n",
      "2:\tlearn: 0.4679294\ttotal: 518ms\tremaining: 1.21s\n",
      "3:\tlearn: 0.4633466\ttotal: 1.03s\tremaining: 1.54s\n",
      "4:\tlearn: 0.4608528\ttotal: 1.19s\tremaining: 1.19s\n",
      "5:\tlearn: 0.4583235\ttotal: 1.71s\tremaining: 1.14s\n",
      "6:\tlearn: 0.4556306\ttotal: 2.19s\tremaining: 937ms\n",
      "7:\tlearn: 0.4530082\ttotal: 2.68s\tremaining: 671ms\n",
      "8:\tlearn: 0.4518134\ttotal: 3.17s\tremaining: 353ms\n",
      "9:\tlearn: 0.4505594\ttotal: 3.71s\tremaining: 0us\n",
      "prediccion =  21\n",
      "0:\tlearn: 0.4794265\ttotal: 10.9ms\tremaining: 98.2ms\n",
      "1:\tlearn: 0.4702429\ttotal: 125ms\tremaining: 501ms\n",
      "2:\tlearn: 0.4653252\ttotal: 228ms\tremaining: 531ms\n",
      "3:\tlearn: 0.4625253\ttotal: 392ms\tremaining: 588ms\n",
      "4:\tlearn: 0.4592922\ttotal: 456ms\tremaining: 456ms\n",
      "5:\tlearn: 0.4568415\ttotal: 577ms\tremaining: 384ms\n",
      "6:\tlearn: 0.4543909\ttotal: 683ms\tremaining: 293ms\n",
      "7:\tlearn: 0.4525563\ttotal: 863ms\tremaining: 216ms\n",
      "8:\tlearn: 0.4511959\ttotal: 891ms\tremaining: 99ms\n",
      "9:\tlearn: 0.4495965\ttotal: 1.01s\tremaining: 0us\n",
      "prediccion =  22\n",
      "0:\tlearn: 0.4794265\ttotal: 16.3ms\tremaining: 147ms\n",
      "1:\tlearn: 0.4697296\ttotal: 276ms\tremaining: 1.1s\n",
      "2:\tlearn: 0.4655942\ttotal: 572ms\tremaining: 1.33s\n",
      "3:\tlearn: 0.4618172\ttotal: 788ms\tremaining: 1.18s\n",
      "4:\tlearn: 0.4578563\ttotal: 1.05s\tremaining: 1.05s\n",
      "5:\tlearn: 0.4562841\ttotal: 1.07s\tremaining: 713ms\n",
      "6:\tlearn: 0.4556288\ttotal: 1.07s\tremaining: 461ms\n",
      "7:\tlearn: 0.4538749\ttotal: 1.08s\tremaining: 271ms\n",
      "8:\tlearn: 0.4513073\ttotal: 1.3s\tremaining: 144ms\n",
      "9:\tlearn: 0.4496551\ttotal: 1.58s\tremaining: 0us\n",
      "prediccion =  23\n",
      "0:\tlearn: 0.4794265\ttotal: 8.59ms\tremaining: 77.3ms\n",
      "1:\tlearn: 0.4691330\ttotal: 583ms\tremaining: 2.33s\n",
      "2:\tlearn: 0.4642986\ttotal: 1.07s\tremaining: 2.5s\n",
      "3:\tlearn: 0.4607090\ttotal: 1.57s\tremaining: 2.35s\n",
      "4:\tlearn: 0.4576322\ttotal: 2.12s\tremaining: 2.12s\n",
      "5:\tlearn: 0.4549266\ttotal: 2.6s\tremaining: 1.74s\n",
      "6:\tlearn: 0.4532838\ttotal: 3.14s\tremaining: 1.35s\n",
      "7:\tlearn: 0.4512076\ttotal: 3.68s\tremaining: 920ms\n",
      "8:\tlearn: 0.4480762\ttotal: 4.14s\tremaining: 460ms\n",
      "9:\tlearn: 0.4468553\ttotal: 4.64s\tremaining: 0us\n",
      "prediccion =  24\n",
      "0:\tlearn: 0.4792390\ttotal: 12.1ms\tremaining: 109ms\n",
      "1:\tlearn: 0.4700386\ttotal: 130ms\tremaining: 522ms\n",
      "2:\tlearn: 0.4651124\ttotal: 235ms\tremaining: 548ms\n",
      "3:\tlearn: 0.4623159\ttotal: 373ms\tremaining: 560ms\n",
      "4:\tlearn: 0.4590456\ttotal: 460ms\tremaining: 460ms\n",
      "5:\tlearn: 0.4565869\ttotal: 580ms\tremaining: 387ms\n",
      "6:\tlearn: 0.4540567\ttotal: 688ms\tremaining: 295ms\n",
      "7:\tlearn: 0.4522890\ttotal: 855ms\tremaining: 214ms\n",
      "8:\tlearn: 0.4507350\ttotal: 890ms\tremaining: 98.8ms\n",
      "9:\tlearn: 0.4489248\ttotal: 1.01s\tremaining: 0us\n",
      "prediccion =  25\n",
      "0:\tlearn: 0.4792390\ttotal: 13.1ms\tremaining: 118ms\n",
      "1:\tlearn: 0.4695164\ttotal: 301ms\tremaining: 1.2s\n",
      "2:\tlearn: 0.4654149\ttotal: 571ms\tremaining: 1.33s\n",
      "3:\tlearn: 0.4619585\ttotal: 788ms\tremaining: 1.18s\n",
      "4:\tlearn: 0.4580701\ttotal: 1.07s\tremaining: 1.07s\n",
      "5:\tlearn: 0.4564419\ttotal: 1.08s\tremaining: 724ms\n",
      "6:\tlearn: 0.4557130\ttotal: 1.09s\tremaining: 467ms\n",
      "7:\tlearn: 0.4523972\ttotal: 1.31s\tremaining: 327ms\n",
      "8:\tlearn: 0.4512984\ttotal: 1.32s\tremaining: 146ms\n",
      "9:\tlearn: 0.4497966\ttotal: 1.6s\tremaining: 0us\n",
      "prediccion =  26\n",
      "0:\tlearn: 0.4792390\ttotal: 9.79ms\tremaining: 88.2ms\n",
      "1:\tlearn: 0.4689110\ttotal: 507ms\tremaining: 2.03s\n",
      "2:\tlearn: 0.4640795\ttotal: 1.03s\tremaining: 2.41s\n",
      "3:\tlearn: 0.4604685\ttotal: 1.55s\tremaining: 2.33s\n",
      "4:\tlearn: 0.4573812\ttotal: 2.05s\tremaining: 2.05s\n",
      "5:\tlearn: 0.4546662\ttotal: 2.55s\tremaining: 1.7s\n",
      "6:\tlearn: 0.4530263\ttotal: 3.05s\tremaining: 1.31s\n",
      "7:\tlearn: 0.4509348\ttotal: 3.55s\tremaining: 888ms\n",
      "8:\tlearn: 0.4477925\ttotal: 4.11s\tremaining: 456ms\n",
      "9:\tlearn: 0.4465806\ttotal: 4.58s\tremaining: 0us\n",
      "prediccion =  27\n",
      "0.5021728633510382\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "eqJNSDwGP4T_",
    "colab_type": "code",
    "colab": {},
    "outputId": "d9d52b7a-0d0e-4c08-f4ae-1c371aee2721"
   },
   "source": [
    "resultados_de_prediccion = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=9,\n",
    "                          learning_rate=0.54,\n",
    "                          depth=14)\n",
    "# Fit model\n",
    "model.fit(train_set, train_label)\n",
    "# Get predictions\n",
    "predicion = model.predict(test_set)\n",
    "cantidadDePredicciones,resultados_de_prediccion = ensamble(resultados_de_prediccion,\n",
    "                                                           0,\n",
    "                                                           predicion,\n",
    "                                                           0.20)\n",
    "\n",
    "resultados_de_prediccion = calcular_resultado_de_prediccion(resultados_de_prediccion,cantidadDePredicciones)\n",
    "print(cantidadDePredicciones)\n",
    "resultados_de_prediccion"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 0.4802866\ttotal: 220ms\tremaining: 1.76s\n",
      "1:\tlearn: 0.4716087\ttotal: 456ms\tremaining: 1.6s\n",
      "2:\tlearn: 0.4644414\ttotal: 690ms\tremaining: 1.38s\n",
      "3:\tlearn: 0.4619445\ttotal: 911ms\tremaining: 1.14s\n",
      "4:\tlearn: 0.4599836\ttotal: 1.15s\tremaining: 922ms\n",
      "5:\tlearn: 0.4584017\ttotal: 1.38s\tremaining: 692ms\n",
      "6:\tlearn: 0.4564027\ttotal: 1.61s\tremaining: 459ms\n",
      "7:\tlearn: 0.4534798\ttotal: 1.84s\tremaining: 231ms\n",
      "8:\tlearn: 0.4490005\ttotal: 2.08s\tremaining: 0us\n1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "                    target\nid                        \n0                     1.00\n2                     1.00\n3                     1.00\n9                     1.00\n11                    1.00\n...                    ...\n10861                 1.00\n10865                 1.00\n10868                 1.00\n10874                 1.00\n10875                 1.00\n\n[3263 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10861</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>10865</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>10868</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>10874</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>10875</th>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 60
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "id": "kiDMLUgVP4UE",
    "colab_type": "code",
    "colab": {},
    "outputId": "2086dcbe-8e6c-4456-a2c4-2013c4496407"
   },
   "source": [
    "print(F1(resultados_de_prediccion))\n"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.5253955037468776\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true,
    "id": "-MectER5P4UN",
    "colab_type": "code",
    "colab": {},
    "outputId": "4ba714af-5d3f-4274-a331-18783a5e0502"
   },
   "source": [
    "#para arbol verificar si esta balanceado o no\n",
    "tweets_entrenamiento = tweets_original_entrenamiento\n",
    "tweets_entrenamiento.groupby([\"target\"]).size()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "dtype: int64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 35
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU_0IFfDP4UU",
    "colab_type": "text"
   },
   "source": [
    "# XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "ir-oFDVVP4UV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "test_set = eliminarErrorDeValores(test_set)\n",
    "train_set = eliminarErrorDeValores(train_set)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "dj_AkDEQP4U_",
    "colab_type": "code",
    "colab": {},
    "outputId": "f8f0ffc7-906b-40a2-a338-6156278183ff"
   },
   "source": [
    "######verificacion de hiperparamentros\n",
    "cantidadDePredicciones = 0\n",
    "resultadoDePrediccionXGBoost = pd.read_csv('sample_submission.csv')\n",
    "for profundidad in range(6,8,1):\n",
    "    for tree in range(40,81,20):\n",
    "        colsampleTree = tree / 100\n",
    "        for lR in range(10,81,20):\n",
    "            learningRate = lR / 100\n",
    "            for alpha in range(5,16,5):\n",
    "                xgb_reg = xgb.XGBRegressor(max_depth = profundidad, \n",
    "                                           colsample_bytree = colsampleTree, \n",
    "                                           learning_rate = learningRate, \n",
    "                                           alpha = alpha,\n",
    "                                           objetive = 'reg:squarederror')\n",
    "                \n",
    "                xgb_reg.fit(train_set, train_label)\n",
    "                predicion = xgb_reg.predict(test_set).round()\n",
    "                cantidadDePredicciones,resultados_de_prediccion = ensamble(resultadoDePrediccionXGBoost,cantidadDePredicciones,predicion)\n",
    "                print(\"prediccion = \",cantidadDePredicciones)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[23:52:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3649851632047478 max 0.3649851632047478\n",
      "[23:53:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.363103953147877 max 0.3649851632047478\n",
      "[23:54:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3652173913043478 max 0.3652173913043478\n",
      "[23:55:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3590462833099579 max 0.3652173913043478\n",
      "[23:56:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3605150214592275 max 0.3652173913043478\n",
      "[23:57:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3705799151343706 max 0.3705799151343706\n",
      "[23:58:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.35112359550561795 max 0.3705799151343706\n",
      "[23:59:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3776223776223776 max 0.3776223776223776\n",
      "[00:00:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3912448700410397 max 0.3912448700410397\n",
      "[00:00:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3590462833099579 max 0.3912448700410397\n",
      "[00:01:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37222222222222223 max 0.3912448700410397\n",
      "[00:02:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3492063492063492 max 0.3912448700410397\n",
      "[00:03:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3595166163141994 max 0.3912448700410397\n",
      "[00:05:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3609898107714702 max 0.3912448700410397\n",
      "[00:07:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37321937321937326 max 0.3912448700410397\n",
      "[00:08:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3507779349363508 max 0.3912448700410397\n",
      "[00:10:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3542857142857142 max 0.3912448700410397\n",
      "[00:11:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3651685393258427 max 0.3912448700410397\n",
      "[00:12:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3664335664335664 max 0.3912448700410397\n",
      "[00:14:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3661971830985915 max 0.3912448700410397\n",
      "[00:15:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37047353760445684 max 0.3912448700410397\n",
      "[00:16:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3676268861454046 max 0.3912448700410397\n",
      "[00:18:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.373113854595336 max 0.3912448700410397\n",
      "[00:19:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3756756756756757 max 0.3912448700410397\n",
      "[00:20:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.35098335854765506 max 0.3912448700410397\n",
      "[00:22:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.36676217765042984 max 0.3912448700410397\n",
      "[00:24:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3851640513552068 max 0.3912448700410397\n",
      "[00:26:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3616133518776078 max 0.3912448700410397\n",
      "[00:28:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3703703703703704 max 0.3912448700410397\n",
      "[00:30:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.391123439667129 max 0.3912448700410397\n",
      "[00:31:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.36235955056179775 max 0.3912448700410397\n",
      "[00:33:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.4016506189821183 max 0.4016506189821183\n",
      "[00:34:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3800277392510402 max 0.4016506189821183\n",
      "[00:36:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.36512261580381467 max 0.4016506189821183\n",
      "[00:38:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3767313019390582 max 0.4016506189821183\n",
      "[00:39:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37119113573407203 max 0.4016506189821183\n",
      "[00:40:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.36896046852122993 max 0.4016506189821183\n",
      "[00:42:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3646723646723647 max 0.4016506189821183\n",
      "[00:43:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3551136363636364 max 0.4016506189821183\n",
      "[00:44:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3686382393397524 max 0.4016506189821183\n",
      "[00:45:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.35127478753541075 max 0.4016506189821183\n",
      "[00:46:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3561253561253561 max 0.4016506189821183\n",
      "[00:47:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.35833333333333334 max 0.4016506189821183\n",
      "[00:48:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3575418994413408 max 0.4016506189821183\n",
      "[00:49:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3955739972337483 max 0.4016506189821183\n",
      "[00:50:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.36187845303867405 max 0.4016506189821183\n",
      "[00:51:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3810848400556328 max 0.4016506189821183\n",
      "[00:52:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37709497206703907 max 0.4016506189821183\n",
      "[00:54:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.36390101892285304 max 0.4016506189821183\n",
      "[00:55:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.375896700143472 max 0.4016506189821183\n",
      "[00:57:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37500000000000006 max 0.4016506189821183\n",
      "[00:59:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3641379310344828 max 0.4016506189821183\n",
      "[01:00:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.36538461538461536 max 0.4016506189821183\n",
      "[01:02:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3767313019390582 max 0.4016506189821183\n",
      "[01:03:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3579234972677595 max 0.4016506189821183\n",
      "[01:05:26] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3641379310344828 max 0.4016506189821183\n",
      "[01:06:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.373806275579809 max 0.4016506189821183\n",
      "[01:08:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.368064952638701 max 0.4016506189821183\n",
      "[01:09:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3698630136986301 max 0.4016506189821183\n",
      "[01:11:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3770491803278688 max 0.4016506189821183\n",
      "[01:13:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3713450292397661 max 0.4016506189821183\n",
      "[01:15:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3602836879432624 max 0.4016506189821183\n",
      "[01:17:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37412095639943743 max 0.4016506189821183\n",
      "[01:19:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.35277777777777775 max 0.4016506189821183\n",
      "[01:21:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37268847795163584 max 0.4016506189821183\n",
      "[01:23:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3737796373779637 max 0.4016506189821183\n",
      "[01:24:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3576341127922971 max 0.4016506189821183\n",
      "[01:26:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3856749311294766 max 0.4016506189821183\n",
      "[01:28:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3746630727762803 max 0.4016506189821183\n",
      "[01:29:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.37600000000000006 max 0.4016506189821183\n",
      "[01:31:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3768913342503439 max 0.4016506189821183\n",
      "[01:33:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "local 0.3796423658872077 max 0.4016506189821183\n",
      "contador = 72\n",
      "[7, 0.5, 6]\n",
      "0.4016506189821183\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "ji7PQz1BP4VE",
    "colab_type": "code",
    "colab": {},
    "outputId": "13c4e772-48e1-43c1-d15c-32c16d3d48a6"
   },
   "source": [
    "#los rangos se van afinando segun corren las pruevas\n",
    "def busqueda_de_hiperparametros_optimos_XGBoost_busqueda_binaria():\n",
    "    parametrosXGBoostProfundidad = list(range(13,16,1))\n",
    "    parametrosXGBoostColSample = list(range(50,61,2))\n",
    "    for i in range(len(parametrosXGBoostColSample)):\n",
    "        parametrosXGBoostColSample[i] /= 100\n",
    "    parametrosXGBoostLR = list(range(50,61,2))\n",
    "    for i in range(len(parametrosXGBoostLR)):\n",
    "        parametrosXGBoostLR[i] /= 100\n",
    "    parametrosXGBoostAlpha = list(range(9,12,1))\n",
    "    listaDeParametros = [parametrosXGBoostProfundidad,parametrosXGBoostColSample,parametrosXGBoostLR,parametrosXGBoostAlpha]\n",
    "    maximo,parametros =busqueda_binaria_de_maximos(listaDeParametros,\n",
    "                                                   [0,0,0,0],\n",
    "                                                   0,\n",
    "                                                   ultimo_Hiper_Parametro_XGBoost)\n",
    "    print(\"maximo {} parametros (iter,learning,profundidad) {}\".format(maximo,parametros))\n",
    "busqueda_de_hiperparametros_optimos_XGBoost_busqueda_binaria()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[13, 0.5, 0.5, 9]\n",
      "[20:32:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.5, 11]\n",
      "[20:32:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.5, 10]\n",
      "[20:32:42] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.6, 9]\n",
      "[20:32:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.6, 11]\n",
      "[20:32:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.6, 10]\n",
      "[20:32:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.54, 9]\n",
      "[20:33:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.54, 11]\n",
      "[20:33:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.54, 10]\n",
      "[20:33:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.52, 9]\n",
      "[20:33:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.52, 11]\n",
      "[20:33:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.5, 0.52, 10]\n",
      "[20:33:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.5, 9]\n",
      "[20:33:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.5, 11]\n",
      "[20:33:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.5, 10]\n",
      "[20:33:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.6, 9]\n",
      "[20:33:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.6, 11]\n",
      "[20:33:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.6, 10]\n",
      "[20:34:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.54, 9]\n",
      "[20:34:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.54, 11]\n",
      "[20:34:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.54, 10]\n",
      "[20:34:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.52, 9]\n",
      "[20:34:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.52, 11]\n",
      "[20:34:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.6, 0.52, 10]\n",
      "[20:34:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.5, 9]\n",
      "[20:34:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.5, 11]\n",
      "[20:34:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.5, 10]\n",
      "[20:34:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.6, 9]\n",
      "[20:34:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.6, 11]\n",
      "[20:35:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.6, 10]\n",
      "[20:35:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.54, 9]\n",
      "[20:35:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.54, 11]\n",
      "[20:35:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.54, 10]\n",
      "[20:35:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.52, 9]\n",
      "[20:35:31] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.52, 11]\n",
      "[20:35:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.54, 0.52, 10]\n",
      "[20:35:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.5, 9]\n",
      "[20:35:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.5, 11]\n",
      "[20:35:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.5, 10]\n",
      "[20:36:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.6, 9]\n",
      "[20:36:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.6, 11]\n",
      "[20:36:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.6, 10]\n",
      "[20:36:15] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.54, 9]\n",
      "[20:36:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.54, 11]\n",
      "[20:36:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.54, 10]\n",
      "[20:36:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.56, 9]\n",
      "[20:36:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.56, 11]\n",
      "[20:36:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.56, 0.56, 10]\n",
      "[20:36:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.5, 9]\n",
      "[20:36:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.5, 11]\n",
      "[20:37:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.5, 10]\n",
      "[20:37:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.6, 9]\n",
      "[20:37:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.6, 11]\n",
      "[20:37:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.6, 10]\n",
      "[20:37:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.54, 9]\n",
      "[20:37:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.54, 11]\n",
      "[20:37:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.54, 10]\n",
      "[20:37:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.52, 9]\n",
      "[20:37:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.52, 11]\n",
      "[20:37:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13, 0.58, 0.52, 10]\n",
      "[20:37:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.5, 9]\n",
      "[20:38:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.5, 11]\n",
      "[20:38:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.5, 10]\n",
      "[20:38:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.6, 9]\n",
      "[20:38:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.6, 11]\n",
      "[20:38:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.6, 10]\n",
      "[20:38:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.54, 9]\n",
      "[20:38:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.54, 11]\n",
      "[20:38:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.54, 10]\n",
      "[20:38:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.52, 9]\n",
      "[20:38:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.52, 11]\n",
      "[20:38:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.5, 0.52, 10]\n",
      "[20:39:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.5, 9]\n",
      "[20:39:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.5, 11]\n",
      "[20:39:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.5, 10]\n",
      "[20:39:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.6, 9]\n",
      "[20:39:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.6, 11]\n",
      "[20:39:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.6, 10]\n",
      "[20:39:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.54, 9]\n",
      "[20:39:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.54, 11]\n",
      "[20:39:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.54, 10]\n",
      "[20:39:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.52, 9]\n",
      "[20:40:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.52, 11]\n",
      "[20:40:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.6, 0.52, 10]\n",
      "[20:40:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.5, 9]\n",
      "[20:40:18] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.5, 11]\n",
      "[20:40:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.5, 10]\n",
      "[20:40:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.6, 9]\n",
      "[20:40:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.6, 11]\n",
      "[20:40:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.6, 10]\n",
      "[20:40:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.54, 9]\n",
      "[20:40:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.54, 11]\n",
      "[20:40:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.54, 10]\n",
      "[20:41:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.52, 9]\n",
      "[20:41:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.52, 11]\n",
      "[20:41:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.54, 0.52, 10]\n",
      "[20:41:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.5, 9]\n",
      "[20:41:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.5, 11]\n",
      "[20:41:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.5, 10]\n",
      "[20:41:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.6, 9]\n",
      "[20:41:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.6, 11]\n",
      "[20:41:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.6, 10]\n",
      "[20:41:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.54, 9]\n",
      "[20:42:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.54, 11]\n",
      "[20:42:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.54, 10]\n",
      "[20:42:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.56, 9]\n",
      "[20:42:23] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.56, 11]\n",
      "[20:42:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15, 0.56, 0.56, 10]\n",
      "[20:42:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.5, 9]\n",
      "[20:42:39] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.5, 11]\n",
      "[20:42:44] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.5, 10]\n",
      "[20:42:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.6, 9]\n",
      "[20:42:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.6, 11]\n",
      "[20:43:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.6, 10]\n",
      "[20:43:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.54, 9]\n",
      "[20:43:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.54, 11]\n",
      "[20:43:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.54, 10]\n",
      "[20:43:21] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.56, 9]\n",
      "[20:43:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.56, 11]\n",
      "[20:43:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.56, 10]\n",
      "[20:43:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.58, 9]\n",
      "[20:43:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.58, 11]\n",
      "[20:43:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.5, 0.58, 10]\n",
      "[20:43:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.5, 9]\n",
      "[20:44:02] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.5, 11]\n",
      "[20:44:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.5, 10]\n",
      "[20:44:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.6, 9]\n",
      "[20:44:20] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.6, 11]\n",
      "[20:44:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.6, 10]\n",
      "[20:44:29] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.54, 9]\n",
      "[20:44:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.54, 11]\n",
      "[20:44:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.54, 10]\n",
      "[20:44:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.56, 9]\n",
      "[20:44:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.56, 11]\n",
      "[20:44:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.56, 10]\n",
      "[20:45:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.58, 9]\n",
      "[20:45:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.58, 11]\n",
      "[20:45:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.6, 0.58, 10]\n",
      "[20:45:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.5, 9]\n",
      "[20:45:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.5, 11]\n",
      "[20:45:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.5, 10]\n",
      "[20:45:40] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.6, 9]\n",
      "[20:45:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.6, 11]\n",
      "[20:45:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.6, 10]\n",
      "[20:45:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.54, 9]\n",
      "[20:46:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.54, 11]\n",
      "[20:46:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.54, 10]\n",
      "[20:46:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.56, 9]\n",
      "[20:46:24] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.56, 11]\n",
      "[20:46:30] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.56, 10]\n",
      "[20:46:35] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.58, 9]\n",
      "[20:46:41] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.58, 11]\n",
      "[20:46:46] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.54, 0.58, 10]\n",
      "[20:46:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.5, 9]\n",
      "[20:46:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.5, 11]\n",
      "[20:47:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.5, 10]\n",
      "[20:47:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.6, 9]\n",
      "[20:47:17] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.6, 11]\n",
      "[20:47:22] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.6, 10]\n",
      "[20:47:28] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.54, 9]\n",
      "[20:47:33] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.54, 11]\n",
      "[20:47:38] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.54, 10]\n",
      "[20:47:45] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.52, 9]\n",
      "[20:47:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.52, 11]\n",
      "[20:47:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14, 0.56, 0.52, 10]\n",
      "[20:48:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "maximo 0.6653831343858299 parametros (iter,learning,profundidad) [14, 0.56, 0.52, 10]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "xlygzJvmP4VJ",
    "colab_type": "code",
    "colab": {},
    "outputId": "f3aa479b-5f88-4f51-809f-ed841a872589"
   },
   "source": [
    "xgb_reg = xgb.XGBRegressor(max_depth = 15, \n",
    "                           colsample_bytree = 0.5, \n",
    "                           learning_rate = 0.8, \n",
    "                           alpha = 10,\n",
    "                           objetive = 'reg:squarederror')\n",
    "\n",
    "xgb_reg.fit(train_set, train_label)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[16:34:09] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { objetive } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.5, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.8, max_delta_step=0, max_depth=15,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objetive='reg:squarederror', random_state=0, reg_alpha=10,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "C6pccP84P4VO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "result = pd.read_csv('sample_submission.csv',index_col=['id'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    },
    "id": "5woOe9eeP4VW",
    "colab_type": "code",
    "colab": {},
    "outputId": "c9b2fd84-85a3-4bb5-a3db-922aae3a11c9"
   },
   "source": [
    "predicts = xgb_reg.predict(test_set)\n",
    "predicts += 0.21\n",
    "predicts = predicts.round()\n",
    "result['target'] = predicts\n",
    "print(F1(result))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0.642122360584732\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03dsDu2aP4Vc",
    "colab_type": "text"
   },
   "source": [
    "Con K-FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "2JC_6JP2P4Vd",
    "colab_type": "code",
    "colab": {},
    "outputId": "47cd61e1-c47b-42f6-d96f-4b551988d9b5"
   },
   "source": [
    "dmatrix = xgb.DMatrix(data=train_set,label=train_label)\n",
    "params = {'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50, early_stopping_rounds=10,\n",
    "                    metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "#ultimo error\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "49                   0.47\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "B-OcjeVwP4WE",
    "colab_type": "code",
    "colab": {},
    "outputId": "cc9595ff-c666-4a64-d736-6ffbb547e774"
   },
   "source": [
    "cv_results.head()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       train-rmse-mean       train-rmse-std       test-rmse-mean  \\\n",
       "0                 0.50                 0.00                 0.50   \n",
       "1                 0.50                 0.00                 0.50   \n",
       "2                 0.50                 0.00                 0.50   \n",
       "3                 0.50                 0.00                 0.50   \n",
       "4                 0.49                 0.00                 0.49   \n",
       "\n",
       "         test-rmse-std  \n",
       "0                 0.00  \n",
       "1                 0.00  \n",
       "2                 0.00  \n",
       "3                 0.00  \n",
       "4                 0.00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    },
    "id": "qD0GKInaP4WY",
    "colab_type": "code",
    "colab": {},
    "outputId": "9084b2d6-c3eb-4115-c1df-ce0b39036eab"
   },
   "source": [
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + 'D:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "\n",
    "xg_reg = xgb.train(params=params, dtrain=dmatrix, num_boost_round=10)\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "xgb.to_graphviz(xg_reg,num_trees=0)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    136\u001b[0m         out = backend.pipe(self._engine, format, data,\n\u001b[0;32m    137\u001b[0m                            \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                            quiet=quiet)\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \"\"\"\n\u001b[0;32m    243\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0xf9be908>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQuZhWJUP4Wp",
    "colab_type": "text"
   },
   "source": [
    "Importancia de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    },
    "id": "S3z-XNO8P4Wq",
    "colab_type": "code",
    "colab": {},
    "outputId": "e5b6dde3-a106-48e4-9dfa-0df7e8580056"
   },
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 7]\n",
    "xgb.plot_importance(xg_reg)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14b28048>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 44
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_zUEEi7P4Wv",
    "colab_type": "text"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "dGNmnkAnP4Ww",
    "colab_type": "code",
    "colab": {},
    "outputId": "05c403fa-d989-49be-8414-4acd806a194f"
   },
   "source": [
    "rf = RandomForestRegressor(random_state=1, n_estimators = 20, max_features = 4, min_samples_split=10)\n",
    "rf.fit(train_set, train_label)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), list(train_set.columns)),\n",
    "             reverse=True))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.1701, 'longitud_de_texto'), (0.16, 'longitud_de_texto_sin_signos'), (0.1212, 'longitud_de_keyword'), (0.0948, 'cantidad_de_palabras_texto'), (0.031, 'cantidad_de_hashtag_en_texto'), (0.0132, 'train'), (0.0095, 'disaster'), (0.0092, 'migrants'), (0.0091, 'families'), (0.0085, 'news'), (0.0071, 'full'), (0.0069, 'fatal'), (0.0051, 'weather'), (0.0047, 'soudelor'), (0.0046, 'rt'), (0.0046, 'let'), (0.0045, 'watch'), (0.0044, 'forest'), (0.0042, 'outrage'), (0.0042, 'earthquake'), (0.0041, 'sinkhole'), (0.0038, 'today'), (0.0038, 'floods'), (0.0035, 'turkey'), (0.0035, 'refugees'), (0.0035, 'pm'), (0.0035, 'hurricane'), (0.0033, 'heavy'), (0.0033, 'death'), (0.0032, 'cantidad_de_palabras_keyword'), (0.0031, 'things'), (0.0031, 'show'), (0.0031, 'im'), (0.003, 'rain'), (0.003, 'possible'), (0.003, 'island'), (0.003, 'derailment'), (0.0028, 'wave'), (0.0027, 'words'), (0.0027, 'airport'), (0.0026, 'damage'), (0.0025, 'youth'), (0.0025, 'wreck'), (0.0025, 'obliteration'), (0.0025, 'la'), (0.0024, 'tornado'), (0.0024, 'derailed'), (0.0024, 'colorado'), (0.0024, 'book'), (0.0023, 'sunk'), (0.0023, 'children'), (0.0023, 'armageddon'), (0.0023, 'aircraft'), (0.0022, 'flash'), (0.0022, 'coast'), (0.0021, 'zone'), (0.0021, 'udhampur'), (0.0021, 'reports'), (0.0021, 'quarantine'), (0.0021, 'order'), (0.0021, 'away'), (0.002, 'lot'), (0.002, 'demolish'), (0.0019, 'summer'), (0.0019, 'second'), (0.0019, 'person'), (0.0019, 'nagasaki'), (0.0019, 'game'), (0.0019, 'denver'), (0.0019, 'become'), (0.0018, 'survived'), (0.0018, 'sandstorm'), (0.0018, 'online'), (0.0018, 'demolished'), (0.0018, 'burned'), (0.0017, 'yes'), (0.0017, 'use'), (0.0017, 'richmond'), (0.0017, 'ok'), (0.0017, 'lost'), (0.0017, 'listen'), (0.0017, 'incident'), (0.0017, 'hailstorm'), (0.0017, 'ebola'), (0.0016, 'week'), (0.0016, 'strike'), (0.0016, 'lets'), (0.0016, 'bang'), (0.0015, 'womens'), (0.0015, 'song'), (0.0015, 'riot'), (0.0015, 'letra_2'), (0.0015, 'fatality'), (0.0014, 'win'), (0.0014, 'letra_0'), (0.0014, 'days'), (0.0014, 'collapsed'), (0.0014, 'cliff'), (0.0014, 'ave'), (0.0013, 'update'), (0.0013, 'turkish'), (0.0013, 'place'), (0.0013, 'okay'), (0.0013, 'mom'), (0.0013, 'legacy'), (0.0013, 'job'), (0.0013, 'hero'), (0.0013, 'continues'), (0.0012, 'uk'), (0.0012, 'letra_1'), (0.0012, 'hail'), (0.0012, 'govt'), (0.0011, 'smaug'), (0.0011, 'mind'), (0.0011, 'letra_3'), (0.0011, 'else'), (0.0011, 'climate'), (0.0011, 'changes'), (0.0011, 'ago'), (0.0011, 'action'), (0.001, 'yrs'), (0.001, 'tired'), (0.001, 'snowstorm'), (0.001, 'residents'), (0.001, 'lucky'), (0.001, 'lorries'), (0.001, 'funny'), (0.001, 'cant'), (0.001, 'buy'), (0.001, 'bout'), (0.001, 'aftershock'), (0.0009, 'theres'), (0.0009, 'structural'), (0.0009, 'riots'), (0.0009, 'official'), (0.0009, 'lose'), (0.0009, 'internet'), (0.0009, 'interesting'), (0.0009, 'hilarious'), (0.0009, 'highway'), (0.0009, 'fantasy'), (0.0009, 'exchange'), (0.0009, 'department'), (0.0009, 'centre'), (0.0009, 'attacks'), (0.0009, 'animal'), (0.0008, 'turned'), (0.0008, 'stage'), (0.0008, 'philippines'), (0.0008, 'moved'), (0.0008, 'metal'), (0.0008, 'mediterranean'), (0.0008, 'matter'), (0.0008, 'local'), (0.0008, 'games'), (0.0008, 'evening'), (0.0008, 'course'), (0.0008, 'bleedingbleeding'), (0.0008, 'app'), (0.0008, 'alps'), (0.0007, 'weird'), (0.0007, 'watched'), (0.0007, 'tribune'), (0.0007, 'survival'), (0.0007, 'se'), (0.0007, 'hotel'), (0.0007, 'fat'), (0.0007, 'detonation'), (0.0007, 'christians'), (0.0007, 'chile'), (0.0007, 'ceo'), (0.0007, 'alarm'), (0.0007, 'aba'), (0.0006, 'walls'), (0.0006, 'thats'), (0.0006, 'stuff'), (0.0006, 'skinny'), (0.0006, 'rubble'), (0.0006, 'root'), (0.0006, 'republicans'), (0.0006, 'flying'), (0.0006, 'droughtdrought'), (0.0006, 'crew'), (0.0006, 'bound'), (0.0006, 'bestnaijamade'), (0.0006, 'begins'), (0.0006, 'baseball'), (0.0006, 'anymore'), (0.0006, 'activity'), (0.0005, 'targets'), (0.0005, 'shop'), (0.0005, 'seat'), (0.0005, 'safe'), (0.0005, 'rip'), (0.0005, 'reno'), (0.0005, 'powerful'), (0.0005, 'political'), (0.0005, 'passing'), (0.0005, 'nd'), (0.0005, 'manchester'), (0.0005, 'location_palabra_4'), (0.0005, 'levels'), (0.0005, 'hills'), (0.0005, 'flamesflames'), (0.0005, 'fail'), (0.0005, 'enter'), (0.0005, 'energy'), (0.0005, 'defense'), (0.0005, 'debate'), (0.0005, 'dance'), (0.0005, 'cost'), (0.0005, 'collapsecollapse'), (0.0005, 'burningburning'), (0.0005, 'australian'), (0.0004, 'yay'), (0.0004, 'weaponweapon'), (0.0004, 'terrorismterrorism'), (0.0004, 'sunday'), (0.0004, 'society'), (0.0004, 'seattle'), (0.0004, 'rights'), (0.0004, 'returns'), (0.0004, 'responds'), (0.0004, 'remembering'), (0.0004, 'nobody'), (0.0004, 'moon'), (0.0004, 'mma'), (0.0004, 'marketing'), (0.0004, 'manager'), (0.0004, 'management'), (0.0004, 'location_palabra_6'), (0.0004, 'location_palabra_3'), (0.0004, 'kerry'), (0.0004, 'jesus'), (0.0004, 'illinois'), (0.0004, 'ill'), (0.0004, 'hughes'), (0.0004, 'horse'), (0.0004, 'hitting'), (0.0004, 'hes'), (0.0004, 'gods'), (0.0004, 'georgia'), (0.0004, 'fair'), (0.0004, 'exactly'), (0.0004, 'edm'), (0.0004, 'earlier'), (0.0004, 'dudes'), (0.0004, 'doors'), (0.0004, 'disasterdisaster'), (0.0004, 'design'), (0.0004, 'defend'), (0.0004, 'cta'), (0.0004, 'contained'), (0.0004, 'clear'), (0.0004, 'campaign'), (0.0004, 'angeles'), (0.0003, 'whats'), (0.0003, 'website'), (0.0003, 'warned'), (0.0003, 'volcanovolcano'), (0.0003, 'virus'), (0.0003, 'veterans'), (0.0003, 'vegas'), (0.0003, 'utc'), (0.0003, 'unlocked'), (0.0003, 'uber'), (0.0003, 'tries'), (0.0003, 'traumatisedtraumatised'), (0.0003, 'trailer'), (0.0003, 'titanic'), (0.0003, 'thriller'), (0.0003, 'tank'), (0.0003, 'style'), (0.0003, 'selfie'), (0.0003, 'saipan'), (0.0003, 'ruined'), (0.0003, 'romance'), (0.0003, 'returned'), (0.0003, 'results'), (0.0003, 'rear'), (0.0003, 'promise'), (0.0003, 'prevention'), (0.0003, 'prayers'), (0.0003, 'plants'), (0.0003, 'parade'), (0.0003, 'opposition'), (0.0003, 'nepal'), (0.0003, 'mountains'), (0.0003, 'model'), (0.0003, 'min'), (0.0003, 'mets'), (0.0003, 'medic'), (0.0003, 'mall'), (0.0003, 'location_palabra_2'), (0.0003, 'legionnaires'), (0.0003, 'jst'), (0.0003, 'journal'), (0.0003, 'integrity'), (0.0003, 'institute'), (0.0003, 'indeed'), (0.0003, 'hopefully'), (0.0003, 'heroin'), (0.0003, 'hardy'), (0.0003, 'fly'), (0.0003, 'eu'), (0.0003, 'electric'), (0.0003, 'drum'), (0.0003, 'disco'), (0.0003, 'dante'), (0.0003, 'cup'), (0.0003, 'cream'), (0.0003, 'cleveland'), (0.0003, 'chaos'), (0.0003, 'cbs'), (0.0003, 'castle'), (0.0003, 'assembly'), (0.0003, 'asian'), (0.0003, 'acres'), (0.0002, 'yemen'), (0.0002, 'yellow'), (0.0002, 'wo'), (0.0002, 'vine'), (0.0002, 'vegetarian'), (0.0002, 'unsafe'), (0.0002, 'tune'), (0.0002, 'throwback'), (0.0002, 'theyre'), (0.0002, 'structure'), (0.0002, 'speak'), (0.0002, 'spain'), (0.0002, 'shoe'), (0.0002, 'senate'), (0.0002, 'rush'), (0.0002, 'ronaldo'), (0.0002, 'proceeds'), (0.0002, 'pieces'), (0.0002, 'nike'), (0.0002, 'mlb'), (0.0002, 'minecraft'), (0.0002, 'microsoft'), (0.0002, 'location_palabra_0'), (0.0002, 'learned'), (0.0002, 'justified'), (0.0002, 'ja'), (0.0002, 'honest'), (0.0002, 'historic'), (0.0002, 'hardly'), (0.0002, 'gps'), (0.0002, 'goals'), (0.0002, 'goal'), (0.0002, 'freedom'), (0.0002, 'experiencing'), (0.0002, 'etc'), (0.0002, 'ep'), (0.0002, 'dvd'), (0.0002, 'crimes'), (0.0002, 'count'), (0.0002, 'controlled'), (0.0002, 'columbia'), (0.0002, 'cloud'), (0.0002, 'clash'), (0.0002, 'certainly'), (0.0002, 'camping'), (0.0002, 'broadway'), (0.0002, 'boston'), (0.0002, 'boom'), (0.0002, 'believing'), (0.0002, 'asleep'), (0.0002, 'asia'), (0.0002, 'analysis'), (0.0002, 'alert'), (0.0001, 'yankees'), (0.0001, 'worries'), (0.0001, 'wed'), (0.0001, 'waters'), (0.0001, 'venezuela'), (0.0001, 'uniform'), (0.0001, 'underway'), (0.0001, 'tumblr'), (0.0001, 'troubletrouble'), (0.0001, 'tower'), (0.0001, 'threats'), (0.0001, 'tattoo'), (0.0001, 'sundays'), (0.0001, 'somalia'), (0.0001, 'snowden'), (0.0001, 'settle'), (0.0001, 'screamsscreams'), (0.0001, 'saturday'), (0.0001, 'recording'), (0.0001, 'notifications'), (0.0001, 'morningderailed'), (0.0001, 'mistake'), (0.0001, 'massacremassacre'), (0.0001, 'maps'), (0.0001, 'lt'), (0.0001, 'location_palabra_5'), (0.0001, 'lifestyle'), (0.0001, 'legs'), (0.0001, 'latin'), (0.0001, 'labour'), (0.0001, 'kindle'), (0.0001, 'kidding'), (0.0001, 'isnt'), (0.0001, 'interest'), (0.0001, 'injuriesinjuries'), (0.0001, 'huh'), (0.0001, 'hs'), (0.0001, 'headlines'), (0.0001, 'grief'), (0.0001, 'gr'), (0.0001, 'glasses'), (0.0001, 'gallipoli'), (0.0001, 'gabon'), (0.0001, 'ft'), (0.0001, 'flip'), (0.0001, 'fixed'), (0.0001, 'fest'), (0.0001, 'farrakhan'), (0.0001, 'extension'), (0.0001, 'explodedexploded'), (0.0001, 'electrocutedelectrocuted'), (0.0001, 'eh'), (0.0001, 'edit'), (0.0001, 'edge'), (0.0001, 'duty'), (0.0001, 'drowndrown'), (0.0001, 'defects'), (0.0001, 'dangerdanger'), (0.0001, 'collidecollide'), (0.0001, 'collapsedcollapsed'), (0.0001, 'closing'), (0.0001, 'citizens'), (0.0001, 'choose'), (0.0001, 'chest'), (0.0001, 'chernobyl'), (0.0001, 'bob'), (0.0001, 'belly'), (0.0001, 'bee'), (0.0001, 'author'), (0.0001, 'argument'), (0.0001, 'adam'), (0.0001, 'acoustic'), (0.0, 'youre'), (0.0, 'wheres'), (0.0, 'tr'), (0.0, 'towel'), (0.0, 'timelapse'), (0.0, 'theyll'), (0.0, 'th'), (0.0, 'tech'), (0.0, 'tahoe'), (0.0, 'strikes'), (0.0, 'speed'), (0.0, 'sinkingsinking'), (0.0, 'sink'), (0.0, 'shops'), (0.0, 'shelli'), (0.0, 'shell'), (0.0, 'shania'), (0.0, 'selfies'), (0.0, 'roh'), (0.0, 'rightways'), (0.0, 'reopens'), (0.0, 'relentless'), (0.0, 'puppy'), (0.0, 'prepper'), (0.0, 'poss'), (0.0, 'pope'), (0.0, 'pin'), (0.0, 'pants'), (0.0, 'pa'), (0.0, 'outfit'), (0.0, 'oo'), (0.0, 'nv'), (0.0, 'ntsb'), (0.0, 'nigeria'), (0.0, 'niall'), (0.0, 'miami'), (0.0, 'mi'), (0.0, 'married'), (0.0, 'location_palabra_1'), (0.0, 'lgbt'), (0.0, 'kodiak'), (0.0, 'journalism'), (0.0, 'ir'), (0.0, 'innovation'), (0.0, 'imagined'), (0.0, 'hoax'), (0.0, 'hmm'), (0.0, 'heavenly'), (0.0, 'genocide'), (0.0, 'genius'), (0.0, 'forex'), (0.0, 'fdny'), (0.0, 'fatalityfatality'), (0.0, 'esp'), (0.0, 'emergencyemergency'), (0.0, 'electricity'), (0.0, 'ds'), (0.0, 'cowboys'), (0.0, 'cooper'), (0.0, 'conclusively'), (0.0, 'cnnbrk'), (0.0, 'cnbc'), (0.0, 'cleared'), (0.0, 'casualtiescasualties'), (0.0, 'blizzardblizzard'), (0.0, 'batteries'), (0.0, 'arizona'), (0.0, 'apartments'), (0.0, 'amp'), (0.0, 'ak'), (0.0, 'aint'), (0.0, 'accidentaccident')]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "id": "DzUpmF51P4XC",
    "colab_type": "code",
    "colab": {},
    "outputId": "c182a79c-ab88-4e9f-87d3-3e99a3411101"
   },
   "source": [
    "train_set_best_features = train_set[['longitud_de_keyword', 'longitud_de_texto', 'cantidad_de_palabras_texto', 'cantidad_de_hashtag_en_texto']]\n",
    "train_set_best_features.head()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    longitud_de_keyword  longitud_de_texto  cantidad_de_palabras_texto  \\\n",
       "id                                                                       \n",
       "1                     0                  0                           0   \n",
       "4                     0                  0                           0   \n",
       "5                     0                  0                           0   \n",
       "6                     0                  0                           0   \n",
       "7                     0                  0                           0   \n",
       "\n",
       "    cantidad_de_hashtag_en_texto  \n",
       "id                                \n",
       "1                              0  \n",
       "4                              0  \n",
       "5                              0  \n",
       "6                              0  \n",
       "7                              0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitud_de_keyword</th>\n",
       "      <th>longitud_de_texto</th>\n",
       "      <th>cantidad_de_palabras_texto</th>\n",
       "      <th>cantidad_de_hashtag_en_texto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 46
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "I_TSlietP4Xi",
    "colab_type": "code",
    "colab": {},
    "outputId": "bcff942d-d9da-49fd-e145-12fe0ec6b514"
   },
   "source": [
    "train_scoreNum, test_scoreNum = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = train_set_best_features, y = train_label, \n",
    "                                param_name = 'n_estimators', \n",
    "                                param_range=np.arange(1, 50),\n",
    "                                cv=3, \n",
    "                                scoring=\"accuracy\", \n",
    "                                n_jobs=-1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'validation_curve' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-36335484b8b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_scoreNum, test_scoreNum = validation_curve(\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set_best_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mparam_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[0mparam_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_curve' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "fkgQNLzcP4Yt",
    "colab_type": "code",
    "colab": {},
    "outputId": "5fa3e929-1ab0-4406-f2b6-9f58b98946ae"
   },
   "source": [
    "train_mean = np.mean(train_scoreNum, axis=1)\n",
    "test_mean = np.mean(test_scoreNum, axis=1)\n",
    "plt.plot(np.arange(1, 50), train_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(np.arange(1, 50), test_mean, label=\"Testing score\", color=\"dimgrey\")\n",
    "plt.title(\"Validation Curve With Random Forest\")\n",
    "plt.xlabel(\"Valores de n_estimators\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_scoreNum' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5699166f8b46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scoreNum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_scoreNum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"black\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Testing score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dimgrey\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation Curve With Random Forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_scoreNum' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "mvqJnaUhP4Y6",
    "colab_type": "code",
    "colab": {},
    "outputId": "68dc0715-82e5-440c-ea04-abed064957d3"
   },
   "source": [
    "train_scoreNum_maxdepth, test_scoreNum_maxdepth = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = train_set_best_features, y = train_label, \n",
    "                                param_name = 'max_depth', \n",
    "                                param_range=np.arange(1, 15),\n",
    "                                cv=3, \n",
    "                                scoring=\"accuracy\", \n",
    "                                n_jobs=-1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'validation_curve' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-7714af550a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_scoreNum_maxdepth, test_scoreNum_maxdepth = validation_curve(\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set_best_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mparam_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[0mparam_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_curve' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "JKmsXXvgP4ZF",
    "colab_type": "code",
    "colab": {},
    "outputId": "85cbdeac-5803-407c-d11c-57c5022cc35e"
   },
   "source": [
    "train_mean = np.mean(train_scoreNum_maxdepth, axis=1)\n",
    "test_mean = np.mean(test_scoreNum_maxdepth, axis=1)\n",
    "plt.plot(np.arange(1, 15), train_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(np.arange(1, 15), test_mean, label=\"Testing score\", color=\"dimgrey\")\n",
    "plt.title(\"Validation Curve With Random Forest\")\n",
    "plt.xlabel(\"Valores de max_depth\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_scoreNum_maxdepth' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-842bcd0f20dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scoreNum_maxdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_scoreNum_maxdepth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"black\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Testing score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dimgrey\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation Curve With Random Forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_scoreNum_maxdepth' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "XMWPMsmMP4ZU",
    "colab_type": "code",
    "colab": {},
    "outputId": "2e513ea2-4bcc-4f98-accd-f402778a96a1"
   },
   "source": [
    "train_scoreNum_min_samples_split, test_scoreNum_min_samples_split = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = train_set_best_features, y = train_label, \n",
    "                                param_name = 'min_samples_split', \n",
    "                                param_range=np.arange(1, 30),\n",
    "                                cv=3, \n",
    "                                scoring=\"accuracy\", \n",
    "                                n_jobs=-1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'validation_curve' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-e200bd422fb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_scoreNum_min_samples_split, test_scoreNum_min_samples_split = validation_curve(\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set_best_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mparam_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'min_samples_split'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[0mparam_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_curve' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "BDmK50q3P4ZY",
    "colab_type": "code",
    "colab": {},
    "outputId": "34d1ee67-68a5-41ae-952b-b49991776760"
   },
   "source": [
    "train_mean = np.mean(train_scoreNum_min_samples_split, axis=1)\n",
    "test_mean = np.mean(test_scoreNum_min_samples_split, axis=1)\n",
    "plt.plot(np.arange(1, 30), train_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(np.arange(1, 30), test_mean, label=\"Testing score\", color=\"dimgrey\")\n",
    "plt.title(\"Validation Curve With Random Forest\")\n",
    "plt.xlabel(\"Valores de min_samples_split\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_scoreNum_min_samples_split' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-987912ab5483>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scoreNum_min_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_scoreNum_min_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"black\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Testing score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dimgrey\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation Curve With Random Forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_scoreNum_min_samples_split' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "4jX0YLP8P4Ze",
    "colab_type": "code",
    "colab": {},
    "outputId": "f5f74ca6-7e72-45b5-c20f-f6bfc63b118f"
   },
   "source": [
    "train_scoreNum_min_samples_leaf, test_scoreNum_min_samples_leaf = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = train_set_best_features, y = train_label, \n",
    "                                param_name = 'min_samples_leaf', \n",
    "                                param_range=np.arange(1, 20),\n",
    "                                cv=3, \n",
    "                                scoring=\"accuracy\", \n",
    "                                n_jobs=-1)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'validation_curve' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-92cfa1080dc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_scoreNum_min_samples_leaf, test_scoreNum_min_samples_leaf = validation_curve(\n\u001b[0m\u001b[0;32m      2\u001b[0m                                 \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set_best_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mparam_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'min_samples_leaf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[0mparam_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_curve' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "F6OffTN0P4Zl",
    "colab_type": "code",
    "colab": {},
    "outputId": "56f1b738-32dd-4f96-f308-92a9d4e5e0b7"
   },
   "source": [
    "train_mean = np.mean(train_scoreNum_min_samples_leaf, axis=1)\n",
    "test_mean = np.mean(test_scoreNum_min_samples_leaf, axis=1)\n",
    "plt.plot(np.arange(1, 20), train_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(np.arange(1, 20), test_mean, label=\"Testing score\", color=\"dimgrey\")\n",
    "plt.title(\"Validation Curve With Random Forest\")\n",
    "plt.xlabel(\"Valores de min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_scoreNum_min_samples_leaf' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-4d83e5240692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_scoreNum_min_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_scoreNum_min_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Training score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"black\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Testing score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dimgrey\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation Curve With Random Forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_scoreNum_min_samples_leaf' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "m2LiZesXP4Z8",
    "colab_type": "code",
    "colab": {},
    "outputId": "983d1612-a484-49ac-80fe-be1534025ee1"
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = np.arange(1, 50)\n",
    "max_depth = np.arange(1, 15)\n",
    "min_samples_split = np.arange(1, 30)\n",
    "min_samples_leaf = np.arange(1, 20)\n",
    "\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "gridF = GridSearchCV(RandomForestClassifier(random_state = 1), hyperF, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(train_set, train_label)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 377986 candidates, totalling 1133958 fits\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:  7.6min\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-ab1e7ddaabcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m gridF = GridSearchCV(RandomForestClassifier(random_state = 1), hyperF, cv = 3, verbose = 1, \n\u001b[0;32m     13\u001b[0m                       n_jobs = -1)\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mbestF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgridF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    538\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    539\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "4dUCp8VAP4aC",
    "colab_type": "code",
    "colab": {},
    "outputId": "7fd8f7c1-359a-4056-aa17-3830db658203"
   },
   "source": [
    "rf = RandomForestRegressor(random_state=5, n_estimators = 46, max_depth = 6, min_samples_split=47, min_samples_leaf = 27)\n",
    "rf.fit(train_set, train_label)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=6, min_samples_leaf=27, min_samples_split=47,\n",
       "                      n_estimators=46, random_state=5)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 68
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "obiCFcptP4aH",
    "colab_type": "code",
    "colab": {},
    "outputId": "59b6bf0b-ff69-4aaa-ae5a-6f05b707e7b7"
   },
   "source": [
    "predicts = rf.predict(test_set)\n",
    "predicts += 0.21\n",
    "result['target'] = predicts.round()\n",
    "print(F1(result))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0.6314265025343954\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "QluoNvIVP4aK",
    "colab_type": "code",
    "colab": {},
    "outputId": "51cf5f54-4db1-43df-ba0d-62ac9abd9485"
   },
   "source": [
    "plt.barh(train_set.columns, rf.feature_importances_)\n",
    "plt.xlabel('Features de train')\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia vs Features con Random Forest')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-e9b6a45e1524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Importancia'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Importancia vs Features con Random Forest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     41\u001b[0m             display(\n\u001b[0;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2091\u001b[1;33m                     **kwargs)\n\u001b[0m\u001b[0;32m   2092\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2093\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1709\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2647\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1203\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m-> 1205\u001b[1;33m                                                                 renderer)\n\u001b[0m\u001b[0;32m   1206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[1;32m-> 1150\u001b[1;33m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[0;32m   1151\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m   1152\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[1;32m-> 1150\u001b[1;33m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[0;32m   1151\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[0;32m   1152\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    891\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;31m# get the rotation matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate_deg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;31m# now offset the individual text lines within the box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mrotate_deg\u001b[1;34m(self, degrees)\u001b[0m\n\u001b[0;32m   1936\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1937\u001b[0m         \"\"\"\n\u001b[1;32m-> 1938\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeg2rad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrotate_around\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dato\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mrotate\u001b[1;34m(self, theta)\u001b[0m\n\u001b[0;32m   1924\u001b[0m         rotate_mtx = np.array([[a, -b, 0.0], [b, a, 0.0], [0.0, 0.0, 1.0]],\n\u001b[0;32m   1925\u001b[0m                               float)\n\u001b[1;32m-> 1926\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotate_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1927\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "Q0zdqdxIP4aN",
    "colab_type": "code",
    "colab": {},
    "outputId": "053ee633-559c-4a40-c398-2ad54904ad81"
   },
   "source": [
    "#los rangos se van afinando segun corren las pruevas\n",
    "def busqueda_de_hiperparametros_optimos_ramdom_forest_busqueda_binaria():\n",
    "    parametrosRFRandom_state = list(range(4,7,1))\n",
    "    parametrosRFn_estimators = list(range(40,51,1))\n",
    "    parametrosRFmax_features = list(range(4,7,1))\n",
    "    parametrosRFmax_depth = list(range(1,51,2))\n",
    "    parametrosRFmin_samples_split = list(range(1,31,1))\n",
    "    listaDeParametros = [parametrosRFRandom_state,parametrosRFn_estimators,\n",
    "                         parametrosRFmax_features,parametrosRFmax_depth,\n",
    "                         parametrosRFmin_samples_split]\n",
    "    maximo,parametros =busqueda_binaria_de_maximos(listaDeParametros,\n",
    "                                                   [0,0,0,0,0],\n",
    "                                                   0,\n",
    "                                                   ultimo_Hiper_Parametro_Ramdom_forest)\n",
    "    print(\"maximo {} parametros (iter,learning,profundidad,profundidad,samplesplit) {}\".format(maximo,parametros))\n",
    "busqueda_de_hiperparametros_optimos_ramdom_forest_busqueda_binaria()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[4, 40, 4, 1, 1]\n",
      "[4, 40, 4, 1, 29]\n",
      "[4, 40, 4, 1, 15]\n",
      "[4, 40, 4, 1, 21]\n",
      "[4, 40, 4, 1, 25]\n",
      "[4, 40, 4, 1, 27]\n",
      "[4, 40, 4, 49, 1]\n",
      "[4, 40, 4, 49, 29]\n",
      "[4, 40, 4, 49, 15]\n",
      "[4, 40, 4, 49, 21]\n",
      "[4, 40, 4, 49, 25]\n",
      "[4, 40, 4, 49, 27]\n",
      "[4, 40, 4, 25, 1]\n",
      "[4, 40, 4, 25, 29]\n",
      "[4, 40, 4, 25, 15]\n",
      "[4, 40, 4, 25, 21]\n",
      "[4, 40, 4, 25, 25]\n",
      "[4, 40, 4, 25, 27]\n",
      "[4, 40, 4, 37, 1]\n",
      "[4, 40, 4, 37, 29]\n",
      "[4, 40, 4, 37, 15]\n",
      "[4, 40, 4, 37, 21]\n",
      "[4, 40, 4, 37, 25]\n",
      "[4, 40, 4, 37, 27]\n",
      "[4, 40, 4, 43, 1]\n",
      "[4, 40, 4, 43, 29]\n",
      "[4, 40, 4, 43, 15]\n",
      "[4, 40, 4, 43, 21]\n",
      "[4, 40, 4, 43, 25]\n",
      "[4, 40, 4, 43, 27]\n",
      "[4, 40, 4, 45, 1]\n",
      "[4, 40, 4, 45, 29]\n",
      "[4, 40, 4, 45, 15]\n",
      "[4, 40, 4, 45, 21]\n",
      "[4, 40, 4, 45, 25]\n",
      "[4, 40, 4, 45, 27]\n",
      "[4, 40, 4, 47, 1]\n",
      "[4, 40, 4, 47, 29]\n",
      "[4, 40, 4, 47, 15]\n",
      "[4, 40, 4, 47, 21]\n",
      "[4, 40, 4, 47, 25]\n",
      "[4, 40, 4, 47, 27]\n",
      "[4, 40, 6, 1, 1]\n",
      "[4, 40, 6, 1, 29]\n",
      "[4, 40, 6, 1, 15]\n",
      "[4, 40, 6, 1, 21]\n",
      "[4, 40, 6, 1, 25]\n",
      "[4, 40, 6, 1, 27]\n",
      "[4, 40, 6, 49, 1]\n",
      "[4, 40, 6, 49, 29]\n",
      "[4, 40, 6, 49, 15]\n",
      "[4, 40, 6, 49, 21]\n",
      "[4, 40, 6, 49, 25]\n",
      "[4, 40, 6, 49, 27]\n",
      "[4, 40, 6, 25, 1]\n",
      "[4, 40, 6, 25, 29]\n",
      "[4, 40, 6, 25, 15]\n",
      "[4, 40, 6, 25, 21]\n",
      "[4, 40, 6, 25, 25]\n",
      "[4, 40, 6, 25, 27]\n",
      "[4, 40, 6, 37, 1]\n",
      "[4, 40, 6, 37, 29]\n",
      "[4, 40, 6, 37, 15]\n",
      "[4, 40, 6, 37, 21]\n",
      "[4, 40, 6, 37, 25]\n",
      "[4, 40, 6, 37, 27]\n",
      "[4, 40, 6, 43, 1]\n",
      "[4, 40, 6, 43, 29]\n",
      "[4, 40, 6, 43, 15]\n",
      "[4, 40, 6, 43, 21]\n",
      "[4, 40, 6, 43, 25]\n",
      "[4, 40, 6, 43, 27]\n",
      "[4, 40, 6, 45, 1]\n",
      "[4, 40, 6, 45, 29]\n",
      "[4, 40, 6, 45, 15]\n",
      "[4, 40, 6, 45, 21]\n",
      "[4, 40, 6, 45, 25]\n",
      "[4, 40, 6, 45, 27]\n",
      "[4, 40, 6, 47, 1]\n",
      "[4, 40, 6, 47, 29]\n",
      "[4, 40, 6, 47, 15]\n",
      "[4, 40, 6, 47, 21]\n",
      "[4, 40, 6, 47, 25]\n",
      "[4, 40, 6, 47, 27]\n",
      "[4, 50, 4, 1, 1]\n",
      "[4, 50, 4, 1, 29]\n",
      "[4, 50, 4, 1, 15]\n",
      "[4, 50, 4, 1, 21]\n",
      "[4, 50, 4, 1, 25]\n",
      "[4, 50, 4, 1, 27]\n",
      "[4, 50, 4, 49, 1]\n",
      "[4, 50, 4, 49, 29]\n",
      "[4, 50, 4, 49, 15]\n",
      "[4, 50, 4, 49, 21]\n",
      "[4, 50, 4, 49, 25]\n",
      "[4, 50, 4, 49, 27]\n",
      "[4, 50, 4, 25, 1]\n",
      "[4, 50, 4, 25, 29]\n",
      "[4, 50, 4, 25, 15]\n",
      "[4, 50, 4, 25, 21]\n",
      "[4, 50, 4, 25, 25]\n",
      "[4, 50, 4, 25, 27]\n",
      "[4, 50, 4, 37, 1]\n",
      "[4, 50, 4, 37, 29]\n",
      "[4, 50, 4, 37, 15]\n",
      "[4, 50, 4, 37, 21]\n",
      "[4, 50, 4, 37, 25]\n",
      "[4, 50, 4, 37, 27]\n",
      "[4, 50, 4, 43, 1]\n",
      "[4, 50, 4, 43, 29]\n",
      "[4, 50, 4, 43, 15]\n",
      "[4, 50, 4, 43, 21]\n",
      "[4, 50, 4, 43, 25]\n",
      "[4, 50, 4, 43, 27]\n",
      "[4, 50, 4, 45, 1]\n",
      "[4, 50, 4, 45, 29]\n",
      "[4, 50, 4, 45, 15]\n",
      "[4, 50, 4, 45, 21]\n",
      "[4, 50, 4, 45, 25]\n",
      "[4, 50, 4, 45, 27]\n",
      "[4, 50, 4, 47, 1]\n",
      "[4, 50, 4, 47, 29]\n",
      "[4, 50, 4, 47, 15]\n",
      "[4, 50, 4, 47, 21]\n",
      "[4, 50, 4, 47, 25]\n",
      "[4, 50, 4, 47, 27]\n",
      "[4, 50, 6, 1, 1]\n",
      "[4, 50, 6, 1, 29]\n",
      "[4, 50, 6, 1, 15]\n",
      "[4, 50, 6, 1, 21]\n",
      "[4, 50, 6, 1, 25]\n",
      "[4, 50, 6, 1, 27]\n",
      "[4, 50, 6, 49, 1]\n",
      "[4, 50, 6, 49, 29]\n",
      "[4, 50, 6, 49, 15]\n",
      "[4, 50, 6, 49, 21]\n",
      "[4, 50, 6, 49, 25]\n",
      "[4, 50, 6, 49, 27]\n",
      "[4, 50, 6, 25, 1]\n",
      "[4, 50, 6, 25, 29]\n",
      "[4, 50, 6, 25, 15]\n",
      "[4, 50, 6, 25, 21]\n",
      "[4, 50, 6, 25, 25]\n",
      "[4, 50, 6, 25, 27]\n",
      "[4, 50, 6, 37, 1]\n",
      "[4, 50, 6, 37, 29]\n",
      "[4, 50, 6, 37, 15]\n",
      "[4, 50, 6, 37, 21]\n",
      "[4, 50, 6, 37, 25]\n",
      "[4, 50, 6, 37, 27]\n",
      "[4, 50, 6, 43, 1]\n",
      "[4, 50, 6, 43, 29]\n",
      "[4, 50, 6, 43, 15]\n",
      "[4, 50, 6, 43, 21]\n",
      "[4, 50, 6, 43, 25]\n",
      "[4, 50, 6, 43, 27]\n",
      "[4, 50, 6, 45, 1]\n",
      "[4, 50, 6, 45, 29]\n",
      "[4, 50, 6, 45, 15]\n",
      "[4, 50, 6, 45, 21]\n",
      "[4, 50, 6, 45, 25]\n",
      "[4, 50, 6, 45, 27]\n",
      "[4, 50, 6, 47, 1]\n",
      "[4, 50, 6, 47, 29]\n",
      "[4, 50, 6, 47, 15]\n",
      "[4, 50, 6, 47, 21]\n",
      "[4, 50, 6, 47, 25]\n",
      "[4, 50, 6, 47, 27]\n",
      "[4, 45, 4, 1, 1]\n",
      "[4, 45, 4, 1, 29]\n",
      "[4, 45, 4, 1, 15]\n",
      "[4, 45, 4, 1, 21]\n",
      "[4, 45, 4, 1, 25]\n",
      "[4, 45, 4, 1, 27]\n",
      "[4, 45, 4, 49, 1]\n",
      "[4, 45, 4, 49, 29]\n",
      "[4, 45, 4, 49, 15]\n",
      "[4, 45, 4, 49, 21]\n",
      "[4, 45, 4, 49, 25]\n",
      "[4, 45, 4, 49, 27]\n",
      "[4, 45, 4, 25, 1]\n",
      "[4, 45, 4, 25, 29]\n",
      "[4, 45, 4, 25, 15]\n",
      "[4, 45, 4, 25, 21]\n",
      "[4, 45, 4, 25, 25]\n",
      "[4, 45, 4, 25, 27]\n",
      "[4, 45, 4, 37, 1]\n",
      "[4, 45, 4, 37, 29]\n",
      "[4, 45, 4, 37, 15]\n",
      "[4, 45, 4, 37, 21]\n",
      "[4, 45, 4, 37, 25]\n",
      "[4, 45, 4, 37, 27]\n",
      "[4, 45, 4, 43, 1]\n",
      "[4, 45, 4, 43, 29]\n",
      "[4, 45, 4, 43, 15]\n",
      "[4, 45, 4, 43, 21]\n",
      "[4, 45, 4, 43, 25]\n",
      "[4, 45, 4, 43, 27]\n",
      "[4, 45, 4, 45, 1]\n",
      "[4, 45, 4, 45, 29]\n",
      "[4, 45, 4, 45, 15]\n",
      "[4, 45, 4, 45, 21]\n",
      "[4, 45, 4, 45, 25]\n",
      "[4, 45, 4, 45, 27]\n",
      "[4, 45, 4, 47, 1]\n",
      "[4, 45, 4, 47, 29]\n",
      "[4, 45, 4, 47, 15]\n",
      "[4, 45, 4, 47, 21]\n",
      "[4, 45, 4, 47, 25]\n",
      "[4, 45, 4, 47, 27]\n",
      "[4, 45, 6, 1, 1]\n",
      "[4, 45, 6, 1, 29]\n",
      "[4, 45, 6, 1, 15]\n",
      "[4, 45, 6, 1, 21]\n",
      "[4, 45, 6, 1, 25]\n",
      "[4, 45, 6, 1, 27]\n",
      "[4, 45, 6, 49, 1]\n",
      "[4, 45, 6, 49, 29]\n",
      "[4, 45, 6, 49, 15]\n",
      "[4, 45, 6, 49, 21]\n",
      "[4, 45, 6, 49, 25]\n",
      "[4, 45, 6, 49, 27]\n",
      "[4, 45, 6, 25, 1]\n",
      "[4, 45, 6, 25, 29]\n",
      "[4, 45, 6, 25, 15]\n",
      "[4, 45, 6, 25, 21]\n",
      "[4, 45, 6, 25, 25]\n",
      "[4, 45, 6, 25, 27]\n",
      "[4, 45, 6, 37, 1]\n",
      "[4, 45, 6, 37, 29]\n",
      "[4, 45, 6, 37, 15]\n",
      "[4, 45, 6, 37, 21]\n",
      "[4, 45, 6, 37, 25]\n",
      "[4, 45, 6, 37, 27]\n",
      "[4, 45, 6, 43, 1]\n",
      "[4, 45, 6, 43, 29]\n",
      "[4, 45, 6, 43, 15]\n",
      "[4, 45, 6, 43, 21]\n",
      "[4, 45, 6, 43, 25]\n",
      "[4, 45, 6, 43, 27]\n",
      "[4, 45, 6, 45, 1]\n",
      "[4, 45, 6, 45, 29]\n",
      "[4, 45, 6, 45, 15]\n",
      "[4, 45, 6, 45, 21]\n",
      "[4, 45, 6, 45, 25]\n",
      "[4, 45, 6, 45, 27]\n",
      "[4, 45, 6, 47, 1]\n",
      "[4, 45, 6, 47, 29]\n",
      "[4, 45, 6, 47, 15]\n",
      "[4, 45, 6, 47, 21]\n",
      "[4, 45, 6, 47, 25]\n",
      "[4, 45, 6, 47, 27]\n",
      "[4, 47, 4, 1, 1]\n",
      "[4, 47, 4, 1, 29]\n",
      "[4, 47, 4, 1, 15]\n",
      "[4, 47, 4, 1, 21]\n",
      "[4, 47, 4, 1, 25]\n",
      "[4, 47, 4, 1, 27]\n",
      "[4, 47, 4, 49, 1]\n",
      "[4, 47, 4, 49, 29]\n",
      "[4, 47, 4, 49, 15]\n",
      "[4, 47, 4, 49, 21]\n",
      "[4, 47, 4, 49, 25]\n",
      "[4, 47, 4, 49, 27]\n",
      "[4, 47, 4, 25, 1]\n",
      "[4, 47, 4, 25, 29]\n",
      "[4, 47, 4, 25, 15]\n",
      "[4, 47, 4, 25, 21]\n",
      "[4, 47, 4, 25, 25]\n",
      "[4, 47, 4, 25, 27]\n",
      "[4, 47, 4, 37, 1]\n",
      "[4, 47, 4, 37, 29]\n",
      "[4, 47, 4, 37, 15]\n",
      "[4, 47, 4, 37, 21]\n",
      "[4, 47, 4, 37, 25]\n",
      "[4, 47, 4, 37, 27]\n",
      "[4, 47, 4, 43, 1]\n",
      "[4, 47, 4, 43, 29]\n",
      "[4, 47, 4, 43, 15]\n",
      "[4, 47, 4, 43, 21]\n",
      "[4, 47, 4, 43, 25]\n",
      "[4, 47, 4, 43, 27]\n",
      "[4, 47, 4, 45, 1]\n",
      "[4, 47, 4, 45, 29]\n",
      "[4, 47, 4, 45, 15]\n",
      "[4, 47, 4, 45, 21]\n",
      "[4, 47, 4, 45, 25]\n",
      "[4, 47, 4, 45, 27]\n",
      "[4, 47, 4, 47, 1]\n",
      "[4, 47, 4, 47, 29]\n",
      "[4, 47, 4, 47, 15]\n",
      "[4, 47, 4, 47, 21]\n",
      "[4, 47, 4, 47, 25]\n",
      "[4, 47, 4, 47, 27]\n",
      "[4, 47, 6, 1, 1]\n",
      "[4, 47, 6, 1, 29]\n",
      "[4, 47, 6, 1, 15]\n",
      "[4, 47, 6, 1, 21]\n",
      "[4, 47, 6, 1, 25]\n",
      "[4, 47, 6, 1, 27]\n",
      "[4, 47, 6, 49, 1]\n",
      "[4, 47, 6, 49, 29]\n",
      "[4, 47, 6, 49, 15]\n",
      "[4, 47, 6, 49, 21]\n",
      "[4, 47, 6, 49, 25]\n",
      "[4, 47, 6, 49, 27]\n",
      "[4, 47, 6, 25, 1]\n",
      "[4, 47, 6, 25, 29]\n",
      "[4, 47, 6, 25, 15]\n",
      "[4, 47, 6, 25, 21]\n",
      "[4, 47, 6, 25, 25]\n",
      "[4, 47, 6, 25, 27]\n",
      "[4, 47, 6, 37, 1]\n",
      "[4, 47, 6, 37, 29]\n",
      "[4, 47, 6, 37, 15]\n",
      "[4, 47, 6, 37, 21]\n",
      "[4, 47, 6, 37, 25]\n",
      "[4, 47, 6, 37, 27]\n",
      "[4, 47, 6, 43, 1]\n",
      "[4, 47, 6, 43, 29]\n",
      "[4, 47, 6, 43, 15]\n",
      "[4, 47, 6, 43, 21]\n",
      "[4, 47, 6, 43, 25]\n",
      "[4, 47, 6, 43, 27]\n",
      "[4, 47, 6, 45, 1]\n",
      "[4, 47, 6, 45, 29]\n",
      "[4, 47, 6, 45, 15]\n",
      "[4, 47, 6, 45, 21]\n",
      "[4, 47, 6, 45, 25]\n",
      "[4, 47, 6, 45, 27]\n",
      "[4, 47, 6, 47, 1]\n",
      "[4, 47, 6, 47, 29]\n",
      "[4, 47, 6, 47, 15]\n",
      "[4, 47, 6, 47, 21]\n",
      "[4, 47, 6, 47, 25]\n",
      "[4, 47, 6, 47, 27]\n",
      "[4, 46, 4, 1, 1]\n",
      "[4, 46, 4, 1, 29]\n",
      "[4, 46, 4, 1, 15]\n",
      "[4, 46, 4, 1, 21]\n",
      "[4, 46, 4, 1, 25]\n",
      "[4, 46, 4, 1, 27]\n",
      "[4, 46, 4, 49, 1]\n",
      "[4, 46, 4, 49, 29]\n",
      "[4, 46, 4, 49, 15]\n",
      "[4, 46, 4, 49, 21]\n",
      "[4, 46, 4, 49, 25]\n",
      "[4, 46, 4, 49, 27]\n",
      "[4, 46, 4, 25, 1]\n",
      "[4, 46, 4, 25, 29]\n",
      "[4, 46, 4, 25, 15]\n",
      "[4, 46, 4, 25, 21]\n",
      "[4, 46, 4, 25, 25]\n",
      "[4, 46, 4, 25, 27]\n",
      "[4, 46, 4, 37, 1]\n",
      "[4, 46, 4, 37, 29]\n",
      "[4, 46, 4, 37, 15]\n",
      "[4, 46, 4, 37, 21]\n",
      "[4, 46, 4, 37, 25]\n",
      "[4, 46, 4, 37, 27]\n",
      "[4, 46, 4, 43, 1]\n",
      "[4, 46, 4, 43, 29]\n",
      "[4, 46, 4, 43, 15]\n",
      "[4, 46, 4, 43, 21]\n",
      "[4, 46, 4, 43, 25]\n",
      "[4, 46, 4, 43, 27]\n",
      "[4, 46, 4, 45, 1]\n",
      "[4, 46, 4, 45, 29]\n",
      "[4, 46, 4, 45, 15]\n",
      "[4, 46, 4, 45, 21]\n",
      "[4, 46, 4, 45, 25]\n",
      "[4, 46, 4, 45, 27]\n",
      "[4, 46, 4, 47, 1]\n",
      "[4, 46, 4, 47, 29]\n",
      "[4, 46, 4, 47, 15]\n",
      "[4, 46, 4, 47, 21]\n",
      "[4, 46, 4, 47, 25]\n",
      "[4, 46, 4, 47, 27]\n",
      "[4, 46, 6, 1, 1]\n",
      "[4, 46, 6, 1, 29]\n",
      "[4, 46, 6, 1, 15]\n",
      "[4, 46, 6, 1, 21]\n",
      "[4, 46, 6, 1, 25]\n",
      "[4, 46, 6, 1, 27]\n",
      "[4, 46, 6, 49, 1]\n",
      "[4, 46, 6, 49, 29]\n",
      "[4, 46, 6, 49, 15]\n",
      "[4, 46, 6, 49, 21]\n",
      "[4, 46, 6, 49, 25]\n",
      "[4, 46, 6, 49, 27]\n",
      "[4, 46, 6, 25, 1]\n",
      "[4, 46, 6, 25, 29]\n",
      "[4, 46, 6, 25, 15]\n",
      "[4, 46, 6, 25, 21]\n",
      "[4, 46, 6, 25, 25]\n",
      "[4, 46, 6, 25, 27]\n",
      "[4, 46, 6, 37, 1]\n",
      "[4, 46, 6, 37, 29]\n",
      "[4, 46, 6, 37, 15]\n",
      "[4, 46, 6, 37, 21]\n",
      "[4, 46, 6, 37, 25]\n",
      "[4, 46, 6, 37, 27]\n",
      "[4, 46, 6, 43, 1]\n",
      "[4, 46, 6, 43, 29]\n",
      "[4, 46, 6, 43, 15]\n",
      "[4, 46, 6, 43, 21]\n",
      "[4, 46, 6, 43, 25]\n",
      "[4, 46, 6, 43, 27]\n",
      "[4, 46, 6, 45, 1]\n",
      "[4, 46, 6, 45, 29]\n",
      "[4, 46, 6, 45, 15]\n",
      "[4, 46, 6, 45, 21]\n",
      "[4, 46, 6, 45, 25]\n",
      "[4, 46, 6, 45, 27]\n",
      "[4, 46, 6, 47, 1]\n",
      "[4, 46, 6, 47, 29]\n",
      "[4, 46, 6, 47, 15]\n",
      "[4, 46, 6, 47, 21]\n",
      "[4, 46, 6, 47, 25]\n",
      "[4, 46, 6, 47, 27]\n",
      "[6, 40, 4, 1, 1]\n",
      "[6, 40, 4, 1, 29]\n",
      "[6, 40, 4, 1, 15]\n",
      "[6, 40, 4, 1, 21]\n",
      "[6, 40, 4, 1, 25]\n",
      "[6, 40, 4, 1, 27]\n",
      "[6, 40, 4, 49, 1]\n",
      "[6, 40, 4, 49, 29]\n",
      "[6, 40, 4, 49, 15]\n",
      "[6, 40, 4, 49, 21]\n",
      "[6, 40, 4, 49, 25]\n",
      "[6, 40, 4, 49, 27]\n",
      "[6, 40, 4, 25, 1]\n",
      "[6, 40, 4, 25, 29]\n",
      "[6, 40, 4, 25, 15]\n",
      "[6, 40, 4, 25, 21]\n",
      "[6, 40, 4, 25, 25]\n",
      "[6, 40, 4, 25, 27]\n",
      "[6, 40, 4, 37, 1]\n",
      "[6, 40, 4, 37, 29]\n",
      "[6, 40, 4, 37, 15]\n",
      "[6, 40, 4, 37, 21]\n",
      "[6, 40, 4, 37, 25]\n",
      "[6, 40, 4, 37, 27]\n",
      "[6, 40, 4, 43, 1]\n",
      "[6, 40, 4, 43, 29]\n",
      "[6, 40, 4, 43, 15]\n",
      "[6, 40, 4, 43, 21]\n",
      "[6, 40, 4, 43, 25]\n",
      "[6, 40, 4, 43, 27]\n",
      "[6, 40, 4, 45, 1]\n",
      "[6, 40, 4, 45, 29]\n",
      "[6, 40, 4, 45, 15]\n",
      "[6, 40, 4, 45, 21]\n",
      "[6, 40, 4, 45, 25]\n",
      "[6, 40, 4, 45, 27]\n",
      "[6, 40, 4, 47, 1]\n",
      "[6, 40, 4, 47, 29]\n",
      "[6, 40, 4, 47, 15]\n",
      "[6, 40, 4, 47, 21]\n",
      "[6, 40, 4, 47, 25]\n",
      "[6, 40, 4, 47, 27]\n",
      "[6, 40, 6, 1, 1]\n",
      "[6, 40, 6, 1, 29]\n",
      "[6, 40, 6, 1, 15]\n",
      "[6, 40, 6, 1, 21]\n",
      "[6, 40, 6, 1, 25]\n",
      "[6, 40, 6, 1, 27]\n",
      "[6, 40, 6, 49, 1]\n",
      "[6, 40, 6, 49, 29]\n",
      "[6, 40, 6, 49, 15]\n",
      "[6, 40, 6, 49, 21]\n",
      "[6, 40, 6, 49, 25]\n",
      "[6, 40, 6, 49, 27]\n",
      "[6, 40, 6, 25, 1]\n",
      "[6, 40, 6, 25, 29]\n",
      "[6, 40, 6, 25, 15]\n",
      "[6, 40, 6, 25, 21]\n",
      "[6, 40, 6, 25, 25]\n",
      "[6, 40, 6, 25, 27]\n",
      "[6, 40, 6, 37, 1]\n",
      "[6, 40, 6, 37, 29]\n",
      "[6, 40, 6, 37, 15]\n",
      "[6, 40, 6, 37, 21]\n",
      "[6, 40, 6, 37, 25]\n",
      "[6, 40, 6, 37, 27]\n",
      "[6, 40, 6, 43, 1]\n",
      "[6, 40, 6, 43, 29]\n",
      "[6, 40, 6, 43, 15]\n",
      "[6, 40, 6, 43, 21]\n",
      "[6, 40, 6, 43, 25]\n",
      "[6, 40, 6, 43, 27]\n",
      "[6, 40, 6, 45, 1]\n",
      "[6, 40, 6, 45, 29]\n",
      "[6, 40, 6, 45, 15]\n",
      "[6, 40, 6, 45, 21]\n",
      "[6, 40, 6, 45, 25]\n",
      "[6, 40, 6, 45, 27]\n",
      "[6, 40, 6, 47, 1]\n",
      "[6, 40, 6, 47, 29]\n",
      "[6, 40, 6, 47, 15]\n",
      "[6, 40, 6, 47, 21]\n",
      "[6, 40, 6, 47, 25]\n",
      "[6, 40, 6, 47, 27]\n",
      "[6, 50, 4, 1, 1]\n",
      "[6, 50, 4, 1, 29]\n",
      "[6, 50, 4, 1, 15]\n",
      "[6, 50, 4, 1, 21]\n",
      "[6, 50, 4, 1, 25]\n",
      "[6, 50, 4, 1, 27]\n",
      "[6, 50, 4, 49, 1]\n",
      "[6, 50, 4, 49, 29]\n",
      "[6, 50, 4, 49, 15]\n",
      "[6, 50, 4, 49, 21]\n",
      "[6, 50, 4, 49, 25]\n",
      "[6, 50, 4, 49, 27]\n",
      "[6, 50, 4, 25, 1]\n",
      "[6, 50, 4, 25, 29]\n",
      "[6, 50, 4, 25, 15]\n",
      "[6, 50, 4, 25, 21]\n",
      "[6, 50, 4, 25, 25]\n",
      "[6, 50, 4, 25, 27]\n",
      "[6, 50, 4, 37, 1]\n",
      "[6, 50, 4, 37, 29]\n",
      "[6, 50, 4, 37, 15]\n",
      "[6, 50, 4, 37, 21]\n",
      "[6, 50, 4, 37, 25]\n",
      "[6, 50, 4, 37, 27]\n",
      "[6, 50, 4, 43, 1]\n",
      "[6, 50, 4, 43, 29]\n",
      "[6, 50, 4, 43, 15]\n",
      "[6, 50, 4, 43, 21]\n",
      "[6, 50, 4, 43, 25]\n",
      "[6, 50, 4, 43, 27]\n",
      "[6, 50, 4, 45, 1]\n",
      "[6, 50, 4, 45, 29]\n",
      "[6, 50, 4, 45, 15]\n",
      "[6, 50, 4, 45, 21]\n",
      "[6, 50, 4, 45, 25]\n",
      "[6, 50, 4, 45, 27]\n",
      "[6, 50, 4, 47, 1]\n",
      "[6, 50, 4, 47, 29]\n",
      "[6, 50, 4, 47, 15]\n",
      "[6, 50, 4, 47, 21]\n",
      "[6, 50, 4, 47, 25]\n",
      "[6, 50, 4, 47, 27]\n",
      "[6, 50, 6, 1, 1]\n",
      "[6, 50, 6, 1, 29]\n",
      "[6, 50, 6, 1, 15]\n",
      "[6, 50, 6, 1, 21]\n",
      "[6, 50, 6, 1, 25]\n",
      "[6, 50, 6, 1, 27]\n",
      "[6, 50, 6, 49, 1]\n",
      "[6, 50, 6, 49, 29]\n",
      "[6, 50, 6, 49, 15]\n",
      "[6, 50, 6, 49, 21]\n",
      "[6, 50, 6, 49, 25]\n",
      "[6, 50, 6, 49, 27]\n",
      "[6, 50, 6, 25, 1]\n",
      "[6, 50, 6, 25, 29]\n",
      "[6, 50, 6, 25, 15]\n",
      "[6, 50, 6, 25, 21]\n",
      "[6, 50, 6, 25, 25]\n",
      "[6, 50, 6, 25, 27]\n",
      "[6, 50, 6, 37, 1]\n",
      "[6, 50, 6, 37, 29]\n",
      "[6, 50, 6, 37, 15]\n",
      "[6, 50, 6, 37, 21]\n",
      "[6, 50, 6, 37, 25]\n",
      "[6, 50, 6, 37, 27]\n",
      "[6, 50, 6, 43, 1]\n",
      "[6, 50, 6, 43, 29]\n",
      "[6, 50, 6, 43, 15]\n",
      "[6, 50, 6, 43, 21]\n",
      "[6, 50, 6, 43, 25]\n",
      "[6, 50, 6, 43, 27]\n",
      "[6, 50, 6, 45, 1]\n",
      "[6, 50, 6, 45, 29]\n",
      "[6, 50, 6, 45, 15]\n",
      "[6, 50, 6, 45, 21]\n",
      "[6, 50, 6, 45, 25]\n",
      "[6, 50, 6, 45, 27]\n",
      "[6, 50, 6, 47, 1]\n",
      "[6, 50, 6, 47, 29]\n",
      "[6, 50, 6, 47, 15]\n",
      "[6, 50, 6, 47, 21]\n",
      "[6, 50, 6, 47, 25]\n",
      "[6, 50, 6, 47, 27]\n",
      "[6, 45, 4, 1, 1]\n",
      "[6, 45, 4, 1, 29]\n",
      "[6, 45, 4, 1, 15]\n",
      "[6, 45, 4, 1, 21]\n",
      "[6, 45, 4, 1, 25]\n",
      "[6, 45, 4, 1, 27]\n",
      "[6, 45, 4, 49, 1]\n",
      "[6, 45, 4, 49, 29]\n",
      "[6, 45, 4, 49, 15]\n",
      "[6, 45, 4, 49, 21]\n",
      "[6, 45, 4, 49, 25]\n",
      "[6, 45, 4, 49, 27]\n",
      "[6, 45, 4, 25, 1]\n",
      "[6, 45, 4, 25, 29]\n",
      "[6, 45, 4, 25, 15]\n",
      "[6, 45, 4, 25, 21]\n",
      "[6, 45, 4, 25, 25]\n",
      "[6, 45, 4, 25, 27]\n",
      "[6, 45, 4, 37, 1]\n",
      "[6, 45, 4, 37, 29]\n",
      "[6, 45, 4, 37, 15]\n",
      "[6, 45, 4, 37, 21]\n",
      "[6, 45, 4, 37, 25]\n",
      "[6, 45, 4, 37, 27]\n",
      "[6, 45, 4, 43, 1]\n",
      "[6, 45, 4, 43, 29]\n",
      "[6, 45, 4, 43, 15]\n",
      "[6, 45, 4, 43, 21]\n",
      "[6, 45, 4, 43, 25]\n",
      "[6, 45, 4, 43, 27]\n",
      "[6, 45, 4, 45, 1]\n",
      "[6, 45, 4, 45, 29]\n",
      "[6, 45, 4, 45, 15]\n",
      "[6, 45, 4, 45, 21]\n",
      "[6, 45, 4, 45, 25]\n",
      "[6, 45, 4, 45, 27]\n",
      "[6, 45, 4, 47, 1]\n",
      "[6, 45, 4, 47, 29]\n",
      "[6, 45, 4, 47, 15]\n",
      "[6, 45, 4, 47, 21]\n",
      "[6, 45, 4, 47, 25]\n",
      "[6, 45, 4, 47, 27]\n",
      "[6, 45, 6, 1, 1]\n",
      "[6, 45, 6, 1, 29]\n",
      "[6, 45, 6, 1, 15]\n",
      "[6, 45, 6, 1, 21]\n",
      "[6, 45, 6, 1, 25]\n",
      "[6, 45, 6, 1, 27]\n",
      "[6, 45, 6, 49, 1]\n",
      "[6, 45, 6, 49, 29]\n",
      "[6, 45, 6, 49, 15]\n",
      "[6, 45, 6, 49, 21]\n",
      "[6, 45, 6, 49, 25]\n",
      "[6, 45, 6, 49, 27]\n",
      "[6, 45, 6, 25, 1]\n",
      "[6, 45, 6, 25, 29]\n",
      "[6, 45, 6, 25, 15]\n",
      "[6, 45, 6, 25, 21]\n",
      "[6, 45, 6, 25, 25]\n",
      "[6, 45, 6, 25, 27]\n",
      "[6, 45, 6, 37, 1]\n",
      "[6, 45, 6, 37, 29]\n",
      "[6, 45, 6, 37, 15]\n",
      "[6, 45, 6, 37, 21]\n",
      "[6, 45, 6, 37, 25]\n",
      "[6, 45, 6, 37, 27]\n",
      "[6, 45, 6, 43, 1]\n",
      "[6, 45, 6, 43, 29]\n",
      "[6, 45, 6, 43, 15]\n",
      "[6, 45, 6, 43, 21]\n",
      "[6, 45, 6, 43, 25]\n",
      "[6, 45, 6, 43, 27]\n",
      "[6, 45, 6, 45, 1]\n",
      "[6, 45, 6, 45, 29]\n",
      "[6, 45, 6, 45, 15]\n",
      "[6, 45, 6, 45, 21]\n",
      "[6, 45, 6, 45, 25]\n",
      "[6, 45, 6, 45, 27]\n",
      "[6, 45, 6, 47, 1]\n",
      "[6, 45, 6, 47, 29]\n",
      "[6, 45, 6, 47, 15]\n",
      "[6, 45, 6, 47, 21]\n",
      "[6, 45, 6, 47, 25]\n",
      "[6, 45, 6, 47, 27]\n",
      "[6, 47, 4, 1, 1]\n",
      "[6, 47, 4, 1, 29]\n",
      "[6, 47, 4, 1, 15]\n",
      "[6, 47, 4, 1, 21]\n",
      "[6, 47, 4, 1, 25]\n",
      "[6, 47, 4, 1, 27]\n",
      "[6, 47, 4, 49, 1]\n",
      "[6, 47, 4, 49, 29]\n",
      "[6, 47, 4, 49, 15]\n",
      "[6, 47, 4, 49, 21]\n",
      "[6, 47, 4, 49, 25]\n",
      "[6, 47, 4, 49, 27]\n",
      "[6, 47, 4, 25, 1]\n",
      "[6, 47, 4, 25, 29]\n",
      "[6, 47, 4, 25, 15]\n",
      "[6, 47, 4, 25, 21]\n",
      "[6, 47, 4, 25, 25]\n",
      "[6, 47, 4, 25, 27]\n",
      "[6, 47, 4, 37, 1]\n",
      "[6, 47, 4, 37, 29]\n",
      "[6, 47, 4, 37, 15]\n",
      "[6, 47, 4, 37, 21]\n",
      "[6, 47, 4, 37, 25]\n",
      "[6, 47, 4, 37, 27]\n",
      "[6, 47, 4, 43, 1]\n",
      "[6, 47, 4, 43, 29]\n",
      "[6, 47, 4, 43, 15]\n",
      "[6, 47, 4, 43, 21]\n",
      "[6, 47, 4, 43, 25]\n",
      "[6, 47, 4, 43, 27]\n",
      "[6, 47, 4, 45, 1]\n",
      "[6, 47, 4, 45, 29]\n",
      "[6, 47, 4, 45, 15]\n",
      "[6, 47, 4, 45, 21]\n",
      "[6, 47, 4, 45, 25]\n",
      "[6, 47, 4, 45, 27]\n",
      "[6, 47, 4, 47, 1]\n",
      "[6, 47, 4, 47, 29]\n",
      "[6, 47, 4, 47, 15]\n",
      "[6, 47, 4, 47, 21]\n",
      "[6, 47, 4, 47, 25]\n",
      "[6, 47, 4, 47, 27]\n",
      "[6, 47, 6, 1, 1]\n",
      "[6, 47, 6, 1, 29]\n",
      "[6, 47, 6, 1, 15]\n",
      "[6, 47, 6, 1, 21]\n",
      "[6, 47, 6, 1, 25]\n",
      "[6, 47, 6, 1, 27]\n",
      "[6, 47, 6, 49, 1]\n",
      "[6, 47, 6, 49, 29]\n",
      "[6, 47, 6, 49, 15]\n",
      "[6, 47, 6, 49, 21]\n",
      "[6, 47, 6, 49, 25]\n",
      "[6, 47, 6, 49, 27]\n",
      "[6, 47, 6, 25, 1]\n",
      "[6, 47, 6, 25, 29]\n",
      "[6, 47, 6, 25, 15]\n",
      "[6, 47, 6, 25, 21]\n",
      "[6, 47, 6, 25, 25]\n",
      "[6, 47, 6, 25, 27]\n",
      "[6, 47, 6, 37, 1]\n",
      "[6, 47, 6, 37, 29]\n",
      "[6, 47, 6, 37, 15]\n",
      "[6, 47, 6, 37, 21]\n",
      "[6, 47, 6, 37, 25]\n",
      "[6, 47, 6, 37, 27]\n",
      "[6, 47, 6, 43, 1]\n",
      "[6, 47, 6, 43, 29]\n",
      "[6, 47, 6, 43, 15]\n",
      "[6, 47, 6, 43, 21]\n",
      "[6, 47, 6, 43, 25]\n",
      "[6, 47, 6, 43, 27]\n",
      "[6, 47, 6, 45, 1]\n",
      "[6, 47, 6, 45, 29]\n",
      "[6, 47, 6, 45, 15]\n",
      "[6, 47, 6, 45, 21]\n",
      "[6, 47, 6, 45, 25]\n",
      "[6, 47, 6, 45, 27]\n",
      "[6, 47, 6, 47, 1]\n",
      "[6, 47, 6, 47, 29]\n",
      "[6, 47, 6, 47, 15]\n",
      "[6, 47, 6, 47, 21]\n",
      "[6, 47, 6, 47, 25]\n",
      "[6, 47, 6, 47, 27]\n",
      "[6, 46, 4, 1, 1]\n",
      "[6, 46, 4, 1, 29]\n",
      "[6, 46, 4, 1, 15]\n",
      "[6, 46, 4, 1, 21]\n",
      "[6, 46, 4, 1, 25]\n",
      "[6, 46, 4, 1, 27]\n",
      "[6, 46, 4, 49, 1]\n",
      "[6, 46, 4, 49, 29]\n",
      "[6, 46, 4, 49, 15]\n",
      "[6, 46, 4, 49, 21]\n",
      "[6, 46, 4, 49, 25]\n",
      "[6, 46, 4, 49, 27]\n",
      "[6, 46, 4, 25, 1]\n",
      "[6, 46, 4, 25, 29]\n",
      "[6, 46, 4, 25, 15]\n",
      "[6, 46, 4, 25, 21]\n",
      "[6, 46, 4, 25, 25]\n",
      "[6, 46, 4, 25, 27]\n",
      "[6, 46, 4, 37, 1]\n",
      "[6, 46, 4, 37, 29]\n",
      "[6, 46, 4, 37, 15]\n",
      "[6, 46, 4, 37, 21]\n",
      "[6, 46, 4, 37, 25]\n",
      "[6, 46, 4, 37, 27]\n",
      "[6, 46, 4, 43, 1]\n",
      "[6, 46, 4, 43, 29]\n",
      "[6, 46, 4, 43, 15]\n",
      "[6, 46, 4, 43, 21]\n",
      "[6, 46, 4, 43, 25]\n",
      "[6, 46, 4, 43, 27]\n",
      "[6, 46, 4, 45, 1]\n",
      "[6, 46, 4, 45, 29]\n",
      "[6, 46, 4, 45, 15]\n",
      "[6, 46, 4, 45, 21]\n",
      "[6, 46, 4, 45, 25]\n",
      "[6, 46, 4, 45, 27]\n",
      "[6, 46, 4, 47, 1]\n",
      "[6, 46, 4, 47, 29]\n",
      "[6, 46, 4, 47, 15]\n",
      "[6, 46, 4, 47, 21]\n",
      "[6, 46, 4, 47, 25]\n",
      "[6, 46, 4, 47, 27]\n",
      "[6, 46, 6, 1, 1]\n",
      "[6, 46, 6, 1, 29]\n",
      "[6, 46, 6, 1, 15]\n",
      "[6, 46, 6, 1, 21]\n",
      "[6, 46, 6, 1, 25]\n",
      "[6, 46, 6, 1, 27]\n",
      "[6, 46, 6, 49, 1]\n",
      "[6, 46, 6, 49, 29]\n",
      "[6, 46, 6, 49, 15]\n",
      "[6, 46, 6, 49, 21]\n",
      "[6, 46, 6, 49, 25]\n",
      "[6, 46, 6, 49, 27]\n",
      "[6, 46, 6, 25, 1]\n",
      "[6, 46, 6, 25, 29]\n",
      "[6, 46, 6, 25, 15]\n",
      "[6, 46, 6, 25, 21]\n",
      "[6, 46, 6, 25, 25]\n",
      "[6, 46, 6, 25, 27]\n",
      "[6, 46, 6, 37, 1]\n",
      "[6, 46, 6, 37, 29]\n",
      "[6, 46, 6, 37, 15]\n",
      "[6, 46, 6, 37, 21]\n",
      "[6, 46, 6, 37, 25]\n",
      "[6, 46, 6, 37, 27]\n",
      "[6, 46, 6, 43, 1]\n",
      "[6, 46, 6, 43, 29]\n",
      "[6, 46, 6, 43, 15]\n",
      "[6, 46, 6, 43, 21]\n",
      "[6, 46, 6, 43, 25]\n",
      "[6, 46, 6, 43, 27]\n",
      "[6, 46, 6, 45, 1]\n",
      "[6, 46, 6, 45, 29]\n",
      "[6, 46, 6, 45, 15]\n",
      "[6, 46, 6, 45, 21]\n",
      "[6, 46, 6, 45, 25]\n",
      "[6, 46, 6, 45, 27]\n",
      "[6, 46, 6, 47, 1]\n",
      "[6, 46, 6, 47, 29]\n",
      "[6, 46, 6, 47, 15]\n",
      "[6, 46, 6, 47, 21]\n",
      "[6, 46, 6, 47, 25]\n",
      "[6, 46, 6, 47, 27]\n",
      "[5, 40, 4, 1, 1]\n",
      "[5, 40, 4, 1, 29]\n",
      "[5, 40, 4, 1, 15]\n",
      "[5, 40, 4, 1, 21]\n",
      "[5, 40, 4, 1, 25]\n",
      "[5, 40, 4, 1, 27]\n",
      "[5, 40, 4, 49, 1]\n",
      "[5, 40, 4, 49, 29]\n",
      "[5, 40, 4, 49, 15]\n",
      "[5, 40, 4, 49, 21]\n",
      "[5, 40, 4, 49, 25]\n",
      "[5, 40, 4, 49, 27]\n",
      "[5, 40, 4, 25, 1]\n",
      "[5, 40, 4, 25, 29]\n",
      "[5, 40, 4, 25, 15]\n",
      "[5, 40, 4, 25, 21]\n",
      "[5, 40, 4, 25, 25]\n",
      "[5, 40, 4, 25, 27]\n",
      "[5, 40, 4, 37, 1]\n",
      "[5, 40, 4, 37, 29]\n",
      "[5, 40, 4, 37, 15]\n",
      "[5, 40, 4, 37, 21]\n",
      "[5, 40, 4, 37, 25]\n",
      "[5, 40, 4, 37, 27]\n",
      "[5, 40, 4, 43, 1]\n",
      "[5, 40, 4, 43, 29]\n",
      "[5, 40, 4, 43, 15]\n",
      "[5, 40, 4, 43, 21]\n",
      "[5, 40, 4, 43, 25]\n",
      "[5, 40, 4, 43, 27]\n",
      "[5, 40, 4, 45, 1]\n",
      "[5, 40, 4, 45, 29]\n",
      "[5, 40, 4, 45, 15]\n",
      "[5, 40, 4, 45, 21]\n",
      "[5, 40, 4, 45, 25]\n",
      "[5, 40, 4, 45, 27]\n",
      "[5, 40, 4, 47, 1]\n",
      "[5, 40, 4, 47, 29]\n",
      "[5, 40, 4, 47, 15]\n",
      "[5, 40, 4, 47, 21]\n",
      "[5, 40, 4, 47, 25]\n",
      "[5, 40, 4, 47, 27]\n",
      "[5, 40, 6, 1, 1]\n",
      "[5, 40, 6, 1, 29]\n",
      "[5, 40, 6, 1, 15]\n",
      "[5, 40, 6, 1, 21]\n",
      "[5, 40, 6, 1, 25]\n",
      "[5, 40, 6, 1, 27]\n",
      "[5, 40, 6, 49, 1]\n",
      "[5, 40, 6, 49, 29]\n",
      "[5, 40, 6, 49, 15]\n",
      "[5, 40, 6, 49, 21]\n",
      "[5, 40, 6, 49, 25]\n",
      "[5, 40, 6, 49, 27]\n",
      "[5, 40, 6, 25, 1]\n",
      "[5, 40, 6, 25, 29]\n",
      "[5, 40, 6, 25, 15]\n",
      "[5, 40, 6, 25, 21]\n",
      "[5, 40, 6, 25, 25]\n",
      "[5, 40, 6, 25, 27]\n",
      "[5, 40, 6, 37, 1]\n",
      "[5, 40, 6, 37, 29]\n",
      "[5, 40, 6, 37, 15]\n",
      "[5, 40, 6, 37, 21]\n",
      "[5, 40, 6, 37, 25]\n",
      "[5, 40, 6, 37, 27]\n",
      "[5, 40, 6, 43, 1]\n",
      "[5, 40, 6, 43, 29]\n",
      "[5, 40, 6, 43, 15]\n",
      "[5, 40, 6, 43, 21]\n",
      "[5, 40, 6, 43, 25]\n",
      "[5, 40, 6, 43, 27]\n",
      "[5, 40, 6, 45, 1]\n",
      "[5, 40, 6, 45, 29]\n",
      "[5, 40, 6, 45, 15]\n",
      "[5, 40, 6, 45, 21]\n",
      "[5, 40, 6, 45, 25]\n",
      "[5, 40, 6, 45, 27]\n",
      "[5, 40, 6, 47, 1]\n",
      "[5, 40, 6, 47, 29]\n",
      "[5, 40, 6, 47, 15]\n",
      "[5, 40, 6, 47, 21]\n",
      "[5, 40, 6, 47, 25]\n",
      "[5, 40, 6, 47, 27]\n",
      "[5, 50, 4, 1, 1]\n",
      "[5, 50, 4, 1, 29]\n",
      "[5, 50, 4, 1, 15]\n",
      "[5, 50, 4, 1, 21]\n",
      "[5, 50, 4, 1, 25]\n",
      "[5, 50, 4, 1, 27]\n",
      "[5, 50, 4, 49, 1]\n",
      "[5, 50, 4, 49, 29]\n",
      "[5, 50, 4, 49, 15]\n",
      "[5, 50, 4, 49, 21]\n",
      "[5, 50, 4, 49, 25]\n",
      "[5, 50, 4, 49, 27]\n",
      "[5, 50, 4, 25, 1]\n",
      "[5, 50, 4, 25, 29]\n",
      "[5, 50, 4, 25, 15]\n",
      "[5, 50, 4, 25, 21]\n",
      "[5, 50, 4, 25, 25]\n",
      "[5, 50, 4, 25, 27]\n",
      "[5, 50, 4, 37, 1]\n",
      "[5, 50, 4, 37, 29]\n",
      "[5, 50, 4, 37, 15]\n",
      "[5, 50, 4, 37, 21]\n",
      "[5, 50, 4, 37, 25]\n",
      "[5, 50, 4, 37, 27]\n",
      "[5, 50, 4, 43, 1]\n",
      "[5, 50, 4, 43, 29]\n",
      "[5, 50, 4, 43, 15]\n",
      "[5, 50, 4, 43, 21]\n",
      "[5, 50, 4, 43, 25]\n",
      "[5, 50, 4, 43, 27]\n",
      "[5, 50, 4, 45, 1]\n",
      "[5, 50, 4, 45, 29]\n",
      "[5, 50, 4, 45, 15]\n",
      "[5, 50, 4, 45, 21]\n",
      "[5, 50, 4, 45, 25]\n",
      "[5, 50, 4, 45, 27]\n",
      "[5, 50, 4, 47, 1]\n",
      "[5, 50, 4, 47, 29]\n",
      "[5, 50, 4, 47, 15]\n",
      "[5, 50, 4, 47, 21]\n",
      "[5, 50, 4, 47, 25]\n",
      "[5, 50, 4, 47, 27]\n",
      "[5, 50, 6, 1, 1]\n",
      "[5, 50, 6, 1, 29]\n",
      "[5, 50, 6, 1, 15]\n",
      "[5, 50, 6, 1, 21]\n",
      "[5, 50, 6, 1, 25]\n",
      "[5, 50, 6, 1, 27]\n",
      "[5, 50, 6, 49, 1]\n",
      "[5, 50, 6, 49, 29]\n",
      "[5, 50, 6, 49, 15]\n",
      "[5, 50, 6, 49, 21]\n",
      "[5, 50, 6, 49, 25]\n",
      "[5, 50, 6, 49, 27]\n",
      "[5, 50, 6, 25, 1]\n",
      "[5, 50, 6, 25, 29]\n",
      "[5, 50, 6, 25, 15]\n",
      "[5, 50, 6, 25, 21]\n",
      "[5, 50, 6, 25, 25]\n",
      "[5, 50, 6, 25, 27]\n",
      "[5, 50, 6, 37, 1]\n",
      "[5, 50, 6, 37, 29]\n",
      "[5, 50, 6, 37, 15]\n",
      "[5, 50, 6, 37, 21]\n",
      "[5, 50, 6, 37, 25]\n",
      "[5, 50, 6, 37, 27]\n",
      "[5, 50, 6, 43, 1]\n",
      "[5, 50, 6, 43, 29]\n",
      "[5, 50, 6, 43, 15]\n",
      "[5, 50, 6, 43, 21]\n",
      "[5, 50, 6, 43, 25]\n",
      "[5, 50, 6, 43, 27]\n",
      "[5, 50, 6, 45, 1]\n",
      "[5, 50, 6, 45, 29]\n",
      "[5, 50, 6, 45, 15]\n",
      "[5, 50, 6, 45, 21]\n",
      "[5, 50, 6, 45, 25]\n",
      "[5, 50, 6, 45, 27]\n",
      "[5, 50, 6, 47, 1]\n",
      "[5, 50, 6, 47, 29]\n",
      "[5, 50, 6, 47, 15]\n",
      "[5, 50, 6, 47, 21]\n",
      "[5, 50, 6, 47, 25]\n",
      "[5, 50, 6, 47, 27]\n",
      "[5, 45, 4, 1, 1]\n",
      "[5, 45, 4, 1, 29]\n",
      "[5, 45, 4, 1, 15]\n",
      "[5, 45, 4, 1, 21]\n",
      "[5, 45, 4, 1, 25]\n",
      "[5, 45, 4, 1, 27]\n",
      "[5, 45, 4, 49, 1]\n",
      "[5, 45, 4, 49, 29]\n",
      "[5, 45, 4, 49, 15]\n",
      "[5, 45, 4, 49, 21]\n",
      "[5, 45, 4, 49, 25]\n",
      "[5, 45, 4, 49, 27]\n",
      "[5, 45, 4, 25, 1]\n",
      "[5, 45, 4, 25, 29]\n",
      "[5, 45, 4, 25, 15]\n",
      "[5, 45, 4, 25, 21]\n",
      "[5, 45, 4, 25, 25]\n",
      "[5, 45, 4, 25, 27]\n",
      "[5, 45, 4, 37, 1]\n",
      "[5, 45, 4, 37, 29]\n",
      "[5, 45, 4, 37, 15]\n",
      "[5, 45, 4, 37, 21]\n",
      "[5, 45, 4, 37, 25]\n",
      "[5, 45, 4, 37, 27]\n",
      "[5, 45, 4, 43, 1]\n",
      "[5, 45, 4, 43, 29]\n",
      "[5, 45, 4, 43, 15]\n",
      "[5, 45, 4, 43, 21]\n",
      "[5, 45, 4, 43, 25]\n",
      "[5, 45, 4, 43, 27]\n",
      "[5, 45, 4, 45, 1]\n",
      "[5, 45, 4, 45, 29]\n",
      "[5, 45, 4, 45, 15]\n",
      "[5, 45, 4, 45, 21]\n",
      "[5, 45, 4, 45, 25]\n",
      "[5, 45, 4, 45, 27]\n",
      "[5, 45, 4, 47, 1]\n",
      "[5, 45, 4, 47, 29]\n",
      "[5, 45, 4, 47, 15]\n",
      "[5, 45, 4, 47, 21]\n",
      "[5, 45, 4, 47, 25]\n",
      "[5, 45, 4, 47, 27]\n",
      "[5, 45, 6, 1, 1]\n",
      "[5, 45, 6, 1, 29]\n",
      "[5, 45, 6, 1, 15]\n",
      "[5, 45, 6, 1, 21]\n",
      "[5, 45, 6, 1, 25]\n",
      "[5, 45, 6, 1, 27]\n",
      "[5, 45, 6, 49, 1]\n",
      "[5, 45, 6, 49, 29]\n",
      "[5, 45, 6, 49, 15]\n",
      "[5, 45, 6, 49, 21]\n",
      "[5, 45, 6, 49, 25]\n",
      "[5, 45, 6, 49, 27]\n",
      "[5, 45, 6, 25, 1]\n",
      "[5, 45, 6, 25, 29]\n",
      "[5, 45, 6, 25, 15]\n",
      "[5, 45, 6, 25, 21]\n",
      "[5, 45, 6, 25, 25]\n",
      "[5, 45, 6, 25, 27]\n",
      "[5, 45, 6, 37, 1]\n",
      "[5, 45, 6, 37, 29]\n",
      "[5, 45, 6, 37, 15]\n",
      "[5, 45, 6, 37, 21]\n",
      "[5, 45, 6, 37, 25]\n",
      "[5, 45, 6, 37, 27]\n",
      "[5, 45, 6, 43, 1]\n",
      "[5, 45, 6, 43, 29]\n",
      "[5, 45, 6, 43, 15]\n",
      "[5, 45, 6, 43, 21]\n",
      "[5, 45, 6, 43, 25]\n",
      "[5, 45, 6, 43, 27]\n",
      "[5, 45, 6, 45, 1]\n",
      "[5, 45, 6, 45, 29]\n",
      "[5, 45, 6, 45, 15]\n",
      "[5, 45, 6, 45, 21]\n",
      "[5, 45, 6, 45, 25]\n",
      "[5, 45, 6, 45, 27]\n",
      "[5, 45, 6, 47, 1]\n",
      "[5, 45, 6, 47, 29]\n",
      "[5, 45, 6, 47, 15]\n",
      "[5, 45, 6, 47, 21]\n",
      "[5, 45, 6, 47, 25]\n",
      "[5, 45, 6, 47, 27]\n",
      "[5, 47, 4, 1, 1]\n",
      "[5, 47, 4, 1, 29]\n",
      "[5, 47, 4, 1, 15]\n",
      "[5, 47, 4, 1, 21]\n",
      "[5, 47, 4, 1, 25]\n",
      "[5, 47, 4, 1, 27]\n",
      "[5, 47, 4, 49, 1]\n",
      "[5, 47, 4, 49, 29]\n",
      "[5, 47, 4, 49, 15]\n",
      "[5, 47, 4, 49, 21]\n",
      "[5, 47, 4, 49, 25]\n",
      "[5, 47, 4, 49, 27]\n",
      "[5, 47, 4, 25, 1]\n",
      "[5, 47, 4, 25, 29]\n",
      "[5, 47, 4, 25, 15]\n",
      "[5, 47, 4, 25, 21]\n",
      "[5, 47, 4, 25, 25]\n",
      "[5, 47, 4, 25, 27]\n",
      "[5, 47, 4, 37, 1]\n",
      "[5, 47, 4, 37, 29]\n",
      "[5, 47, 4, 37, 15]\n",
      "[5, 47, 4, 37, 21]\n",
      "[5, 47, 4, 37, 25]\n",
      "[5, 47, 4, 37, 27]\n",
      "[5, 47, 4, 43, 1]\n",
      "[5, 47, 4, 43, 29]\n",
      "[5, 47, 4, 43, 15]\n",
      "[5, 47, 4, 43, 21]\n",
      "[5, 47, 4, 43, 25]\n",
      "[5, 47, 4, 43, 27]\n",
      "[5, 47, 4, 45, 1]\n",
      "[5, 47, 4, 45, 29]\n",
      "[5, 47, 4, 45, 15]\n",
      "[5, 47, 4, 45, 21]\n",
      "[5, 47, 4, 45, 25]\n",
      "[5, 47, 4, 45, 27]\n",
      "[5, 47, 4, 47, 1]\n",
      "[5, 47, 4, 47, 29]\n",
      "[5, 47, 4, 47, 15]\n",
      "[5, 47, 4, 47, 21]\n",
      "[5, 47, 4, 47, 25]\n",
      "[5, 47, 4, 47, 27]\n",
      "[5, 47, 6, 1, 1]\n",
      "[5, 47, 6, 1, 29]\n",
      "[5, 47, 6, 1, 15]\n",
      "[5, 47, 6, 1, 21]\n",
      "[5, 47, 6, 1, 25]\n",
      "[5, 47, 6, 1, 27]\n",
      "[5, 47, 6, 49, 1]\n",
      "[5, 47, 6, 49, 29]\n",
      "[5, 47, 6, 49, 15]\n",
      "[5, 47, 6, 49, 21]\n",
      "[5, 47, 6, 49, 25]\n",
      "[5, 47, 6, 49, 27]\n",
      "[5, 47, 6, 25, 1]\n",
      "[5, 47, 6, 25, 29]\n",
      "[5, 47, 6, 25, 15]\n",
      "[5, 47, 6, 25, 21]\n",
      "[5, 47, 6, 25, 25]\n",
      "[5, 47, 6, 25, 27]\n",
      "[5, 47, 6, 37, 1]\n",
      "[5, 47, 6, 37, 29]\n",
      "[5, 47, 6, 37, 15]\n",
      "[5, 47, 6, 37, 21]\n",
      "[5, 47, 6, 37, 25]\n",
      "[5, 47, 6, 37, 27]\n",
      "[5, 47, 6, 43, 1]\n",
      "[5, 47, 6, 43, 29]\n",
      "[5, 47, 6, 43, 15]\n",
      "[5, 47, 6, 43, 21]\n",
      "[5, 47, 6, 43, 25]\n",
      "[5, 47, 6, 43, 27]\n",
      "[5, 47, 6, 45, 1]\n",
      "[5, 47, 6, 45, 29]\n",
      "[5, 47, 6, 45, 15]\n",
      "[5, 47, 6, 45, 21]\n",
      "[5, 47, 6, 45, 25]\n",
      "[5, 47, 6, 45, 27]\n",
      "[5, 47, 6, 47, 1]\n",
      "[5, 47, 6, 47, 29]\n",
      "[5, 47, 6, 47, 15]\n",
      "[5, 47, 6, 47, 21]\n",
      "[5, 47, 6, 47, 25]\n",
      "[5, 47, 6, 47, 27]\n",
      "[5, 46, 4, 1, 1]\n",
      "[5, 46, 4, 1, 29]\n",
      "[5, 46, 4, 1, 15]\n",
      "[5, 46, 4, 1, 21]\n",
      "[5, 46, 4, 1, 25]\n",
      "[5, 46, 4, 1, 27]\n",
      "[5, 46, 4, 49, 1]\n",
      "[5, 46, 4, 49, 29]\n",
      "[5, 46, 4, 49, 15]\n",
      "[5, 46, 4, 49, 21]\n",
      "[5, 46, 4, 49, 25]\n",
      "[5, 46, 4, 49, 27]\n",
      "[5, 46, 4, 25, 1]\n",
      "[5, 46, 4, 25, 29]\n",
      "[5, 46, 4, 25, 15]\n",
      "[5, 46, 4, 25, 21]\n",
      "[5, 46, 4, 25, 25]\n",
      "[5, 46, 4, 25, 27]\n",
      "[5, 46, 4, 37, 1]\n",
      "[5, 46, 4, 37, 29]\n",
      "[5, 46, 4, 37, 15]\n",
      "[5, 46, 4, 37, 21]\n",
      "[5, 46, 4, 37, 25]\n",
      "[5, 46, 4, 37, 27]\n",
      "[5, 46, 4, 43, 1]\n",
      "[5, 46, 4, 43, 29]\n",
      "[5, 46, 4, 43, 15]\n",
      "[5, 46, 4, 43, 21]\n",
      "[5, 46, 4, 43, 25]\n",
      "[5, 46, 4, 43, 27]\n",
      "[5, 46, 4, 45, 1]\n",
      "[5, 46, 4, 45, 29]\n",
      "[5, 46, 4, 45, 15]\n",
      "[5, 46, 4, 45, 21]\n",
      "[5, 46, 4, 45, 25]\n",
      "[5, 46, 4, 45, 27]\n",
      "[5, 46, 4, 47, 1]\n",
      "[5, 46, 4, 47, 29]\n",
      "[5, 46, 4, 47, 15]\n",
      "[5, 46, 4, 47, 21]\n",
      "[5, 46, 4, 47, 25]\n",
      "[5, 46, 4, 47, 27]\n",
      "[5, 46, 6, 1, 1]\n",
      "[5, 46, 6, 1, 29]\n",
      "[5, 46, 6, 1, 15]\n",
      "[5, 46, 6, 1, 21]\n",
      "[5, 46, 6, 1, 25]\n",
      "[5, 46, 6, 1, 27]\n",
      "[5, 46, 6, 49, 1]\n",
      "[5, 46, 6, 49, 29]\n",
      "[5, 46, 6, 49, 15]\n",
      "[5, 46, 6, 49, 21]\n",
      "[5, 46, 6, 49, 25]\n",
      "[5, 46, 6, 49, 27]\n",
      "[5, 46, 6, 25, 1]\n",
      "[5, 46, 6, 25, 29]\n",
      "[5, 46, 6, 25, 15]\n",
      "[5, 46, 6, 25, 21]\n",
      "[5, 46, 6, 25, 25]\n",
      "[5, 46, 6, 25, 27]\n",
      "[5, 46, 6, 37, 1]\n",
      "[5, 46, 6, 37, 29]\n",
      "[5, 46, 6, 37, 15]\n",
      "[5, 46, 6, 37, 21]\n",
      "[5, 46, 6, 37, 25]\n",
      "[5, 46, 6, 37, 27]\n",
      "[5, 46, 6, 43, 1]\n",
      "[5, 46, 6, 43, 29]\n",
      "[5, 46, 6, 43, 15]\n",
      "[5, 46, 6, 43, 21]\n",
      "[5, 46, 6, 43, 25]\n",
      "[5, 46, 6, 43, 27]\n",
      "[5, 46, 6, 45, 1]\n",
      "[5, 46, 6, 45, 29]\n",
      "[5, 46, 6, 45, 15]\n",
      "[5, 46, 6, 45, 21]\n",
      "[5, 46, 6, 45, 25]\n",
      "[5, 46, 6, 45, 27]\n",
      "[5, 46, 6, 47, 1]\n",
      "[5, 46, 6, 47, 29]\n",
      "[5, 46, 6, 47, 15]\n",
      "[5, 46, 6, 47, 21]\n",
      "[5, 46, 6, 47, 25]\n",
      "[5, 46, 6, 47, 27]\n",
      "maximo 0.619482496194825 parametros (iter,learning,profundidad,profundidad,samplesplit) [5, 46, 6, 47, 27]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "4ahhiflxP4aQ",
    "colab_type": "text"
   },
   "source": [
    "## Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "xzLt9mw_P4aR",
    "colab_type": "code",
    "colab": {},
    "outputId": "e6661b4f-6756-4b53-a65a-69d31b003137"
   },
   "source": [
    "\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=[len(train_set.keys())]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               55168     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 71,809\n",
      "Trainable params: 71,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "wmiZge_YP4aU",
    "colab_type": "code",
    "colab": {},
    "outputId": "9990abeb-5754-4ceb-a247-715913525e0d"
   },
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(train_set, train_label, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "................................"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "5KJS2dCQP4ac",
    "colab_type": "code",
    "colab": {},
    "outputId": "fbb194cc-e394-4b9a-a916-52a6d3fafea7"
   },
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error')\n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,5])\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,20])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "yp1kgV_eP4af",
    "colab_type": "code",
    "colab": {},
    "outputId": "1e73cd45-99e7-41e9-abaa-59f06c1bee07"
   },
   "source": [
    "preds = model.predict(np.asarray(test_set)).round()\n",
    "result['target'] = preds\n",
    "print(F1(result))\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0.6143465909090909\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "JJ2rufAJP4aj",
    "colab_type": "text"
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "JzKlfIKNP4al",
    "colab_type": "code",
    "colab": {},
    "outputId": "6748764a-bd89-4ffd-b579-478c7b3022e5"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='sag', C=10)\n",
    "classifier.fit(train_set, train_label)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, solver='sag')"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 78
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "ibOvxnRsP4ar",
    "colab_type": "code",
    "colab": {},
    "outputId": "023e2751-4bb2-4f28-945f-69ebb906d29a"
   },
   "source": [
    "preds = classifier.predict(test_set)\n",
    "result['target'] = preds\n",
    "print(F1(result))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0.49274160099543757\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "6GrjfZ1IP4at",
    "colab_type": "code",
    "colab": {},
    "outputId": "05a06d76-ba69-49a6-de80-7ae31c593e5e"
   },
   "source": [
    "#NO EJECUTAR ESTA CELDA SALVO NESESIDAD DE ACTUALIZAR LAS PALABRAS IMPORTANTES\n",
    "importancia = rf.feature_importances_\n",
    "cols = test_set.columns\n",
    "#dataImportacia = pd.DataFrame(columns=('importacia', 'col'))\n",
    "#dataImportacia['importacia'] = importancia\n",
    "#dataImportacia['col'] = cols\n",
    "#dataImportacia = dataImportacia[dataImportacia['importacia'] > 0.001]\n",
    "#dataImportacia.to_csv('impotacia.csv', index=False)#linea bloqueada por las dudas\n",
    "cantidadImportantes = 0\n",
    "for i in range(len(cols)):\n",
    "    if (importancia[i] < 0.001):\n",
    "        continue\n",
    "    print(importancia[i],cols[i])\n",
    "    cantidadImportantes += 1\n",
    "print(cantidadImportantes,len(cols))\n",
    "#dataImportacia.head()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "0.2390805634162692 longitud_de_texto\n",
      "0.10356755451085793 longitud_de_keyword\n",
      "0.1495785422543723 cantidad_de_palabras_texto\n",
      "0.00237350375031132 cantidad_de_palabras_keyword\n",
      "0.04685193773478123 cantidad_de_hashtag_en_texto\n",
      "0.004982539313145062 letra_0\n",
      "0.003926678582109837 letra_1\n",
      "0.004440598419622883 letra_2\n",
      "0.005233410028750109 letra_3\n",
      "0.0027622963481758874 earthquake\n",
      "0.002358470515813103 everyone\n",
      "0.0016901006666783641 street\n",
      "0.001392154803011899 hey\n",
      "0.00214993673194334 im\n",
      "0.001033612848961267 song\n",
      "0.0013459283696241483 traffic\n",
      "0.002461013186582841 black\n",
      "0.0033705876530110736 injured\n",
      "0.001626441965061608 week\n",
      "0.0012977403101263724 fall\n",
      "0.001594919807935172 far\n",
      "0.0010876019596148874 history\n",
      "0.0010840221701216746 hard\n",
      "0.002529627304767267 lol\n",
      "0.0016005423181616816 fan\n",
      "0.002106555365330004 god\n",
      "0.0027767866723538053 air\n",
      "0.0014003068324652227 island\n",
      "0.0020361721529647578 times\n",
      "0.007302318866651086 train\n",
      "0.001051999048052131 die\n",
      "0.0018248692018590466 change\n",
      "0.0015764677032969036 latest\n",
      "0.0015124668692279692 pakistan\n",
      "0.001872583852202618 big\n",
      "0.0010802192175297992 miss\n",
      "0.00112032665341032 weapon\n",
      "0.0012471788616191396 lot\n",
      "0.003126383782038611 time\n",
      "0.00102720023807461 fukushima\n",
      "0.003796918248602936 nuclear\n",
      "0.0015663306164032116 book\n",
      "0.0014159940787617515 turkey\n",
      "0.0015786448005137097 site\n",
      "0.0025277376223977036 help\n",
      "0.0014415293699384616 hear\n",
      "0.002949003439786448 pm\n",
      "0.001275238648798061 post\n",
      "0.0020443611282247457 hot\n",
      "0.002075412367513136 better\n",
      "0.0016510264262280749 bag\n",
      "0.0012683931234419412 ebola\n",
      "0.0010779757564960027 tomorrow\n",
      "0.0012745500878390428 ok\n",
      "0.002527864545757649 school\n",
      "0.002319716039460509 story\n",
      "0.0010713833236944885 name\n",
      "0.0010213028404991117 hell\n",
      "0.0010096175020253909 drake\n",
      "0.0023216708940437766 abc\n",
      "0.003220302111139931 japan\n",
      "0.0011067862080023552 anything\n",
      "0.0010583080340576772 states\n",
      "0.0010662060281178601 failure\n",
      "0.0012487263075719544 tonight\n",
      "0.0010721088638457176 children\n",
      "0.0019545953703887344 area\n",
      "0.001116844963166452 worse\n",
      "0.0013688752019462712 explosion\n",
      "0.0012217529267068343 trapped\n",
      "0.001221573560845762 maybe\n",
      "0.0011004995260186809 india\n",
      "0.0027634118176262717 officials\n",
      "0.0030363953965558523 investigators\n",
      "0.0016863119050543993 floods\n",
      "0.0016495308049762816 terrorist\n",
      "0.0010391250322356641 passengers\n",
      "0.0011057075336575143 peace\n",
      "0.0011373950271728985 libya\n",
      "0.0018032059479601713 evacuation\n",
      "0.001629409842431337 theater\n",
      "0.001088113258000132 hostage\n",
      "0.0017574755983630244 detonated\n",
      "0.0012380361383519396 gun\n",
      "0.0010499373857936448 tragedy\n",
      "0.002101617976212307 projected\n",
      "0.001935213864117912 location_palabra_0\n",
      "0.0020253560003658526 location_palabra_2\n",
      "0.0024245835882353364 location_palabra_3\n",
      "0.0018593669823577126 location_palabra_4\n",
      "0.0023965314902333213 location_palabra_5\n",
      "0.0025938447302839 location_palabra_6\n",
      "0.003222118293726095 location_palabra_7\n",
      "0.0028307669521819914 location_palabra_8\n",
      "0.002591628692144604 location_palabra_9\n",
      "0.0030170729005660492 location_palabra_10\n",
      "0.002233876853370022 location_palabra_11\n",
      "0.0217166272835874 keyword_palabra_0\n",
      "0.009836870464537783 keyword_palabra_1\n",
      "0.019925615936382455 keyword_palabra_2\n",
      "0.017843305368881415 keyword_palabra_3\n",
      "0.02358903261147145 keyword_palabra_4\n",
      "0.01869999906938677 keyword_palabra_5\n",
      "0.03275719122141423 keyword_palabra_6\n",
      "0.027647624805756593 keyword_palabra_7\n",
      "105\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7kwOSQWP9Lz",
    "colab_type": "text"
   },
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[50, 10, -0.3]\n[1]\ttraining's l2: 0.238768",
      "\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231",
      "\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n",
      "[46]\ttraining's l2: 0.186876\n",
      "[47]\ttraining's l2: 0.186434\n",
      "[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 10, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n",
      "[21]\ttraining's l2: 0.199798\n",
      "[22]\ttraining's l2: 0.19898\n",
      "[23]\ttraining's l2: 0.198141\n",
      "[24]\ttraining's l2: 0.197363\n",
      "[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 10, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n",
      "[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 10, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n",
      "[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n",
      "[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n",
      "[33]\ttraining's l2: 0.192172\n",
      "[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n",
      "[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 10, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 50, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n",
      "[11]\ttraining's l2: 0.210319\n",
      "[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437",
      "\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 50, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029",
      "\n",
      "[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 50, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 50, 0.15]\n[1]\ttraining's l2: 0.238768",
      "\nTraining until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n",
      "[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 50, 0.2]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434",
      "\n",
      "[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 30, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n",
      "[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n",
      "[40]\ttraining's l2: 0.189106\n",
      "[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 30, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 30, 0.0]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n",
      "[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n",
      "[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103",
      "\n",
      "[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 30, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 30, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n",
      "[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106",
      "\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n",
      "[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 40, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 40, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n",
      "[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 40, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n",
      "[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463",
      "\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n",
      "[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n",
      "[50, 40, 0.15]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647",
      "\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n",
      "[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[50, 40, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n",
      "[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578",
      "\n[50]\ttraining's l2: 0.185219\nDid not meet early stopping. Best iteration is:\n[50]\ttraining's l2: 0.185219\n[150, 10, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n",
      "[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n",
      "[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n",
      "[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518",
      "\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146",
      "\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n[150, 10, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n",
      "[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745",
      "\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n",
      "[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n",
      "[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832",
      "\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n",
      "[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n",
      "[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n",
      "[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 10, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n",
      "[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n",
      "[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917",
      "\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n",
      "[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n",
      "[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 10, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n",
      "[10]\ttraining's l2: 0.211783\n",
      "[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578",
      "\n",
      "[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n",
      "[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733",
      "\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294",
      "\n[124]\ttraining's l2: 0.163901\n",
      "[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n[150, 10, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n",
      "[36]\ttraining's l2: 0.190745\n",
      "[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n",
      "[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831",
      "\n",
      "[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n",
      "[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n",
      "[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n",
      "[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n",
      "[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n",
      "[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 50, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n",
      "[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n",
      "[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 50, 0.3]\n[1]\ttraining's l2: 0.238768",
      "\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n",
      "[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457",
      "\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n",
      "[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n[150, 50, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029",
      "\n",
      "[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n",
      "[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n",
      "[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 50, 0.15]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n",
      "[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n",
      "[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n",
      "[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059",
      "\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n",
      "[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n",
      "[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n",
      "[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 50, 0.2]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n",
      "[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n",
      "[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n",
      "[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n",
      "[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353",
      "\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n",
      "[123]\ttraining's l2: 0.164294\n",
      "[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n",
      "[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 30, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n",
      "[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n",
      "[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 30, 0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n",
      "[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009",
      "\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n",
      "[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049",
      "\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n",
      "[68]\ttraining's l2: 0.179059\n",
      "[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n",
      "[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n",
      "[84]\ttraining's l2: 0.174071\n",
      "[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n",
      "[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n",
      "[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n",
      "[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n",
      "[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n[150, 30, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n",
      "[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219",
      "\n",
      "[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n",
      "[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275",
      "\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 30, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n",
      "[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114",
      "\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 30, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476",
      "\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n",
      "[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 40, -0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515",
      "\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n",
      "[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n",
      "[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n",
      "[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n",
      "[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n",
      "[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 40, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539",
      "\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n",
      "[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768",
      "\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n[150, 40, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n",
      "[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n",
      "[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n",
      "[134]\ttraining's l2: 0.161444\n",
      "[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n[150, 40, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n",
      "[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n",
      "[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n",
      "[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n",
      "[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[150, 40, 0.2]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011",
      "\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n",
      "[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686",
      "\n",
      "[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n",
      "[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\n[121]\ttraining's l2: 0.164679\n[122]\ttraining's l2: 0.164492\n[123]\ttraining's l2: 0.164294\n[124]\ttraining's l2: 0.163901\n[125]\ttraining's l2: 0.163788\n[126]\ttraining's l2: 0.163685\n[127]\ttraining's l2: 0.163421\n[128]\ttraining's l2: 0.163266\n[129]\ttraining's l2: 0.16303\n[130]\ttraining's l2: 0.162661\n[131]\ttraining's l2: 0.162504\n[132]\ttraining's l2: 0.162075\n[133]\ttraining's l2: 0.161726\n[134]\ttraining's l2: 0.161444\n[135]\ttraining's l2: 0.161288\n[136]\ttraining's l2: 0.160944\n[137]\ttraining's l2: 0.160812\n[138]\ttraining's l2: 0.160498\n[139]\ttraining's l2: 0.160146\n[140]\ttraining's l2: 0.15983\n[141]\ttraining's l2: 0.159498\n[142]\ttraining's l2: 0.159275\n[143]\ttraining's l2: 0.159062\n[144]\ttraining's l2: 0.158863\n[145]\ttraining's l2: 0.158655\n[146]\ttraining's l2: 0.158445\n[147]\ttraining's l2: 0.158259\n[148]\ttraining's l2: 0.158152\n[149]\ttraining's l2: 0.158007\n[150]\ttraining's l2: 0.157768\nDid not meet early stopping. Best iteration is:\n[150]\ttraining's l2: 0.157768\n",
      "[100, 10, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n",
      "[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437",
      "\n",
      "[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n",
      "[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n",
      "[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n",
      "[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n",
      "[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n",
      "[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 10, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n",
      "[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n",
      "[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[100, 10, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n",
      "[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434",
      "\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n",
      "[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n",
      "[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431",
      "\n",
      "[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n",
      "[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n",
      "[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[100, 10, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n",
      "[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n",
      "[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n",
      "[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 10, 0.2]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768",
      "\n",
      "[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n",
      "[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n",
      "[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n",
      "[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n",
      "[70]\ttraining's l2: 0.178431\n",
      "[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 50, -0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n",
      "[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n",
      "[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795",
      "\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n",
      "[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n",
      "[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n",
      "[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[100, 50, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n",
      "[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n",
      "[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 50, 0.0]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106",
      "\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n",
      "[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437",
      "\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 50, 0.15]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n",
      "[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019",
      "\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n",
      "[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012",
      "\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n",
      "[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n",
      "[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 50, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n",
      "[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n",
      "[52]\ttraining's l2: 0.184527\n",
      "[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 30, -0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n",
      "[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n",
      "[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n",
      "[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n",
      "[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 30, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n",
      "[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831",
      "\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n",
      "[60]\ttraining's l2: 0.181465\n",
      "[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n",
      "[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n",
      "[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 30, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n",
      "[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527",
      "\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089",
      "\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[100, 30, 0.15]",
      "\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n",
      "[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717",
      "\n",
      "[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n",
      "[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[100, 30, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n",
      "[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n",
      "[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099",
      "\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[100, 40, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925",
      "\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 40, 0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 40, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n",
      "[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n",
      "[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n",
      "[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686",
      "\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n",
      "[100, 40, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n",
      "[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n",
      "[17]\ttraining's l2: 0.203463\n",
      "[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n",
      "[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n",
      "[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n",
      "[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806",
      "\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n",
      "[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[100, 40, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n",
      "[9]\ttraining's l2: 0.213287\n",
      "[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n",
      "[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686",
      "\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n[120, 10, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n",
      "[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n",
      "[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n",
      "[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n",
      "[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023",
      "\n",
      "[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 10, 0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898",
      "\n",
      "[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434",
      "\n",
      "[43]\ttraining's l2: 0.188025\n",
      "[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n",
      "[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496",
      "\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n",
      "[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n",
      "[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n",
      "[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 10, 0.0]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705",
      "\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n",
      "[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n",
      "[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n",
      "[53]\ttraining's l2: 0.184017\n",
      "[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n",
      "[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n",
      "[64]\ttraining's l2: 0.180304\n",
      "[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518",
      "\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n",
      "[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n",
      "[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 10, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798",
      "\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n",
      "[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n",
      "[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n",
      "[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n",
      "[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n",
      "[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n[120, 10, 0.2]",
      "\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319",
      "\n",
      "[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n",
      "[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n",
      "[40]\ttraining's l2: 0.189106\n",
      "[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n",
      "[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n",
      "[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n",
      "[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n[120, 50, -0.3]",
      "\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n",
      "[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n",
      "[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n",
      "[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n",
      "[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n",
      "[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 50, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745",
      "\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n",
      "[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n",
      "[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925",
      "\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948",
      "\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n",
      "[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 50, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783",
      "\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n",
      "[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n",
      "[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n",
      "[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n",
      "[82]\ttraining's l2: 0.174705\n",
      "[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n",
      "[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 50, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n",
      "[32]\ttraining's l2: 0.192728\n",
      "[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n",
      "[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n",
      "[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n",
      "[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n",
      "[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n",
      "[112]\ttraining's l2: 0.166733\n",
      "[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 50, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n",
      "[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n",
      "[39]\ttraining's l2: 0.189531\n",
      "[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n",
      "[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n",
      "[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n",
      "[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n",
      "[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917",
      "\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n",
      "[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n[120, 30, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n",
      "[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n",
      "[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n",
      "[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n",
      "[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n",
      "[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n",
      "[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n",
      "[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 30, 0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds",
      "\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705",
      "\n[5]\ttraining's l2: 0.222512",
      "\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n",
      "[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n",
      "[49]\ttraining's l2: 0.185578\n",
      "[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n",
      "[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n",
      "[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n",
      "[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 30, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n",
      "[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172",
      "\n[34]\ttraining's l2: 0.191795",
      "\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n",
      "[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n",
      "[42]\ttraining's l2: 0.188434\n",
      "[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n",
      "[56]\ttraining's l2: 0.182831\n",
      "[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n",
      "[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n",
      "[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 30, 0.15]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n",
      "[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n",
      "[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n",
      "[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n",
      "[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059",
      "\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n",
      "[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n",
      "[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n",
      "[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n[120, 30, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n",
      "[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n",
      "[19]\ttraining's l2: 0.201533\n",
      "[20]\ttraining's l2: 0.200697\n",
      "[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n",
      "[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n",
      "[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n",
      "[38]\ttraining's l2: 0.190029\n",
      "[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n",
      "[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n",
      "[49]\ttraining's l2: 0.185578\n",
      "[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n",
      "[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n",
      "[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n",
      "[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n",
      "[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n",
      "[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 40, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n",
      "[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n",
      "[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n",
      "[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n",
      "[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n",
      "[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n",
      "[89]\ttraining's l2: 0.172248\n",
      "[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n",
      "[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n",
      "[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n",
      "[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n",
      "[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n[120, 40, 0.3]",
      "\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n",
      "[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n",
      "[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n",
      "[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n",
      "[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n",
      "[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n",
      "[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n",
      "[103]\ttraining's l2: 0.169107\n",
      "[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n",
      "[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 40, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n",
      "[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n",
      "[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n",
      "[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n",
      "[37]\ttraining's l2: 0.190437\n",
      "[38]\ttraining's l2: 0.190029\n",
      "[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n",
      "[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n",
      "[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089",
      "\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 40, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647",
      "\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n",
      "[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[120, 40, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n",
      "[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n",
      "[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n",
      "[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n",
      "[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n",
      "[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n",
      "[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n",
      "[107]\ttraining's l2: 0.168264\n",
      "[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n",
      "[110]\ttraining's l2: 0.167556\n[111]\ttraining's l2: 0.167161\n",
      "[112]\ttraining's l2: 0.166733\n[113]\ttraining's l2: 0.166542\n[114]\ttraining's l2: 0.166353\n[115]\ttraining's l2: 0.166176\n",
      "[116]\ttraining's l2: 0.165974\n[117]\ttraining's l2: 0.165743\n[118]\ttraining's l2: 0.165413\n[119]\ttraining's l2: 0.165127\n[120]\ttraining's l2: 0.164968\nDid not meet early stopping. Best iteration is:\n[120]\ttraining's l2: 0.164968\n",
      "[110, 10, -0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783",
      "\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925",
      "\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 10, 0.3]\n[1]\ttraining's l2: 0.238768\n",
      "Training until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n",
      "[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n",
      "[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n",
      "[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n",
      "[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n",
      "[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n",
      "[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n",
      "[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n",
      "[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n",
      "[96]\ttraining's l2: 0.170771\n",
      "[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 10, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n",
      "[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n",
      "[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n",
      "[59]\ttraining's l2: 0.181686\n",
      "[60]\ttraining's l2: 0.181465\n",
      "[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n",
      "[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n",
      "[69]\ttraining's l2: 0.178727\n",
      "[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686",
      "\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n",
      "[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n",
      "[105]\ttraining's l2: 0.168566\n",
      "[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n",
      "[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 10, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n",
      "[7]\ttraining's l2: 0.217214\n",
      "[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n",
      "[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n",
      "[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n",
      "[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n",
      "[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n",
      "[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n",
      "[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n",
      "[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n",
      "[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 10, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017",
      "\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n",
      "[89]\ttraining's l2: 0.172248\n",
      "[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n",
      "[97]\ttraining's l2: 0.170518\n",
      "[98]\ttraining's l2: 0.17023\n",
      "[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n",
      "[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 50, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n",
      "[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n",
      "[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n",
      "[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n",
      "[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n",
      "[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 50, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n",
      "[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n",
      "[72]\ttraining's l2: 0.177806\n",
      "[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114",
      "\n",
      "[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n",
      "[102]\ttraining's l2: 0.169244\n",
      "[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n",
      "[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 50, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n",
      "[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133",
      "\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n",
      "[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114",
      "\n",
      "[95]\ttraining's l2: 0.170948\n",
      "[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n",
      "[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 50, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n",
      "[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n",
      "[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214",
      "\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n",
      "[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049",
      "\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n[110, 50, 0.2]",
      "\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 50 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n",
      "[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n",
      "[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n",
      "[98]\ttraining's l2: 0.17023\n",
      "[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 30, -0.3]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n",
      "[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n",
      "[16]\ttraining's l2: 0.204348\n",
      "[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n",
      "[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n",
      "[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n",
      "[68]\ttraining's l2: 0.179059\n",
      "[69]\ttraining's l2: 0.178727\n",
      "[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686",
      "\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712",
      "\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n[110, 30, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n",
      "[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 30, 0.0]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n",
      "[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n",
      "[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n",
      "[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n",
      "[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n",
      "[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n",
      "[99]\ttraining's l2: 0.169997\n",
      "[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n",
      "[107]\ttraining's l2: 0.168264\n",
      "[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n[110, 30, 0.15]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976",
      "\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 30, 0.2]\n[1]\ttraining's l2: 0.238768\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n",
      "[13]\ttraining's l2: 0.207734\n",
      "[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n",
      "[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533",
      "\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688",
      "\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 40, -0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n",
      "[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n",
      "[81]\ttraining's l2: 0.174976\n",
      "[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437",
      "\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 40, 0.3]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n",
      "[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n",
      "[10]\ttraining's l2: 0.211783\n",
      "[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n",
      "[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n",
      "[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 40, 0.0]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n",
      "[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n",
      "[27]\ttraining's l2: 0.195571\n",
      "[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n",
      "[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686",
      "\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n",
      "[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n",
      "[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804",
      "\n[76]\ttraining's l2: 0.176555\n",
      "[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099",
      "\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 40, 0.15]\n[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n",
      "[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531",
      "\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943",
      "\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "[110, 40, 0.2]\n",
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 40 rounds\n[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231",
      "\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832\n[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n",
      "[56]\ttraining's l2: 0.182831\n",
      "[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n",
      "[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106",
      "\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n",
      "[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n",
      "[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\n[101]\ttraining's l2: 0.169457\n[102]\ttraining's l2: 0.169244\n[103]\ttraining's l2: 0.169107\n[104]\ttraining's l2: 0.168917\n[105]\ttraining's l2: 0.168566\n[106]\ttraining's l2: 0.16845\n[107]\ttraining's l2: 0.168264\n[108]\ttraining's l2: 0.167943\n[109]\ttraining's l2: 0.16776\n[110]\ttraining's l2: 0.167556\nDid not meet early stopping. Best iteration is:\n[110]\ttraining's l2: 0.167556\n",
      "maximo 0.652300524170064 parametros (num_boost_round,early_stopping_rounds,desviacion) [110, 40, 0.2]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#los rangos se van afinando segun corren las pruevas\n",
    "def busqueda_de_hiperparametros_optimos_LightGBM_busqueda_binaria():\n",
    "    parametros_num_boost_round = list(range(50,151,10))\n",
    "    parametros_early_stopping_rounds = list(range(10,51,10))\n",
    "    parametrosDesviacion = list(range(-30,31,5))\n",
    "    for i in range(len(parametrosDesviacion)):\n",
    "        parametrosDesviacion[i] /= 100\n",
    "    listaDeParametros = [parametros_num_boost_round,parametros_early_stopping_rounds,\n",
    "                         parametrosDesviacion]\n",
    "    maximo,parametros =busqueda_binaria_de_maximos(listaDeParametros,\n",
    "                                                   [0,0,0],\n",
    "                                                   0,\n",
    "                                                   ultimo_Hiper_Parametro_LigthBM)\n",
    "    print(\"maximo {} parametros (num_boost_round,early_stopping_rounds,desviacion) {}\".format(maximo,parametros))\n",
    "busqueda_de_hiperparametros_optimos_LightGBM_busqueda_binaria()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XezKFIi1QKnL",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1597094581122,
     "user_tz": 180,
     "elapsed": 1412,
     "user": {
      "displayName": "Francisco Nasif",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWM7nf1fhF4aYsCcMLGLOf4Is_wBSS-mO5ylX-=s64",
      "userId": "16587794859851209437"
     }
    },
    "outputId": "2fbe7c9b-e04f-4c35-c222-7928881d534f",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "\n",
    "lgb_train = lgb.Dataset(train_set, train_label)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets = lgb_train,\n",
    "                num_boost_round=100,\n",
    "                early_stopping_rounds=10)"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1]\ttraining's l2: 0.238768\nTraining until validation scores don't improve for 10 rounds\n",
      "[2]\ttraining's l2: 0.233647\n[3]\ttraining's l2: 0.229373\n[4]\ttraining's l2: 0.225705\n[5]\ttraining's l2: 0.222512\n[6]\ttraining's l2: 0.219768\n[7]\ttraining's l2: 0.217214\n[8]\ttraining's l2: 0.21515\n[9]\ttraining's l2: 0.213287\n[10]\ttraining's l2: 0.211783\n[11]\ttraining's l2: 0.210319\n[12]\ttraining's l2: 0.209019\n[13]\ttraining's l2: 0.207734\n[14]\ttraining's l2: 0.206537\n[15]\ttraining's l2: 0.205388\n[16]\ttraining's l2: 0.204348\n[17]\ttraining's l2: 0.203463\n[18]\ttraining's l2: 0.202426\n[19]\ttraining's l2: 0.201533\n[20]\ttraining's l2: 0.200697\n[21]\ttraining's l2: 0.199798\n[22]\ttraining's l2: 0.19898\n[23]\ttraining's l2: 0.198141\n[24]\ttraining's l2: 0.197363\n[25]\ttraining's l2: 0.196771\n[26]\ttraining's l2: 0.196098\n[27]\ttraining's l2: 0.195571\n[28]\ttraining's l2: 0.195012\n[29]\ttraining's l2: 0.194231\n[30]\ttraining's l2: 0.193688\n[31]\ttraining's l2: 0.193103\n[32]\ttraining's l2: 0.192728\n[33]\ttraining's l2: 0.192172\n[34]\ttraining's l2: 0.191795\n[35]\ttraining's l2: 0.191211\n[36]\ttraining's l2: 0.190745\n[37]\ttraining's l2: 0.190437\n[38]\ttraining's l2: 0.190029\n[39]\ttraining's l2: 0.189531\n[40]\ttraining's l2: 0.189106\n[41]\ttraining's l2: 0.188798\n[42]\ttraining's l2: 0.188434\n[43]\ttraining's l2: 0.188025\n[44]\ttraining's l2: 0.187521\n[45]\ttraining's l2: 0.187133\n[46]\ttraining's l2: 0.186876\n[47]\ttraining's l2: 0.186434\n[48]\ttraining's l2: 0.185963\n[49]\ttraining's l2: 0.185578\n[50]\ttraining's l2: 0.185219\n[51]\ttraining's l2: 0.184832",
      "\n",
      "[52]\ttraining's l2: 0.184527\n[53]\ttraining's l2: 0.184017\n[54]\ttraining's l2: 0.183541\n[55]\ttraining's l2: 0.183238\n[56]\ttraining's l2: 0.182831\n[57]\ttraining's l2: 0.182412\n[58]\ttraining's l2: 0.182009\n[59]\ttraining's l2: 0.181686\n[60]\ttraining's l2: 0.181465\n[61]\ttraining's l2: 0.181106\n[62]\ttraining's l2: 0.180892\n[63]\ttraining's l2: 0.180568\n[64]\ttraining's l2: 0.180304\n[65]\ttraining's l2: 0.180049\n[66]\ttraining's l2: 0.179539\n[67]\ttraining's l2: 0.179241\n[68]\ttraining's l2: 0.179059\n[69]\ttraining's l2: 0.178727\n[70]\ttraining's l2: 0.178431\n[71]\ttraining's l2: 0.178081\n[72]\ttraining's l2: 0.177806\n[73]\ttraining's l2: 0.177496\n[74]\ttraining's l2: 0.177011\n[75]\ttraining's l2: 0.176804\n[76]\ttraining's l2: 0.176555\n[77]\ttraining's l2: 0.176223\n[78]\ttraining's l2: 0.175925\n[79]\ttraining's l2: 0.175717\n[80]\ttraining's l2: 0.175476\n[81]\ttraining's l2: 0.174976\n[82]\ttraining's l2: 0.174705\n[83]\ttraining's l2: 0.17437\n[84]\ttraining's l2: 0.174071\n[85]\ttraining's l2: 0.17367\n[86]\ttraining's l2: 0.17347\n[87]\ttraining's l2: 0.173099\n[88]\ttraining's l2: 0.172686\n[89]\ttraining's l2: 0.172248\n[90]\ttraining's l2: 0.172089\n[91]\ttraining's l2: 0.171872\n[92]\ttraining's l2: 0.171686\n[93]\ttraining's l2: 0.171476\n[94]\ttraining's l2: 0.17114\n[95]\ttraining's l2: 0.170948\n[96]\ttraining's l2: 0.170771\n",
      "[97]\ttraining's l2: 0.170518\n[98]\ttraining's l2: 0.17023\n[99]\ttraining's l2: 0.169997\n[100]\ttraining's l2: 0.169712\nDid not meet early stopping. Best iteration is:\n[100]\ttraining's l2: 0.169712\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OQpRsMzXQOce",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1597094587358,
     "user_tz": 180,
     "elapsed": 1122,
     "user": {
      "displayName": "Francisco Nasif",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWM7nf1fhF4aYsCcMLGLOf4Is_wBSS-mO5ylX-=s64",
      "userId": "16587794859851209437"
     }
    },
    "outputId": "9f7bfda6-2f53-4882-d5ff-3a61447bd3ae",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "preds = gbm.predict(test_set, num_iteration=gbm.best_iteration)\n",
    "result = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "preds += 0.2\n",
    "preds = preds.round()\n",
    "result['target'] = preds\n",
    "print(F1(result))"
   ],
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.64317880794702\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUnKGaHyP4ay",
    "colab_type": "text"
   },
   "source": [
    "## ENTREGA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "9uN3-BEWP4az",
    "colab_type": "code",
    "colab": {},
    "outputId": "bd8527a8-8e07-409f-b3be-753d3eccca46"
   },
   "source": [
    "resultado_final = result#varia segun el metodo\n",
    "#resultado_final.columns = ['id','target']\n",
    "#resultado_final.reset_index()\n",
    "resultado_final.head()"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "                 target\nid                     \n0                  1.00\n2                  1.00\n3                  1.00\n9                  1.00\n11                 1.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 74
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    },
    "id": "Qjeva8FpP4a4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#cuando todo termina el archivo de entrega\n",
    "resultado_final.to_csv('submit.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}