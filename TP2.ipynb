{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 75.06/95.58 Organización de Datos\n",
    "# Primer Cuatrimestre de 2020\n",
    "# Trabajo Práctico 2: Enunciado\n",
    "\n",
    "\n",
    "El segundo TP es una competencia de Machine Learning en donde cada grupo debe intentar determinar, para cada tweet brindado, si el mismo esta basado en un hecho real o no.\n",
    "\n",
    "La competencia se desarrolla en la plataforma de Kaggle  https://www.kaggle.com/c/nlp-getting-started.  \n",
    "\n",
    "El dataset consta de una serie de tweets, para los cuales se informa:\n",
    "\n",
    "- id - identificador unico para cada  tweet\n",
    "- text - el texto del tweet\n",
    "- location - ubicación desde donde fue enviado (podría no estar)\n",
    "- keyword - un keyword para el tweet  (podría faltar)\n",
    "- target - en train.csv, indica si se trata de un desastre real  (1) o no (0)\n",
    " \n",
    "\n",
    "\n",
    "Los submits con el resultado deben tener el formato:\n",
    "\n",
    "Id: Un id numérico para identificar el tweet\n",
    "target: 1 / 0 según se crea que el tweet se trata sobre un desastre real, o no.\n",
    "\n",
    "Los grupos deberán probar distintos algoritmos de Machine Learning para intentar predecir si el tweet está basado en hechos reales o no. A medida que los grupos realicen pruebas deben realizar el correspondiente submit en Kaggle para evaluar el resultado de los mismos.\n",
    "\n",
    "Al finalizar la competencia el grupo que mejor resultado tenga obtendrá 10 puntos para cada uno de sus integrantes que podrán ser usados en el examen por promoción o segundo recuperatorio.\n",
    "\n",
    "## Requisitos para la entrega del TP2:\n",
    "\n",
    "- El TP debe programarse en Python o R.\n",
    "- Debe entregarse un pdf con el informe de algoritmos probados, algoritmo final utilizado, transformaciones realizadas a los datos, feature engineering, etc. \n",
    "- El informe debe incluir también un link a github con el informe presentado en pdf, y todo el código.\n",
    "- El grupo debe presentar el TP en una computadora en la fecha indicada por la cátedra, el TP debe correr en un lapso de tiempo razonable (inferior a 1 hora) y generar un submission válido que iguale el mejor resultado obtenido por el grupo en Kaggle. (mas detalles a definir)\n",
    "\n",
    "## El TP2 se va a evaluar en función del siguiente criterio:\n",
    "\n",
    "- Cantidad de trabajo (esfuerzo) del grupo: ¿Probaron muchos algoritmos? ¿Hicieron un buen trabajo de pre-procesamiento de los datos y feature engineering?\n",
    "- Resultado obtenido en Kaggle (obviamente cuanto mejor resultado mejor nota)\n",
    "- Presentación final del informe, calidad de la redacción, uso de información obtenida en el TP1, conclusiones presentadas.\n",
    "- Performance de la solución final."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forma de evaluar kaggle\n",
    "\n",
    "Las presentaciones se evalúan utilizando F1 entre las respuestas previstas y esperadas.\n",
    "\n",
    "F1 se calcula de la siguiente manera:\n",
    "$ F1=(2∗precision∗recall)/(precision+recall) $\n",
    "\n",
    "donde:\n",
    "\n",
    "$precision=TP/(TP+FP)$\n",
    "\n",
    "$recall=TP/(TP+FN)$\n",
    "\n",
    "\n",
    "con:\n",
    "\n",
    "- Verdadero positivo [TP] = your prediction is 1, and the ground truth is also 1 - you predicted a positive and that's true!\n",
    "- Falso positivo [FP] = your prediction is 1, and the ground truth is 0 - you predicted a positive, and that's false.\n",
    "- Falso Negativo [FN] = your prediction is 0, and the ground truth is 1 - you predicted a negative, and that's false."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "importaciones"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#plt.style.use('default')\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    " \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    " \n",
    "#librerias para KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#red neuronal\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "#arboles de decicion\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "#catboost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "#palabras\n",
    "import nltk\n",
    "#nltk.download('stopwords')#si no tiene stopword habilitar esta linea\n",
    "from nltk.corpus import stopwords\n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "#tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "stopwordEnglis = stopwords.words('english')\n",
    "tfidf = TfidfVectorizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "inicio de csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tweets_original_entrenamiento = pd.read_csv('train.csv',index_col=['id'])\n",
    "tweets_original_entrenamiento.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword location                                               text  target\nid                                                                            \n1      NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n4      NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n5      NaN      NaN  All residents asked to 'shelter in place' are ...       1\n6      NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n7      NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword location                                               text\nid                                                                    \n0      NaN      NaN                 Just happened a terrible car crash\n2      NaN      NaN  Heard about #earthquake is different cities, s...\n3      NaN      NaN  there is a forest fire at spot pond, geese are...\n9      NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 32
    }
   ],
   "source": [
    "tweets_original_prueva = pd.read_csv('test.csv',index_col=['id'])\n",
    "tweets_original_prueva.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "calculo resultado"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "resultados_de_test = pd.read_csv('sample_submission.csv',index_col=['id'])\n",
    "\n",
    "def calclarPresicionYRecall(df):\n",
    "    df['TP'] = (df['target'] and resultados_de_test['target'])\n",
    "    df['FP'] = ((not df['target']) and resultados_de_test['target'])\n",
    "    df['FN'] = (df['target'] and (not resultados_de_test['target']))\n",
    "    tp = df['TP'].sum\n",
    "    fp = df['FP'].sum\n",
    "    fn = df['FM'].sum\n",
    "    presicion = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return (presicion,recall)\n",
    "\n",
    "def F1(df):\n",
    "    presicion,recall = calclarPresicionYRecall(df)\n",
    "    resultado = 2 * presicion * recall\n",
    "    resultado /= (presicion + recall)\n",
    "    return resultado"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "inicio de problema"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CATBOOST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def preparar_df(df):\n",
    "    df['text'].fillna(\"\", inplace=True)\n",
    "    df['keyword'].fillna(\"\", inplace=True)\n",
    "    df['location'].fillna(\"\", inplace=True)\n",
    "    \n",
    "    df['longitud_de_texto'] = df['text'].str.len()\n",
    "    df['longitud_de_keyword'] = df['keyword'].str.len()\n",
    "    \n",
    "    df['palabras_de_texto'] = df['text'].str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    df['palabras_de_keyword'] = df['text'].str.split().apply(lambda x: [item for item in x if item not in stopwordEnglis])\n",
    "    \n",
    "    df['cantidad_de_palabras_texto'] = df['palabras_de_texto'].map(len)\n",
    "    df['cantidad_de_palabras_keyword'] = df['palabras_de_keyword'].map(len)\n",
    "    \n",
    "    #df['text'] = df['text'].str.replace(r' ', '')\n",
    "    #df['keyword'] = df['keyword'].str.replace(r' ', '')\n",
    "    #df['location'] = df['location'].str.replace(r' ', '')\n",
    "    \n",
    "    #x = tfidf.fit_transform(df['text'])\n",
    "    #df_tfidf = pd.DataFrame(x.toarray(), columns=tfidf.get_feature_names())\n",
    "    #df.join(df_tfidf)#mal planteado\n",
    "    \n",
    "    df = df.drop(columns=['keyword','text','location'])\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-3f33282461dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_original_entrenamiento\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_original_entrenamiento\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreparar_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-712f4e80908e>\u001b[0m in \u001b[0;36mpreparar_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdf_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Index' object is not callable"
     ],
     "ename": "TypeError",
     "evalue": "'Index' object is not callable",
     "output_type": "error"
    }
   ],
   "source": [
    "train_label = tweets_original_entrenamiento['target']\n",
    "train_set = tweets_original_entrenamiento.drop(columns=['target'])\n",
    "train_set = preparar_df(train_set)\n",
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "    longitud_de_texto  longitud_de_keyword  \\\nid                                           \n0                  34                    0   \n2                  64                    0   \n3                  96                    0   \n9                  40                    0   \n11                 45                    0   \n\n                                    palabras_de_texto  \\\nid                                                      \n0              [Just, happened, terrible, car, crash]   \n2   [Heard, #earthquake, different, cities,, stay,...   \n3   [forest, fire, spot, pond,, geese, fleeing, ac...   \n9       [Apocalypse, lighting., #Spokane, #wildfires]   \n11      [Typhoon, Soudelor, kills, 28, China, Taiwan]   \n\n                                  palabras_de_keyword  \\\nid                                                      \n0              [Just, happened, terrible, car, crash]   \n2   [Heard, #earthquake, different, cities,, stay,...   \n3   [forest, fire, spot, pond,, geese, fleeing, ac...   \n9       [Apocalypse, lighting., #Spokane, #wildfires]   \n11      [Typhoon, Soudelor, kills, 28, China, Taiwan]   \n\n    cantidad_de_palabras_texto  cantidad_de_palabras_keyword  \nid                                                            \n0                            5                             5  \n2                            7                             7  \n3                           11                            11  \n9                            4                             4  \n11                           6                             6  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitud_de_texto</th>\n      <th>longitud_de_keyword</th>\n      <th>palabras_de_texto</th>\n      <th>palabras_de_keyword</th>\n      <th>cantidad_de_palabras_texto</th>\n      <th>cantidad_de_palabras_keyword</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>0</td>\n      <td>[Just, happened, terrible, car, crash]</td>\n      <td>[Just, happened, terrible, car, crash]</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>64</td>\n      <td>0</td>\n      <td>[Heard, #earthquake, different, cities,, stay,...</td>\n      <td>[Heard, #earthquake, different, cities,, stay,...</td>\n      <td>7</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96</td>\n      <td>0</td>\n      <td>[forest, fire, spot, pond,, geese, fleeing, ac...</td>\n      <td>[forest, fire, spot, pond,, geese, fleeing, ac...</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>40</td>\n      <td>0</td>\n      <td>[Apocalypse, lighting., #Spokane, #wildfires]</td>\n      <td>[Apocalypse, lighting., #Spokane, #wildfires]</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>45</td>\n      <td>0</td>\n      <td>[Typhoon, Soudelor, kills, 28, China, Taiwan]</td>\n      <td>[Typhoon, Soudelor, kills, 28, China, Taiwan]</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 35
    }
   ],
   "source": [
    "test_set = tweets_original_prueva\n",
    "test_set = preparar_df(test_set)\n",
    "test_set.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 0.4868874\ttotal: 74.7ms\tremaining: 299ms\n1:\tlearn: 0.4823555\ttotal: 76.5ms\tremaining: 115ms\n2:\tlearn: 0.4795201\ttotal: 78ms\tremaining: 52ms\n3:\tlearn: 0.4767718\ttotal: 79.4ms\tremaining: 19.9ms\n4:\tlearn: 0.4750395\ttotal: 81ms\tremaining: 0us\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#revisar hiperparametros\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=5,\n",
    "                          learning_rate=0.3,\n",
    "                          depth=3)\n",
    "# Fit model\n",
    "model.fit(train_set, train_label)\n",
    "# Get predictions\n",
    "predicion = model.predict(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "                target  id\n0                 0.00   0\n1                 1.00   2\n2                 1.00   3\n3                 0.00   9\n4                 0.00  11",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.00</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.00</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    }
   ],
   "source": [
    "#resultado\n",
    "solucionCatBoost =pd.DataFrame(data=predicion)\n",
    "solucionCatBoost.columns = ['target']\n",
    "#solucionCatBoost['id'] = test_set.reset_index()['id']\n",
    "solucionCatBoost['target'] = solucionCatBoost['target'].round()\n",
    "#solucionCatBoost.set_index(['id'])\n",
    "solucionCatBoost.head()\n",
    "#resultado = F1(solucionCatBoost)\n",
    "#print(resultado)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ARBOL DE DECISION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#para arbol verificar si esta balanceado o no\n",
    "train_set.groupby([\"target\"]).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}